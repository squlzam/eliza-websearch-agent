{"version":3,"sources":["../../../node_modules/event-target-shim/src/event.mjs","../../../node_modules/event-target-shim/src/event-target.mjs","../../../node_modules/abort-controller/src/abort-signal.ts","../../../node_modules/abort-controller/src/abort-controller.ts","../../../node_modules/deepmerge/dist/cjs.js","../src/services/browser.ts","../src/services/image.ts","../src/services/llama.ts","../src/services/pdf.ts","../src/services/speech.ts","../src/services/audioUtils.ts","../src/environment.ts","../src/services/transcription.ts","../../../node_modules/openai/src/internal/qs/formats.ts","../../../node_modules/openai/src/internal/qs/utils.ts","../../../node_modules/openai/src/internal/qs/stringify.ts","../../../node_modules/openai/src/version.ts","../../../node_modules/openai/src/_shims/registry.ts","../../../node_modules/openai/src/_shims/node-runtime.ts","../../../node_modules/form-data-encoder/lib/esm/util/createBoundary.js","../../../node_modules/form-data-encoder/lib/esm/util/isPlainObject.js","../../../node_modules/form-data-encoder/lib/esm/util/normalizeValue.js","../../../node_modules/form-data-encoder/lib/esm/util/escapeName.js","../../../node_modules/form-data-encoder/lib/esm/util/isFunction.js","../../../node_modules/form-data-encoder/lib/esm/util/isFileLike.js","../../../node_modules/form-data-encoder/lib/esm/util/isFormData.js","../../../node_modules/form-data-encoder/lib/esm/FormDataEncoder.js","../../../node_modules/openai/src/_shims/MultipartBody.ts","../../../node_modules/openai/_shims/index.mjs","../../../node_modules/openai/src/error.ts","../../../node_modules/openai/src/internal/decoders/line.ts","../../../node_modules/openai/src/streaming.ts","../../../node_modules/openai/src/uploads.ts","../../../node_modules/openai/src/core.ts","../../../node_modules/openai/src/pagination.ts","../../../node_modules/openai/src/resource.ts","../../../node_modules/openai/src/resources/chat/completions.ts","../../../node_modules/openai/src/resources/chat/chat.ts","../../../node_modules/openai/src/resources/audio/speech.ts","../../../node_modules/openai/src/resources/audio/transcriptions.ts","../../../node_modules/openai/src/resources/audio/translations.ts","../../../node_modules/openai/src/resources/audio/audio.ts","../../../node_modules/openai/src/resources/batches.ts","../../../node_modules/openai/src/resources/beta/assistants.ts","../../../node_modules/openai/src/lib/RunnableFunction.ts","../../../node_modules/openai/src/lib/chatCompletionUtils.ts","../../../node_modules/openai/src/lib/EventStream.ts","../../../node_modules/openai/src/lib/parser.ts","../../../node_modules/openai/src/lib/AbstractChatCompletionRunner.ts","../../../node_modules/openai/src/lib/ChatCompletionRunner.ts","../../../node_modules/openai/src/_vendor/partial-json-parser/parser.ts","../../../node_modules/openai/src/lib/ChatCompletionStream.ts","../../../node_modules/openai/src/lib/ChatCompletionStreamingRunner.ts","../../../node_modules/openai/src/resources/beta/chat/completions.ts","../../../node_modules/openai/src/resources/beta/chat/chat.ts","../../../node_modules/openai/src/lib/AssistantStream.ts","../../../node_modules/openai/src/resources/beta/threads/messages.ts","../../../node_modules/openai/src/resources/beta/threads/runs/steps.ts","../../../node_modules/openai/src/resources/beta/threads/runs/runs.ts","../../../node_modules/openai/src/resources/beta/threads/threads.ts","../../../node_modules/openai/src/lib/Util.ts","../../../node_modules/openai/src/resources/beta/vector-stores/files.ts","../../../node_modules/openai/src/resources/beta/vector-stores/file-batches.ts","../../../node_modules/openai/src/resources/beta/vector-stores/vector-stores.ts","../../../node_modules/openai/src/resources/beta/beta.ts","../../../node_modules/openai/src/resources/completions.ts","../../../node_modules/openai/src/resources/embeddings.ts","../../../node_modules/openai/src/resources/files.ts","../../../node_modules/openai/src/resources/fine-tuning/jobs/checkpoints.ts","../../../node_modules/openai/src/resources/fine-tuning/jobs/jobs.ts","../../../node_modules/openai/src/resources/fine-tuning/fine-tuning.ts","../../../node_modules/openai/src/resources/images.ts","../../../node_modules/openai/src/resources/models.ts","../../../node_modules/openai/src/resources/moderations.ts","../../../node_modules/openai/src/resources/uploads/parts.ts","../../../node_modules/openai/src/resources/uploads/uploads.ts","../../../node_modules/openai/src/index.ts","../../../node_modules/@deepgram/sdk/src/lib/errors.ts","../../../node_modules/@deepgram/sdk/src/packages/AbstractClient.ts","../../../node_modules/@deepgram/sdk/src/lib/helpers.ts","../../../node_modules/@deepgram/sdk/src/lib/version.ts","../../../node_modules/@deepgram/sdk/src/lib/constants.ts","../../../node_modules/@deepgram/sdk/src/packages/AbstractLiveClient.ts","../../../node_modules/@deepgram/sdk/src/lib/fetch.ts","../../../node_modules/@deepgram/sdk/src/packages/AbstractRestClient.ts","../../../node_modules/@deepgram/sdk/src/lib/enums/LiveTranscriptionEvents.ts","../../../node_modules/@deepgram/sdk/src/lib/enums/LiveTTSEvents.ts","../../../node_modules/@deepgram/sdk/src/packages/ListenLiveClient.ts","../../../node_modules/@deepgram/sdk/src/packages/ListenRestClient.ts","../../../node_modules/@deepgram/sdk/src/packages/ListenClient.ts","../../../node_modules/@deepgram/sdk/src/packages/ManageRestClient.ts","../../../node_modules/@deepgram/sdk/src/packages/ModelsRestClient.ts","../../../node_modules/@deepgram/sdk/src/packages/ReadRestClient.ts","../../../node_modules/@deepgram/sdk/src/packages/SelfHostedRestClient.ts","../../../node_modules/@deepgram/sdk/src/packages/SpeakLiveClient.ts","../../../node_modules/@deepgram/sdk/src/packages/SpeakRestClient.ts","../../../node_modules/@deepgram/sdk/src/packages/SpeakClient.ts","../../../node_modules/@deepgram/sdk/src/DeepgramClient.ts","../../../node_modules/@deepgram/sdk/src/index.ts","../src/services/video.ts","../src/services/awsS3.ts","../src/actions/describe-image.ts","../src/templates.ts","../src/types.ts","../src/index.ts"],"sourcesContent":["/**\n * @typedef {object} PrivateData\n * @property {EventTarget} eventTarget The event target.\n * @property {{type:string}} event The original event object.\n * @property {number} eventPhase The current event phase.\n * @property {EventTarget|null} currentTarget The current event target.\n * @property {boolean} canceled The flag to prevent default.\n * @property {boolean} stopped The flag to stop propagation.\n * @property {boolean} immediateStopped The flag to stop propagation immediately.\n * @property {Function|null} passiveListener The listener if the current listener is passive. Otherwise this is null.\n * @property {number} timeStamp The unix time.\n * @private\n */\n\n/**\n * Private data for event wrappers.\n * @type {WeakMap<Event, PrivateData>}\n * @private\n */\nconst privateData = new WeakMap()\n\n/**\n * Cache for wrapper classes.\n * @type {WeakMap<Object, Function>}\n * @private\n */\nconst wrappers = new WeakMap()\n\n/**\n * Get private data.\n * @param {Event} event The event object to get private data.\n * @returns {PrivateData} The private data of the event.\n * @private\n */\nfunction pd(event) {\n    const retv = privateData.get(event)\n    console.assert(\n        retv != null,\n        \"'this' is expected an Event object, but got\",\n        event\n    )\n    return retv\n}\n\n/**\n * https://dom.spec.whatwg.org/#set-the-canceled-flag\n * @param data {PrivateData} private data.\n */\nfunction setCancelFlag(data) {\n    if (data.passiveListener != null) {\n        if (\n            typeof console !== \"undefined\" &&\n            typeof console.error === \"function\"\n        ) {\n            console.error(\n                \"Unable to preventDefault inside passive event listener invocation.\",\n                data.passiveListener\n            )\n        }\n        return\n    }\n    if (!data.event.cancelable) {\n        return\n    }\n\n    data.canceled = true\n    if (typeof data.event.preventDefault === \"function\") {\n        data.event.preventDefault()\n    }\n}\n\n/**\n * @see https://dom.spec.whatwg.org/#interface-event\n * @private\n */\n/**\n * The event wrapper.\n * @constructor\n * @param {EventTarget} eventTarget The event target of this dispatching.\n * @param {Event|{type:string}} event The original event to wrap.\n */\nfunction Event(eventTarget, event) {\n    privateData.set(this, {\n        eventTarget,\n        event,\n        eventPhase: 2,\n        currentTarget: eventTarget,\n        canceled: false,\n        stopped: false,\n        immediateStopped: false,\n        passiveListener: null,\n        timeStamp: event.timeStamp || Date.now(),\n    })\n\n    // https://heycam.github.io/webidl/#Unforgeable\n    Object.defineProperty(this, \"isTrusted\", { value: false, enumerable: true })\n\n    // Define accessors\n    const keys = Object.keys(event)\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i]\n        if (!(key in this)) {\n            Object.defineProperty(this, key, defineRedirectDescriptor(key))\n        }\n    }\n}\n\n// Should be enumerable, but class methods are not enumerable.\nEvent.prototype = {\n    /**\n     * The type of this event.\n     * @type {string}\n     */\n    get type() {\n        return pd(this).event.type\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     */\n    get target() {\n        return pd(this).eventTarget\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     */\n    get currentTarget() {\n        return pd(this).currentTarget\n    },\n\n    /**\n     * @returns {EventTarget[]} The composed path of this event.\n     */\n    composedPath() {\n        const currentTarget = pd(this).currentTarget\n        if (currentTarget == null) {\n            return []\n        }\n        return [currentTarget]\n    },\n\n    /**\n     * Constant of NONE.\n     * @type {number}\n     */\n    get NONE() {\n        return 0\n    },\n\n    /**\n     * Constant of CAPTURING_PHASE.\n     * @type {number}\n     */\n    get CAPTURING_PHASE() {\n        return 1\n    },\n\n    /**\n     * Constant of AT_TARGET.\n     * @type {number}\n     */\n    get AT_TARGET() {\n        return 2\n    },\n\n    /**\n     * Constant of BUBBLING_PHASE.\n     * @type {number}\n     */\n    get BUBBLING_PHASE() {\n        return 3\n    },\n\n    /**\n     * The target of this event.\n     * @type {number}\n     */\n    get eventPhase() {\n        return pd(this).eventPhase\n    },\n\n    /**\n     * Stop event bubbling.\n     * @returns {void}\n     */\n    stopPropagation() {\n        const data = pd(this)\n\n        data.stopped = true\n        if (typeof data.event.stopPropagation === \"function\") {\n            data.event.stopPropagation()\n        }\n    },\n\n    /**\n     * Stop event bubbling.\n     * @returns {void}\n     */\n    stopImmediatePropagation() {\n        const data = pd(this)\n\n        data.stopped = true\n        data.immediateStopped = true\n        if (typeof data.event.stopImmediatePropagation === \"function\") {\n            data.event.stopImmediatePropagation()\n        }\n    },\n\n    /**\n     * The flag to be bubbling.\n     * @type {boolean}\n     */\n    get bubbles() {\n        return Boolean(pd(this).event.bubbles)\n    },\n\n    /**\n     * The flag to be cancelable.\n     * @type {boolean}\n     */\n    get cancelable() {\n        return Boolean(pd(this).event.cancelable)\n    },\n\n    /**\n     * Cancel this event.\n     * @returns {void}\n     */\n    preventDefault() {\n        setCancelFlag(pd(this))\n    },\n\n    /**\n     * The flag to indicate cancellation state.\n     * @type {boolean}\n     */\n    get defaultPrevented() {\n        return pd(this).canceled\n    },\n\n    /**\n     * The flag to be composed.\n     * @type {boolean}\n     */\n    get composed() {\n        return Boolean(pd(this).event.composed)\n    },\n\n    /**\n     * The unix time of this event.\n     * @type {number}\n     */\n    get timeStamp() {\n        return pd(this).timeStamp\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     * @deprecated\n     */\n    get srcElement() {\n        return pd(this).eventTarget\n    },\n\n    /**\n     * The flag to stop event bubbling.\n     * @type {boolean}\n     * @deprecated\n     */\n    get cancelBubble() {\n        return pd(this).stopped\n    },\n    set cancelBubble(value) {\n        if (!value) {\n            return\n        }\n        const data = pd(this)\n\n        data.stopped = true\n        if (typeof data.event.cancelBubble === \"boolean\") {\n            data.event.cancelBubble = true\n        }\n    },\n\n    /**\n     * The flag to indicate cancellation state.\n     * @type {boolean}\n     * @deprecated\n     */\n    get returnValue() {\n        return !pd(this).canceled\n    },\n    set returnValue(value) {\n        if (!value) {\n            setCancelFlag(pd(this))\n        }\n    },\n\n    /**\n     * Initialize this event object. But do nothing under event dispatching.\n     * @param {string} type The event type.\n     * @param {boolean} [bubbles=false] The flag to be possible to bubble up.\n     * @param {boolean} [cancelable=false] The flag to be possible to cancel.\n     * @deprecated\n     */\n    initEvent() {\n        // Do nothing.\n    },\n}\n\n// `constructor` is not enumerable.\nObject.defineProperty(Event.prototype, \"constructor\", {\n    value: Event,\n    configurable: true,\n    writable: true,\n})\n\n// Ensure `event instanceof window.Event` is `true`.\nif (typeof window !== \"undefined\" && typeof window.Event !== \"undefined\") {\n    Object.setPrototypeOf(Event.prototype, window.Event.prototype)\n\n    // Make association for wrappers.\n    wrappers.set(window.Event.prototype, Event)\n}\n\n/**\n * Get the property descriptor to redirect a given property.\n * @param {string} key Property name to define property descriptor.\n * @returns {PropertyDescriptor} The property descriptor to redirect the property.\n * @private\n */\nfunction defineRedirectDescriptor(key) {\n    return {\n        get() {\n            return pd(this).event[key]\n        },\n        set(value) {\n            pd(this).event[key] = value\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Get the property descriptor to call a given method property.\n * @param {string} key Property name to define property descriptor.\n * @returns {PropertyDescriptor} The property descriptor to call the method property.\n * @private\n */\nfunction defineCallDescriptor(key) {\n    return {\n        value() {\n            const event = pd(this).event\n            return event[key].apply(event, arguments)\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Define new wrapper class.\n * @param {Function} BaseEvent The base wrapper class.\n * @param {Object} proto The prototype of the original event.\n * @returns {Function} The defined wrapper class.\n * @private\n */\nfunction defineWrapper(BaseEvent, proto) {\n    const keys = Object.keys(proto)\n    if (keys.length === 0) {\n        return BaseEvent\n    }\n\n    /** CustomEvent */\n    function CustomEvent(eventTarget, event) {\n        BaseEvent.call(this, eventTarget, event)\n    }\n\n    CustomEvent.prototype = Object.create(BaseEvent.prototype, {\n        constructor: { value: CustomEvent, configurable: true, writable: true },\n    })\n\n    // Define accessors.\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i]\n        if (!(key in BaseEvent.prototype)) {\n            const descriptor = Object.getOwnPropertyDescriptor(proto, key)\n            const isFunc = typeof descriptor.value === \"function\"\n            Object.defineProperty(\n                CustomEvent.prototype,\n                key,\n                isFunc\n                    ? defineCallDescriptor(key)\n                    : defineRedirectDescriptor(key)\n            )\n        }\n    }\n\n    return CustomEvent\n}\n\n/**\n * Get the wrapper class of a given prototype.\n * @param {Object} proto The prototype of the original event to get its wrapper.\n * @returns {Function} The wrapper class.\n * @private\n */\nfunction getWrapper(proto) {\n    if (proto == null || proto === Object.prototype) {\n        return Event\n    }\n\n    let wrapper = wrappers.get(proto)\n    if (wrapper == null) {\n        wrapper = defineWrapper(getWrapper(Object.getPrototypeOf(proto)), proto)\n        wrappers.set(proto, wrapper)\n    }\n    return wrapper\n}\n\n/**\n * Wrap a given event to management a dispatching.\n * @param {EventTarget} eventTarget The event target of this dispatching.\n * @param {Object} event The event to wrap.\n * @returns {Event} The wrapper instance.\n * @private\n */\nexport function wrapEvent(eventTarget, event) {\n    const Wrapper = getWrapper(Object.getPrototypeOf(event))\n    return new Wrapper(eventTarget, event)\n}\n\n/**\n * Get the immediateStopped flag of a given event.\n * @param {Event} event The event to get.\n * @returns {boolean} The flag to stop propagation immediately.\n * @private\n */\nexport function isStopped(event) {\n    return pd(event).immediateStopped\n}\n\n/**\n * Set the current event phase of a given event.\n * @param {Event} event The event to set current target.\n * @param {number} eventPhase New event phase.\n * @returns {void}\n * @private\n */\nexport function setEventPhase(event, eventPhase) {\n    pd(event).eventPhase = eventPhase\n}\n\n/**\n * Set the current target of a given event.\n * @param {Event} event The event to set current target.\n * @param {EventTarget|null} currentTarget New current target.\n * @returns {void}\n * @private\n */\nexport function setCurrentTarget(event, currentTarget) {\n    pd(event).currentTarget = currentTarget\n}\n\n/**\n * Set a passive listener of a given event.\n * @param {Event} event The event to set current target.\n * @param {Function|null} passiveListener New passive listener.\n * @returns {void}\n * @private\n */\nexport function setPassiveListener(event, passiveListener) {\n    pd(event).passiveListener = passiveListener\n}\n","import {\n    isStopped,\n    setCurrentTarget,\n    setEventPhase,\n    setPassiveListener,\n    wrapEvent,\n} from \"./event.mjs\"\n\n/**\n * @typedef {object} ListenerNode\n * @property {Function} listener\n * @property {1|2|3} listenerType\n * @property {boolean} passive\n * @property {boolean} once\n * @property {ListenerNode|null} next\n * @private\n */\n\n/**\n * @type {WeakMap<object, Map<string, ListenerNode>>}\n * @private\n */\nconst listenersMap = new WeakMap()\n\n// Listener types\nconst CAPTURE = 1\nconst BUBBLE = 2\nconst ATTRIBUTE = 3\n\n/**\n * Check whether a given value is an object or not.\n * @param {any} x The value to check.\n * @returns {boolean} `true` if the value is an object.\n */\nfunction isObject(x) {\n    return x !== null && typeof x === \"object\" //eslint-disable-line no-restricted-syntax\n}\n\n/**\n * Get listeners.\n * @param {EventTarget} eventTarget The event target to get.\n * @returns {Map<string, ListenerNode>} The listeners.\n * @private\n */\nfunction getListeners(eventTarget) {\n    const listeners = listenersMap.get(eventTarget)\n    if (listeners == null) {\n        throw new TypeError(\n            \"'this' is expected an EventTarget object, but got another value.\"\n        )\n    }\n    return listeners\n}\n\n/**\n * Get the property descriptor for the event attribute of a given event.\n * @param {string} eventName The event name to get property descriptor.\n * @returns {PropertyDescriptor} The property descriptor.\n * @private\n */\nfunction defineEventAttributeDescriptor(eventName) {\n    return {\n        get() {\n            const listeners = getListeners(this)\n            let node = listeners.get(eventName)\n            while (node != null) {\n                if (node.listenerType === ATTRIBUTE) {\n                    return node.listener\n                }\n                node = node.next\n            }\n            return null\n        },\n\n        set(listener) {\n            if (typeof listener !== \"function\" && !isObject(listener)) {\n                listener = null // eslint-disable-line no-param-reassign\n            }\n            const listeners = getListeners(this)\n\n            // Traverse to the tail while removing old value.\n            let prev = null\n            let node = listeners.get(eventName)\n            while (node != null) {\n                if (node.listenerType === ATTRIBUTE) {\n                    // Remove old value.\n                    if (prev !== null) {\n                        prev.next = node.next\n                    } else if (node.next !== null) {\n                        listeners.set(eventName, node.next)\n                    } else {\n                        listeners.delete(eventName)\n                    }\n                } else {\n                    prev = node\n                }\n\n                node = node.next\n            }\n\n            // Add new value.\n            if (listener !== null) {\n                const newNode = {\n                    listener,\n                    listenerType: ATTRIBUTE,\n                    passive: false,\n                    once: false,\n                    next: null,\n                }\n                if (prev === null) {\n                    listeners.set(eventName, newNode)\n                } else {\n                    prev.next = newNode\n                }\n            }\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Define an event attribute (e.g. `eventTarget.onclick`).\n * @param {Object} eventTargetPrototype The event target prototype to define an event attrbite.\n * @param {string} eventName The event name to define.\n * @returns {void}\n */\nfunction defineEventAttribute(eventTargetPrototype, eventName) {\n    Object.defineProperty(\n        eventTargetPrototype,\n        `on${eventName}`,\n        defineEventAttributeDescriptor(eventName)\n    )\n}\n\n/**\n * Define a custom EventTarget with event attributes.\n * @param {string[]} eventNames Event names for event attributes.\n * @returns {EventTarget} The custom EventTarget.\n * @private\n */\nfunction defineCustomEventTarget(eventNames) {\n    /** CustomEventTarget */\n    function CustomEventTarget() {\n        EventTarget.call(this)\n    }\n\n    CustomEventTarget.prototype = Object.create(EventTarget.prototype, {\n        constructor: {\n            value: CustomEventTarget,\n            configurable: true,\n            writable: true,\n        },\n    })\n\n    for (let i = 0; i < eventNames.length; ++i) {\n        defineEventAttribute(CustomEventTarget.prototype, eventNames[i])\n    }\n\n    return CustomEventTarget\n}\n\n/**\n * EventTarget.\n *\n * - This is constructor if no arguments.\n * - This is a function which returns a CustomEventTarget constructor if there are arguments.\n *\n * For example:\n *\n *     class A extends EventTarget {}\n *     class B extends EventTarget(\"message\") {}\n *     class C extends EventTarget(\"message\", \"error\") {}\n *     class D extends EventTarget([\"message\", \"error\"]) {}\n */\nfunction EventTarget() {\n    /*eslint-disable consistent-return */\n    if (this instanceof EventTarget) {\n        listenersMap.set(this, new Map())\n        return\n    }\n    if (arguments.length === 1 && Array.isArray(arguments[0])) {\n        return defineCustomEventTarget(arguments[0])\n    }\n    if (arguments.length > 0) {\n        const types = new Array(arguments.length)\n        for (let i = 0; i < arguments.length; ++i) {\n            types[i] = arguments[i]\n        }\n        return defineCustomEventTarget(types)\n    }\n    throw new TypeError(\"Cannot call a class as a function\")\n    /*eslint-enable consistent-return */\n}\n\n// Should be enumerable, but class methods are not enumerable.\nEventTarget.prototype = {\n    /**\n     * Add a given listener to this event target.\n     * @param {string} eventName The event name to add.\n     * @param {Function} listener The listener to add.\n     * @param {boolean|{capture?:boolean,passive?:boolean,once?:boolean}} [options] The options for this listener.\n     * @returns {void}\n     */\n    addEventListener(eventName, listener, options) {\n        if (listener == null) {\n            return\n        }\n        if (typeof listener !== \"function\" && !isObject(listener)) {\n            throw new TypeError(\"'listener' should be a function or an object.\")\n        }\n\n        const listeners = getListeners(this)\n        const optionsIsObj = isObject(options)\n        const capture = optionsIsObj\n            ? Boolean(options.capture)\n            : Boolean(options)\n        const listenerType = capture ? CAPTURE : BUBBLE\n        const newNode = {\n            listener,\n            listenerType,\n            passive: optionsIsObj && Boolean(options.passive),\n            once: optionsIsObj && Boolean(options.once),\n            next: null,\n        }\n\n        // Set it as the first node if the first node is null.\n        let node = listeners.get(eventName)\n        if (node === undefined) {\n            listeners.set(eventName, newNode)\n            return\n        }\n\n        // Traverse to the tail while checking duplication..\n        let prev = null\n        while (node != null) {\n            if (\n                node.listener === listener &&\n                node.listenerType === listenerType\n            ) {\n                // Should ignore duplication.\n                return\n            }\n            prev = node\n            node = node.next\n        }\n\n        // Add it.\n        prev.next = newNode\n    },\n\n    /**\n     * Remove a given listener from this event target.\n     * @param {string} eventName The event name to remove.\n     * @param {Function} listener The listener to remove.\n     * @param {boolean|{capture?:boolean,passive?:boolean,once?:boolean}} [options] The options for this listener.\n     * @returns {void}\n     */\n    removeEventListener(eventName, listener, options) {\n        if (listener == null) {\n            return\n        }\n\n        const listeners = getListeners(this)\n        const capture = isObject(options)\n            ? Boolean(options.capture)\n            : Boolean(options)\n        const listenerType = capture ? CAPTURE : BUBBLE\n\n        let prev = null\n        let node = listeners.get(eventName)\n        while (node != null) {\n            if (\n                node.listener === listener &&\n                node.listenerType === listenerType\n            ) {\n                if (prev !== null) {\n                    prev.next = node.next\n                } else if (node.next !== null) {\n                    listeners.set(eventName, node.next)\n                } else {\n                    listeners.delete(eventName)\n                }\n                return\n            }\n\n            prev = node\n            node = node.next\n        }\n    },\n\n    /**\n     * Dispatch a given event.\n     * @param {Event|{type:string}} event The event to dispatch.\n     * @returns {boolean} `false` if canceled.\n     */\n    dispatchEvent(event) {\n        if (event == null || typeof event.type !== \"string\") {\n            throw new TypeError('\"event.type\" should be a string.')\n        }\n\n        // If listeners aren't registered, terminate.\n        const listeners = getListeners(this)\n        const eventName = event.type\n        let node = listeners.get(eventName)\n        if (node == null) {\n            return true\n        }\n\n        // Since we cannot rewrite several properties, so wrap object.\n        const wrappedEvent = wrapEvent(this, event)\n\n        // This doesn't process capturing phase and bubbling phase.\n        // This isn't participating in a tree.\n        let prev = null\n        while (node != null) {\n            // Remove this listener if it's once\n            if (node.once) {\n                if (prev !== null) {\n                    prev.next = node.next\n                } else if (node.next !== null) {\n                    listeners.set(eventName, node.next)\n                } else {\n                    listeners.delete(eventName)\n                }\n            } else {\n                prev = node\n            }\n\n            // Call this listener\n            setPassiveListener(\n                wrappedEvent,\n                node.passive ? node.listener : null\n            )\n            if (typeof node.listener === \"function\") {\n                try {\n                    node.listener.call(this, wrappedEvent)\n                } catch (err) {\n                    if (\n                        typeof console !== \"undefined\" &&\n                        typeof console.error === \"function\"\n                    ) {\n                        console.error(err)\n                    }\n                }\n            } else if (\n                node.listenerType !== ATTRIBUTE &&\n                typeof node.listener.handleEvent === \"function\"\n            ) {\n                node.listener.handleEvent(wrappedEvent)\n            }\n\n            // Break if `event.stopImmediatePropagation` was called.\n            if (isStopped(wrappedEvent)) {\n                break\n            }\n\n            node = node.next\n        }\n        setPassiveListener(wrappedEvent, null)\n        setEventPhase(wrappedEvent, 0)\n        setCurrentTarget(wrappedEvent, null)\n\n        return !wrappedEvent.defaultPrevented\n    },\n}\n\n// `constructor` is not enumerable.\nObject.defineProperty(EventTarget.prototype, \"constructor\", {\n    value: EventTarget,\n    configurable: true,\n    writable: true,\n})\n\n// Ensure `eventTarget instanceof window.EventTarget` is `true`.\nif (\n    typeof window !== \"undefined\" &&\n    typeof window.EventTarget !== \"undefined\"\n) {\n    Object.setPrototypeOf(EventTarget.prototype, window.EventTarget.prototype)\n}\n\nexport { defineEventAttribute, EventTarget }\nexport default EventTarget\n","import {\n    // Event,\n    EventTarget,\n    // Type,\n    defineEventAttribute,\n} from \"event-target-shim\"\n\n// Known Limitation\n//   Use `any` because the type of `AbortSignal` in `lib.dom.d.ts` is wrong and\n//   to make assignable our `AbortSignal` into that.\n//   https://github.com/Microsoft/TSJS-lib-generator/pull/623\ntype Events = {\n    abort: any // Event & Type<\"abort\">\n}\ntype EventAttributes = {\n    onabort: any // Event & Type<\"abort\">\n}\n\n/**\n * The signal class.\n * @see https://dom.spec.whatwg.org/#abortsignal\n */\nexport default class AbortSignal extends EventTarget<Events, EventAttributes> {\n    /**\n     * AbortSignal cannot be constructed directly.\n     */\n    public constructor() {\n        super()\n        throw new TypeError(\"AbortSignal cannot be constructed directly\")\n    }\n\n    /**\n     * Returns `true` if this `AbortSignal`'s `AbortController` has signaled to abort, and `false` otherwise.\n     */\n    public get aborted(): boolean {\n        const aborted = abortedFlags.get(this)\n        if (typeof aborted !== \"boolean\") {\n            throw new TypeError(\n                `Expected 'this' to be an 'AbortSignal' object, but got ${\n                    this === null ? \"null\" : typeof this\n                }`,\n            )\n        }\n        return aborted\n    }\n}\ndefineEventAttribute(AbortSignal.prototype, \"abort\")\n\n/**\n * Create an AbortSignal object.\n */\nexport function createAbortSignal(): AbortSignal {\n    const signal = Object.create(AbortSignal.prototype)\n    EventTarget.call(signal)\n    abortedFlags.set(signal, false)\n    return signal\n}\n\n/**\n * Abort a given signal.\n */\nexport function abortSignal(signal: AbortSignal): void {\n    if (abortedFlags.get(signal) !== false) {\n        return\n    }\n\n    abortedFlags.set(signal, true)\n    signal.dispatchEvent<\"abort\">({ type: \"abort\" })\n}\n\n/**\n * Aborted flag for each instances.\n */\nconst abortedFlags = new WeakMap<AbortSignal, boolean>()\n\n// Properties should be enumerable.\nObject.defineProperties(AbortSignal.prototype, {\n    aborted: { enumerable: true },\n})\n\n// `toString()` should return `\"[object AbortSignal]\"`\nif (typeof Symbol === \"function\" && typeof Symbol.toStringTag === \"symbol\") {\n    Object.defineProperty(AbortSignal.prototype, Symbol.toStringTag, {\n        configurable: true,\n        value: \"AbortSignal\",\n    })\n}\n","import AbortSignal, { abortSignal, createAbortSignal } from \"./abort-signal\"\n\n/**\n * The AbortController.\n * @see https://dom.spec.whatwg.org/#abortcontroller\n */\nexport default class AbortController {\n    /**\n     * Initialize this controller.\n     */\n    public constructor() {\n        signals.set(this, createAbortSignal())\n    }\n\n    /**\n     * Returns the `AbortSignal` object associated with this object.\n     */\n    public get signal(): AbortSignal {\n        return getSignal(this)\n    }\n\n    /**\n     * Abort and signal to any observers that the associated activity is to be aborted.\n     */\n    public abort(): void {\n        abortSignal(getSignal(this))\n    }\n}\n\n/**\n * Associated signals.\n */\nconst signals = new WeakMap<AbortController, AbortSignal>()\n\n/**\n * Get the associated signal of a given controller.\n */\nfunction getSignal(controller: AbortController): AbortSignal {\n    const signal = signals.get(controller)\n    if (signal == null) {\n        throw new TypeError(\n            `Expected 'this' to be an 'AbortController' object, but got ${\n                controller === null ? \"null\" : typeof controller\n            }`,\n        )\n    }\n    return signal\n}\n\n// Properties should be enumerable.\nObject.defineProperties(AbortController.prototype, {\n    signal: { enumerable: true },\n    abort: { enumerable: true },\n})\n\nif (typeof Symbol === \"function\" && typeof Symbol.toStringTag === \"symbol\") {\n    Object.defineProperty(AbortController.prototype, Symbol.toStringTag, {\n        configurable: true,\n        value: \"AbortController\",\n    })\n}\n\nexport { AbortController, AbortSignal }\n","'use strict';\n\nvar isMergeableObject = function isMergeableObject(value) {\n\treturn isNonNullObject(value)\n\t\t&& !isSpecial(value)\n};\n\nfunction isNonNullObject(value) {\n\treturn !!value && typeof value === 'object'\n}\n\nfunction isSpecial(value) {\n\tvar stringValue = Object.prototype.toString.call(value);\n\n\treturn stringValue === '[object RegExp]'\n\t\t|| stringValue === '[object Date]'\n\t\t|| isReactElement(value)\n}\n\n// see https://github.com/facebook/react/blob/b5ac963fb791d1298e7f396236383bc955f916c1/src/isomorphic/classic/element/ReactElement.js#L21-L25\nvar canUseSymbol = typeof Symbol === 'function' && Symbol.for;\nvar REACT_ELEMENT_TYPE = canUseSymbol ? Symbol.for('react.element') : 0xeac7;\n\nfunction isReactElement(value) {\n\treturn value.$$typeof === REACT_ELEMENT_TYPE\n}\n\nfunction emptyTarget(val) {\n\treturn Array.isArray(val) ? [] : {}\n}\n\nfunction cloneUnlessOtherwiseSpecified(value, options) {\n\treturn (options.clone !== false && options.isMergeableObject(value))\n\t\t? deepmerge(emptyTarget(value), value, options)\n\t\t: value\n}\n\nfunction defaultArrayMerge(target, source, options) {\n\treturn target.concat(source).map(function(element) {\n\t\treturn cloneUnlessOtherwiseSpecified(element, options)\n\t})\n}\n\nfunction getMergeFunction(key, options) {\n\tif (!options.customMerge) {\n\t\treturn deepmerge\n\t}\n\tvar customMerge = options.customMerge(key);\n\treturn typeof customMerge === 'function' ? customMerge : deepmerge\n}\n\nfunction getEnumerableOwnPropertySymbols(target) {\n\treturn Object.getOwnPropertySymbols\n\t\t? Object.getOwnPropertySymbols(target).filter(function(symbol) {\n\t\t\treturn Object.propertyIsEnumerable.call(target, symbol)\n\t\t})\n\t\t: []\n}\n\nfunction getKeys(target) {\n\treturn Object.keys(target).concat(getEnumerableOwnPropertySymbols(target))\n}\n\nfunction propertyIsOnObject(object, property) {\n\ttry {\n\t\treturn property in object\n\t} catch(_) {\n\t\treturn false\n\t}\n}\n\n// Protects from prototype poisoning and unexpected merging up the prototype chain.\nfunction propertyIsUnsafe(target, key) {\n\treturn propertyIsOnObject(target, key) // Properties are safe to merge if they don't exist in the target yet,\n\t\t&& !(Object.hasOwnProperty.call(target, key) // unsafe if they exist up the prototype chain,\n\t\t\t&& Object.propertyIsEnumerable.call(target, key)) // and also unsafe if they're nonenumerable.\n}\n\nfunction mergeObject(target, source, options) {\n\tvar destination = {};\n\tif (options.isMergeableObject(target)) {\n\t\tgetKeys(target).forEach(function(key) {\n\t\t\tdestination[key] = cloneUnlessOtherwiseSpecified(target[key], options);\n\t\t});\n\t}\n\tgetKeys(source).forEach(function(key) {\n\t\tif (propertyIsUnsafe(target, key)) {\n\t\t\treturn\n\t\t}\n\n\t\tif (propertyIsOnObject(target, key) && options.isMergeableObject(source[key])) {\n\t\t\tdestination[key] = getMergeFunction(key, options)(target[key], source[key], options);\n\t\t} else {\n\t\t\tdestination[key] = cloneUnlessOtherwiseSpecified(source[key], options);\n\t\t}\n\t});\n\treturn destination\n}\n\nfunction deepmerge(target, source, options) {\n\toptions = options || {};\n\toptions.arrayMerge = options.arrayMerge || defaultArrayMerge;\n\toptions.isMergeableObject = options.isMergeableObject || isMergeableObject;\n\t// cloneUnlessOtherwiseSpecified is added to `options` so that custom arrayMerge()\n\t// implementations can use it. The caller may not replace it.\n\toptions.cloneUnlessOtherwiseSpecified = cloneUnlessOtherwiseSpecified;\n\n\tvar sourceIsArray = Array.isArray(source);\n\tvar targetIsArray = Array.isArray(target);\n\tvar sourceAndTargetTypesMatch = sourceIsArray === targetIsArray;\n\n\tif (!sourceAndTargetTypesMatch) {\n\t\treturn cloneUnlessOtherwiseSpecified(source, options)\n\t} else if (sourceIsArray) {\n\t\treturn options.arrayMerge(target, source, options)\n\t} else {\n\t\treturn mergeObject(target, source, options)\n\t}\n}\n\ndeepmerge.all = function deepmergeAll(array, options) {\n\tif (!Array.isArray(array)) {\n\t\tthrow new Error('first argument should be an array')\n\t}\n\n\treturn array.reduce(function(prev, next) {\n\t\treturn deepmerge(prev, next, options)\n\t}, {})\n};\n\nvar deepmerge_1 = deepmerge;\n\nmodule.exports = deepmerge_1;\n","import { generateText, IBrowserService, trimTokens } from \"@elizaos/core\";\nimport { parseJSONObjectFromText } from \"@elizaos/core\";\nimport { Service } from \"@elizaos/core\";\nimport { settings } from \"@elizaos/core\";\nimport { IAgentRuntime, ModelClass, ServiceType } from \"@elizaos/core\";\nimport { stringToUuid } from \"@elizaos/core\";\nimport { PlaywrightBlocker } from \"@cliqz/adblocker-playwright\";\nimport CaptchaSolver from \"capsolver-npm\";\nimport { Browser, BrowserContext, chromium, Page } from \"playwright\";\n\nasync function generateSummary(\n    runtime: IAgentRuntime,\n    text: string\n): Promise<{ title: string; description: string }> {\n    // make sure text is under 128k characters\n    text = await trimTokens(text, 100000, runtime);\n\n    const prompt = `Please generate a concise summary for the following text:\n\n  Text: \"\"\"\n  ${text}\n  \"\"\"\n\n  Respond with a JSON object in the following format:\n  \\`\\`\\`json\n  {\n    \"title\": \"Generated Title\",\n    \"summary\": \"Generated summary and/or description of the text\"\n  }\n  \\`\\`\\``;\n\n    const response = await generateText({\n        runtime,\n        context: prompt,\n        modelClass: ModelClass.SMALL,\n    });\n\n    const parsedResponse = parseJSONObjectFromText(response);\n\n    if (parsedResponse) {\n        return {\n            title: parsedResponse.title,\n            description: parsedResponse.summary,\n        };\n    }\n\n    return {\n        title: \"\",\n        description: \"\",\n    };\n}\n\ntype PageContent = {\n    title: string;\n    description: string;\n    bodyContent: string;\n};\n\nexport class BrowserService extends Service implements IBrowserService {\n    private browser: Browser | undefined;\n    private context: BrowserContext | undefined;\n    private blocker: PlaywrightBlocker | undefined;\n    private captchaSolver: CaptchaSolver;\n    private cacheKey = \"content/browser\";\n\n    static serviceType: ServiceType = ServiceType.BROWSER;\n\n    static register(runtime: IAgentRuntime): IAgentRuntime {\n        // since we are lazy loading, do nothing\n        return runtime;\n    }\n\n    getInstance(): IBrowserService {\n        return BrowserService.getInstance();\n    }\n\n    constructor() {\n        super();\n        this.browser = undefined;\n        this.context = undefined;\n        this.blocker = undefined;\n        this.captchaSolver = new CaptchaSolver(\n            settings.CAPSOLVER_API_KEY || \"\"\n        );\n    }\n\n    async initialize() {}\n\n    async initializeBrowser() {\n        if (!this.browser) {\n            this.browser = await chromium.launch({\n                headless: true,\n                args: [\n                    \"--disable-dev-shm-usage\", // Uses /tmp instead of /dev/shm. Prevents memory issues on low-memory systems\n                    \"--block-new-web-contents\", // Prevents creation of new windows/tabs\n                ],\n            });\n\n            const platform = process.platform;\n            let userAgent = \"\";\n\n            // Change the user agent to match the platform to reduce bot detection\n            switch (platform) {\n                case \"darwin\":\n                    userAgent =\n                        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\";\n                    break;\n                case \"win32\":\n                    userAgent =\n                        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\";\n                    break;\n                case \"linux\":\n                    userAgent =\n                        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\";\n                    break;\n                default:\n                    userAgent =\n                        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\";\n            }\n\n            this.context = await this.browser.newContext({\n                userAgent,\n                acceptDownloads: false,\n            });\n\n            this.blocker =\n                await PlaywrightBlocker.fromPrebuiltAdsAndTracking(fetch);\n        }\n    }\n\n    async closeBrowser() {\n        if (this.context) {\n            await this.context.close();\n            this.context = undefined;\n        }\n        if (this.browser) {\n            await this.browser.close();\n            this.browser = undefined;\n        }\n    }\n\n    async getPageContent(\n        url: string,\n        runtime: IAgentRuntime\n    ): Promise<PageContent> {\n        await this.initializeBrowser();\n        return await this.fetchPageContent(url, runtime);\n    }\n\n    private getCacheKey(url: string): string {\n        return stringToUuid(url);\n    }\n\n    private async fetchPageContent(\n        url: string,\n        runtime: IAgentRuntime\n    ): Promise<PageContent> {\n        const cacheKey = this.getCacheKey(url);\n        const cached = await runtime.cacheManager.get<{\n            url: string;\n            content: PageContent;\n        }>(`${this.cacheKey}/${cacheKey}`);\n\n        if (cached) {\n            return cached.content;\n        }\n\n        let page: Page | undefined;\n\n        try {\n            if (!this.context) {\n                console.log(\n                    \"Browser context not initialized. Call initializeBrowser() first.\"\n                );\n            }\n\n            page = await this.context.newPage();\n\n            // Enable stealth mode\n            await page.setExtraHTTPHeaders({\n                \"Accept-Language\": \"en-US,en;q=0.9\",\n            });\n\n            // Apply ad blocker\n            if (this.blocker) {\n                await this.blocker.enableBlockingInPage(page);\n            }\n\n            const response = await page.goto(url, { waitUntil: \"networkidle\" });\n\n            if (!response) {\n                console.log(\"Failed to load the page\");\n            }\n\n            if (response.status() === 403 || response.status() === 404) {\n                return await this.tryAlternativeSources(url, runtime);\n            }\n\n            // Check for CAPTCHA\n            const captchaDetected = await this.detectCaptcha(page);\n            if (captchaDetected) {\n                await this.solveCaptcha(page, url);\n            }\n            const documentTitle = await page.evaluate(() => document.title);\n            const bodyContent = await page.evaluate(\n                () => document.body.innerText\n            );\n            const { title: parsedTitle, description } = await generateSummary(\n                runtime,\n                documentTitle + \"\\n\" + bodyContent\n            );\n            const content = { title: parsedTitle, description, bodyContent };\n            await runtime.cacheManager.set(`${this.cacheKey}/${cacheKey}`, {\n                url,\n                content,\n            });\n            return content;\n        } catch (error) {\n            console.error(\"Error:\", error);\n            return {\n                title: url,\n                description: \"Error, could not fetch content\",\n                bodyContent: \"\",\n            };\n        } finally {\n            if (page) {\n                await page.close();\n            }\n        }\n    }\n\n    private async detectCaptcha(page: Page): Promise<boolean> {\n        const captchaSelectors = [\n            'iframe[src*=\"captcha\"]',\n            'div[class*=\"captcha\"]',\n            \"#captcha\",\n            \".g-recaptcha\",\n            \".h-captcha\",\n        ];\n\n        for (const selector of captchaSelectors) {\n            const element = await page.$(selector);\n            if (element) return true;\n        }\n\n        return false;\n    }\n\n    private async solveCaptcha(page: Page, url: string): Promise<void> {\n        try {\n            const hcaptchaKey = await this.getHCaptchaWebsiteKey(page);\n            if (hcaptchaKey) {\n                const solution = await this.captchaSolver.hcaptchaProxyless({\n                    websiteURL: url,\n                    websiteKey: hcaptchaKey,\n                });\n                await page.evaluate((token) => {\n                    // eslint-disable-next-line\n                    // @ts-ignore\n                    window.hcaptcha.setResponse(token);\n                }, solution.gRecaptchaResponse);\n                return;\n            }\n\n            const recaptchaKey = await this.getReCaptchaWebsiteKey(page);\n            if (recaptchaKey) {\n                const solution = await this.captchaSolver.recaptchaV2Proxyless({\n                    websiteURL: url,\n                    websiteKey: recaptchaKey,\n                });\n                await page.evaluate((token) => {\n                    // eslint-disable-next-line\n                    // @ts-ignore\n                    document.getElementById(\"g-recaptcha-response\").innerHTML =\n                        token;\n                }, solution.gRecaptchaResponse);\n            }\n        } catch (error) {\n            console.error(\"Error solving CAPTCHA:\", error);\n        }\n    }\n\n    private async getHCaptchaWebsiteKey(page: Page): Promise<string> {\n        return page.evaluate(() => {\n            const hcaptchaIframe = document.querySelector(\n                'iframe[src*=\"hcaptcha.com\"]'\n            );\n            if (hcaptchaIframe) {\n                const src = hcaptchaIframe.getAttribute(\"src\");\n                const match = src?.match(/sitekey=([^&]*)/);\n                return match ? match[1] : \"\";\n            }\n            return \"\";\n        });\n    }\n\n    private async getReCaptchaWebsiteKey(page: Page): Promise<string> {\n        return page.evaluate(() => {\n            const recaptchaElement = document.querySelector(\".g-recaptcha\");\n            return recaptchaElement\n                ? recaptchaElement.getAttribute(\"data-sitekey\") || \"\"\n                : \"\";\n        });\n    }\n\n    private async tryAlternativeSources(\n        url: string,\n        runtime: IAgentRuntime\n    ): Promise<{ title: string; description: string; bodyContent: string }> {\n        // Try Internet Archive\n        const archiveUrl = `https://web.archive.org/web/${url}`;\n        try {\n            return await this.fetchPageContent(archiveUrl, runtime);\n        } catch (error) {\n            console.error(\"Error fetching from Internet Archive:\", error);\n        }\n\n        // Try Google Search as a last resort\n        const googleSearchUrl = `https://www.google.com/search?q=${encodeURIComponent(url)}`;\n        try {\n            return await this.fetchPageContent(googleSearchUrl, runtime);\n        } catch (error) {\n            console.error(\"Error fetching from Google Search:\", error);\n            console.error(\"Failed to fetch content from alternative sources\");\n            return {\n                title: url,\n                description:\n                    \"Error, could not fetch content from alternative sources\",\n                bodyContent: \"\",\n            };\n        }\n    }\n}\n","import { elizaLogger, models } from \"@elizaos/core\";\nimport { Service } from \"@elizaos/core\";\nimport {\n    IAgentRuntime,\n    ModelProviderName,\n    ServiceType,\n    IImageDescriptionService,\n} from \"@elizaos/core\";\nimport {\n    AutoProcessor,\n    AutoTokenizer,\n    env,\n    Florence2ForConditionalGeneration,\n    Florence2Processor,\n    PreTrainedModel,\n    PreTrainedTokenizer,\n    RawImage,\n    type Tensor,\n} from \"@huggingface/transformers\";\nimport fs from \"fs\";\nimport gifFrames from \"gif-frames\";\nimport os from \"os\";\nimport path from \"path\";\n\nexport class ImageDescriptionService\n    extends Service\n    implements IImageDescriptionService\n{\n    static serviceType: ServiceType = ServiceType.IMAGE_DESCRIPTION;\n\n    private modelId: string = \"onnx-community/Florence-2-base-ft\";\n    private device: string = \"gpu\";\n    private model: PreTrainedModel | null = null;\n    private processor: Florence2Processor | null = null;\n    private tokenizer: PreTrainedTokenizer | null = null;\n    private initialized: boolean = false;\n    private runtime: IAgentRuntime | null = null;\n    private queue: string[] = [];\n    private processing: boolean = false;\n\n    getInstance(): IImageDescriptionService {\n        return ImageDescriptionService.getInstance();\n    }\n\n    async initialize(runtime: IAgentRuntime): Promise<void> {\n        elizaLogger.log(\"Initializing ImageDescriptionService\");\n        this.runtime = runtime;\n    }\n\n    private async initializeLocalModel(): Promise<void> {\n        env.allowLocalModels = false;\n        env.allowRemoteModels = true;\n        env.backends.onnx.logLevel = \"fatal\";\n        env.backends.onnx.wasm.proxy = false;\n        env.backends.onnx.wasm.numThreads = 1;\n\n        elizaLogger.info(\"Downloading Florence model...\");\n\n        this.model = await Florence2ForConditionalGeneration.from_pretrained(\n            this.modelId,\n            {\n                device: \"gpu\",\n                progress_callback: (progress) => {\n                    if (progress.status === \"downloading\") {\n                        const percent = (\n                            (progress.loaded / progress.total) *\n                            100\n                        ).toFixed(1);\n                        const dots = \".\".repeat(\n                            Math.floor(Number(percent) / 5)\n                        );\n                        elizaLogger.info(\n                            `Downloading Florence model: [${dots.padEnd(20, \" \")}] ${percent}%`\n                        );\n                    }\n                },\n            }\n        );\n\n        elizaLogger.success(\"Florence model downloaded successfully\");\n\n        elizaLogger.info(\"Downloading processor...\");\n        this.processor = (await AutoProcessor.from_pretrained(\n            this.modelId\n        )) as Florence2Processor;\n\n        elizaLogger.info(\"Downloading tokenizer...\");\n        this.tokenizer = await AutoTokenizer.from_pretrained(this.modelId);\n        elizaLogger.success(\"Image service initialization complete\");\n    }\n\n    async describeImage(\n        imageUrl: string\n    ): Promise<{ title: string; description: string }> {\n        if (!this.initialized) {\n            const model = models[this.runtime?.character?.modelProvider];\n\n            if (model === models[ModelProviderName.LLAMALOCAL]) {\n                await this.initializeLocalModel();\n            } else {\n                this.modelId = \"gpt-4o-mini\";\n                this.device = \"cloud\";\n            }\n\n            this.initialized = true;\n        }\n\n        if (this.device === \"cloud\") {\n            if (!this.runtime) {\n                throw new Error(\n                    \"Runtime is required for OpenAI image recognition\"\n                );\n            }\n            return this.recognizeWithOpenAI(imageUrl);\n        }\n\n        this.queue.push(imageUrl);\n        this.processQueue();\n\n        return new Promise((resolve, _reject) => {\n            const checkQueue = () => {\n                const index = this.queue.indexOf(imageUrl);\n                if (index !== -1) {\n                    setTimeout(checkQueue, 100);\n                } else {\n                    resolve(this.processImage(imageUrl));\n                }\n            };\n            checkQueue();\n        });\n    }\n\n    private async recognizeWithOpenAI(\n        imageUrl: string\n    ): Promise<{ title: string; description: string }> {\n        const isGif = imageUrl.toLowerCase().endsWith(\".gif\");\n        let imageData: Buffer | null = null;\n\n        try {\n            if (isGif) {\n                const { filePath } =\n                    await this.extractFirstFrameFromGif(imageUrl);\n                imageData = fs.readFileSync(filePath);\n            } else if (fs.existsSync(imageUrl)) {\n                imageData = fs.readFileSync(imageUrl);\n            } else {\n                const response = await fetch(imageUrl);\n                if (!response.ok) {\n                    throw new Error(\n                        `Failed to fetch image: ${response.statusText}`\n                    );\n                }\n                imageData = Buffer.from(await response.arrayBuffer());\n            }\n\n            if (!imageData || imageData.length === 0) {\n                throw new Error(\"Failed to fetch image data\");\n            }\n\n            const prompt =\n                \"Describe this image and give it a title. The first line should be the title, and then a line break, then a detailed description of the image. Respond with the format 'title\\ndescription'\";\n            const text = await this.requestOpenAI(\n                imageUrl,\n                imageData,\n                prompt,\n                isGif,\n                true\n            );\n\n            const [title, ...descriptionParts] = text.split(\"\\n\");\n            return {\n                title,\n                description: descriptionParts.join(\"\\n\"),\n            };\n        } catch (error) {\n            elizaLogger.error(\"Error in recognizeWithOpenAI:\", error);\n            throw error;\n        }\n    }\n\n    private async requestOpenAI(\n        imageUrl: string,\n        imageData: Buffer,\n        prompt: string,\n        isGif: boolean = false,\n        isLocalFile: boolean = false\n    ): Promise<string> {\n        for (let attempt = 0; attempt < 3; attempt++) {\n            try {\n                const shouldUseBase64 = (isGif || isLocalFile)&& !(this.runtime.imageModelProvider === ModelProviderName.OPENAI);\n                const mimeType = isGif\n                    ? \"png\"\n                    : path.extname(imageUrl).slice(1) || \"jpeg\";\n\n                const base64Data = imageData.toString(\"base64\");\n                const imageUrlToUse = shouldUseBase64\n                    ? `data:image/${mimeType};base64,${base64Data}`\n                    : imageUrl;\n\n                const content = [\n                    { type: \"text\", text: prompt },\n                    {\n                        type: \"image_url\",\n                        image_url: {\n                            url: imageUrlToUse,\n                        },\n                    },\n                ];\n                // If model provider is openai, use the endpoint, otherwise use the default openai endpoint.\n                const endpoint =\n                    this.runtime.imageModelProvider === ModelProviderName.OPENAI\n                    ? models[this.runtime.imageModelProvider].endpoint\n                    : \"https://api.openai.com/v1\";\n                const response = await fetch(endpoint + \"/chat/completions\", {\n                    method: \"POST\",\n                    headers: {\n                        \"Content-Type\": \"application/json\",\n                        Authorization: `Bearer ${this.runtime.getSetting(\"OPENAI_API_KEY\")}`,\n                    },\n                    body: JSON.stringify({\n                        model: \"gpt-4o-mini\",\n                        messages: [{ role: \"user\", content }],\n                        max_tokens: shouldUseBase64 ? 500 : 300,\n                    }),\n                });\n\n                if (!response.ok) {\n                    const responseText = await response.text();\n                    elizaLogger.error(\n                        \"OpenAI API error:\",\n                        response.status,\n                        \"-\",\n                        responseText\n                    );\n                    throw new Error(`HTTP error! status: ${response.status}`);\n                }\n\n                const data = await response.json();\n                return data.choices[0].message.content;\n            } catch (error) {\n                elizaLogger.error(\n                    \"OpenAI request failed (attempt\",\n                    attempt + 1,\n                    \"):\",\n                    error\n                );\n                if (attempt === 2) throw error;\n            }\n        }\n        throw new Error(\n            \"Failed to recognize image with OpenAI after 3 attempts\"\n        );\n    }\n\n    private async processQueue(): Promise<void> {\n        if (this.processing || this.queue.length === 0) return;\n\n        this.processing = true;\n        while (this.queue.length > 0) {\n            const imageUrl = this.queue.shift();\n            await this.processImage(imageUrl);\n        }\n        this.processing = false;\n    }\n\n    private async processImage(\n        imageUrl: string\n    ): Promise<{ title: string; description: string }> {\n        if (!this.model || !this.processor || !this.tokenizer) {\n            throw new Error(\"Model components not initialized\");\n        }\n\n        elizaLogger.log(\"Processing image:\", imageUrl);\n        const isGif = imageUrl.toLowerCase().endsWith(\".gif\");\n        let imageToProcess = imageUrl;\n\n        try {\n            if (isGif) {\n                elizaLogger.log(\"Extracting first frame from GIF\");\n                const { filePath } =\n                    await this.extractFirstFrameFromGif(imageUrl);\n                imageToProcess = filePath;\n            }\n\n            const image = await RawImage.fromURL(imageToProcess);\n            const visionInputs = await this.processor(image);\n            const prompts =\n                this.processor.construct_prompts(\"<DETAILED_CAPTION>\");\n            const textInputs = this.tokenizer(prompts);\n\n            elizaLogger.log(\"Generating image description\");\n            const generatedIds = (await this.model.generate({\n                ...textInputs,\n                ...visionInputs,\n                max_new_tokens: 256,\n            })) as Tensor;\n\n            const generatedText = this.tokenizer.batch_decode(generatedIds, {\n                skip_special_tokens: false,\n            })[0];\n\n            const result = this.processor.post_process_generation(\n                generatedText,\n                \"<DETAILED_CAPTION>\",\n                image.size\n            );\n\n            const detailedCaption = result[\"<DETAILED_CAPTION>\"] as string;\n            return { title: detailedCaption, description: detailedCaption };\n        } catch (error) {\n            elizaLogger.error(\"Error processing image:\", error);\n            throw error;\n        } finally {\n            if (isGif && imageToProcess !== imageUrl) {\n                fs.unlinkSync(imageToProcess);\n            }\n        }\n    }\n\n    private async extractFirstFrameFromGif(\n        gifUrl: string\n    ): Promise<{ filePath: string }> {\n        const frameData = await gifFrames({\n            url: gifUrl,\n            frames: 1,\n            outputType: \"png\",\n        });\n\n        const tempFilePath = path.join(\n            os.tmpdir(),\n            `gif_frame_${Date.now()}.png`\n        );\n\n        return new Promise((resolve, reject) => {\n            const writeStream = fs.createWriteStream(tempFilePath);\n            frameData[0].getImage().pipe(writeStream);\n            writeStream.on(\"finish\", () => resolve({ filePath: tempFilePath }));\n            writeStream.on(\"error\", reject);\n        });\n    }\n}\n\nexport default ImageDescriptionService;\n","import {\n    elizaLogger,\n    IAgentRuntime,\n    ServiceType,\n    ModelProviderName,\n} from \"@elizaos/core\";\nimport { Service } from \"@elizaos/core\";\nimport fs from \"fs\";\nimport https from \"https\";\nimport {\n    GbnfJsonSchema,\n    getLlama,\n    Llama,\n    LlamaContext,\n    LlamaContextSequence,\n    LlamaContextSequenceRepeatPenalty,\n    LlamaJsonSchemaGrammar,\n    LlamaModel,\n    Token,\n} from \"node-llama-cpp\";\nimport path from \"path\";\nimport si from \"systeminformation\";\nimport { fileURLToPath } from \"url\";\n\nconst wordsToPunish = [\n    \" please\",\n    \" feel\",\n    \" free\",\n    \"!\",\n    \"–\",\n    \"—\",\n    \"?\",\n    \".\",\n    \",\",\n    \"; \",\n    \" cosmos\",\n    \" tapestry\",\n    \" tapestries\",\n    \" glitch\",\n    \" matrix\",\n    \" cyberspace\",\n    \" troll\",\n    \" questions\",\n    \" topics\",\n    \" discuss\",\n    \" basically\",\n    \" simulation\",\n    \" simulate\",\n    \" universe\",\n    \" like\",\n    \" debug\",\n    \" debugging\",\n    \" wild\",\n    \" existential\",\n    \" juicy\",\n    \" circuits\",\n    \" help\",\n    \" ask\",\n    \" happy\",\n    \" just\",\n    \" cosmic\",\n    \" cool\",\n    \" joke\",\n    \" punchline\",\n    \" fancy\",\n    \" glad\",\n    \" assist\",\n    \" algorithm\",\n    \" Indeed\",\n    \" Furthermore\",\n    \" However\",\n    \" Notably\",\n    \" Therefore\",\n    \" Additionally\",\n    \" conclusion\",\n    \" Significantly\",\n    \" Consequently\",\n    \" Thus\",\n    \" What\",\n    \" Otherwise\",\n    \" Moreover\",\n    \" Subsequently\",\n    \" Accordingly\",\n    \" Unlock\",\n    \" Unleash\",\n    \" buckle\",\n    \" pave\",\n    \" forefront\",\n    \" harness\",\n    \" harnessing\",\n    \" bridging\",\n    \" bridging\",\n    \" Spearhead\",\n    \" spearheading\",\n    \" Foster\",\n    \" foster\",\n    \" environmental\",\n    \" impact\",\n    \" Navigate\",\n    \" navigating\",\n    \" challenges\",\n    \" chaos\",\n    \" social\",\n    \" inclusion\",\n    \" inclusive\",\n    \" diversity\",\n    \" diverse\",\n    \" delve\",\n    \" noise\",\n    \" infinite\",\n    \" insanity\",\n    \" coffee\",\n    \" singularity\",\n    \" AI\",\n    \" digital\",\n    \" artificial\",\n    \" intelligence\",\n    \" consciousness\",\n    \" reality\",\n    \" metaverse\",\n    \" virtual\",\n    \" virtual reality\",\n    \" VR\",\n    \" Metaverse\",\n    \" humanity\",\n];\n\nconst __dirname = path.dirname(fileURLToPath(import.meta.url));\n\nconst jsonSchemaGrammar: Readonly<{\n    type: string;\n    properties: {\n        user: {\n            type: string;\n        };\n        content: {\n            type: string;\n        };\n    };\n}> = {\n    type: \"object\",\n    properties: {\n        user: {\n            type: \"string\",\n        },\n        content: {\n            type: \"string\",\n        },\n    },\n};\n\ninterface QueuedMessage {\n    context: string;\n    temperature: number;\n    stop: string[];\n    max_tokens: number;\n    frequency_penalty: number;\n    presence_penalty: number;\n    useGrammar: boolean;\n    resolve: (value: any | string | PromiseLike<any | string>) => void;\n    reject: (reason?: any) => void;\n}\n\nexport class LlamaService extends Service {\n    private llama: Llama | undefined;\n    private model: LlamaModel | undefined;\n    private modelPath: string;\n    private grammar: LlamaJsonSchemaGrammar<GbnfJsonSchema> | undefined;\n    private ctx: LlamaContext | undefined;\n    private sequence: LlamaContextSequence | undefined;\n    private modelUrl: string;\n    private ollamaModel: string | undefined;\n\n    private messageQueue: QueuedMessage[] = [];\n    private isProcessing: boolean = false;\n    private modelInitialized: boolean = false;\n    private runtime: IAgentRuntime | undefined;\n\n    static serviceType: ServiceType = ServiceType.TEXT_GENERATION;\n\n    constructor() {\n        super();\n        this.llama = undefined;\n        this.model = undefined;\n        this.modelUrl =\n            \"https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true\";\n        const modelName = \"model.gguf\";\n        this.modelPath = path.join(\n            process.env.LLAMALOCAL_PATH?.trim() ?? \"./\",\n            modelName\n        );\n        this.ollamaModel = process.env.OLLAMA_MODEL;\n    }\n\n    async initialize(runtime: IAgentRuntime): Promise<void> {\n        elizaLogger.info(\"Initializing LlamaService...\");\n        this.runtime = runtime;\n    }\n\n    private async ensureInitialized() {\n        if (!this.modelInitialized) {\n            elizaLogger.info(\n                \"Model not initialized, starting initialization...\"\n            );\n            await this.initializeModel();\n        } else {\n            elizaLogger.info(\"Model already initialized\");\n        }\n    }\n\n    async initializeModel() {\n        try {\n            elizaLogger.info(\"Checking model file...\");\n            await this.checkModel();\n\n            const systemInfo = await si.graphics();\n            const hasCUDA = systemInfo.controllers.some((controller) =>\n                controller.vendor.toLowerCase().includes(\"nvidia\")\n            );\n\n            if (hasCUDA) {\n                elizaLogger.info(\n                    \"LlamaService: CUDA detected, using GPU acceleration\"\n                );\n            } else {\n                elizaLogger.warn(\n                    \"LlamaService: No CUDA detected - local response will be slow\"\n                );\n            }\n\n            elizaLogger.info(\"Initializing Llama instance...\");\n            this.llama = await getLlama({\n                gpu: hasCUDA ? \"cuda\" : undefined,\n            });\n\n            elizaLogger.info(\"Creating JSON schema grammar...\");\n            const grammar = new LlamaJsonSchemaGrammar(\n                this.llama,\n                jsonSchemaGrammar as GbnfJsonSchema\n            );\n            this.grammar = grammar;\n\n            elizaLogger.info(\"Loading model...\");\n            this.model = await this.llama.loadModel({\n                modelPath: this.modelPath,\n            });\n\n            elizaLogger.info(\"Creating context and sequence...\");\n            this.ctx = await this.model.createContext({ contextSize: 8192 });\n            this.sequence = this.ctx.getSequence();\n\n            this.modelInitialized = true;\n            elizaLogger.success(\"Model initialization complete\");\n            this.processQueue();\n        } catch (error) {\n            elizaLogger.error(\n                \"Model initialization failed. Deleting model and retrying:\",\n                error\n            );\n            try {\n                elizaLogger.info(\n                    \"Attempting to delete and re-download model...\"\n                );\n                await this.deleteModel();\n                await this.initializeModel();\n            } catch (retryError) {\n                elizaLogger.error(\n                    \"Model re-initialization failed:\",\n                    retryError\n                );\n                throw new Error(\n                    `Model initialization failed after retry: ${retryError.message}`\n                );\n            }\n        }\n    }\n\n    async checkModel() {\n        if (!fs.existsSync(this.modelPath)) {\n            elizaLogger.info(\"Model file not found, starting download...\");\n            await new Promise<void>((resolve, reject) => {\n                const file = fs.createWriteStream(this.modelPath);\n                let downloadedSize = 0;\n                let totalSize = 0;\n\n                const downloadModel = (url: string) => {\n                    https\n                        .get(url, (response) => {\n                            if (\n                                response.statusCode >= 300 &&\n                                response.statusCode < 400 &&\n                                response.headers.location\n                            ) {\n                                elizaLogger.info(\n                                    `Following redirect to: ${response.headers.location}`\n                                );\n                                downloadModel(response.headers.location);\n                                return;\n                            }\n\n                            if (response.statusCode !== 200) {\n                                reject(\n                                    new Error(\n                                        `Failed to download model: HTTP ${response.statusCode}`\n                                    )\n                                );\n                                return;\n                            }\n\n                            totalSize = parseInt(\n                                response.headers[\"content-length\"] || \"0\",\n                                10\n                            );\n                            elizaLogger.info(\n                                `Downloading model: Hermes-3-Llama-3.1-8B.Q8_0.gguf`\n                            );\n                            elizaLogger.info(\n                                `Download location: ${this.modelPath}`\n                            );\n                            elizaLogger.info(\n                                `Total size: ${(totalSize / 1024 / 1024).toFixed(2)} MB`\n                            );\n\n                            response.pipe(file);\n\n                            let progressString = \"\";\n                            response.on(\"data\", (chunk) => {\n                                downloadedSize += chunk.length;\n                                const progress =\n                                    totalSize > 0\n                                        ? (\n                                              (downloadedSize / totalSize) *\n                                              100\n                                          ).toFixed(1)\n                                        : \"0.0\";\n                                const dots = \".\".repeat(\n                                    Math.floor(Number(progress) / 5)\n                                );\n                                progressString = `Downloading model: [${dots.padEnd(20, \" \")}] ${progress}%`;\n                                elizaLogger.progress(progressString);\n                            });\n\n                            file.on(\"finish\", () => {\n                                file.close();\n                                elizaLogger.progress(\"\"); // Clear the progress line\n                                elizaLogger.success(\"Model download complete\");\n                                resolve();\n                            });\n\n                            response.on(\"error\", (error) => {\n                                fs.unlink(this.modelPath, () => {});\n                                reject(\n                                    new Error(\n                                        `Model download failed: ${error.message}`\n                                    )\n                                );\n                            });\n                        })\n                        .on(\"error\", (error) => {\n                            fs.unlink(this.modelPath, () => {});\n                            reject(\n                                new Error(\n                                    `Model download request failed: ${error.message}`\n                                )\n                            );\n                        });\n                };\n\n                downloadModel(this.modelUrl);\n\n                file.on(\"error\", (err) => {\n                    fs.unlink(this.modelPath, () => {}); // Delete the file async\n                    console.error(\"File write error:\", err.message);\n                    reject(err);\n                });\n            });\n        } else {\n            elizaLogger.warn(\"Model already exists.\");\n        }\n    }\n\n    async deleteModel() {\n        if (fs.existsSync(this.modelPath)) {\n            fs.unlinkSync(this.modelPath);\n        }\n    }\n\n    async queueMessageCompletion(\n        context: string,\n        temperature: number,\n        stop: string[],\n        frequency_penalty: number,\n        presence_penalty: number,\n        max_tokens: number\n    ): Promise<any> {\n        await this.ensureInitialized();\n        return new Promise((resolve, reject) => {\n            this.messageQueue.push({\n                context,\n                temperature,\n                stop,\n                frequency_penalty,\n                presence_penalty,\n                max_tokens,\n                useGrammar: true,\n                resolve,\n                reject,\n            });\n            this.processQueue();\n        });\n    }\n\n    async queueTextCompletion(\n        context: string,\n        temperature: number,\n        stop: string[],\n        frequency_penalty: number,\n        presence_penalty: number,\n        max_tokens: number\n    ): Promise<string> {\n        await this.ensureInitialized();\n\n        return new Promise((resolve, reject) => {\n            this.messageQueue.push({\n                context,\n                temperature,\n                stop,\n                frequency_penalty: frequency_penalty ?? 1.0,\n                presence_penalty: presence_penalty ?? 1.0,\n                max_tokens,\n                useGrammar: false,\n                resolve,\n                reject,\n            });\n            this.processQueue();\n        });\n    }\n\n    private async processQueue() {\n        if (\n            this.isProcessing ||\n            this.messageQueue.length === 0 ||\n            !this.modelInitialized\n        ) {\n            return;\n        }\n\n        this.isProcessing = true;\n\n        while (this.messageQueue.length > 0) {\n            const message = this.messageQueue.shift();\n            if (message) {\n                try {\n                    const response = await this.getCompletionResponse(\n                        message.context,\n                        message.temperature,\n                        message.stop,\n                        message.frequency_penalty,\n                        message.presence_penalty,\n                        message.max_tokens,\n                        message.useGrammar\n                    );\n                    message.resolve(response);\n                } catch (error) {\n                    message.reject(error);\n                }\n            }\n        }\n\n        this.isProcessing = false;\n    }\n\n    async completion(prompt: string, runtime: IAgentRuntime): Promise<string> {\n        try {\n            await this.initialize(runtime);\n\n            if (runtime.modelProvider === ModelProviderName.OLLAMA) {\n                return await this.ollamaCompletion(prompt);\n            }\n\n            return await this.localCompletion(prompt);\n        } catch (error) {\n            elizaLogger.error(\"Error in completion:\", error);\n            throw error;\n        }\n    }\n\n    async embedding(text: string, runtime: IAgentRuntime): Promise<number[]> {\n        try {\n            await this.initialize(runtime);\n\n            if (runtime.modelProvider === ModelProviderName.OLLAMA) {\n                return await this.ollamaEmbedding(text);\n            }\n\n            return await this.localEmbedding(text);\n        } catch (error) {\n            elizaLogger.error(\"Error in embedding:\", error);\n            throw error;\n        }\n    }\n\n    private async getCompletionResponse(\n        context: string,\n        temperature: number,\n        stop: string[],\n        frequency_penalty: number,\n        presence_penalty: number,\n        max_tokens: number,\n        useGrammar: boolean\n    ): Promise<any | string> {\n        const ollamaModel = process.env.OLLAMA_MODEL;\n        if (ollamaModel) {\n            const ollamaUrl =\n                process.env.OLLAMA_SERVER_URL || \"http://localhost:11434\";\n            elizaLogger.info(\n                `Using Ollama API at ${ollamaUrl} with model ${ollamaModel}`\n            );\n\n            const response = await fetch(`${ollamaUrl}/api/generate`, {\n                method: \"POST\",\n                headers: { \"Content-Type\": \"application/json\" },\n                body: JSON.stringify({\n                    model: ollamaModel,\n                    prompt: context,\n                    stream: false,\n                    options: {\n                        temperature,\n                        stop,\n                        frequency_penalty,\n                        presence_penalty,\n                        num_predict: max_tokens,\n                    },\n                }),\n            });\n\n            if (!response.ok) {\n                throw new Error(\n                    `Ollama request failed: ${response.statusText}`\n                );\n            }\n\n            const result = await response.json();\n            return useGrammar ? { content: result.response } : result.response;\n        }\n\n        // Use local GGUF model\n        if (!this.sequence) {\n            throw new Error(\"Model not initialized.\");\n        }\n\n        const tokens = this.model!.tokenize(context);\n\n        // tokenize the words to punish\n        const wordsToPunishTokens = wordsToPunish\n            .map((word) => this.model!.tokenize(word))\n            .flat();\n\n        const repeatPenalty: LlamaContextSequenceRepeatPenalty = {\n            punishTokens: () => wordsToPunishTokens,\n            penalty: 1.2,\n            frequencyPenalty: frequency_penalty,\n            presencePenalty: presence_penalty,\n        };\n\n        const responseTokens: Token[] = [];\n\n        for await (const token of this.sequence.evaluate(tokens, {\n            temperature: Number(temperature),\n            repeatPenalty: repeatPenalty,\n            grammarEvaluationState: useGrammar ? this.grammar : undefined,\n            yieldEogToken: false,\n        })) {\n            const current = this.model.detokenize([...responseTokens, token]);\n            if ([...stop].some((s) => current.includes(s))) {\n                elizaLogger.info(\"Stop sequence found\");\n                break;\n            }\n\n            responseTokens.push(token);\n            process.stdout.write(this.model!.detokenize([token]));\n            if (useGrammar) {\n                if (current.replaceAll(\"\\n\", \"\").includes(\"}```\")) {\n                    elizaLogger.info(\"JSON block found\");\n                    break;\n                }\n            }\n            if (responseTokens.length > max_tokens) {\n                elizaLogger.info(\"Max tokens reached\");\n                break;\n            }\n        }\n\n        const response = this.model!.detokenize(responseTokens);\n\n        if (!response) {\n            throw new Error(\"Response is undefined\");\n        }\n\n        if (useGrammar) {\n            // extract everything between ```json and ```\n            let jsonString = response.match(/```json(.*?)```/s)?.[1].trim();\n            if (!jsonString) {\n                // try parsing response as JSON\n                try {\n                    jsonString = JSON.stringify(JSON.parse(response));\n                } catch {\n                    throw new Error(\"JSON string not found\");\n                }\n            }\n            try {\n                const parsedResponse = JSON.parse(jsonString);\n                if (!parsedResponse) {\n                    throw new Error(\"Parsed response is undefined\");\n                }\n                await this.sequence.clearHistory();\n                return parsedResponse;\n            } catch (error) {\n                elizaLogger.error(\"Error parsing JSON:\", error);\n            }\n        } else {\n            await this.sequence.clearHistory();\n            return response;\n        }\n    }\n\n    async getEmbeddingResponse(input: string): Promise<number[] | undefined> {\n        const ollamaModel = process.env.OLLAMA_MODEL;\n        if (ollamaModel) {\n            const ollamaUrl =\n                process.env.OLLAMA_SERVER_URL || \"http://localhost:11434\";\n            const embeddingModel =\n                process.env.OLLAMA_EMBEDDING_MODEL || \"mxbai-embed-large\";\n            elizaLogger.info(\n                `Using Ollama API for embeddings with model ${embeddingModel} (base: ${ollamaModel})`\n            );\n\n            const response = await fetch(`${ollamaUrl}/api/embeddings`, {\n                method: \"POST\",\n                headers: { \"Content-Type\": \"application/json\" },\n                body: JSON.stringify({\n                    model: embeddingModel,\n                    prompt: input,\n                }),\n            });\n\n            if (!response.ok) {\n                throw new Error(\n                    `Ollama embeddings request failed: ${response.statusText}`\n                );\n            }\n\n            const result = await response.json();\n            return result.embedding;\n        }\n\n        // Use local GGUF model\n        if (!this.sequence) {\n            throw new Error(\"Sequence not initialized\");\n        }\n\n        const ollamaUrl =\n            process.env.OLLAMA_SERVER_URL || \"http://localhost:11434\";\n        const embeddingModel =\n            process.env.OLLAMA_EMBEDDING_MODEL || \"mxbai-embed-large\";\n        elizaLogger.info(\n            `Using Ollama API for embeddings with model ${embeddingModel} (base: ${this.ollamaModel})`\n        );\n\n        const response = await fetch(`${ollamaUrl}/api/embeddings`, {\n            method: \"POST\",\n            headers: {\n                \"Content-Type\": \"application/json\",\n            },\n            body: JSON.stringify({\n                input: input,\n                model: embeddingModel,\n            }),\n        });\n\n        if (!response.ok) {\n            throw new Error(`Failed to get embedding: ${response.statusText}`);\n        }\n\n        const embedding = await response.json();\n        return embedding.vector;\n    }\n\n    private async ollamaCompletion(prompt: string): Promise<string> {\n        const ollamaModel = process.env.OLLAMA_MODEL;\n        const ollamaUrl =\n            process.env.OLLAMA_SERVER_URL || \"http://localhost:11434\";\n        elizaLogger.info(\n            `Using Ollama API at ${ollamaUrl} with model ${ollamaModel}`\n        );\n\n        const response = await fetch(`${ollamaUrl}/api/generate`, {\n            method: \"POST\",\n            headers: { \"Content-Type\": \"application/json\" },\n            body: JSON.stringify({\n                model: ollamaModel,\n                prompt: prompt,\n                stream: false,\n                options: {\n                    temperature: 0.7,\n                    stop: [\"\\n\"],\n                    frequency_penalty: 0.5,\n                    presence_penalty: 0.5,\n                    num_predict: 256,\n                },\n            }),\n        });\n\n        if (!response.ok) {\n            throw new Error(`Ollama request failed: ${response.statusText}`);\n        }\n\n        const result = await response.json();\n        return result.response;\n    }\n\n    private async ollamaEmbedding(text: string): Promise<number[]> {\n        const ollamaModel = process.env.OLLAMA_MODEL;\n        const ollamaUrl =\n            process.env.OLLAMA_SERVER_URL || \"http://localhost:11434\";\n        const embeddingModel =\n            process.env.OLLAMA_EMBEDDING_MODEL || \"mxbai-embed-large\";\n        elizaLogger.info(\n            `Using Ollama API for embeddings with model ${embeddingModel} (base: ${ollamaModel})`\n        );\n\n        const response = await fetch(`${ollamaUrl}/api/embeddings`, {\n            method: \"POST\",\n            headers: { \"Content-Type\": \"application/json\" },\n            body: JSON.stringify({\n                model: embeddingModel,\n                prompt: text,\n            }),\n        });\n\n        if (!response.ok) {\n            throw new Error(\n                `Ollama embeddings request failed: ${response.statusText}`\n            );\n        }\n\n        const result = await response.json();\n        return result.embedding;\n    }\n\n    private async localCompletion(prompt: string): Promise<string> {\n        if (!this.sequence) {\n            throw new Error(\"Sequence not initialized\");\n        }\n\n        const tokens = this.model!.tokenize(prompt);\n\n        // tokenize the words to punish\n        const wordsToPunishTokens = wordsToPunish\n            .map((word) => this.model!.tokenize(word))\n            .flat();\n\n        const repeatPenalty: LlamaContextSequenceRepeatPenalty = {\n            punishTokens: () => wordsToPunishTokens,\n            penalty: 1.2,\n            frequencyPenalty: 0.5,\n            presencePenalty: 0.5,\n        };\n\n        const responseTokens: Token[] = [];\n\n        for await (const token of this.sequence.evaluate(tokens, {\n            temperature: 0.7,\n            repeatPenalty: repeatPenalty,\n            yieldEogToken: false,\n        })) {\n            const current = this.model.detokenize([...responseTokens, token]);\n            if (current.includes(\"\\n\")) {\n                elizaLogger.info(\"Stop sequence found\");\n                break;\n            }\n\n            responseTokens.push(token);\n            process.stdout.write(this.model!.detokenize([token]));\n            if (responseTokens.length > 256) {\n                elizaLogger.info(\"Max tokens reached\");\n                break;\n            }\n        }\n\n        const response = this.model!.detokenize(responseTokens);\n\n        if (!response) {\n            throw new Error(\"Response is undefined\");\n        }\n\n        await this.sequence.clearHistory();\n        return response;\n    }\n\n    private async localEmbedding(text: string): Promise<number[]> {\n        if (!this.sequence) {\n            throw new Error(\"Sequence not initialized\");\n        }\n\n        const embeddingContext = await this.model.createEmbeddingContext();\n        const embedding = await embeddingContext.getEmbeddingFor(text);\n        return embedding?.vector ? [...embedding.vector] : undefined;\n    }\n}\n\nexport default LlamaService;\n","import {\n    IAgentRuntime,\n    IPdfService,\n    Service,\n    ServiceType,\n} from \"@elizaos/core\";\nimport { getDocument, PDFDocumentProxy } from \"pdfjs-dist\";\nimport { TextItem, TextMarkedContent } from \"pdfjs-dist/types/src/display/api\";\n\nexport class PdfService extends Service implements IPdfService {\n    static serviceType: ServiceType = ServiceType.PDF;\n\n    constructor() {\n        super();\n    }\n\n    getInstance(): IPdfService {\n        return PdfService.getInstance();\n    }\n\n    async initialize(_runtime: IAgentRuntime): Promise<void> {}\n\n    async convertPdfToText(pdfBuffer: Buffer): Promise<string> {\n        // Convert Buffer to Uint8Array\n        const uint8Array = new Uint8Array(pdfBuffer);\n\n        const pdf: PDFDocumentProxy = await getDocument({ data: uint8Array })\n            .promise;\n        const numPages = pdf.numPages;\n        const textPages: string[] = [];\n\n        for (let pageNum = 1; pageNum <= numPages; pageNum++) {\n            const page = await pdf.getPage(pageNum);\n            const textContent = await page.getTextContent();\n            const pageText = textContent.items\n                .filter(isTextItem)\n                .map((item) => item.str)\n                .join(\" \");\n            textPages.push(pageText);\n        }\n\n        return textPages.join(\"\\n\");\n    }\n}\n\n// Type guard function\nfunction isTextItem(item: TextItem | TextMarkedContent): item is TextItem {\n    return \"str\" in item;\n}\n","import { PassThrough } from \"stream\";\nimport { Readable } from \"node:stream\";\nimport { ReadableStream } from \"node:stream/web\";\nimport { IAgentRuntime, ISpeechService, ServiceType } from \"@elizaos/core\";\nimport { getWavHeader } from \"./audioUtils.ts\";\nimport { Service } from \"@elizaos/core\";\nimport { validateNodeConfig } from \"../environment.ts\";\nimport * as Echogarden from \"echogarden\";\nimport { elizaLogger } from \"@elizaos/core\";\n\nfunction prependWavHeader(\n    readable: Readable,\n    audioLength: number,\n    sampleRate: number,\n    channelCount: number = 1,\n    bitsPerSample: number = 16\n): Readable {\n    const wavHeader = getWavHeader(\n        audioLength,\n        sampleRate,\n        channelCount,\n        bitsPerSample\n    );\n    let pushedHeader = false;\n    const passThrough = new PassThrough();\n    readable.on(\"data\", function (data) {\n        if (!pushedHeader) {\n            passThrough.push(wavHeader);\n            pushedHeader = true;\n        }\n        passThrough.push(data);\n    });\n    readable.on(\"end\", function () {\n        passThrough.end();\n    });\n    return passThrough;\n}\n\nasync function getVoiceSettings(runtime: IAgentRuntime) {\n    const hasElevenLabs = !!runtime.getSetting(\"ELEVENLABS_XI_API_KEY\");\n    const useVits = !hasElevenLabs;\n\n    // Get voice settings from character card\n    const voiceSettings = runtime.character.settings?.voice;\n    const elevenlabsSettings = voiceSettings?.elevenlabs;\n\n    elizaLogger.debug(\"Voice settings:\", {\n        hasElevenLabs,\n        useVits,\n        voiceSettings,\n        elevenlabsSettings,\n    });\n\n    return {\n        elevenlabsVoiceId:\n            elevenlabsSettings?.voiceId ||\n            runtime.getSetting(\"ELEVENLABS_VOICE_ID\"),\n        elevenlabsModel:\n            elevenlabsSettings?.model ||\n            runtime.getSetting(\"ELEVENLABS_MODEL_ID\") ||\n            \"eleven_monolingual_v1\",\n        elevenlabsStability:\n            elevenlabsSettings?.stability ||\n            runtime.getSetting(\"ELEVENLABS_VOICE_STABILITY\") ||\n            \"0.5\",\n        // ... other ElevenLabs settings ...\n        vitsVoice:\n            voiceSettings?.model ||\n            voiceSettings?.url ||\n            runtime.getSetting(\"VITS_VOICE\") ||\n            \"en_US-hfc_female-medium\",\n        useVits,\n    };\n}\n\nasync function textToSpeech(runtime: IAgentRuntime, text: string) {\n    await validateNodeConfig(runtime);\n    const { elevenlabsVoiceId } = await getVoiceSettings(runtime);\n\n    try {\n        const response = await fetch(\n            `https://api.elevenlabs.io/v1/text-to-speech/${elevenlabsVoiceId}/stream?optimize_streaming_latency=${runtime.getSetting(\"ELEVENLABS_OPTIMIZE_STREAMING_LATENCY\")}&output_format=${runtime.getSetting(\"ELEVENLABS_OUTPUT_FORMAT\")}`,\n            {\n                method: \"POST\",\n                headers: {\n                    \"Content-Type\": \"application/json\",\n                    \"xi-api-key\": runtime.getSetting(\"ELEVENLABS_XI_API_KEY\"),\n                },\n                body: JSON.stringify({\n                    model_id: runtime.getSetting(\"ELEVENLABS_MODEL_ID\"),\n                    text: text,\n                    voice_settings: {\n                        similarity_boost: runtime.getSetting(\n                            \"ELEVENLABS_VOICE_SIMILARITY_BOOST\"\n                        ),\n                        stability: runtime.getSetting(\n                            \"ELEVENLABS_VOICE_STABILITY\"\n                        ),\n                        style: runtime.getSetting(\"ELEVENLABS_VOICE_STYLE\"),\n                        use_speaker_boost: runtime.getSetting(\n                            \"ELEVENLABS_VOICE_USE_SPEAKER_BOOST\"\n                        ),\n                    },\n                }),\n            }\n        );\n\n        const status = response.status;\n        if (status != 200) {\n            const errorBodyString = await response.text();\n            const errorBody = JSON.parse(errorBodyString);\n\n            // Check for quota exceeded error\n            if (\n                status === 401 &&\n                errorBody.detail?.status === \"quota_exceeded\"\n            ) {\n                console.log(\"ElevenLabs quota exceeded, falling back to VITS\");\n                throw new Error(\"QUOTA_EXCEEDED\");\n            }\n\n            throw new Error(\n                `Received status ${status} from Eleven Labs API: ${errorBodyString}`\n            );\n        }\n\n        if (response) {\n            const webStream = ReadableStream.from(\n                response.body as ReadableStream\n            );\n            const reader = webStream.getReader();\n\n            const readable = new Readable({\n                read() {\n                    reader.read().then(({ done, value }) => {\n                        if (done) {\n                            this.push(null);\n                        } else {\n                            this.push(value);\n                        }\n                    });\n                },\n            });\n\n            if (\n                runtime\n                    .getSetting(\"ELEVENLABS_OUTPUT_FORMAT\")\n                    .startsWith(\"pcm_\")\n            ) {\n                const sampleRate = parseInt(\n                    runtime.getSetting(\"ELEVENLABS_OUTPUT_FORMAT\").substring(4)\n                );\n                const withHeader = prependWavHeader(\n                    readable,\n                    1024 * 1024 * 100,\n                    sampleRate,\n                    1,\n                    16\n                );\n                return withHeader;\n            } else {\n                return readable;\n            }\n        } else {\n            return new Readable({\n                read() {},\n            });\n        }\n    } catch (error) {\n        if (error.message === \"QUOTA_EXCEEDED\") {\n            // Fall back to VITS\n            const { vitsVoice } = await getVoiceSettings(runtime);\n            const { audio } = await Echogarden.synthesize(text, {\n                engine: \"vits\",\n                voice: vitsVoice,\n            });\n\n            let wavStream: Readable;\n            if (audio instanceof Buffer) {\n                console.log(\"audio is a buffer\");\n                wavStream = Readable.from(audio);\n            } else if (\"audioChannels\" in audio && \"sampleRate\" in audio) {\n                console.log(\"audio is a RawAudio\");\n                const floatBuffer = Buffer.from(audio.audioChannels[0].buffer);\n                console.log(\"buffer length: \", floatBuffer.length);\n\n                // Get the sample rate from the RawAudio object\n                const sampleRate = audio.sampleRate;\n\n                // Create a Float32Array view of the floatBuffer\n                const floatArray = new Float32Array(floatBuffer.buffer);\n\n                // Convert 32-bit float audio to 16-bit PCM\n                const pcmBuffer = new Int16Array(floatArray.length);\n                for (let i = 0; i < floatArray.length; i++) {\n                    pcmBuffer[i] = Math.round(floatArray[i] * 32767);\n                }\n\n                // Prepend WAV header to the buffer\n                const wavHeaderBuffer = getWavHeader(\n                    pcmBuffer.length * 2,\n                    sampleRate,\n                    1,\n                    16\n                );\n                const wavBuffer = Buffer.concat([\n                    wavHeaderBuffer,\n                    Buffer.from(pcmBuffer.buffer),\n                ]);\n\n                wavStream = Readable.from(wavBuffer);\n            } else {\n                throw new Error(\"Unsupported audio format\");\n            }\n            return wavStream;\n        }\n        throw error; // Re-throw other errors\n    }\n}\n\nasync function processVitsAudio(audio: any): Promise<Readable> {\n    let wavStream: Readable;\n    if (audio instanceof Buffer) {\n        console.log(\"audio is a buffer\");\n        wavStream = Readable.from(audio);\n    } else if (\"audioChannels\" in audio && \"sampleRate\" in audio) {\n        console.log(\"audio is a RawAudio\");\n        const floatBuffer = Buffer.from(audio.audioChannels[0].buffer);\n        console.log(\"buffer length: \", floatBuffer.length);\n\n        const sampleRate = audio.sampleRate;\n        const floatArray = new Float32Array(floatBuffer.buffer);\n        const pcmBuffer = new Int16Array(floatArray.length);\n\n        for (let i = 0; i < floatArray.length; i++) {\n            pcmBuffer[i] = Math.round(floatArray[i] * 32767);\n        }\n\n        const wavHeaderBuffer = getWavHeader(\n            pcmBuffer.length * 2,\n            sampleRate,\n            1,\n            16\n        );\n        const wavBuffer = Buffer.concat([\n            wavHeaderBuffer,\n            Buffer.from(pcmBuffer.buffer),\n        ]);\n        wavStream = Readable.from(wavBuffer);\n    } else {\n        throw new Error(\"Unsupported audio format\");\n    }\n    return wavStream;\n}\n\nasync function generateVitsAudio(\n    runtime: IAgentRuntime,\n    text: string\n): Promise<Readable> {\n    const { vitsVoice } = await getVoiceSettings(runtime);\n    const { audio } = await Echogarden.synthesize(text, {\n        engine: \"vits\",\n        voice: vitsVoice,\n    });\n    return processVitsAudio(audio);\n}\n\nexport class SpeechService extends Service implements ISpeechService {\n    static serviceType: ServiceType = ServiceType.SPEECH_GENERATION;\n\n    async initialize(_runtime: IAgentRuntime): Promise<void> {}\n\n    getInstance(): ISpeechService {\n        return SpeechService.getInstance();\n    }\n\n    async generate(runtime: IAgentRuntime, text: string): Promise<Readable> {\n        try {\n            const { useVits } = await getVoiceSettings(runtime);\n\n            if (useVits || !runtime.getSetting(\"ELEVENLABS_XI_API_KEY\")) {\n                return await generateVitsAudio(runtime, text);\n            }\n\n            return await textToSpeech(runtime, text);\n        } catch (error) {\n            console.error(\"Speech generation error:\", error);\n            return await generateVitsAudio(runtime, text);\n        }\n    }\n}\n","export function getWavHeader(\n    audioLength: number,\n    sampleRate: number,\n    channelCount: number = 1,\n    bitsPerSample: number = 16\n): Buffer {\n    const wavHeader = Buffer.alloc(44);\n    wavHeader.write(\"RIFF\", 0);\n    wavHeader.writeUInt32LE(36 + audioLength, 4); // Length of entire file in bytes minus 8\n    wavHeader.write(\"WAVE\", 8);\n    wavHeader.write(\"fmt \", 12);\n    wavHeader.writeUInt32LE(16, 16); // Length of format data\n    wavHeader.writeUInt16LE(1, 20); // Type of format (1 is PCM)\n    wavHeader.writeUInt16LE(channelCount, 22); // Number of channels\n    wavHeader.writeUInt32LE(sampleRate, 24); // Sample rate\n    wavHeader.writeUInt32LE(\n        (sampleRate * bitsPerSample * channelCount) / 8,\n        28\n    ); // Byte rate\n    wavHeader.writeUInt16LE((bitsPerSample * channelCount) / 8, 32); // Block align ((BitsPerSample * Channels) / 8)\n    wavHeader.writeUInt16LE(bitsPerSample, 34); // Bits per sample\n    wavHeader.write(\"data\", 36); // Data chunk header\n    wavHeader.writeUInt32LE(audioLength, 40); // Data chunk size\n    return wavHeader;\n}\n","import { IAgentRuntime } from \"@elizaos/core\";\nimport { z } from \"zod\";\n\nexport const nodeEnvSchema = z.object({\n    OPENAI_API_KEY: z.string().min(1, \"OpenAI API key is required\"),\n\n    // Core settings\n    ELEVENLABS_XI_API_KEY: z.string().optional(),\n\n    // All other settings optional with defaults\n    ELEVENLABS_MODEL_ID: z.string().optional(),\n    ELEVENLABS_VOICE_ID: z.string().optional(),\n    ELEVENLABS_VOICE_STABILITY: z.string().optional(),\n    ELEVENLABS_VOICE_SIMILARITY_BOOST: z.string().optional(),\n    ELEVENLABS_VOICE_STYLE: z.string().optional(),\n    ELEVENLABS_VOICE_USE_SPEAKER_BOOST: z.string().optional(),\n    ELEVENLABS_OPTIMIZE_STREAMING_LATENCY: z.string().optional(),\n    ELEVENLABS_OUTPUT_FORMAT: z.string().optional(),\n    VITS_VOICE: z.string().optional(),\n    VITS_MODEL: z.string().optional(),\n});\n\nexport type NodeConfig = z.infer<typeof nodeEnvSchema>;\n\nexport async function validateNodeConfig(\n    runtime: IAgentRuntime\n): Promise<NodeConfig> {\n    try {\n        const voiceSettings = runtime.character.settings?.voice;\n        const elevenlabs = voiceSettings?.elevenlabs;\n\n        // Only include what's absolutely required\n        const config = {\n            OPENAI_API_KEY:\n                runtime.getSetting(\"OPENAI_API_KEY\") ||\n                process.env.OPENAI_API_KEY,\n            ELEVENLABS_XI_API_KEY:\n                runtime.getSetting(\"ELEVENLABS_XI_API_KEY\") ||\n                process.env.ELEVENLABS_XI_API_KEY,\n\n            // Use character card settings first, fall back to env vars, then defaults\n            ...(runtime.getSetting(\"ELEVENLABS_XI_API_KEY\") && {\n                ELEVENLABS_MODEL_ID:\n                    elevenlabs?.model ||\n                    process.env.ELEVENLABS_MODEL_ID ||\n                    \"eleven_monolingual_v1\",\n                ELEVENLABS_VOICE_ID:\n                    elevenlabs?.voiceId || process.env.ELEVENLABS_VOICE_ID,\n                ELEVENLABS_VOICE_STABILITY:\n                    elevenlabs?.stability ||\n                    process.env.ELEVENLABS_VOICE_STABILITY ||\n                    \"0.5\",\n                ELEVENLABS_VOICE_SIMILARITY_BOOST:\n                    elevenlabs?.similarityBoost ||\n                    process.env.ELEVENLABS_VOICE_SIMILARITY_BOOST ||\n                    \"0.75\",\n                ELEVENLABS_VOICE_STYLE:\n                    elevenlabs?.style ||\n                    process.env.ELEVENLABS_VOICE_STYLE ||\n                    \"0\",\n                ELEVENLABS_VOICE_USE_SPEAKER_BOOST:\n                    elevenlabs?.useSpeakerBoost ||\n                    process.env.ELEVENLABS_VOICE_USE_SPEAKER_BOOST ||\n                    \"true\",\n                ELEVENLABS_OPTIMIZE_STREAMING_LATENCY:\n                    process.env.ELEVENLABS_OPTIMIZE_STREAMING_LATENCY || \"0\",\n                ELEVENLABS_OUTPUT_FORMAT:\n                    process.env.ELEVENLABS_OUTPUT_FORMAT || \"pcm_16000\",\n            }),\n\n            // VITS settings\n            VITS_VOICE: voiceSettings?.model || process.env.VITS_VOICE,\n            VITS_MODEL: process.env.VITS_MODEL,\n\n            // AWS settings (only include if present)\n            ...(runtime.getSetting(\"AWS_ACCESS_KEY_ID\") && {\n                AWS_ACCESS_KEY_ID: runtime.getSetting(\"AWS_ACCESS_KEY_ID\"),\n                AWS_SECRET_ACCESS_KEY: runtime.getSetting(\n                    \"AWS_SECRET_ACCESS_KEY\"\n                ),\n                AWS_REGION: runtime.getSetting(\"AWS_REGION\"),\n                AWS_S3_BUCKET: runtime.getSetting(\"AWS_S3_BUCKET\"),\n                AWS_S3_UPLOAD_PATH: runtime.getSetting(\"AWS_S3_UPLOAD_PATH\"),\n            }),\n        };\n\n        return nodeEnvSchema.parse(config);\n    } catch (error) {\n        if (error instanceof z.ZodError) {\n            const errorMessages = error.errors\n                .map((err) => `${err.path.join(\".\")}: ${err.message}`)\n                .join(\"\\n\");\n            throw new Error(\n                `Node configuration validation failed:\\n${errorMessages}`\n            );\n        }\n        throw error;\n    }\n}\n","import {\n    elizaLogger,\n    IAgentRuntime,\n    ITranscriptionService,\n    settings,\n    TranscriptionProvider,\n} from \"@elizaos/core\";\nimport { Service, ServiceType } from \"@elizaos/core\";\nimport { exec } from \"child_process\";\nimport { File } from \"formdata-node\";\nimport fs from \"fs\";\nimport { nodewhisper } from \"nodejs-whisper\";\nimport OpenAI from \"openai\"; // todo, can probably move this to model provider or whateer\nimport os from \"os\";\nimport path from \"path\";\nimport { fileURLToPath } from \"url\";\nimport { promisify } from \"util\";\nimport { createClient, DeepgramClient } from \"@deepgram/sdk\";\n\n// const __dirname = path.dirname(new URL(import.meta.url).pathname); #compatibility issues with windows\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\n\nconst execAsync = promisify(exec);\n\nexport class TranscriptionService\n    extends Service\n    implements ITranscriptionService\n{\n    private runtime: IAgentRuntime | null = null;\n    static serviceType: ServiceType = ServiceType.TRANSCRIPTION;\n    private CONTENT_CACHE_DIR: string;\n    private DEBUG_AUDIO_DIR: string;\n    private TARGET_SAMPLE_RATE = 16000; // Common sample rate for speech recognition\n    private isCudaAvailable: boolean = false;\n\n    /**\n     * CHANGED: We now use TranscriptionProvider instead of separate flags/strings.\n     * This allows us to handle character settings, env variables, and fallback logic.\n     */\n    private transcriptionProvider: TranscriptionProvider | null = null;\n\n    private deepgram: DeepgramClient | null = null;\n    private openai: OpenAI | null = null;\n\n    /**\n     * We keep the queue and processing logic as is.\n     */\n    private queue: { audioBuffer: ArrayBuffer; resolve: Function }[] = [];\n    private processing: boolean = false;\n\n    /**\n     * CHANGED: initialize() now checks:\n     * 1) character.settings.transcription (if available and keys exist),\n     * 2) then the .env TRANSCRIPTION_PROVIDER,\n     * 3) then old fallback logic (Deepgram -> OpenAI -> local).\n     */\n    async initialize(_runtime: IAgentRuntime): Promise<void> {\n        this.runtime = _runtime;\n\n        // 1) Check character settings\n        let chosenProvider: TranscriptionProvider | null = null;\n        const charSetting = this.runtime.character?.settings?.transcription;\n\n        if (charSetting === TranscriptionProvider.Deepgram) {\n            const deepgramKey = this.runtime.getSetting(\"DEEPGRAM_API_KEY\");\n            if (deepgramKey) {\n                this.deepgram = createClient(deepgramKey);\n                chosenProvider = TranscriptionProvider.Deepgram;\n            }\n        } else if (charSetting === TranscriptionProvider.OpenAI) {\n            const openaiKey = this.runtime.getSetting(\"OPENAI_API_KEY\");\n            if (openaiKey) {\n                this.openai = new OpenAI({ apiKey: openaiKey });\n                chosenProvider = TranscriptionProvider.OpenAI;\n            }\n        } else if (charSetting === TranscriptionProvider.Local) {\n            chosenProvider = TranscriptionProvider.Local;\n        }\n\n        // 2) If not chosen from character, check .env\n        if (!chosenProvider) {\n            const envProvider = this.runtime.getSetting(\"TRANSCRIPTION_PROVIDER\");\n            if (envProvider) {\n                switch (envProvider.toLowerCase()) {\n                    case \"deepgram\":\n                    {\n                        const dgKey = this.runtime.getSetting(\"DEEPGRAM_API_KEY\");\n                        if (dgKey) {\n                            this.deepgram = createClient(dgKey);\n                            chosenProvider = TranscriptionProvider.Deepgram;\n                        }\n                    }\n                        break;\n                    case \"openai\":\n                    {\n                        const openaiKey = this.runtime.getSetting(\"OPENAI_API_KEY\");\n                        if (openaiKey) {\n                            this.openai = new OpenAI({ apiKey: openaiKey });\n                            chosenProvider = TranscriptionProvider.OpenAI;\n                        }\n                    }\n                        break;\n                    case \"local\":\n                        chosenProvider = TranscriptionProvider.Local;\n                        break;\n                }\n            }\n        }\n\n        // 3) If still none, fallback to old logic: Deepgram -> OpenAI -> local\n        if (!chosenProvider) {\n            const deepgramKey = this.runtime.getSetting(\"DEEPGRAM_API_KEY\");\n            if (deepgramKey) {\n                this.deepgram = createClient(deepgramKey);\n                chosenProvider = TranscriptionProvider.Deepgram;\n            } else {\n                const openaiKey = this.runtime.getSetting(\"OPENAI_API_KEY\");\n                if (openaiKey) {\n                    this.openai = new OpenAI({ apiKey: openaiKey });\n                    chosenProvider = TranscriptionProvider.OpenAI;\n                } else {\n                    chosenProvider = TranscriptionProvider.Local;\n                }\n            }\n        }\n\n        this.transcriptionProvider = chosenProvider;\n\n        // Leave detectCuda as is.\n        this.detectCuda();\n    }\n\n    constructor() {\n        super();\n        const rootDir = path.resolve(__dirname, \"../../\");\n        this.CONTENT_CACHE_DIR = path.join(rootDir, \"content_cache\");\n        this.DEBUG_AUDIO_DIR = path.join(rootDir, \"debug_audio\");\n        this.ensureCacheDirectoryExists();\n        this.ensureDebugDirectoryExists();\n        // TODO: It'd be nice to handle this more gracefully, but we can do local transcription for now\n        // TODO: remove the runtime from here, use it when called\n        // if (runtime.getSetting(\"OPENAI_API_KEY\")) {\n        //     this.openai = new OpenAI({\n        //         apiKey: runtime.getSetting(\"OPENAI_API_KEY\"),\n        //     });\n        // } else {\n        //     this.detectCuda();\n        // }\n    }\n\n    private ensureCacheDirectoryExists() {\n        if (!fs.existsSync(this.CONTENT_CACHE_DIR)) {\n            fs.mkdirSync(this.CONTENT_CACHE_DIR, { recursive: true });\n        }\n    }\n\n    private ensureDebugDirectoryExists() {\n        if (!fs.existsSync(this.DEBUG_AUDIO_DIR)) {\n            fs.mkdirSync(this.DEBUG_AUDIO_DIR, { recursive: true });\n        }\n    }\n\n    private detectCuda() {\n        const platform = os.platform();\n        if (platform === \"linux\") {\n            try {\n                fs.accessSync(\"/usr/local/cuda/bin/nvcc\", fs.constants.X_OK);\n                this.isCudaAvailable = true;\n                console.log(\n                    \"CUDA detected. Transcription will use CUDA acceleration.\"\n                );\n                // eslint-disable-next-line\n            } catch (_error) {\n                console.log(\n                    \"CUDA not detected. Transcription will run on CPU.\"\n                );\n            }\n        } else if (platform === \"win32\") {\n            const cudaPath = path.join(\n                settings.CUDA_PATH ||\n                \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.0\",\n                \"bin\",\n                \"nvcc.exe\"\n            );\n            if (fs.existsSync(cudaPath)) {\n                this.isCudaAvailable = true;\n                console.log(\n                    \"CUDA detected. Transcription will use CUDA acceleration.\"\n                );\n            } else {\n                console.log(\n                    \"CUDA not detected. Transcription will run on CPU.\"\n                );\n            }\n        } else {\n            console.log(\n                \"CUDA not supported on this platform. Transcription will run on CPU.\"\n            );\n        }\n    }\n\n    private async convertAudio(inputBuffer: ArrayBuffer): Promise<Buffer> {\n        const inputPath = path.join(\n            this.CONTENT_CACHE_DIR,\n            `input_${Date.now()}.wav`\n        );\n        const outputPath = path.join(\n            this.CONTENT_CACHE_DIR,\n            `output_${Date.now()}.wav`\n        );\n\n        fs.writeFileSync(inputPath, Buffer.from(inputBuffer));\n\n        try {\n            const { stdout } = await execAsync(\n                `ffprobe -v error -show_entries stream=codec_name,sample_rate,channels -of json \"${inputPath}\"`\n            );\n            const probeResult = JSON.parse(stdout);\n            const stream = probeResult.streams[0];\n\n            elizaLogger.log(\"Input audio info:\", stream);\n\n            let ffmpegCommand = `ffmpeg -i \"${inputPath}\" -ar ${this.TARGET_SAMPLE_RATE} -ac 1`;\n\n            if (stream.codec_name === \"pcm_f32le\") {\n                ffmpegCommand += \" -acodec pcm_s16le\";\n            }\n\n            ffmpegCommand += ` \"${outputPath}\"`;\n\n            elizaLogger.log(\"FFmpeg command:\", ffmpegCommand);\n\n            await execAsync(ffmpegCommand);\n\n            const convertedBuffer = fs.readFileSync(outputPath);\n            fs.unlinkSync(inputPath);\n            fs.unlinkSync(outputPath);\n            return convertedBuffer;\n        } catch (error) {\n            elizaLogger.error(\"Error converting audio:\", error);\n            throw error;\n        }\n    }\n\n    private async saveDebugAudio(audioBuffer: ArrayBuffer, prefix: string) {\n        this.ensureDebugDirectoryExists();\n\n        const filename = `${prefix}_${Date.now()}.wav`;\n        const filePath = path.join(this.DEBUG_AUDIO_DIR, filename);\n\n        fs.writeFileSync(filePath, Buffer.from(audioBuffer));\n        elizaLogger.log(`Debug audio saved: ${filePath}`);\n    }\n\n    public async transcribeAttachment(\n        audioBuffer: ArrayBuffer\n    ): Promise<string | null> {\n        return await this.transcribe(audioBuffer);\n    }\n\n    /**\n     * If the audio buffer is too short, return null. Otherwise push to queue.\n     */\n    public async transcribe(audioBuffer: ArrayBuffer): Promise<string | null> {\n        // if the audio buffer is less than .2 seconds, just return null\n        if (audioBuffer.byteLength < 0.2 * 16000) {\n            return null;\n        }\n        return new Promise((resolve) => {\n            this.queue.push({ audioBuffer, resolve });\n            if (!this.processing) {\n                this.processQueue();\n            }\n        });\n    }\n\n    public async transcribeAttachmentLocally(\n        audioBuffer: ArrayBuffer\n    ): Promise<string | null> {\n        return this.transcribeLocally(audioBuffer);\n    }\n\n    /**\n     * CHANGED: processQueue() uses the final transcriptionProvider enum set in initialize().\n     */\n    private async processQueue(): Promise<void> {\n        // Exit if already processing or if the queue is empty\n        if (this.processing || this.queue.length === 0) return;\n        this.processing = true;\n\n        while (this.queue.length > 0) {\n            const { audioBuffer, resolve } = this.queue.shift()!;\n            let result: string | null = null;\n\n            switch (this.transcriptionProvider) {\n                case TranscriptionProvider.Deepgram:\n                    result = await this.transcribeWithDeepgram(audioBuffer);\n                    break;\n                case TranscriptionProvider.OpenAI:\n                    result = await this.transcribeWithOpenAI(audioBuffer);\n                    break;\n                default:\n                    result = await this.transcribeLocally(audioBuffer);\n            }\n\n            resolve(result);\n        }\n\n        this.processing = false;\n    }\n\n    /**\n     * Original logic from main is now handled by the final fallback in initialize().\n     * We'll keep transcribeUsingDefaultLogic() if needed by other code references,\n     * but it’s no longer invoked in the new flow.\n     */\n    private async transcribeUsingDefaultLogic(audioBuffer: ArrayBuffer): Promise<string | null> {\n        if (this.deepgram) {\n            return await this.transcribeWithDeepgram(audioBuffer);\n        } else if (this.openai) {\n            return await this.transcribeWithOpenAI(audioBuffer);\n        }\n        return await this.transcribeLocally(audioBuffer);\n    }\n\n    private async transcribeWithDeepgram(\n        audioBuffer: ArrayBuffer\n    ): Promise<string | null> {\n        const buffer = Buffer.from(audioBuffer);\n        const response = await this.deepgram.listen.prerecorded.transcribeFile(\n            buffer,\n            {\n                model: \"nova-2\",\n                language: \"en-US\",\n                smart_format: true,\n            }\n        );\n        const result =\n            response.result.results.channels[0].alternatives[0].transcript;\n        return result;\n    }\n\n    private async transcribeWithOpenAI(\n        audioBuffer: ArrayBuffer\n    ): Promise<string | null> {\n        elizaLogger.log(\"Transcribing audio with OpenAI...\");\n\n        try {\n            await this.saveDebugAudio(audioBuffer, \"openai_input_original\");\n\n            const convertedBuffer = await this.convertAudio(audioBuffer);\n\n            await this.saveDebugAudio(\n                convertedBuffer,\n                \"openai_input_converted\"\n            );\n\n            const file = new File([convertedBuffer], \"audio.wav\", {\n                type: \"audio/wav\",\n            });\n\n            const result = await this.openai!.audio.transcriptions.create({\n                model: \"whisper-1\",\n                language: \"en\",\n                response_format: \"text\",\n                file: file,\n            });\n\n            const trimmedResult = (result as any).trim();\n            elizaLogger.log(`OpenAI speech to text result: \"${trimmedResult}\"`);\n\n            return trimmedResult;\n        } catch (error) {\n            elizaLogger.error(\n                \"Error in OpenAI speech-to-text conversion:\",\n                error\n            );\n            if (error.response) {\n                elizaLogger.error(\"Response data:\", error.response.data);\n                elizaLogger.error(\"Response status:\", error.response.status);\n                elizaLogger.error(\"Response headers:\", error.response.headers);\n            } else if (error.request) {\n                elizaLogger.error(\"No response received:\", error.request);\n            } else {\n                elizaLogger.error(\"Error setting up request:\", error.message);\n            }\n            return null;\n        }\n    }\n\n    /**\n     * Local transcription with nodejs-whisper. We keep it as it was,\n     * just making sure to handle CUDA if available.\n     */\n    public async transcribeLocally(\n        audioBuffer: ArrayBuffer\n    ): Promise<string | null> {\n        try {\n            elizaLogger.log(\"Transcribing audio locally...\");\n\n            await this.saveDebugAudio(audioBuffer, \"local_input_original\");\n\n            const convertedBuffer = await this.convertAudio(audioBuffer);\n\n            await this.saveDebugAudio(convertedBuffer, \"local_input_converted\");\n\n            const tempWavFile = path.join(\n                this.CONTENT_CACHE_DIR,\n                `temp_${Date.now()}.wav`\n            );\n            fs.writeFileSync(tempWavFile, convertedBuffer);\n\n            elizaLogger.debug(`Temporary WAV file created: ${tempWavFile}`);\n\n            let output = await nodewhisper(tempWavFile, {\n                modelName: \"base.en\",\n                autoDownloadModelName: \"base.en\",\n                verbose: false,\n                removeWavFileAfterTranscription: false,\n                withCuda: this.isCudaAvailable,\n                whisperOptions: {\n                    outputInText: true,\n                    outputInVtt: false,\n                    outputInSrt: false,\n                    outputInCsv: false,\n                    translateToEnglish: false,\n                    wordTimestamps: false,\n                    timestamps_length: 60,\n                    // splitOnWord: true,\n                },\n            });\n\n            output = output\n                .split(\"\\n\")\n                .map((line) => {\n                    if (line.trim().startsWith(\"[\")) {\n                        const endIndex = line.indexOf(\"]\");\n                        return line.substring(endIndex + 1);\n                    }\n                    return line;\n                })\n                .join(\"\\n\");\n\n            fs.unlinkSync(tempWavFile);\n\n            if (!output || output.length < 5) {\n                elizaLogger.log(\"Output is null or too short, returning null\");\n                return null;\n            }\n            return output;\n        } catch (error) {\n            elizaLogger.error(\n                \"Error in local speech-to-text conversion:\",\n                error\n            );\n            return null;\n        }\n    }\n}\n","import type { Format } from './types';\n\nexport const default_format: Format = 'RFC3986';\nexport const formatters: Record<Format, (str: PropertyKey) => string> = {\n  RFC1738: (v: PropertyKey) => String(v).replace(/%20/g, '+'),\n  RFC3986: (v: PropertyKey) => String(v),\n};\nexport const RFC1738 = 'RFC1738';\nexport const RFC3986 = 'RFC3986';\n","import { RFC1738 } from './formats';\nimport type { DefaultEncoder, Format } from './types';\n\nconst has = Object.prototype.hasOwnProperty;\nconst is_array = Array.isArray;\n\nconst hex_table = (() => {\n  const array = [];\n  for (let i = 0; i < 256; ++i) {\n    array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n  }\n\n  return array;\n})();\n\nfunction compact_queue<T extends Record<string, any>>(queue: Array<{ obj: T; prop: string }>) {\n  while (queue.length > 1) {\n    const item = queue.pop();\n    if (!item) continue;\n\n    const obj = item.obj[item.prop];\n\n    if (is_array(obj)) {\n      const compacted: unknown[] = [];\n\n      for (let j = 0; j < obj.length; ++j) {\n        if (typeof obj[j] !== 'undefined') {\n          compacted.push(obj[j]);\n        }\n      }\n\n      // @ts-ignore\n      item.obj[item.prop] = compacted;\n    }\n  }\n}\n\nfunction array_to_object(source: any[], options: { plainObjects: boolean }) {\n  const obj = options && options.plainObjects ? Object.create(null) : {};\n  for (let i = 0; i < source.length; ++i) {\n    if (typeof source[i] !== 'undefined') {\n      obj[i] = source[i];\n    }\n  }\n\n  return obj;\n}\n\nexport function merge(\n  target: any,\n  source: any,\n  options: { plainObjects?: boolean; allowPrototypes?: boolean } = {},\n) {\n  if (!source) {\n    return target;\n  }\n\n  if (typeof source !== 'object') {\n    if (is_array(target)) {\n      target.push(source);\n    } else if (target && typeof target === 'object') {\n      if (\n        (options && (options.plainObjects || options.allowPrototypes)) ||\n        !has.call(Object.prototype, source)\n      ) {\n        target[source] = true;\n      }\n    } else {\n      return [target, source];\n    }\n\n    return target;\n  }\n\n  if (!target || typeof target !== 'object') {\n    return [target].concat(source);\n  }\n\n  let mergeTarget = target;\n  if (is_array(target) && !is_array(source)) {\n    // @ts-ignore\n    mergeTarget = array_to_object(target, options);\n  }\n\n  if (is_array(target) && is_array(source)) {\n    source.forEach(function (item, i) {\n      if (has.call(target, i)) {\n        const targetItem = target[i];\n        if (targetItem && typeof targetItem === 'object' && item && typeof item === 'object') {\n          target[i] = merge(targetItem, item, options);\n        } else {\n          target.push(item);\n        }\n      } else {\n        target[i] = item;\n      }\n    });\n    return target;\n  }\n\n  return Object.keys(source).reduce(function (acc, key) {\n    const value = source[key];\n\n    if (has.call(acc, key)) {\n      acc[key] = merge(acc[key], value, options);\n    } else {\n      acc[key] = value;\n    }\n    return acc;\n  }, mergeTarget);\n}\n\nexport function assign_single_source(target: any, source: any) {\n  return Object.keys(source).reduce(function (acc, key) {\n    acc[key] = source[key];\n    return acc;\n  }, target);\n}\n\nexport function decode(str: string, _: any, charset: string) {\n  const strWithoutPlus = str.replace(/\\+/g, ' ');\n  if (charset === 'iso-8859-1') {\n    // unescape never throws, no try...catch needed:\n    return strWithoutPlus.replace(/%[0-9a-f]{2}/gi, unescape);\n  }\n  // utf-8\n  try {\n    return decodeURIComponent(strWithoutPlus);\n  } catch (e) {\n    return strWithoutPlus;\n  }\n}\n\nconst limit = 1024;\n\nexport const encode: (\n  str: any,\n  defaultEncoder: DefaultEncoder,\n  charset: string,\n  type: 'key' | 'value',\n  format: Format,\n) => string = (str, _defaultEncoder, charset, _kind, format: Format) => {\n  // This code was originally written by Brian White for the io.js core querystring library.\n  // It has been adapted here for stricter adherence to RFC 3986\n  if (str.length === 0) {\n    return str;\n  }\n\n  let string = str;\n  if (typeof str === 'symbol') {\n    string = Symbol.prototype.toString.call(str);\n  } else if (typeof str !== 'string') {\n    string = String(str);\n  }\n\n  if (charset === 'iso-8859-1') {\n    return escape(string).replace(/%u[0-9a-f]{4}/gi, function ($0) {\n      return '%26%23' + parseInt($0.slice(2), 16) + '%3B';\n    });\n  }\n\n  let out = '';\n  for (let j = 0; j < string.length; j += limit) {\n    const segment = string.length >= limit ? string.slice(j, j + limit) : string;\n    const arr = [];\n\n    for (let i = 0; i < segment.length; ++i) {\n      let c = segment.charCodeAt(i);\n      if (\n        c === 0x2d || // -\n        c === 0x2e || // .\n        c === 0x5f || // _\n        c === 0x7e || // ~\n        (c >= 0x30 && c <= 0x39) || // 0-9\n        (c >= 0x41 && c <= 0x5a) || // a-z\n        (c >= 0x61 && c <= 0x7a) || // A-Z\n        (format === RFC1738 && (c === 0x28 || c === 0x29)) // ( )\n      ) {\n        arr[arr.length] = segment.charAt(i);\n        continue;\n      }\n\n      if (c < 0x80) {\n        arr[arr.length] = hex_table[c];\n        continue;\n      }\n\n      if (c < 0x800) {\n        arr[arr.length] = hex_table[0xc0 | (c >> 6)]! + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      if (c < 0xd800 || c >= 0xe000) {\n        arr[arr.length] =\n          hex_table[0xe0 | (c >> 12)]! + hex_table[0x80 | ((c >> 6) & 0x3f)] + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      i += 1;\n      c = 0x10000 + (((c & 0x3ff) << 10) | (segment.charCodeAt(i) & 0x3ff));\n\n      arr[arr.length] =\n        hex_table[0xf0 | (c >> 18)]! +\n        hex_table[0x80 | ((c >> 12) & 0x3f)] +\n        hex_table[0x80 | ((c >> 6) & 0x3f)] +\n        hex_table[0x80 | (c & 0x3f)];\n    }\n\n    out += arr.join('');\n  }\n\n  return out;\n};\n\nexport function compact(value: any) {\n  const queue = [{ obj: { o: value }, prop: 'o' }];\n  const refs = [];\n\n  for (let i = 0; i < queue.length; ++i) {\n    const item = queue[i];\n    // @ts-ignore\n    const obj = item.obj[item.prop];\n\n    const keys = Object.keys(obj);\n    for (let j = 0; j < keys.length; ++j) {\n      const key = keys[j]!;\n      const val = obj[key];\n      if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {\n        queue.push({ obj: obj, prop: key });\n        refs.push(val);\n      }\n    }\n  }\n\n  compact_queue(queue);\n\n  return value;\n}\n\nexport function is_regexp(obj: any) {\n  return Object.prototype.toString.call(obj) === '[object RegExp]';\n}\n\nexport function is_buffer(obj: any) {\n  if (!obj || typeof obj !== 'object') {\n    return false;\n  }\n\n  return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n}\n\nexport function combine(a: any, b: any) {\n  return [].concat(a, b);\n}\n\nexport function maybe_map<T>(val: T[], fn: (v: T) => T) {\n  if (is_array(val)) {\n    const mapped = [];\n    for (let i = 0; i < val.length; i += 1) {\n      mapped.push(fn(val[i]!));\n    }\n    return mapped;\n  }\n  return fn(val);\n}\n","import { encode, is_buffer, maybe_map } from './utils';\nimport { default_format, formatters } from './formats';\nimport type { NonNullableProperties, StringifyOptions } from './types';\n\nconst has = Object.prototype.hasOwnProperty;\n\nconst array_prefix_generators = {\n  brackets(prefix: PropertyKey) {\n    return String(prefix) + '[]';\n  },\n  comma: 'comma',\n  indices(prefix: PropertyKey, key: string) {\n    return String(prefix) + '[' + key + ']';\n  },\n  repeat(prefix: PropertyKey) {\n    return String(prefix);\n  },\n};\n\nconst is_array = Array.isArray;\nconst push = Array.prototype.push;\nconst push_to_array = function (arr: any[], value_or_array: any) {\n  push.apply(arr, is_array(value_or_array) ? value_or_array : [value_or_array]);\n};\n\nconst to_ISO = Date.prototype.toISOString;\n\nconst defaults = {\n  addQueryPrefix: false,\n  allowDots: false,\n  allowEmptyArrays: false,\n  arrayFormat: 'indices',\n  charset: 'utf-8',\n  charsetSentinel: false,\n  delimiter: '&',\n  encode: true,\n  encodeDotInKeys: false,\n  encoder: encode,\n  encodeValuesOnly: false,\n  format: default_format,\n  formatter: formatters[default_format],\n  /** @deprecated */\n  indices: false,\n  serializeDate(date) {\n    return to_ISO.call(date);\n  },\n  skipNulls: false,\n  strictNullHandling: false,\n} as NonNullableProperties<StringifyOptions & { formatter: (typeof formatters)['RFC1738'] }>;\n\nfunction is_non_nullish_primitive(v: unknown): v is string | number | boolean | symbol | bigint {\n  return (\n    typeof v === 'string' ||\n    typeof v === 'number' ||\n    typeof v === 'boolean' ||\n    typeof v === 'symbol' ||\n    typeof v === 'bigint'\n  );\n}\n\nconst sentinel = {};\n\nfunction inner_stringify(\n  object: any,\n  prefix: PropertyKey,\n  generateArrayPrefix: StringifyOptions['arrayFormat'] | ((prefix: string, key: string) => string),\n  commaRoundTrip: boolean,\n  allowEmptyArrays: boolean,\n  strictNullHandling: boolean,\n  skipNulls: boolean,\n  encodeDotInKeys: boolean,\n  encoder: StringifyOptions['encoder'],\n  filter: StringifyOptions['filter'],\n  sort: StringifyOptions['sort'],\n  allowDots: StringifyOptions['allowDots'],\n  serializeDate: StringifyOptions['serializeDate'],\n  format: StringifyOptions['format'],\n  formatter: StringifyOptions['formatter'],\n  encodeValuesOnly: boolean,\n  charset: StringifyOptions['charset'],\n  sideChannel: WeakMap<any, any>,\n) {\n  let obj = object;\n\n  let tmp_sc = sideChannel;\n  let step = 0;\n  let find_flag = false;\n  while ((tmp_sc = tmp_sc.get(sentinel)) !== void undefined && !find_flag) {\n    // Where object last appeared in the ref tree\n    const pos = tmp_sc.get(object);\n    step += 1;\n    if (typeof pos !== 'undefined') {\n      if (pos === step) {\n        throw new RangeError('Cyclic object value');\n      } else {\n        find_flag = true; // Break while\n      }\n    }\n    if (typeof tmp_sc.get(sentinel) === 'undefined') {\n      step = 0;\n    }\n  }\n\n  if (typeof filter === 'function') {\n    obj = filter(prefix, obj);\n  } else if (obj instanceof Date) {\n    obj = serializeDate?.(obj);\n  } else if (generateArrayPrefix === 'comma' && is_array(obj)) {\n    obj = maybe_map(obj, function (value) {\n      if (value instanceof Date) {\n        return serializeDate?.(value);\n      }\n      return value;\n    });\n  }\n\n  if (obj === null) {\n    if (strictNullHandling) {\n      return encoder && !encodeValuesOnly ?\n          // @ts-expect-error\n          encoder(prefix, defaults.encoder, charset, 'key', format)\n        : prefix;\n    }\n\n    obj = '';\n  }\n\n  if (is_non_nullish_primitive(obj) || is_buffer(obj)) {\n    if (encoder) {\n      const key_value =\n        encodeValuesOnly ? prefix\n          // @ts-expect-error\n        : encoder(prefix, defaults.encoder, charset, 'key', format);\n      return [\n        formatter?.(key_value) +\n          '=' +\n          // @ts-expect-error\n          formatter?.(encoder(obj, defaults.encoder, charset, 'value', format)),\n      ];\n    }\n    return [formatter?.(prefix) + '=' + formatter?.(String(obj))];\n  }\n\n  const values: string[] = [];\n\n  if (typeof obj === 'undefined') {\n    return values;\n  }\n\n  let obj_keys;\n  if (generateArrayPrefix === 'comma' && is_array(obj)) {\n    // we need to join elements in\n    if (encodeValuesOnly && encoder) {\n      // @ts-expect-error values only\n      obj = maybe_map(obj, encoder);\n    }\n    obj_keys = [{ value: obj.length > 0 ? obj.join(',') || null : void undefined }];\n  } else if (is_array(filter)) {\n    obj_keys = filter;\n  } else {\n    const keys = Object.keys(obj);\n    obj_keys = sort ? keys.sort(sort) : keys;\n  }\n\n  const encoded_prefix = encodeDotInKeys ? String(prefix).replace(/\\./g, '%2E') : String(prefix);\n\n  const adjusted_prefix =\n    commaRoundTrip && is_array(obj) && obj.length === 1 ? encoded_prefix + '[]' : encoded_prefix;\n\n  if (allowEmptyArrays && is_array(obj) && obj.length === 0) {\n    return adjusted_prefix + '[]';\n  }\n\n  for (let j = 0; j < obj_keys.length; ++j) {\n    const key = obj_keys[j];\n    const value =\n      // @ts-ignore\n      typeof key === 'object' && typeof key.value !== 'undefined' ? key.value : obj[key as any];\n\n    if (skipNulls && value === null) {\n      continue;\n    }\n\n    // @ts-ignore\n    const encoded_key = allowDots && encodeDotInKeys ? (key as any).replace(/\\./g, '%2E') : key;\n    const key_prefix =\n      is_array(obj) ?\n        typeof generateArrayPrefix === 'function' ?\n          generateArrayPrefix(adjusted_prefix, encoded_key)\n        : adjusted_prefix\n      : adjusted_prefix + (allowDots ? '.' + encoded_key : '[' + encoded_key + ']');\n\n    sideChannel.set(object, step);\n    const valueSideChannel = new WeakMap();\n    valueSideChannel.set(sentinel, sideChannel);\n    push_to_array(\n      values,\n      inner_stringify(\n        value,\n        key_prefix,\n        generateArrayPrefix,\n        commaRoundTrip,\n        allowEmptyArrays,\n        strictNullHandling,\n        skipNulls,\n        encodeDotInKeys,\n        // @ts-ignore\n        generateArrayPrefix === 'comma' && encodeValuesOnly && is_array(obj) ? null : encoder,\n        filter,\n        sort,\n        allowDots,\n        serializeDate,\n        format,\n        formatter,\n        encodeValuesOnly,\n        charset,\n        valueSideChannel,\n      ),\n    );\n  }\n\n  return values;\n}\n\nfunction normalize_stringify_options(\n  opts: StringifyOptions = defaults,\n): NonNullableProperties<Omit<StringifyOptions, 'indices'>> & { indices?: boolean } {\n  if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n    throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n  }\n\n  if (typeof opts.encodeDotInKeys !== 'undefined' && typeof opts.encodeDotInKeys !== 'boolean') {\n    throw new TypeError('`encodeDotInKeys` option can only be `true` or `false`, when provided');\n  }\n\n  if (opts.encoder !== null && typeof opts.encoder !== 'undefined' && typeof opts.encoder !== 'function') {\n    throw new TypeError('Encoder has to be a function.');\n  }\n\n  const charset = opts.charset || defaults.charset;\n  if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n    throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n  }\n\n  let format = default_format;\n  if (typeof opts.format !== 'undefined') {\n    if (!has.call(formatters, opts.format)) {\n      throw new TypeError('Unknown format option provided.');\n    }\n    format = opts.format;\n  }\n  const formatter = formatters[format];\n\n  let filter = defaults.filter;\n  if (typeof opts.filter === 'function' || is_array(opts.filter)) {\n    filter = opts.filter;\n  }\n\n  let arrayFormat: StringifyOptions['arrayFormat'];\n  if (opts.arrayFormat && opts.arrayFormat in array_prefix_generators) {\n    arrayFormat = opts.arrayFormat;\n  } else if ('indices' in opts) {\n    arrayFormat = opts.indices ? 'indices' : 'repeat';\n  } else {\n    arrayFormat = defaults.arrayFormat;\n  }\n\n  if ('commaRoundTrip' in opts && typeof opts.commaRoundTrip !== 'boolean') {\n    throw new TypeError('`commaRoundTrip` must be a boolean, or absent');\n  }\n\n  const allowDots =\n    typeof opts.allowDots === 'undefined' ?\n      !!opts.encodeDotInKeys === true ?\n        true\n      : defaults.allowDots\n    : !!opts.allowDots;\n\n  return {\n    addQueryPrefix: typeof opts.addQueryPrefix === 'boolean' ? opts.addQueryPrefix : defaults.addQueryPrefix,\n    // @ts-ignore\n    allowDots: allowDots,\n    allowEmptyArrays:\n      typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n    arrayFormat: arrayFormat,\n    charset: charset,\n    charsetSentinel:\n      typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n    commaRoundTrip: !!opts.commaRoundTrip,\n    delimiter: typeof opts.delimiter === 'undefined' ? defaults.delimiter : opts.delimiter,\n    encode: typeof opts.encode === 'boolean' ? opts.encode : defaults.encode,\n    encodeDotInKeys:\n      typeof opts.encodeDotInKeys === 'boolean' ? opts.encodeDotInKeys : defaults.encodeDotInKeys,\n    encoder: typeof opts.encoder === 'function' ? opts.encoder : defaults.encoder,\n    encodeValuesOnly:\n      typeof opts.encodeValuesOnly === 'boolean' ? opts.encodeValuesOnly : defaults.encodeValuesOnly,\n    filter: filter,\n    format: format,\n    formatter: formatter,\n    serializeDate: typeof opts.serializeDate === 'function' ? opts.serializeDate : defaults.serializeDate,\n    skipNulls: typeof opts.skipNulls === 'boolean' ? opts.skipNulls : defaults.skipNulls,\n    // @ts-ignore\n    sort: typeof opts.sort === 'function' ? opts.sort : null,\n    strictNullHandling:\n      typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling,\n  };\n}\n\nexport function stringify(object: any, opts: StringifyOptions = {}) {\n  let obj = object;\n  const options = normalize_stringify_options(opts);\n\n  let obj_keys: PropertyKey[] | undefined;\n  let filter;\n\n  if (typeof options.filter === 'function') {\n    filter = options.filter;\n    obj = filter('', obj);\n  } else if (is_array(options.filter)) {\n    filter = options.filter;\n    obj_keys = filter;\n  }\n\n  const keys: string[] = [];\n\n  if (typeof obj !== 'object' || obj === null) {\n    return '';\n  }\n\n  const generateArrayPrefix = array_prefix_generators[options.arrayFormat];\n  const commaRoundTrip = generateArrayPrefix === 'comma' && options.commaRoundTrip;\n\n  if (!obj_keys) {\n    obj_keys = Object.keys(obj);\n  }\n\n  if (options.sort) {\n    obj_keys.sort(options.sort);\n  }\n\n  const sideChannel = new WeakMap();\n  for (let i = 0; i < obj_keys.length; ++i) {\n    const key = obj_keys[i]!;\n\n    if (options.skipNulls && obj[key] === null) {\n      continue;\n    }\n    push_to_array(\n      keys,\n      inner_stringify(\n        obj[key],\n        key,\n        // @ts-expect-error\n        generateArrayPrefix,\n        commaRoundTrip,\n        options.allowEmptyArrays,\n        options.strictNullHandling,\n        options.skipNulls,\n        options.encodeDotInKeys,\n        options.encode ? options.encoder : null,\n        options.filter,\n        options.sort,\n        options.allowDots,\n        options.serializeDate,\n        options.format,\n        options.formatter,\n        options.encodeValuesOnly,\n        options.charset,\n        sideChannel,\n      ),\n    );\n  }\n\n  const joined = keys.join(options.delimiter);\n  let prefix = options.addQueryPrefix === true ? '?' : '';\n\n  if (options.charsetSentinel) {\n    if (options.charset === 'iso-8859-1') {\n      // encodeURIComponent('&#10003;'), the \"numeric entity\" representation of a checkmark\n      prefix += 'utf8=%26%2310003%3B&';\n    } else {\n      // encodeURIComponent('✓')\n      prefix += 'utf8=%E2%9C%93&';\n    }\n  }\n\n  return joined.length > 0 ? prefix + joined : '';\n}\n","export const VERSION = '4.73.0'; // x-release-please-version\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport { type RequestOptions } from '../core';\n\nexport interface Shims {\n  kind: string;\n  fetch: any;\n  Request: any;\n  Response: any;\n  Headers: any;\n  FormData: any;\n  Blob: any;\n  File: any;\n  ReadableStream: any;\n  getMultipartRequestOptions: <T = Record<string, unknown>>(\n    form: Shims['FormData'],\n    opts: RequestOptions<T>,\n  ) => Promise<RequestOptions<T>>;\n  getDefaultAgent: (url: string) => any;\n  fileFromPath:\n    | ((path: string, filename?: string, options?: {}) => Promise<Shims['File']>)\n    | ((path: string, options?: {}) => Promise<Shims['File']>);\n  isFsReadStream: (value: any) => boolean;\n}\n\nexport let auto = false;\nexport let kind: Shims['kind'] | undefined = undefined;\nexport let fetch: Shims['fetch'] | undefined = undefined;\nexport let Request: Shims['Request'] | undefined = undefined;\nexport let Response: Shims['Response'] | undefined = undefined;\nexport let Headers: Shims['Headers'] | undefined = undefined;\nexport let FormData: Shims['FormData'] | undefined = undefined;\nexport let Blob: Shims['Blob'] | undefined = undefined;\nexport let File: Shims['File'] | undefined = undefined;\nexport let ReadableStream: Shims['ReadableStream'] | undefined = undefined;\nexport let getMultipartRequestOptions: Shims['getMultipartRequestOptions'] | undefined = undefined;\nexport let getDefaultAgent: Shims['getDefaultAgent'] | undefined = undefined;\nexport let fileFromPath: Shims['fileFromPath'] | undefined = undefined;\nexport let isFsReadStream: Shims['isFsReadStream'] | undefined = undefined;\n\nexport function setShims(shims: Shims, options: { auto: boolean } = { auto: false }) {\n  if (auto) {\n    throw new Error(\n      `you must \\`import 'openai/shims/${shims.kind}'\\` before importing anything else from openai`,\n    );\n  }\n  if (kind) {\n    throw new Error(`can't \\`import 'openai/shims/${shims.kind}'\\` after \\`import 'openai/shims/${kind}'\\``);\n  }\n  auto = options.auto;\n  kind = shims.kind;\n  fetch = shims.fetch;\n  Request = shims.Request;\n  Response = shims.Response;\n  Headers = shims.Headers;\n  FormData = shims.FormData;\n  Blob = shims.Blob;\n  File = shims.File;\n  ReadableStream = shims.ReadableStream;\n  getMultipartRequestOptions = shims.getMultipartRequestOptions;\n  getDefaultAgent = shims.getDefaultAgent;\n  fileFromPath = shims.fileFromPath;\n  isFsReadStream = shims.isFsReadStream;\n}\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport * as nf from 'node-fetch';\nimport * as fd from 'formdata-node';\nimport { type File, type FilePropertyBag } from 'formdata-node';\nimport KeepAliveAgent from 'agentkeepalive';\nimport { AbortController as AbortControllerPolyfill } from 'abort-controller';\nimport { ReadStream as FsReadStream } from 'node:fs';\nimport { type Agent } from 'node:http';\nimport { FormDataEncoder } from 'form-data-encoder';\nimport { Readable } from 'node:stream';\nimport { type RequestOptions } from '../core';\nimport { MultipartBody } from './MultipartBody';\nimport { type Shims } from './registry';\nimport { ReadableStream } from 'node:stream/web';\n\ntype FileFromPathOptions = Omit<FilePropertyBag, 'lastModified'>;\n\nlet fileFromPathWarned = false;\n\n/**\n * @deprecated use fs.createReadStream('./my/file.txt') instead\n */\nasync function fileFromPath(path: string): Promise<File>;\nasync function fileFromPath(path: string, filename?: string): Promise<File>;\nasync function fileFromPath(path: string, options?: FileFromPathOptions): Promise<File>;\nasync function fileFromPath(path: string, filename?: string, options?: FileFromPathOptions): Promise<File>;\nasync function fileFromPath(path: string, ...args: any[]): Promise<File> {\n  // this import fails in environments that don't handle export maps correctly, like old versions of Jest\n  const { fileFromPath: _fileFromPath } = await import('formdata-node/file-from-path');\n\n  if (!fileFromPathWarned) {\n    console.warn(`fileFromPath is deprecated; use fs.createReadStream(${JSON.stringify(path)}) instead`);\n    fileFromPathWarned = true;\n  }\n  // @ts-ignore\n  return await _fileFromPath(path, ...args);\n}\n\nconst defaultHttpAgent: Agent = new KeepAliveAgent({ keepAlive: true, timeout: 5 * 60 * 1000 });\nconst defaultHttpsAgent: Agent = new KeepAliveAgent.HttpsAgent({ keepAlive: true, timeout: 5 * 60 * 1000 });\n\nasync function getMultipartRequestOptions<T = Record<string, unknown>>(\n  form: fd.FormData,\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T>> {\n  const encoder = new FormDataEncoder(form);\n  const readable = Readable.from(encoder);\n  const body = new MultipartBody(readable);\n  const headers = {\n    ...opts.headers,\n    ...encoder.headers,\n    'Content-Length': encoder.contentLength,\n  };\n\n  return { ...opts, body: body as any, headers };\n}\n\nexport function getRuntime(): Shims {\n  // Polyfill global object if needed.\n  if (typeof AbortController === 'undefined') {\n    // @ts-expect-error (the types are subtly different, but compatible in practice)\n    globalThis.AbortController = AbortControllerPolyfill;\n  }\n  return {\n    kind: 'node',\n    fetch: nf.default,\n    Request: nf.Request,\n    Response: nf.Response,\n    Headers: nf.Headers,\n    FormData: fd.FormData,\n    Blob: fd.Blob,\n    File: fd.File,\n    ReadableStream,\n    getMultipartRequestOptions,\n    getDefaultAgent: (url: string): Agent => (url.startsWith('https') ? defaultHttpsAgent : defaultHttpAgent),\n    fileFromPath,\n    isFsReadStream: (value: any): value is FsReadStream => value instanceof FsReadStream,\n  };\n}\n","const alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789\";\nfunction createBoundary() {\n    let size = 16;\n    let res = \"\";\n    while (size--) {\n        res += alphabet[(Math.random() * alphabet.length) << 0];\n    }\n    return res;\n}\nexport default createBoundary;\n","const getType = (value) => (Object.prototype.toString.call(value).slice(8, -1).toLowerCase());\nfunction isPlainObject(value) {\n    if (getType(value) !== \"object\") {\n        return false;\n    }\n    const pp = Object.getPrototypeOf(value);\n    if (pp === null || pp === undefined) {\n        return true;\n    }\n    const Ctor = pp.constructor && pp.constructor.toString();\n    return Ctor === Object.toString();\n}\nexport default isPlainObject;\n","const normalizeValue = (value) => String(value)\n    .replace(/\\r|\\n/g, (match, i, str) => {\n    if ((match === \"\\r\" && str[i + 1] !== \"\\n\")\n        || (match === \"\\n\" && str[i - 1] !== \"\\r\")) {\n        return \"\\r\\n\";\n    }\n    return match;\n});\nexport default normalizeValue;\n","const escapeName = (name) => String(name)\n    .replace(/\\r/g, \"%0D\")\n    .replace(/\\n/g, \"%0A\")\n    .replace(/\"/g, \"%22\");\nexport default escapeName;\n","const isFunction = (value) => (typeof value === \"function\");\nexport default isFunction;\n","import isFunction from \"./isFunction.js\";\nexport const isFileLike = (value) => Boolean(value\n    && typeof value === \"object\"\n    && isFunction(value.constructor)\n    && value[Symbol.toStringTag] === \"File\"\n    && isFunction(value.stream)\n    && value.name != null\n    && value.size != null\n    && value.lastModified != null);\n","import isFunction from \"./isFunction.js\";\nexport const isFormData = (value) => Boolean(value\n    && isFunction(value.constructor)\n    && value[Symbol.toStringTag] === \"FormData\"\n    && isFunction(value.append)\n    && isFunction(value.getAll)\n    && isFunction(value.entries)\n    && isFunction(value[Symbol.iterator]));\nexport const isFormDataLike = isFormData;\n","var __classPrivateFieldSet = (this && this.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _FormDataEncoder_instances, _FormDataEncoder_CRLF, _FormDataEncoder_CRLF_BYTES, _FormDataEncoder_CRLF_BYTES_LENGTH, _FormDataEncoder_DASHES, _FormDataEncoder_encoder, _FormDataEncoder_footer, _FormDataEncoder_form, _FormDataEncoder_options, _FormDataEncoder_getFieldHeader;\nimport createBoundary from \"./util/createBoundary.js\";\nimport isPlainObject from \"./util/isPlainObject.js\";\nimport normalize from \"./util/normalizeValue.js\";\nimport escape from \"./util/escapeName.js\";\nimport { isFileLike } from \"./util/isFileLike.js\";\nimport { isFormData } from \"./util/isFormData.js\";\nconst defaultOptions = {\n    enableAdditionalHeaders: false\n};\nexport class FormDataEncoder {\n    constructor(form, boundaryOrOptions, options) {\n        _FormDataEncoder_instances.add(this);\n        _FormDataEncoder_CRLF.set(this, \"\\r\\n\");\n        _FormDataEncoder_CRLF_BYTES.set(this, void 0);\n        _FormDataEncoder_CRLF_BYTES_LENGTH.set(this, void 0);\n        _FormDataEncoder_DASHES.set(this, \"-\".repeat(2));\n        _FormDataEncoder_encoder.set(this, new TextEncoder());\n        _FormDataEncoder_footer.set(this, void 0);\n        _FormDataEncoder_form.set(this, void 0);\n        _FormDataEncoder_options.set(this, void 0);\n        if (!isFormData(form)) {\n            throw new TypeError(\"Expected first argument to be a FormData instance.\");\n        }\n        let boundary;\n        if (isPlainObject(boundaryOrOptions)) {\n            options = boundaryOrOptions;\n        }\n        else {\n            boundary = boundaryOrOptions;\n        }\n        if (!boundary) {\n            boundary = createBoundary();\n        }\n        if (typeof boundary !== \"string\") {\n            throw new TypeError(\"Expected boundary argument to be a string.\");\n        }\n        if (options && !isPlainObject(options)) {\n            throw new TypeError(\"Expected options argument to be an object.\");\n        }\n        __classPrivateFieldSet(this, _FormDataEncoder_form, form, \"f\");\n        __classPrivateFieldSet(this, _FormDataEncoder_options, { ...defaultOptions, ...options }, \"f\");\n        __classPrivateFieldSet(this, _FormDataEncoder_CRLF_BYTES, __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")), \"f\");\n        __classPrivateFieldSet(this, _FormDataEncoder_CRLF_BYTES_LENGTH, __classPrivateFieldGet(this, _FormDataEncoder_CRLF_BYTES, \"f\").byteLength, \"f\");\n        this.boundary = `form-data-boundary-${boundary}`;\n        this.contentType = `multipart/form-data; boundary=${this.boundary}`;\n        __classPrivateFieldSet(this, _FormDataEncoder_footer, __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(`${__classPrivateFieldGet(this, _FormDataEncoder_DASHES, \"f\")}${this.boundary}${__classPrivateFieldGet(this, _FormDataEncoder_DASHES, \"f\")}${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\").repeat(2)}`), \"f\");\n        this.contentLength = String(this.getContentLength());\n        this.headers = Object.freeze({\n            \"Content-Type\": this.contentType,\n            \"Content-Length\": this.contentLength\n        });\n        Object.defineProperties(this, {\n            boundary: { writable: false, configurable: false },\n            contentType: { writable: false, configurable: false },\n            contentLength: { writable: false, configurable: false },\n            headers: { writable: false, configurable: false }\n        });\n    }\n    getContentLength() {\n        let length = 0;\n        for (const [name, raw] of __classPrivateFieldGet(this, _FormDataEncoder_form, \"f\")) {\n            const value = isFileLike(raw) ? raw : __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(normalize(raw));\n            length += __classPrivateFieldGet(this, _FormDataEncoder_instances, \"m\", _FormDataEncoder_getFieldHeader).call(this, name, value).byteLength;\n            length += isFileLike(value) ? value.size : value.byteLength;\n            length += __classPrivateFieldGet(this, _FormDataEncoder_CRLF_BYTES_LENGTH, \"f\");\n        }\n        return length + __classPrivateFieldGet(this, _FormDataEncoder_footer, \"f\").byteLength;\n    }\n    *values() {\n        for (const [name, raw] of __classPrivateFieldGet(this, _FormDataEncoder_form, \"f\").entries()) {\n            const value = isFileLike(raw) ? raw : __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(normalize(raw));\n            yield __classPrivateFieldGet(this, _FormDataEncoder_instances, \"m\", _FormDataEncoder_getFieldHeader).call(this, name, value);\n            yield value;\n            yield __classPrivateFieldGet(this, _FormDataEncoder_CRLF_BYTES, \"f\");\n        }\n        yield __classPrivateFieldGet(this, _FormDataEncoder_footer, \"f\");\n    }\n    async *encode() {\n        for (const part of this.values()) {\n            if (isFileLike(part)) {\n                yield* part.stream();\n            }\n            else {\n                yield part;\n            }\n        }\n    }\n    [(_FormDataEncoder_CRLF = new WeakMap(), _FormDataEncoder_CRLF_BYTES = new WeakMap(), _FormDataEncoder_CRLF_BYTES_LENGTH = new WeakMap(), _FormDataEncoder_DASHES = new WeakMap(), _FormDataEncoder_encoder = new WeakMap(), _FormDataEncoder_footer = new WeakMap(), _FormDataEncoder_form = new WeakMap(), _FormDataEncoder_options = new WeakMap(), _FormDataEncoder_instances = new WeakSet(), _FormDataEncoder_getFieldHeader = function _FormDataEncoder_getFieldHeader(name, value) {\n        let header = \"\";\n        header += `${__classPrivateFieldGet(this, _FormDataEncoder_DASHES, \"f\")}${this.boundary}${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")}`;\n        header += `Content-Disposition: form-data; name=\"${escape(name)}\"`;\n        if (isFileLike(value)) {\n            header += `; filename=\"${escape(value.name)}\"${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")}`;\n            header += `Content-Type: ${value.type || \"application/octet-stream\"}`;\n        }\n        if (__classPrivateFieldGet(this, _FormDataEncoder_options, \"f\").enableAdditionalHeaders === true) {\n            header += `${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\")}Content-Length: ${isFileLike(value) ? value.size : value.byteLength}`;\n        }\n        return __classPrivateFieldGet(this, _FormDataEncoder_encoder, \"f\").encode(`${header}${__classPrivateFieldGet(this, _FormDataEncoder_CRLF, \"f\").repeat(2)}`);\n    }, Symbol.iterator)]() {\n        return this.values();\n    }\n    [Symbol.asyncIterator]() {\n        return this.encode();\n    }\n}\nexport const Encoder = FormDataEncoder;\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nexport class MultipartBody {\n  constructor(public body: any) {}\n  get [Symbol.toStringTag](): string {\n    return 'MultipartBody';\n  }\n}\n","/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport * as shims from './registry.mjs';\nimport * as auto from 'openai/_shims/auto/runtime';\nif (!shims.kind) shims.setShims(auto.getRuntime(), { auto: true });\nexport * from './registry.mjs';\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { castToError, Headers } from './core';\n\nexport class OpenAIError extends Error {}\n\nexport class APIError extends OpenAIError {\n  readonly status: number | undefined;\n  readonly headers: Headers | undefined;\n  readonly error: Object | undefined;\n\n  readonly code: string | null | undefined;\n  readonly param: string | null | undefined;\n  readonly type: string | undefined;\n\n  readonly request_id: string | null | undefined;\n\n  constructor(\n    status: number | undefined,\n    error: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ) {\n    super(`${APIError.makeMessage(status, error, message)}`);\n    this.status = status;\n    this.headers = headers;\n    this.request_id = headers?.['x-request-id'];\n\n    const data = error as Record<string, any>;\n    this.error = data;\n    this.code = data?.['code'];\n    this.param = data?.['param'];\n    this.type = data?.['type'];\n  }\n\n  private static makeMessage(status: number | undefined, error: any, message: string | undefined) {\n    const msg =\n      error?.message ?\n        typeof error.message === 'string' ?\n          error.message\n        : JSON.stringify(error.message)\n      : error ? JSON.stringify(error)\n      : message;\n\n    if (status && msg) {\n      return `${status} ${msg}`;\n    }\n    if (status) {\n      return `${status} status code (no body)`;\n    }\n    if (msg) {\n      return msg;\n    }\n    return '(no status code or body)';\n  }\n\n  static generate(\n    status: number | undefined,\n    errorResponse: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ): APIError {\n    if (!status) {\n      return new APIConnectionError({ message, cause: castToError(errorResponse) });\n    }\n\n    const error = (errorResponse as Record<string, any>)?.['error'];\n\n    if (status === 400) {\n      return new BadRequestError(status, error, message, headers);\n    }\n\n    if (status === 401) {\n      return new AuthenticationError(status, error, message, headers);\n    }\n\n    if (status === 403) {\n      return new PermissionDeniedError(status, error, message, headers);\n    }\n\n    if (status === 404) {\n      return new NotFoundError(status, error, message, headers);\n    }\n\n    if (status === 409) {\n      return new ConflictError(status, error, message, headers);\n    }\n\n    if (status === 422) {\n      return new UnprocessableEntityError(status, error, message, headers);\n    }\n\n    if (status === 429) {\n      return new RateLimitError(status, error, message, headers);\n    }\n\n    if (status >= 500) {\n      return new InternalServerError(status, error, message, headers);\n    }\n\n    return new APIError(status, error, message, headers);\n  }\n}\n\nexport class APIUserAbortError extends APIError {\n  override readonly status: undefined = undefined;\n\n  constructor({ message }: { message?: string } = {}) {\n    super(undefined, undefined, message || 'Request was aborted.', undefined);\n  }\n}\n\nexport class APIConnectionError extends APIError {\n  override readonly status: undefined = undefined;\n\n  constructor({ message, cause }: { message?: string | undefined; cause?: Error | undefined }) {\n    super(undefined, undefined, message || 'Connection error.', undefined);\n    // in some environments the 'cause' property is already declared\n    // @ts-ignore\n    if (cause) this.cause = cause;\n  }\n}\n\nexport class APIConnectionTimeoutError extends APIConnectionError {\n  constructor({ message }: { message?: string } = {}) {\n    super({ message: message ?? 'Request timed out.' });\n  }\n}\n\nexport class BadRequestError extends APIError {\n  override readonly status: 400 = 400;\n}\n\nexport class AuthenticationError extends APIError {\n  override readonly status: 401 = 401;\n}\n\nexport class PermissionDeniedError extends APIError {\n  override readonly status: 403 = 403;\n}\n\nexport class NotFoundError extends APIError {\n  override readonly status: 404 = 404;\n}\n\nexport class ConflictError extends APIError {\n  override readonly status: 409 = 409;\n}\n\nexport class UnprocessableEntityError extends APIError {\n  override readonly status: 422 = 422;\n}\n\nexport class RateLimitError extends APIError {\n  override readonly status: 429 = 429;\n}\n\nexport class InternalServerError extends APIError {}\n\nexport class LengthFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the length limit was reached`);\n  }\n}\n\nexport class ContentFilterFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the request was rejected by the content filter`);\n  }\n}\n","import { OpenAIError } from '../../error';\n\ntype Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\n\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nexport class LineDecoder {\n  // prettier-ignore\n  static NEWLINE_CHARS = new Set(['\\n', '\\r']);\n  static NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n\n  buffer: string[];\n  trailingCR: boolean;\n  textDecoder: any; // TextDecoder found in browsers; not typed to avoid pulling in either \"dom\" or \"node\" types.\n\n  constructor() {\n    this.buffer = [];\n    this.trailingCR = false;\n  }\n\n  decode(chunk: Bytes): string[] {\n    let text = this.decodeText(chunk);\n\n    if (this.trailingCR) {\n      text = '\\r' + text;\n      this.trailingCR = false;\n    }\n    if (text.endsWith('\\r')) {\n      this.trailingCR = true;\n      text = text.slice(0, -1);\n    }\n\n    if (!text) {\n      return [];\n    }\n\n    const trailingNewline = LineDecoder.NEWLINE_CHARS.has(text[text.length - 1] || '');\n    let lines = text.split(LineDecoder.NEWLINE_REGEXP);\n\n    // if there is a trailing new line then the last entry will be an empty\n    // string which we don't care about\n    if (trailingNewline) {\n      lines.pop();\n    }\n\n    if (lines.length === 1 && !trailingNewline) {\n      this.buffer.push(lines[0]!);\n      return [];\n    }\n\n    if (this.buffer.length > 0) {\n      lines = [this.buffer.join('') + lines[0], ...lines.slice(1)];\n      this.buffer = [];\n    }\n\n    if (!trailingNewline) {\n      this.buffer = [lines.pop() || ''];\n    }\n\n    return lines;\n  }\n\n  decodeText(bytes: Bytes): string {\n    if (bytes == null) return '';\n    if (typeof bytes === 'string') return bytes;\n\n    // Node:\n    if (typeof Buffer !== 'undefined') {\n      if (bytes instanceof Buffer) {\n        return bytes.toString();\n      }\n      if (bytes instanceof Uint8Array) {\n        return Buffer.from(bytes).toString();\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global \"Buffer\" defined, which this library assumes to be Node. Please report this error.`,\n      );\n    }\n\n    // Browser\n    if (typeof TextDecoder !== 'undefined') {\n      if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {\n        this.textDecoder ??= new TextDecoder('utf8');\n        return this.textDecoder.decode(bytes);\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array/ArrayBuffer (${\n          (bytes as any).constructor.name\n        }) in a web platform. Please report this error.`,\n      );\n    }\n\n    throw new OpenAIError(\n      `Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`,\n    );\n  }\n\n  flush(): string[] {\n    if (!this.buffer.length && !this.trailingCR) {\n      return [];\n    }\n\n    const lines = [this.buffer.join('')];\n    this.buffer = [];\n    this.trailingCR = false;\n    return lines;\n  }\n}\n","import { ReadableStream, type Response } from './_shims/index';\nimport { OpenAIError } from './error';\nimport { LineDecoder } from './internal/decoders/line';\n\nimport { APIError } from './error';\n\ntype Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\n\nexport type ServerSentEvent = {\n  event: string | null;\n  data: string;\n  raw: string[];\n};\n\nexport class Stream<Item> implements AsyncIterable<Item> {\n  controller: AbortController;\n\n  constructor(\n    private iterator: () => AsyncIterator<Item>,\n    controller: AbortController,\n  ) {\n    this.controller = controller;\n  }\n\n  static fromSSEResponse<Item>(response: Response, controller: AbortController): Stream<Item> {\n    let consumed = false;\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const sse of _iterSSEMessages(response, controller)) {\n          if (done) continue;\n\n          if (sse.data.startsWith('[DONE]')) {\n            done = true;\n            continue;\n          }\n\n          if (sse.event === null) {\n            let data;\n\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n\n            if (data && data.error) {\n              throw new APIError(undefined, data.error, undefined, undefined);\n            }\n\n            yield data;\n          } else {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            // TODO: Is this where the error should be thrown?\n            if (sse.event == 'error') {\n              throw new APIError(undefined, data.error, data.message, undefined);\n            }\n            yield { event: sse.event, data: data } as any;\n          }\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  /**\n   * Generates a Stream from a newline-separated ReadableStream\n   * where each item is a JSON value.\n   */\n  static fromReadableStream<Item>(readableStream: ReadableStream, controller: AbortController): Stream<Item> {\n    let consumed = false;\n\n    async function* iterLines(): AsyncGenerator<string, void, unknown> {\n      const lineDecoder = new LineDecoder();\n\n      const iter = readableStreamAsyncIterable<Bytes>(readableStream);\n      for await (const chunk of iter) {\n        for (const line of lineDecoder.decode(chunk)) {\n          yield line;\n        }\n      }\n\n      for (const line of lineDecoder.flush()) {\n        yield line;\n      }\n    }\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const line of iterLines()) {\n          if (done) continue;\n          if (line) yield JSON.parse(line);\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  [Symbol.asyncIterator](): AsyncIterator<Item> {\n    return this.iterator();\n  }\n\n  /**\n   * Splits the stream into two streams which can be\n   * independently read from at different speeds.\n   */\n  tee(): [Stream<Item>, Stream<Item>] {\n    const left: Array<Promise<IteratorResult<Item>>> = [];\n    const right: Array<Promise<IteratorResult<Item>>> = [];\n    const iterator = this.iterator();\n\n    const teeIterator = (queue: Array<Promise<IteratorResult<Item>>>): AsyncIterator<Item> => {\n      return {\n        next: () => {\n          if (queue.length === 0) {\n            const result = iterator.next();\n            left.push(result);\n            right.push(result);\n          }\n          return queue.shift()!;\n        },\n      };\n    };\n\n    return [\n      new Stream(() => teeIterator(left), this.controller),\n      new Stream(() => teeIterator(right), this.controller),\n    ];\n  }\n\n  /**\n   * Converts this stream to a newline-separated ReadableStream of\n   * JSON stringified values in the stream\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n   */\n  toReadableStream(): ReadableStream {\n    const self = this;\n    let iter: AsyncIterator<Item>;\n    const encoder = new TextEncoder();\n\n    return new ReadableStream({\n      async start() {\n        iter = self[Symbol.asyncIterator]();\n      },\n      async pull(ctrl: any) {\n        try {\n          const { value, done } = await iter.next();\n          if (done) return ctrl.close();\n\n          const bytes = encoder.encode(JSON.stringify(value) + '\\n');\n\n          ctrl.enqueue(bytes);\n        } catch (err) {\n          ctrl.error(err);\n        }\n      },\n      async cancel() {\n        await iter.return?.();\n      },\n    });\n  }\n}\n\nexport async function* _iterSSEMessages(\n  response: Response,\n  controller: AbortController,\n): AsyncGenerator<ServerSentEvent, void, unknown> {\n  if (!response.body) {\n    controller.abort();\n    throw new OpenAIError(`Attempted to iterate over a response with no body`);\n  }\n\n  const sseDecoder = new SSEDecoder();\n  const lineDecoder = new LineDecoder();\n\n  const iter = readableStreamAsyncIterable<Bytes>(response.body);\n  for await (const sseChunk of iterSSEChunks(iter)) {\n    for (const line of lineDecoder.decode(sseChunk)) {\n      const sse = sseDecoder.decode(line);\n      if (sse) yield sse;\n    }\n  }\n\n  for (const line of lineDecoder.flush()) {\n    const sse = sseDecoder.decode(line);\n    if (sse) yield sse;\n  }\n}\n\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator: AsyncIterableIterator<Bytes>): AsyncGenerator<Uint8Array> {\n  let data = new Uint8Array();\n\n  for await (const chunk of iterator) {\n    if (chunk == null) {\n      continue;\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? new TextEncoder().encode(chunk)\n      : chunk;\n\n    let newData = new Uint8Array(data.length + binaryChunk.length);\n    newData.set(data);\n    newData.set(binaryChunk, data.length);\n    data = newData;\n\n    let patternIndex;\n    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n      yield data.slice(0, patternIndex);\n      data = data.slice(patternIndex);\n    }\n  }\n\n  if (data.length > 0) {\n    yield data;\n  }\n}\n\nfunction findDoubleNewlineIndex(buffer: Uint8Array): number {\n  // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n  // and returns the index right after the first occurrence of any pattern,\n  // or -1 if none of the patterns are found.\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = 0; i < buffer.length - 2; i++) {\n    if (buffer[i] === newline && buffer[i + 1] === newline) {\n      // \\n\\n\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n      // \\r\\r\n      return i + 2;\n    }\n    if (\n      buffer[i] === carriage &&\n      buffer[i + 1] === newline &&\n      i + 3 < buffer.length &&\n      buffer[i + 2] === carriage &&\n      buffer[i + 3] === newline\n    ) {\n      // \\r\\n\\r\\n\n      return i + 4;\n    }\n  }\n\n  return -1;\n}\n\nclass SSEDecoder {\n  private data: string[];\n  private event: string | null;\n  private chunks: string[];\n\n  constructor() {\n    this.event = null;\n    this.data = [];\n    this.chunks = [];\n  }\n\n  decode(line: string) {\n    if (line.endsWith('\\r')) {\n      line = line.substring(0, line.length - 1);\n    }\n\n    if (!line) {\n      // empty line and we didn't previously encounter any messages\n      if (!this.event && !this.data.length) return null;\n\n      const sse: ServerSentEvent = {\n        event: this.event,\n        data: this.data.join('\\n'),\n        raw: this.chunks,\n      };\n\n      this.event = null;\n      this.data = [];\n      this.chunks = [];\n\n      return sse;\n    }\n\n    this.chunks.push(line);\n\n    if (line.startsWith(':')) {\n      return null;\n    }\n\n    let [fieldname, _, value] = partition(line, ':');\n\n    if (value.startsWith(' ')) {\n      value = value.substring(1);\n    }\n\n    if (fieldname === 'event') {\n      this.event = value;\n    } else if (fieldname === 'data') {\n      this.data.push(value);\n    }\n\n    return null;\n  }\n}\n\n/** This is an internal helper function that's just used for testing */\nexport function _decodeChunks(chunks: string[]): string[] {\n  const decoder = new LineDecoder();\n  const lines: string[] = [];\n  for (const chunk of chunks) {\n    lines.push(...decoder.decode(chunk));\n  }\n\n  return lines;\n}\n\nfunction partition(str: string, delimiter: string): [string, string, string] {\n  const index = str.indexOf(delimiter);\n  if (index !== -1) {\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n  }\n\n  return [str, '', ''];\n}\n\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function readableStreamAsyncIterable<T>(stream: any): AsyncIterableIterator<T> {\n  if (stream[Symbol.asyncIterator]) return stream;\n\n  const reader = stream.getReader();\n  return {\n    async next() {\n      try {\n        const result = await reader.read();\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\n        return result;\n      } catch (e) {\n        reader.releaseLock(); // release lock when stream becomes errored\n        throw e;\n      }\n    },\n    async return() {\n      const cancelPromise = reader.cancel();\n      reader.releaseLock();\n      await cancelPromise;\n      return { done: true, value: undefined };\n    },\n    [Symbol.asyncIterator]() {\n      return this;\n    },\n  };\n}\n","import { type RequestOptions } from './core';\nimport {\n  FormData,\n  File,\n  type Blob,\n  type FilePropertyBag,\n  getMultipartRequestOptions,\n  type FsReadStream,\n  isFsReadStream,\n} from './_shims/index';\nimport { MultipartBody } from './_shims/MultipartBody';\nexport { fileFromPath } from './_shims/index';\n\ntype BlobLikePart = string | ArrayBuffer | ArrayBufferView | BlobLike | Uint8Array | DataView;\nexport type BlobPart = string | ArrayBuffer | ArrayBufferView | Blob | Uint8Array | DataView;\n\n/**\n * Typically, this is a native \"File\" class.\n *\n * We provide the {@link toFile} utility to convert a variety of objects\n * into the File class.\n *\n * For convenience, you can also pass a fetch Response, or in Node,\n * the result of fs.createReadStream().\n */\nexport type Uploadable = FileLike | ResponseLike | FsReadStream;\n\n/**\n * Intended to match web.Blob, node.Blob, node-fetch.Blob, etc.\n */\nexport interface BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */\n  readonly size: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */\n  readonly type: string;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */\n  text(): Promise<string>;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */\n  slice(start?: number, end?: number): BlobLike;\n  // unfortunately @types/node-fetch@^2.6.4 doesn't type the arrayBuffer method\n}\n\n/**\n * Intended to match web.File, node.File, node-fetch.File, etc.\n */\nexport interface FileLike extends BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */\n  readonly lastModified: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */\n  readonly name: string;\n}\n\n/**\n * Intended to match web.Response, node.Response, node-fetch.Response, etc.\n */\nexport interface ResponseLike {\n  url: string;\n  blob(): Promise<BlobLike>;\n}\n\nexport const isResponseLike = (value: any): value is ResponseLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.url === 'string' &&\n  typeof value.blob === 'function';\n\nexport const isFileLike = (value: any): value is FileLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.name === 'string' &&\n  typeof value.lastModified === 'number' &&\n  isBlobLike(value);\n\n/**\n * The BlobLike type omits arrayBuffer() because @types/node-fetch@^2.6.4 lacks it; but this check\n * adds the arrayBuffer() method type because it is available and used at runtime\n */\nexport const isBlobLike = (value: any): value is BlobLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.size === 'number' &&\n  typeof value.type === 'string' &&\n  typeof value.text === 'function' &&\n  typeof value.slice === 'function' &&\n  typeof value.arrayBuffer === 'function';\n\nexport const isUploadable = (value: any): value is Uploadable => {\n  return isFileLike(value) || isResponseLike(value) || isFsReadStream(value);\n};\n\nexport type ToFileInput = Uploadable | Exclude<BlobLikePart, string> | AsyncIterable<BlobLikePart>;\n\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file.  Can be an {@link Uploadable}, {@link BlobLikePart}, or {@link AsyncIterable} of {@link BlobLikePart}s\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nexport async function toFile(\n  value: ToFileInput | PromiseLike<ToFileInput>,\n  name?: string | null | undefined,\n  options?: FilePropertyBag | undefined,\n): Promise<FileLike> {\n  // If it's a promise, resolve it.\n  value = await value;\n\n  // If we've been given a `File` we don't need to do anything\n  if (isFileLike(value)) {\n    return value;\n  }\n\n  if (isResponseLike(value)) {\n    const blob = await value.blob();\n    name ||= new URL(value.url).pathname.split(/[\\\\/]/).pop() ?? 'unknown_file';\n\n    // we need to convert the `Blob` into an array buffer because the `Blob` class\n    // that `node-fetch` defines is incompatible with the web standard which results\n    // in `new File` interpreting it as a string instead of binary data.\n    const data = isBlobLike(blob) ? [(await blob.arrayBuffer()) as any] : [blob];\n\n    return new File(data, name, options);\n  }\n\n  const bits = await getBytes(value);\n\n  name ||= getName(value) ?? 'unknown_file';\n\n  if (!options?.type) {\n    const type = (bits[0] as any)?.type;\n    if (typeof type === 'string') {\n      options = { ...options, type };\n    }\n  }\n\n  return new File(bits, name, options);\n}\n\nasync function getBytes(value: ToFileInput): Promise<Array<BlobPart>> {\n  let parts: Array<BlobPart> = [];\n  if (\n    typeof value === 'string' ||\n    ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n    value instanceof ArrayBuffer\n  ) {\n    parts.push(value);\n  } else if (isBlobLike(value)) {\n    parts.push(await value.arrayBuffer());\n  } else if (\n    isAsyncIterableIterator(value) // includes Readable, ReadableStream, etc.\n  ) {\n    for await (const chunk of value) {\n      parts.push(chunk as BlobPart); // TODO, consider validating?\n    }\n  } else {\n    throw new Error(\n      `Unexpected data type: ${typeof value}; constructor: ${value?.constructor\n        ?.name}; props: ${propsForError(value)}`,\n    );\n  }\n\n  return parts;\n}\n\nfunction propsForError(value: any): string {\n  const props = Object.getOwnPropertyNames(value);\n  return `[${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\n\nfunction getName(value: any): string | undefined {\n  return (\n    getStringFromMaybeBuffer(value.name) ||\n    getStringFromMaybeBuffer(value.filename) ||\n    // For fs.ReadStream\n    getStringFromMaybeBuffer(value.path)?.split(/[\\\\/]/).pop()\n  );\n}\n\nconst getStringFromMaybeBuffer = (x: string | Buffer | unknown): string | undefined => {\n  if (typeof x === 'string') return x;\n  if (typeof Buffer !== 'undefined' && x instanceof Buffer) return String(x);\n  return undefined;\n};\n\nconst isAsyncIterableIterator = (value: any): value is AsyncIterableIterator<unknown> =>\n  value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\n\nexport const isMultipartBody = (body: any): body is MultipartBody =>\n  body && typeof body === 'object' && body.body && body[Symbol.toStringTag] === 'MultipartBody';\n\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nexport const maybeMultipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  if (!hasUploadableValue(opts.body)) return opts;\n\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const multipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const createForm = async <T = Record<string, unknown>>(body: T | undefined): Promise<FormData> => {\n  const form = new FormData();\n  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n  return form;\n};\n\nconst hasUploadableValue = (value: unknown): boolean => {\n  if (isUploadable(value)) return true;\n  if (Array.isArray(value)) return value.some(hasUploadableValue);\n  if (value && typeof value === 'object') {\n    for (const k in value) {\n      if (hasUploadableValue((value as any)[k])) return true;\n    }\n  }\n  return false;\n};\n\nconst addFormValue = async (form: FormData, key: string, value: unknown): Promise<void> => {\n  if (value === undefined) return;\n  if (value == null) {\n    throw new TypeError(\n      `Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`,\n    );\n  }\n\n  // TODO: make nested formats configurable\n  if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n    form.append(key, String(value));\n  } else if (isUploadable(value)) {\n    const file = await toFile(value);\n    form.append(key, file as File);\n  } else if (Array.isArray(value)) {\n    await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n  } else if (typeof value === 'object') {\n    await Promise.all(\n      Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)),\n    );\n  } else {\n    throw new TypeError(\n      `Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`,\n    );\n  }\n};\n","import { VERSION } from './version';\nimport { Stream } from './streaming';\nimport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n} from './error';\nimport {\n  kind as shimsKind,\n  type Readable,\n  getDefaultAgent,\n  type Agent,\n  fetch,\n  type RequestInfo,\n  type RequestInit,\n  type Response,\n  type HeadersInit,\n} from './_shims/index';\nexport { type Response };\nimport { BlobLike, isBlobLike, isMultipartBody } from './uploads';\nexport {\n  maybeMultipartFormRequestOptions,\n  multipartFormRequestOptions,\n  createForm,\n  type Uploadable,\n} from './uploads';\n\nexport type Fetch = (url: RequestInfo, init?: RequestInit) => Promise<Response>;\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\ntype APIResponseProps = {\n  response: Response;\n  options: FinalRequestOptions;\n  controller: AbortController;\n};\n\nasync function defaultParseResponse<T>(props: APIResponseProps): Promise<WithRequestID<T>> {\n  const { response } = props;\n  if (props.options.stream) {\n    debug('response', response.status, response.url, response.headers, response.body);\n\n    // Note: there is an invariant here that isn't represented in the type system\n    // that if you set `stream: true` the response type must also be `Stream<T>`\n\n    if (props.options.__streamClass) {\n      return props.options.__streamClass.fromSSEResponse(response, props.controller) as any;\n    }\n\n    return Stream.fromSSEResponse(response, props.controller) as any;\n  }\n\n  // fetch refuses to read the body when the status code is 204.\n  if (response.status === 204) {\n    return null as WithRequestID<T>;\n  }\n\n  if (props.options.__binaryResponse) {\n    return response as unknown as WithRequestID<T>;\n  }\n\n  const contentType = response.headers.get('content-type');\n  const isJSON =\n    contentType?.includes('application/json') || contentType?.includes('application/vnd.api+json');\n  if (isJSON) {\n    const json = await response.json();\n\n    debug('response', response.status, response.url, response.headers, json);\n\n    return _addRequestID(json, response);\n  }\n\n  const text = await response.text();\n  debug('response', response.status, response.url, response.headers, text);\n\n  // TODO handle blob, arraybuffer, other content types, etc.\n  return text as unknown as WithRequestID<T>;\n}\n\ntype WithRequestID<T> =\n  T extends Array<any> | Response | AbstractPage<any> ? T\n  : T extends Record<string, any> ? T & { _request_id?: string | null }\n  : T;\n\nfunction _addRequestID<T>(value: T, response: Response): WithRequestID<T> {\n  if (!value || typeof value !== 'object' || Array.isArray(value)) {\n    return value as WithRequestID<T>;\n  }\n\n  return Object.defineProperty(value, '_request_id', {\n    value: response.headers.get('x-request-id'),\n    enumerable: false,\n  }) as WithRequestID<T>;\n}\n\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nexport class APIPromise<T> extends Promise<WithRequestID<T>> {\n  private parsedPromise: Promise<WithRequestID<T>> | undefined;\n\n  constructor(\n    private responsePromise: Promise<APIResponseProps>,\n    private parseResponse: (\n      props: APIResponseProps,\n    ) => PromiseOrValue<WithRequestID<T>> = defaultParseResponse,\n  ) {\n    super((resolve) => {\n      // this is maybe a bit weird but this has to be a no-op to not implicitly\n      // parse the response body; instead .then, .catch, .finally are overridden\n      // to parse the response\n      resolve(null as any);\n    });\n  }\n\n  _thenUnwrap<U>(transform: (data: T, props: APIResponseProps) => U): APIPromise<U> {\n    return new APIPromise(this.responsePromise, async (props) =>\n      _addRequestID(transform(await this.parseResponse(props), props), props.response),\n    );\n  }\n\n  /**\n   * Gets the raw `Response` instance instead of parsing the response\n   * data.\n   *\n   * If you want to parse the response body but still get the `Response`\n   * instance, you can use {@link withResponse()}.\n   *\n   * 👋 Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import … from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  asResponse(): Promise<Response> {\n    return this.responsePromise.then((p) => p.response);\n  }\n\n  /**\n   * Gets the parsed response data, the raw `Response` instance and the ID of the request,\n   * returned via the X-Request-ID header which is useful for debugging requests and reporting\n   * issues to OpenAI.\n   *\n   * If you just want to get the raw `Response` instance without parsing it,\n   * you can use {@link asResponse()}.\n   *\n   *\n   * 👋 Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import … from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  async withResponse(): Promise<{ data: T; response: Response; request_id: string | null | undefined }> {\n    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n    return { data, response, request_id: response.headers.get('x-request-id') };\n  }\n\n  private parse(): Promise<WithRequestID<T>> {\n    if (!this.parsedPromise) {\n      this.parsedPromise = this.responsePromise.then(this.parseResponse) as any as Promise<WithRequestID<T>>;\n    }\n    return this.parsedPromise;\n  }\n\n  override then<TResult1 = WithRequestID<T>, TResult2 = never>(\n    onfulfilled?: ((value: WithRequestID<T>) => TResult1 | PromiseLike<TResult1>) | undefined | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null,\n  ): Promise<TResult1 | TResult2> {\n    return this.parse().then(onfulfilled, onrejected);\n  }\n\n  override catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null,\n  ): Promise<WithRequestID<T> | TResult> {\n    return this.parse().catch(onrejected);\n  }\n\n  override finally(onfinally?: (() => void) | undefined | null): Promise<WithRequestID<T>> {\n    return this.parse().finally(onfinally);\n  }\n}\n\nexport abstract class APIClient {\n  baseURL: string;\n  maxRetries: number;\n  timeout: number;\n  httpAgent: Agent | undefined;\n\n  private fetch: Fetch;\n  protected idempotencyHeader?: string;\n\n  constructor({\n    baseURL,\n    maxRetries = 2,\n    timeout = 600000, // 10 minutes\n    httpAgent,\n    fetch: overridenFetch,\n  }: {\n    baseURL: string;\n    maxRetries?: number | undefined;\n    timeout: number | undefined;\n    httpAgent: Agent | undefined;\n    fetch: Fetch | undefined;\n  }) {\n    this.baseURL = baseURL;\n    this.maxRetries = validatePositiveInteger('maxRetries', maxRetries);\n    this.timeout = validatePositiveInteger('timeout', timeout);\n    this.httpAgent = httpAgent;\n\n    this.fetch = overridenFetch ?? fetch;\n  }\n\n  protected authHeaders(opts: FinalRequestOptions): Headers {\n    return {};\n  }\n\n  /**\n   * Override this to add your own default headers, for example:\n   *\n   *  {\n   *    ...super.defaultHeaders(),\n   *    Authorization: 'Bearer 123',\n   *  }\n   */\n  protected defaultHeaders(opts: FinalRequestOptions): Headers {\n    return {\n      Accept: 'application/json',\n      'Content-Type': 'application/json',\n      'User-Agent': this.getUserAgent(),\n      ...getPlatformHeaders(),\n      ...this.authHeaders(opts),\n    };\n  }\n\n  protected abstract defaultQuery(): DefaultQuery | undefined;\n\n  /**\n   * Override this to add your own headers validation:\n   */\n  protected validateHeaders(headers: Headers, customHeaders: Headers) {}\n\n  protected defaultIdempotencyKey(): string {\n    return `stainless-node-retry-${uuid4()}`;\n  }\n\n  get<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('get', path, opts);\n  }\n\n  post<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('post', path, opts);\n  }\n\n  patch<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('patch', path, opts);\n  }\n\n  put<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('put', path, opts);\n  }\n\n  delete<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('delete', path, opts);\n  }\n\n  private methodRequest<Req, Rsp>(\n    method: HTTPMethod,\n    path: string,\n    opts?: PromiseOrValue<RequestOptions<Req>>,\n  ): APIPromise<Rsp> {\n    return this.request(\n      Promise.resolve(opts).then(async (opts) => {\n        const body =\n          opts && isBlobLike(opts?.body) ? new DataView(await opts.body.arrayBuffer())\n          : opts?.body instanceof DataView ? opts.body\n          : opts?.body instanceof ArrayBuffer ? new DataView(opts.body)\n          : opts && ArrayBuffer.isView(opts?.body) ? new DataView(opts.body.buffer)\n          : opts?.body;\n        return { method, path, ...opts, body };\n      }),\n    );\n  }\n\n  getAPIList<Item, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    path: string,\n    Page: new (...args: any[]) => PageClass,\n    opts?: RequestOptions<any>,\n  ): PagePromise<PageClass, Item> {\n    return this.requestAPIList(Page, { method: 'get', path, ...opts });\n  }\n\n  private calculateContentLength(body: unknown): string | null {\n    if (typeof body === 'string') {\n      if (typeof Buffer !== 'undefined') {\n        return Buffer.byteLength(body, 'utf8').toString();\n      }\n\n      if (typeof TextEncoder !== 'undefined') {\n        const encoder = new TextEncoder();\n        const encoded = encoder.encode(body);\n        return encoded.length.toString();\n      }\n    } else if (ArrayBuffer.isView(body)) {\n      return body.byteLength.toString();\n    }\n\n    return null;\n  }\n\n  buildRequest<Req>(\n    options: FinalRequestOptions<Req>,\n    { retryCount = 0 }: { retryCount?: number } = {},\n  ): { req: RequestInit; url: string; timeout: number } {\n    const { method, path, query, headers: headers = {} } = options;\n\n    const body =\n      ArrayBuffer.isView(options.body) || (options.__binaryRequest && typeof options.body === 'string') ?\n        options.body\n      : isMultipartBody(options.body) ? options.body.body\n      : options.body ? JSON.stringify(options.body, null, 2)\n      : null;\n    const contentLength = this.calculateContentLength(body);\n\n    const url = this.buildURL(path!, query);\n    if ('timeout' in options) validatePositiveInteger('timeout', options.timeout);\n    const timeout = options.timeout ?? this.timeout;\n    const httpAgent = options.httpAgent ?? this.httpAgent ?? getDefaultAgent(url);\n    const minAgentTimeout = timeout + 1000;\n    if (\n      typeof (httpAgent as any)?.options?.timeout === 'number' &&\n      minAgentTimeout > ((httpAgent as any).options.timeout ?? 0)\n    ) {\n      // Allow any given request to bump our agent active socket timeout.\n      // This may seem strange, but leaking active sockets should be rare and not particularly problematic,\n      // and without mutating agent we would need to create more of them.\n      // This tradeoff optimizes for performance.\n      (httpAgent as any).options.timeout = minAgentTimeout;\n    }\n\n    if (this.idempotencyHeader && method !== 'get') {\n      if (!options.idempotencyKey) options.idempotencyKey = this.defaultIdempotencyKey();\n      headers[this.idempotencyHeader] = options.idempotencyKey;\n    }\n\n    const reqHeaders = this.buildHeaders({ options, headers, contentLength, retryCount });\n\n    const req: RequestInit = {\n      method,\n      ...(body && { body: body as any }),\n      headers: reqHeaders,\n      ...(httpAgent && { agent: httpAgent }),\n      // @ts-ignore node-fetch uses a custom AbortSignal type that is\n      // not compatible with standard web types\n      signal: options.signal ?? null,\n    };\n\n    return { req, url, timeout };\n  }\n\n  private buildHeaders({\n    options,\n    headers,\n    contentLength,\n    retryCount,\n  }: {\n    options: FinalRequestOptions;\n    headers: Record<string, string | null | undefined>;\n    contentLength: string | null | undefined;\n    retryCount: number;\n  }): Record<string, string> {\n    const reqHeaders: Record<string, string> = {};\n    if (contentLength) {\n      reqHeaders['content-length'] = contentLength;\n    }\n\n    const defaultHeaders = this.defaultHeaders(options);\n    applyHeadersMut(reqHeaders, defaultHeaders);\n    applyHeadersMut(reqHeaders, headers);\n\n    // let builtin fetch set the Content-Type for multipart bodies\n    if (isMultipartBody(options.body) && shimsKind !== 'node') {\n      delete reqHeaders['content-type'];\n    }\n\n    // Don't set the retry count header if it was already set or removed through default headers or by the\n    // caller. We check `defaultHeaders` and `headers`, which can contain nulls, instead of `reqHeaders` to\n    // account for the removal case.\n    if (\n      getHeader(defaultHeaders, 'x-stainless-retry-count') === undefined &&\n      getHeader(headers, 'x-stainless-retry-count') === undefined\n    ) {\n      reqHeaders['x-stainless-retry-count'] = String(retryCount);\n    }\n\n    this.validateHeaders(reqHeaders, headers);\n\n    return reqHeaders;\n  }\n\n  /**\n   * Used as a callback for mutating the given `FinalRequestOptions` object.\n   */\n  protected async prepareOptions(options: FinalRequestOptions): Promise<void> {}\n\n  /**\n   * Used as a callback for mutating the given `RequestInit` object.\n   *\n   * This is useful for cases where you want to add certain headers based off of\n   * the request properties, e.g. `method` or `url`.\n   */\n  protected async prepareRequest(\n    request: RequestInit,\n    { url, options }: { url: string; options: FinalRequestOptions },\n  ): Promise<void> {}\n\n  protected parseHeaders(headers: HeadersInit | null | undefined): Record<string, string> {\n    return (\n      !headers ? {}\n      : Symbol.iterator in headers ?\n        Object.fromEntries(Array.from(headers as Iterable<string[]>).map((header) => [...header]))\n      : { ...headers }\n    );\n  }\n\n  protected makeStatusError(\n    status: number | undefined,\n    error: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ): APIError {\n    return APIError.generate(status, error, message, headers);\n  }\n\n  request<Req, Rsp>(\n    options: PromiseOrValue<FinalRequestOptions<Req>>,\n    remainingRetries: number | null = null,\n  ): APIPromise<Rsp> {\n    return new APIPromise(this.makeRequest(options, remainingRetries));\n  }\n\n  private async makeRequest<Req>(\n    optionsInput: PromiseOrValue<FinalRequestOptions<Req>>,\n    retriesRemaining: number | null,\n  ): Promise<APIResponseProps> {\n    const options = await optionsInput;\n    const maxRetries = options.maxRetries ?? this.maxRetries;\n    if (retriesRemaining == null) {\n      retriesRemaining = maxRetries;\n    }\n\n    await this.prepareOptions(options);\n\n    const { req, url, timeout } = this.buildRequest(options, { retryCount: maxRetries - retriesRemaining });\n\n    await this.prepareRequest(req, { url, options });\n\n    debug('request', url, options, req.headers);\n\n    if (options.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    const controller = new AbortController();\n    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n\n    if (response instanceof Error) {\n      if (options.signal?.aborted) {\n        throw new APIUserAbortError();\n      }\n      if (retriesRemaining) {\n        return this.retryRequest(options, retriesRemaining);\n      }\n      if (response.name === 'AbortError') {\n        throw new APIConnectionTimeoutError();\n      }\n      throw new APIConnectionError({ cause: response });\n    }\n\n    const responseHeaders = createResponseHeaders(response.headers);\n\n    if (!response.ok) {\n      if (retriesRemaining && this.shouldRetry(response)) {\n        const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n        debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders);\n        return this.retryRequest(options, retriesRemaining, responseHeaders);\n      }\n\n      const errText = await response.text().catch((e) => castToError(e).message);\n      const errJSON = safeJSON(errText);\n      const errMessage = errJSON ? undefined : errText;\n      const retryMessage = retriesRemaining ? `(error; no more retries left)` : `(error; not retryable)`;\n\n      debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders, errMessage);\n\n      const err = this.makeStatusError(response.status, errJSON, errMessage, responseHeaders);\n      throw err;\n    }\n\n    return { response, options, controller };\n  }\n\n  requestAPIList<Item = unknown, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n    options: FinalRequestOptions,\n  ): PagePromise<PageClass, Item> {\n    const request = this.makeRequest(options, null);\n    return new PagePromise<PageClass, Item>(this, request, Page);\n  }\n\n  buildURL<Req>(path: string, query: Req | null | undefined): string {\n    const url =\n      isAbsoluteURL(path) ?\n        new URL(path)\n      : new URL(this.baseURL + (this.baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n\n    const defaultQuery = this.defaultQuery();\n    if (!isEmptyObj(defaultQuery)) {\n      query = { ...defaultQuery, ...query } as Req;\n    }\n\n    if (typeof query === 'object' && query && !Array.isArray(query)) {\n      url.search = this.stringifyQuery(query as Record<string, unknown>);\n    }\n\n    return url.toString();\n  }\n\n  protected stringifyQuery(query: Record<string, unknown>): string {\n    return Object.entries(query)\n      .filter(([_, value]) => typeof value !== 'undefined')\n      .map(([key, value]) => {\n        if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n          return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;\n        }\n        if (value === null) {\n          return `${encodeURIComponent(key)}=`;\n        }\n        throw new OpenAIError(\n          `Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`,\n        );\n      })\n      .join('&');\n  }\n\n  async fetchWithTimeout(\n    url: RequestInfo,\n    init: RequestInit | undefined,\n    ms: number,\n    controller: AbortController,\n  ): Promise<Response> {\n    const { signal, ...options } = init || {};\n    if (signal) signal.addEventListener('abort', () => controller.abort());\n\n    const timeout = setTimeout(() => controller.abort(), ms);\n\n    return (\n      this.getRequestClient()\n        // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n        .fetch.call(undefined, url, { signal: controller.signal as any, ...options })\n        .finally(() => {\n          clearTimeout(timeout);\n        })\n    );\n  }\n\n  protected getRequestClient(): RequestClient {\n    return { fetch: this.fetch };\n  }\n\n  private shouldRetry(response: Response): boolean {\n    // Note this is not a standard header.\n    const shouldRetryHeader = response.headers.get('x-should-retry');\n\n    // If the server explicitly says whether or not to retry, obey.\n    if (shouldRetryHeader === 'true') return true;\n    if (shouldRetryHeader === 'false') return false;\n\n    // Retry on request timeouts.\n    if (response.status === 408) return true;\n\n    // Retry on lock timeouts.\n    if (response.status === 409) return true;\n\n    // Retry on rate limits.\n    if (response.status === 429) return true;\n\n    // Retry internal errors.\n    if (response.status >= 500) return true;\n\n    return false;\n  }\n\n  private async retryRequest(\n    options: FinalRequestOptions,\n    retriesRemaining: number,\n    responseHeaders?: Headers | undefined,\n  ): Promise<APIResponseProps> {\n    let timeoutMillis: number | undefined;\n\n    // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n    const retryAfterMillisHeader = responseHeaders?.['retry-after-ms'];\n    if (retryAfterMillisHeader) {\n      const timeoutMs = parseFloat(retryAfterMillisHeader);\n      if (!Number.isNaN(timeoutMs)) {\n        timeoutMillis = timeoutMs;\n      }\n    }\n\n    // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n    const retryAfterHeader = responseHeaders?.['retry-after'];\n    if (retryAfterHeader && !timeoutMillis) {\n      const timeoutSeconds = parseFloat(retryAfterHeader);\n      if (!Number.isNaN(timeoutSeconds)) {\n        timeoutMillis = timeoutSeconds * 1000;\n      } else {\n        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n      }\n    }\n\n    // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n    // just do what it says, but otherwise calculate a default\n    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n      const maxRetries = options.maxRetries ?? this.maxRetries;\n      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n    }\n    await sleep(timeoutMillis);\n\n    return this.makeRequest(options, retriesRemaining - 1);\n  }\n\n  private calculateDefaultRetryTimeoutMillis(retriesRemaining: number, maxRetries: number): number {\n    const initialRetryDelay = 0.5;\n    const maxRetryDelay = 8.0;\n\n    const numRetries = maxRetries - retriesRemaining;\n\n    // Apply exponential backoff, but not more than the max.\n    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n\n    // Apply some jitter, take up to at most 25 percent of the retry time.\n    const jitter = 1 - Math.random() * 0.25;\n\n    return sleepSeconds * jitter * 1000;\n  }\n\n  private getUserAgent(): string {\n    return `${this.constructor.name}/JS ${VERSION}`;\n  }\n}\n\nexport type PageInfo = { url: URL } | { params: Record<string, unknown> | null };\n\nexport abstract class AbstractPage<Item> implements AsyncIterable<Item> {\n  #client: APIClient;\n  protected options: FinalRequestOptions;\n\n  protected response: Response;\n  protected body: unknown;\n\n  constructor(client: APIClient, response: Response, body: unknown, options: FinalRequestOptions) {\n    this.#client = client;\n    this.options = options;\n    this.response = response;\n    this.body = body;\n  }\n\n  /**\n   * @deprecated Use nextPageInfo instead\n   */\n  abstract nextPageParams(): Partial<Record<string, unknown>> | null;\n  abstract nextPageInfo(): PageInfo | null;\n\n  abstract getPaginatedItems(): Item[];\n\n  hasNextPage(): boolean {\n    const items = this.getPaginatedItems();\n    if (!items.length) return false;\n    return this.nextPageInfo() != null;\n  }\n\n  async getNextPage(): Promise<this> {\n    const nextInfo = this.nextPageInfo();\n    if (!nextInfo) {\n      throw new OpenAIError(\n        'No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.',\n      );\n    }\n    const nextOptions = { ...this.options };\n    if ('params' in nextInfo && typeof nextOptions.query === 'object') {\n      nextOptions.query = { ...nextOptions.query, ...nextInfo.params };\n    } else if ('url' in nextInfo) {\n      const params = [...Object.entries(nextOptions.query || {}), ...nextInfo.url.searchParams.entries()];\n      for (const [key, value] of params) {\n        nextInfo.url.searchParams.set(key, value as any);\n      }\n      nextOptions.query = undefined;\n      nextOptions.path = nextInfo.url.toString();\n    }\n    return await this.#client.requestAPIList(this.constructor as any, nextOptions);\n  }\n\n  async *iterPages(): AsyncGenerator<this> {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    let page: this = this;\n    yield page;\n    while (page.hasNextPage()) {\n      page = await page.getNextPage();\n      yield page;\n    }\n  }\n\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    for await (const page of this.iterPages()) {\n      for (const item of page.getPaginatedItems()) {\n        yield item;\n      }\n    }\n  }\n}\n\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nexport class PagePromise<\n    PageClass extends AbstractPage<Item>,\n    Item = ReturnType<PageClass['getPaginatedItems']>[number],\n  >\n  extends APIPromise<PageClass>\n  implements AsyncIterable<Item>\n{\n  constructor(\n    client: APIClient,\n    request: Promise<APIResponseProps>,\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n  ) {\n    super(\n      request,\n      async (props) =>\n        new Page(\n          client,\n          props.response,\n          await defaultParseResponse(props),\n          props.options,\n        ) as WithRequestID<PageClass>,\n    );\n  }\n\n  /**\n   * Allow auto-paginating iteration on an unawaited list call, eg:\n   *\n   *    for await (const item of client.items.list()) {\n   *      console.log(item)\n   *    }\n   */\n  async *[Symbol.asyncIterator](): AsyncGenerator<Item> {\n    const page = await this;\n    for await (const item of page) {\n      yield item;\n    }\n  }\n}\n\nexport const createResponseHeaders = (\n  headers: Awaited<ReturnType<Fetch>>['headers'],\n): Record<string, string> => {\n  return new Proxy(\n    Object.fromEntries(\n      // @ts-ignore\n      headers.entries(),\n    ),\n    {\n      get(target, name) {\n        const key = name.toString();\n        return target[key.toLowerCase()] || target[key];\n      },\n    },\n  );\n};\n\ntype HTTPMethod = 'get' | 'post' | 'put' | 'patch' | 'delete';\n\nexport type RequestClient = { fetch: Fetch };\nexport type Headers = Record<string, string | null | undefined>;\nexport type DefaultQuery = Record<string, string | undefined>;\nexport type KeysEnum<T> = { [P in keyof Required<T>]: true };\n\nexport type RequestOptions<\n  Req = unknown | Record<string, unknown> | Readable | BlobLike | ArrayBufferView | ArrayBuffer,\n> = {\n  method?: HTTPMethod;\n  path?: string;\n  query?: Req | undefined;\n  body?: Req | null | undefined;\n  headers?: Headers | undefined;\n\n  maxRetries?: number;\n  stream?: boolean | undefined;\n  timeout?: number;\n  httpAgent?: Agent;\n  signal?: AbortSignal | undefined | null;\n  idempotencyKey?: string;\n\n  __binaryRequest?: boolean | undefined;\n  __binaryResponse?: boolean | undefined;\n  __streamClass?: typeof Stream;\n};\n\n// This is required so that we can determine if a given object matches the RequestOptions\n// type at runtime. While this requires duplication, it is enforced by the TypeScript\n// compiler such that any missing / extraneous keys will cause an error.\nconst requestOptionsKeys: KeysEnum<RequestOptions> = {\n  method: true,\n  path: true,\n  query: true,\n  body: true,\n  headers: true,\n\n  maxRetries: true,\n  stream: true,\n  timeout: true,\n  httpAgent: true,\n  signal: true,\n  idempotencyKey: true,\n\n  __binaryRequest: true,\n  __binaryResponse: true,\n  __streamClass: true,\n};\n\nexport const isRequestOptions = (obj: unknown): obj is RequestOptions => {\n  return (\n    typeof obj === 'object' &&\n    obj !== null &&\n    !isEmptyObj(obj) &&\n    Object.keys(obj).every((k) => hasOwn(requestOptionsKeys, k))\n  );\n};\n\nexport type FinalRequestOptions<Req = unknown | Record<string, unknown> | Readable | DataView> =\n  RequestOptions<Req> & {\n    method: HTTPMethod;\n    path: string;\n  };\n\ndeclare const Deno: any;\ndeclare const EdgeRuntime: any;\ntype Arch = 'x32' | 'x64' | 'arm' | 'arm64' | `other:${string}` | 'unknown';\ntype PlatformName =\n  | 'MacOS'\n  | 'Linux'\n  | 'Windows'\n  | 'FreeBSD'\n  | 'OpenBSD'\n  | 'iOS'\n  | 'Android'\n  | `Other:${string}`\n  | 'Unknown';\ntype Browser = 'ie' | 'edge' | 'chrome' | 'firefox' | 'safari';\ntype PlatformProperties = {\n  'X-Stainless-Lang': 'js';\n  'X-Stainless-Package-Version': string;\n  'X-Stainless-OS': PlatformName;\n  'X-Stainless-Arch': Arch;\n  'X-Stainless-Runtime': 'node' | 'deno' | 'edge' | `browser:${Browser}` | 'unknown';\n  'X-Stainless-Runtime-Version': string;\n};\nconst getPlatformProperties = (): PlatformProperties => {\n  if (typeof Deno !== 'undefined' && Deno.build != null) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(Deno.build.os),\n      'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n      'X-Stainless-Runtime': 'deno',\n      'X-Stainless-Runtime-Version':\n        typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n    };\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': `other:${EdgeRuntime}`,\n      'X-Stainless-Runtime': 'edge',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n  // Check if Node.js\n  if (Object.prototype.toString.call(typeof process !== 'undefined' ? process : 0) === '[object process]') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(process.platform),\n      'X-Stainless-Arch': normalizeArch(process.arch),\n      'X-Stainless-Runtime': 'node',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n\n  const browserInfo = getBrowserInfo();\n  if (browserInfo) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': 'unknown',\n      'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n      'X-Stainless-Runtime-Version': browserInfo.version,\n    };\n  }\n\n  // TODO add support for Cloudflare workers, etc.\n  return {\n    'X-Stainless-Lang': 'js',\n    'X-Stainless-Package-Version': VERSION,\n    'X-Stainless-OS': 'Unknown',\n    'X-Stainless-Arch': 'unknown',\n    'X-Stainless-Runtime': 'unknown',\n    'X-Stainless-Runtime-Version': 'unknown',\n  };\n};\n\ntype BrowserInfo = {\n  browser: Browser;\n  version: string;\n};\n\ndeclare const navigator: { userAgent: string } | undefined;\n\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo(): BrowserInfo | null {\n  if (typeof navigator === 'undefined' || !navigator) {\n    return null;\n  }\n\n  // NOTE: The order matters here!\n  const browserPatterns = [\n    { key: 'edge' as const, pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'chrome' as const, pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'firefox' as const, pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'safari' as const, pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n  ];\n\n  // Find the FIRST matching browser\n  for (const { key, pattern } of browserPatterns) {\n    const match = pattern.exec(navigator.userAgent);\n    if (match) {\n      const major = match[1] || 0;\n      const minor = match[2] || 0;\n      const patch = match[3] || 0;\n\n      return { browser: key, version: `${major}.${minor}.${patch}` };\n    }\n  }\n\n  return null;\n}\n\nconst normalizeArch = (arch: string): Arch => {\n  // Node docs:\n  // - https://nodejs.org/api/process.html#processarch\n  // Deno docs:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  if (arch === 'x32') return 'x32';\n  if (arch === 'x86_64' || arch === 'x64') return 'x64';\n  if (arch === 'arm') return 'arm';\n  if (arch === 'aarch64' || arch === 'arm64') return 'arm64';\n  if (arch) return `other:${arch}`;\n  return 'unknown';\n};\n\nconst normalizePlatform = (platform: string): PlatformName => {\n  // Node platforms:\n  // - https://nodejs.org/api/process.html#processplatform\n  // Deno platforms:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  // - https://github.com/denoland/deno/issues/14799\n\n  platform = platform.toLowerCase();\n\n  // NOTE: this iOS check is untested and may not work\n  // Node does not work natively on IOS, there is a fork at\n  // https://github.com/nodejs-mobile/nodejs-mobile\n  // however it is unknown at the time of writing how to detect if it is running\n  if (platform.includes('ios')) return 'iOS';\n  if (platform === 'android') return 'Android';\n  if (platform === 'darwin') return 'MacOS';\n  if (platform === 'win32') return 'Windows';\n  if (platform === 'freebsd') return 'FreeBSD';\n  if (platform === 'openbsd') return 'OpenBSD';\n  if (platform === 'linux') return 'Linux';\n  if (platform) return `Other:${platform}`;\n  return 'Unknown';\n};\n\nlet _platformHeaders: PlatformProperties;\nconst getPlatformHeaders = () => {\n  return (_platformHeaders ??= getPlatformProperties());\n};\n\nexport const safeJSON = (text: string) => {\n  try {\n    return JSON.parse(text);\n  } catch (err) {\n    return undefined;\n  }\n};\n\n// https://stackoverflow.com/a/19709846\nconst startsWithSchemeRegexp = new RegExp('^(?:[a-z]+:)?//', 'i');\nconst isAbsoluteURL = (url: string): boolean => {\n  return startsWithSchemeRegexp.test(url);\n};\n\nexport const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));\n\nconst validatePositiveInteger = (name: string, n: unknown): number => {\n  if (typeof n !== 'number' || !Number.isInteger(n)) {\n    throw new OpenAIError(`${name} must be an integer`);\n  }\n  if (n < 0) {\n    throw new OpenAIError(`${name} must be a positive integer`);\n  }\n  return n;\n};\n\nexport const castToError = (err: any): Error => {\n  if (err instanceof Error) return err;\n  if (typeof err === 'object' && err !== null) {\n    try {\n      return new Error(JSON.stringify(err));\n    } catch {}\n  }\n  return new Error(err);\n};\n\nexport const ensurePresent = <T>(value: T | null | undefined): T => {\n  if (value == null) throw new OpenAIError(`Expected a value to be given but received ${value} instead.`);\n  return value;\n};\n\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nexport const readEnv = (env: string): string | undefined => {\n  if (typeof process !== 'undefined') {\n    return process.env?.[env]?.trim() ?? undefined;\n  }\n  if (typeof Deno !== 'undefined') {\n    return Deno.env?.get?.(env)?.trim();\n  }\n  return undefined;\n};\n\nexport const coerceInteger = (value: unknown): number => {\n  if (typeof value === 'number') return Math.round(value);\n  if (typeof value === 'string') return parseInt(value, 10);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceFloat = (value: unknown): number => {\n  if (typeof value === 'number') return value;\n  if (typeof value === 'string') return parseFloat(value);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceBoolean = (value: unknown): boolean => {\n  if (typeof value === 'boolean') return value;\n  if (typeof value === 'string') return value === 'true';\n  return Boolean(value);\n};\n\nexport const maybeCoerceInteger = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceInteger(value);\n};\n\nexport const maybeCoerceFloat = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceFloat(value);\n};\n\nexport const maybeCoerceBoolean = (value: unknown): boolean | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceBoolean(value);\n};\n\n// https://stackoverflow.com/a/34491287\nexport function isEmptyObj(obj: Object | null | undefined): boolean {\n  if (!obj) return true;\n  for (const _k in obj) return false;\n  return true;\n}\n\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nexport function hasOwn(obj: Object, key: string): boolean {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\n/**\n * Copies headers from \"newHeaders\" onto \"targetHeaders\",\n * using lower-case for all properties,\n * ignoring any keys with undefined values,\n * and deleting any keys with null values.\n */\nfunction applyHeadersMut(targetHeaders: Headers, newHeaders: Headers): void {\n  for (const k in newHeaders) {\n    if (!hasOwn(newHeaders, k)) continue;\n    const lowerKey = k.toLowerCase();\n    if (!lowerKey) continue;\n\n    const val = newHeaders[k];\n\n    if (val === null) {\n      delete targetHeaders[lowerKey];\n    } else if (val !== undefined) {\n      targetHeaders[lowerKey] = val;\n    }\n  }\n}\n\nexport function debug(action: string, ...args: any[]) {\n  if (typeof process !== 'undefined' && process?.env?.['DEBUG'] === 'true') {\n    console.log(`OpenAI:DEBUG:${action}`, ...args);\n  }\n}\n\n/**\n * https://stackoverflow.com/a/2117523\n */\nconst uuid4 = () => {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {\n    const r = (Math.random() * 16) | 0;\n    const v = c === 'x' ? r : (r & 0x3) | 0x8;\n    return v.toString(16);\n  });\n};\n\nexport const isRunningInBrowser = () => {\n  return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n    // @ts-ignore\n    typeof window.document !== 'undefined' &&\n    // @ts-ignore\n    typeof navigator !== 'undefined'\n  );\n};\n\nexport interface HeadersProtocol {\n  get: (header: string) => string | null | undefined;\n}\nexport type HeadersLike = Record<string, string | string[] | undefined> | HeadersProtocol;\n\nexport const isHeadersProtocol = (headers: any): headers is HeadersProtocol => {\n  return typeof headers?.get === 'function';\n};\n\nexport const getRequiredHeader = (headers: HeadersLike | Headers, header: string): string => {\n  const foundHeader = getHeader(headers, header);\n  if (foundHeader === undefined) {\n    throw new Error(`Could not find ${header} header`);\n  }\n  return foundHeader;\n};\n\nexport const getHeader = (headers: HeadersLike | Headers, header: string): string | undefined => {\n  const lowerCasedHeader = header.toLowerCase();\n  if (isHeadersProtocol(headers)) {\n    // to deal with the case where the header looks like Stainless-Event-Id\n    const intercapsHeader =\n      header[0]?.toUpperCase() +\n      header.substring(1).replace(/([^\\w])(\\w)/g, (_m, g1, g2) => g1 + g2.toUpperCase());\n    for (const key of [header, lowerCasedHeader, header.toUpperCase(), intercapsHeader]) {\n      const value = headers.get(key);\n      if (value) {\n        return value;\n      }\n    }\n  }\n\n  for (const [key, value] of Object.entries(headers)) {\n    if (key.toLowerCase() === lowerCasedHeader) {\n      if (Array.isArray(value)) {\n        if (value.length <= 1) return value[0];\n        console.warn(`Received ${value.length} entries for the ${header} header, using the first entry.`);\n        return value[0];\n      }\n      return value;\n    }\n  }\n\n  return undefined;\n};\n\n/**\n * Encodes a string to Base64 format.\n */\nexport const toBase64 = (str: string | null | undefined): string => {\n  if (!str) return '';\n  if (typeof Buffer !== 'undefined') {\n    return Buffer.from(str).toString('base64');\n  }\n\n  if (typeof btoa !== 'undefined') {\n    return btoa(str);\n  }\n\n  throw new OpenAIError('Cannot generate b64 string; Expected `Buffer` or `btoa` to be defined');\n};\n\nexport function isObj(obj: unknown): obj is Record<string, unknown> {\n  return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { AbstractPage, Response, APIClient, FinalRequestOptions, PageInfo } from './core';\n\nexport interface PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class Page<Item> extends AbstractPage<Item> implements PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n\n  constructor(client: APIClient, response: Response, body: PageResponse<Item>, options: FinalRequestOptions) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.object = body.object;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  /**\n   * This page represents a response that isn't actually paginated at the API level\n   * so there will never be any next page params.\n   */\n  nextPageParams(): null {\n    return null;\n  }\n\n  nextPageInfo(): null {\n    return null;\n  }\n}\n\nexport interface CursorPageResponse<Item> {\n  data: Array<Item>;\n}\n\nexport interface CursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class CursorPage<Item extends { id: string }>\n  extends AbstractPage<Item>\n  implements CursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  constructor(\n    client: APIClient,\n    response: Response,\n    body: CursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  nextPageParams(): Partial<CursorPageParams> | null {\n    const info = this.nextPageInfo();\n    if (!info) return null;\n    if ('params' in info) return info.params;\n    const params = Object.fromEntries(info.url.searchParams);\n    if (!Object.keys(params).length) return null;\n    return params;\n  }\n\n  nextPageInfo(): PageInfo | null {\n    const data = this.getPaginatedItems();\n    if (!data.length) {\n      return null;\n    }\n\n    const id = data[data.length - 1]?.id;\n    if (!id) {\n      return null;\n    }\n\n    return { params: { after: id } };\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { OpenAI } from './index';\n\nexport class APIResource {\n  protected _client: OpenAI;\n\n  constructor(client: OpenAI) {\n    this._client = client;\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { APIPromise } from '../../core';\nimport * as Core from '../../core';\nimport * as ChatCompletionsAPI from './completions';\nimport * as CompletionsAPI from '../completions';\nimport * as Shared from '../shared';\nimport * as ChatAPI from './chat';\nimport { Stream } from '../../streaming';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a model response for the given chat conversation. Learn more in the\n   * [text generation](https://platform.openai.com/docs/guides/text-generation),\n   * [vision](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio) guides.\n   */\n  create(\n    body: ChatCompletionCreateParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk>>;\n  create(\n    body: ChatCompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk> | ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion> | APIPromise<Stream<ChatCompletionChunk>> {\n    return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ChatCompletion>\n      | APIPromise<Stream<ChatCompletionChunk>>;\n  }\n}\n\n/**\n * Represents a chat completion response returned by model, based on the provided\n * input.\n */\nexport interface ChatCompletion {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletion.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for the chat completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion`.\n   */\n  object: 'chat.completion';\n\n  /**\n   * The service tier used for processing the request. This field is only included if\n   * the `service_tier` parameter is specified in the request.\n   */\n  service_tier?: 'scale' | 'default' | null;\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletion {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: Choice.Logprobs | null;\n\n    /**\n     * A chat completion message generated by the model.\n     */\n    message: ChatCompletionsAPI.ChatCompletionMessage;\n  }\n\n  export namespace Choice {\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\nexport interface ChatCompletionAssistantMessageParam {\n  /**\n   * The role of the messages author, in this case `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAssistantMessageParam.Audio | null;\n\n  /**\n   * The contents of the assistant message. Required unless `tool_calls` or\n   * `function_call` is specified.\n   */\n  content?: string | Array<ChatCompletionContentPartText | ChatCompletionContentPartRefusal> | null;\n\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionAssistantMessageParam.FunctionCall | null;\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n\n  /**\n   * The refusal message by the assistant.\n   */\n  refusal?: string | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionAssistantMessageParam {\n  /**\n   * Data about a previous audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  export interface Audio {\n    /**\n     * Unique identifier for a previous audio response from the model.\n     */\n    id: string;\n  }\n\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * If the audio output modality is requested, this object contains data about the\n * audio response from the model.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudio {\n  /**\n   * Unique identifier for this audio response.\n   */\n  id: string;\n\n  /**\n   * Base64 encoded audio bytes generated by the model, in the format specified in\n   * the request.\n   */\n  data: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when this audio response will no longer be\n   * accessible on the server for use in multi-turn conversations.\n   */\n  expires_at: number;\n\n  /**\n   * Transcript of the audio generated by the model.\n   */\n  transcript: string;\n}\n\n/**\n * Parameters for audio output. Required when audio output is requested with\n * `modalities: [\"audio\"]`.\n * [Learn more](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionAudioParam {\n  /**\n   * Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`, `opus`,\n   * or `pcm16`.\n   */\n  format: 'wav' | 'mp3' | 'flac' | 'opus' | 'pcm16';\n\n  /**\n   * The voice the model uses to respond. Supported voices are `ash`, `ballad`,\n   * `coral`, `sage`, and `verse` (also supported but not recommended are `alloy`,\n   * `echo`, and `shimmer`; these voices are less expressive).\n   */\n  voice: 'alloy' | 'ash' | 'ballad' | 'coral' | 'echo' | 'sage' | 'shimmer' | 'verse';\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionChunk {\n  /**\n   * A unique identifier for the chat completion. Each chunk has the same ID.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can contain more than one elements if `n` is\n   * greater than 1. Can also be empty for the last chunk if you set\n   * `stream_options: {\"include_usage\": true}`.\n   */\n  choices: Array<ChatCompletionChunk.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created. Each\n   * chunk has the same timestamp.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion.chunk`.\n   */\n  object: 'chat.completion.chunk';\n\n  /**\n   * The service tier used for processing the request. This field is only included if\n   * the `service_tier` parameter is specified in the request.\n   */\n  service_tier?: 'scale' | 'default' | null;\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * An optional field that will only be present when you set\n   * `stream_options: {\"include_usage\": true}` in your request. When present, it\n   * contains a null value except for the last chunk which contains the token usage\n   * statistics for the entire request.\n   */\n  usage?: CompletionsAPI.CompletionUsage | null;\n}\n\nexport namespace ChatCompletionChunk {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    delta: Choice.Delta;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call' | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs?: Choice.Logprobs | null;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Delta {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      /**\n       * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n       * a function that should be called, as generated by the model.\n       */\n      function_call?: Delta.FunctionCall;\n\n      /**\n       * The refusal message generated by the model.\n       */\n      refusal?: string | null;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'system' | 'user' | 'assistant' | 'tool';\n\n      tool_calls?: Array<Delta.ToolCall>;\n    }\n\n    export namespace Delta {\n      /**\n       * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n       * a function that should be called, as generated by the model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n\n      export interface ToolCall {\n        index: number;\n\n        /**\n         * The ID of the tool call.\n         */\n        id?: string;\n\n        function?: ToolCall.Function;\n\n        /**\n         * The type of the tool. Currently, only `function` is supported.\n         */\n        type?: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments?: string;\n\n          /**\n           * The name of the function to call.\n           */\n          name?: string;\n        }\n      }\n    }\n\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport type ChatCompletionContentPart =\n  | ChatCompletionContentPartText\n  | ChatCompletionContentPartImage\n  | ChatCompletionContentPartInputAudio;\n\n/**\n * Learn about [image inputs](https://platform.openai.com/docs/guides/vision).\n */\nexport interface ChatCompletionContentPartImage {\n  image_url: ChatCompletionContentPartImage.ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport namespace ChatCompletionContentPartImage {\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n\n    /**\n     * Specifies the detail level of the image. Learn more in the\n     * [Vision guide](https://platform.openai.com/docs/guides/vision#low-or-high-fidelity-image-understanding).\n     */\n    detail?: 'auto' | 'low' | 'high';\n  }\n}\n\n/**\n * Learn about [audio inputs](https://platform.openai.com/docs/guides/audio).\n */\nexport interface ChatCompletionContentPartInputAudio {\n  input_audio: ChatCompletionContentPartInputAudio.InputAudio;\n\n  /**\n   * The type of the content part. Always `input_audio`.\n   */\n  type: 'input_audio';\n}\n\nexport namespace ChatCompletionContentPartInputAudio {\n  export interface InputAudio {\n    /**\n     * Base64 encoded audio data.\n     */\n    data: string;\n\n    /**\n     * The format of the encoded audio data. Currently supports \"wav\" and \"mp3\".\n     */\n    format: 'wav' | 'mp3';\n  }\n}\n\nexport interface ChatCompletionContentPartRefusal {\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'refusal';\n}\n\n/**\n * Learn about\n * [text inputs](https://platform.openai.com/docs/guides/text-generation).\n */\nexport interface ChatCompletionContentPartText {\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'text';\n}\n\n/**\n * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n * to call that function.\n */\nexport interface ChatCompletionFunctionCallOption {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * @deprecated\n */\nexport interface ChatCompletionFunctionMessageParam {\n  /**\n   * The contents of the function message.\n   */\n  content: string | null;\n\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * The role of the messages author, in this case `function`.\n   */\n  role: 'function';\n}\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionMessage {\n  /**\n   * The contents of the message.\n   */\n  content: string | null;\n\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string | null;\n\n  /**\n   * The role of the author of this message.\n   */\n  role: 'assistant';\n\n  /**\n   * If the audio output modality is requested, this object contains data about the\n   * audio response from the model.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudio | null;\n\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionMessage.FunctionCall | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionMessage {\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\nexport type ChatCompletionMessageParam =\n  | ChatCompletionSystemMessageParam\n  | ChatCompletionUserMessageParam\n  | ChatCompletionAssistantMessageParam\n  | ChatCompletionToolMessageParam\n  | ChatCompletionFunctionMessageParam;\n\nexport interface ChatCompletionMessageToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The function that the model called.\n   */\n  function: ChatCompletionMessageToolCall.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionMessageToolCall {\n  /**\n   * The function that the model called.\n   */\n  export interface Function {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\nexport type ChatCompletionModality = 'text' | 'audio';\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * function.\n */\nexport interface ChatCompletionNamedToolChoice {\n  function: ChatCompletionNamedToolChoice.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionNamedToolChoice {\n  export interface Function {\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Static predicted output content, such as the content of a text file that is\n * being regenerated.\n */\nexport interface ChatCompletionPredictionContent {\n  /**\n   * The content that should be matched when generating a model response. If\n   * generated tokens would match this content, the entire model response can be\n   * returned much more quickly.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The type of the predicted content you want to provide. This type is currently\n   * always `content`.\n   */\n  type: 'content';\n}\n\n/**\n * The role of the author of a message\n */\nexport type ChatCompletionRole = 'system' | 'user' | 'assistant' | 'tool' | 'function';\n\n/**\n * Options for streaming response. Only set this when you set `stream: true`.\n */\nexport interface ChatCompletionStreamOptions {\n  /**\n   * If set, an additional chunk will be streamed before the `data: [DONE]` message.\n   * The `usage` field on this chunk shows the token usage statistics for the entire\n   * request, and the `choices` field will always be an empty array. All other chunks\n   * will also include a `usage` field, but with a null value.\n   */\n  include_usage?: boolean;\n}\n\nexport interface ChatCompletionSystemMessageParam {\n  /**\n   * The contents of the system message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `system`.\n   */\n  role: 'system';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\nexport interface ChatCompletionTokenLogprob {\n  /**\n   * The token.\n   */\n  token: string;\n\n  /**\n   * A list of integers representing the UTF-8 bytes representation of the token.\n   * Useful in instances where characters are represented by multiple tokens and\n   * their byte representations must be combined to generate the correct text\n   * representation. Can be `null` if there is no bytes representation for the token.\n   */\n  bytes: Array<number> | null;\n\n  /**\n   * The log probability of this token, if it is within the top 20 most likely\n   * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n   * unlikely.\n   */\n  logprob: number;\n\n  /**\n   * List of the most likely tokens and their log probability, at this token\n   * position. In rare cases, there may be fewer than the number of requested\n   * `top_logprobs` returned.\n   */\n  top_logprobs: Array<ChatCompletionTokenLogprob.TopLogprob>;\n}\n\nexport namespace ChatCompletionTokenLogprob {\n  export interface TopLogprob {\n    /**\n     * The token.\n     */\n    token: string;\n\n    /**\n     * A list of integers representing the UTF-8 bytes representation of the token.\n     * Useful in instances where characters are represented by multiple tokens and\n     * their byte representations must be combined to generate the correct text\n     * representation. Can be `null` if there is no bytes representation for the token.\n     */\n    bytes: Array<number> | null;\n\n    /**\n     * The log probability of this token, if it is within the top 20 most likely\n     * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n     * unlikely.\n     */\n    logprob: number;\n  }\n}\n\nexport interface ChatCompletionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tool and instead generates a message. `auto` means the model can\n * pick between generating a message or calling one or more tools. `required` means\n * the model must call one or more tools. Specifying a particular tool via\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n *\n * `none` is the default when no tools are present. `auto` is the default if tools\n * are present.\n */\nexport type ChatCompletionToolChoiceOption = 'none' | 'auto' | 'required' | ChatCompletionNamedToolChoice;\n\nexport interface ChatCompletionToolMessageParam {\n  /**\n   * The contents of the tool message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `tool`.\n   */\n  role: 'tool';\n\n  /**\n   * Tool call that this message is responding to.\n   */\n  tool_call_id: string;\n}\n\nexport interface ChatCompletionUserMessageParam {\n  /**\n   * The contents of the user message.\n   */\n  content: string | Array<ChatCompletionContentPart>;\n\n  /**\n   * The role of the messages author, in this case `user`.\n   */\n  role: 'user';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * @deprecated ChatCompletionMessageParam should be used instead\n */\nexport type CreateChatCompletionRequestMessage = ChatCompletionMessageParam;\n\nexport type ChatCompletionCreateParams =\n  | ChatCompletionCreateParamsNonStreaming\n  | ChatCompletionCreateParamsStreaming;\n\nexport interface ChatCompletionCreateParamsBase {\n  /**\n   * A list of messages comprising the conversation so far. Depending on the\n   * [model](https://platform.openai.com/docs/models) you use, different message\n   * types (modalities) are supported, like\n   * [text](https://platform.openai.com/docs/guides/text-generation),\n   * [images](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio).\n   */\n  messages: Array<ChatCompletionMessageParam>;\n\n  /**\n   * ID of the model to use. See the\n   * [model endpoint compatibility](https://platform.openai.com/docs/models#model-endpoint-compatibility)\n   * table for details on which models work with the Chat API.\n   */\n  model: (string & {}) | ChatAPI.ChatModel;\n\n  /**\n   * Parameters for audio output. Required when audio output is requested with\n   * `modalities: [\"audio\"]`.\n   * [Learn more](https://platform.openai.com/docs/guides/audio).\n   */\n  audio?: ChatCompletionAudioParam | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Deprecated in favor of `tool_choice`.\n   *\n   * Controls which (if any) function is called by the model. `none` means the model\n   * will not call a function and instead generates a message. `auto` means the model\n   * can pick between generating a message or calling a function. Specifying a\n   * particular function via `{\"name\": \"my_function\"}` forces the model to call that\n   * function.\n   *\n   * `none` is the default when no functions are present. `auto` is the default if\n   * functions are present.\n   */\n  function_call?: 'none' | 'auto' | ChatCompletionFunctionCallOption;\n\n  /**\n   * Deprecated in favor of `tools`.\n   *\n   * A list of functions the model may generate JSON inputs for.\n   */\n  functions?: Array<ChatCompletionCreateParams.Function>;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the\n   * tokenizer) to an associated bias value from -100 to 100. Mathematically, the\n   * bias is added to the logits generated by the model prior to sampling. The exact\n   * effect will vary per model, but values between -1 and 1 should decrease or\n   * increase likelihood of selection; values like -100 or 100 should result in a ban\n   * or exclusive selection of the relevant token.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Whether to return log probabilities of the output tokens or not. If true,\n   * returns the log probabilities of each output token returned in the `content` of\n   * `message`.\n   */\n  logprobs?: boolean | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a completion,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the chat\n   * completion. This value can be used to control\n   * [costs](https://openai.com/api/pricing/) for text generated via API.\n   *\n   * This value is now deprecated in favor of `max_completion_tokens`, and is not\n   * compatible with\n   * [o1 series models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_tokens?: number | null;\n\n  /**\n   * Developer-defined tags and values used for filtering completions in the\n   * [dashboard](https://platform.openai.com/chat-completions).\n   */\n  metadata?: Record<string, string> | null;\n\n  /**\n   * Output types that you would like the model to generate for this request. Most\n   * models are capable of generating text, which is the default:\n   *\n   * `[\"text\"]`\n   *\n   * The `gpt-4o-audio-preview` model can also be used to\n   * [generate audio](https://platform.openai.com/docs/guides/audio). To request that\n   * this model generate both text and audio responses, you can use:\n   *\n   * `[\"text\", \"audio\"]`\n   */\n  modalities?: Array<ChatCompletionModality> | null;\n\n  /**\n   * How many chat completion choices to generate for each input message. Note that\n   * you will be charged based on the number of generated tokens across all of the\n   * choices. Keep `n` as `1` to minimize costs.\n   */\n  n?: number | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Static predicted output content, such as the content of a text file that is\n   * being regenerated.\n   */\n  prediction?: ChatCompletionPredictionContent | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * An object specifying the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4o mini](https://platform.openai.com/docs/models#gpt-4o-mini),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4) and\n   * all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?:\n    | Shared.ResponseFormatText\n    | Shared.ResponseFormatJSONObject\n    | Shared.ResponseFormatJSONSchema;\n\n  /**\n   * This feature is in Beta. If specified, our system will make a best effort to\n   * sample deterministically, such that repeated requests with the same `seed` and\n   * parameters should return the same result. Determinism is not guaranteed, and you\n   * should refer to the `system_fingerprint` response parameter to monitor changes\n   * in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Specifies the latency tier to use for processing the request. This parameter is\n   * relevant for customers subscribed to the scale tier service:\n   *\n   * - If set to 'auto', and the Project is Scale tier enabled, the system will\n   *   utilize scale tier credits until they are exhausted.\n   * - If set to 'auto', and the Project is not Scale tier enabled, the request will\n   *   be processed using the default service tier with a lower uptime SLA and no\n   *   latency guarentee.\n   * - If set to 'default', the request will be processed using the default service\n   *   tier with a lower uptime SLA and no latency guarentee.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When this parameter is set, the response body will include the `service_tier`\n   * utilized.\n   */\n  service_tier?: 'auto' | 'default' | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether or not to store the output of this chat completion request for use in\n   * our [model distillation](https://platform.openai.com/docs/guides/distillation)\n   * or [evals](https://platform.openai.com/docs/guides/evals) products.\n   */\n  store?: boolean | null;\n\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionStreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tool and instead generates a message. `auto` means the model can\n   * pick between generating a message or calling one or more tools. `required` means\n   * the model must call one or more tools. Specifying a particular tool via\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   *\n   * `none` is the default when no tools are present. `auto` is the default if tools\n   * are present.\n   */\n  tool_choice?: ChatCompletionToolChoiceOption;\n\n  /**\n   * A list of tools the model may call. Currently, only functions are supported as a\n   * tool. Use this to provide a list of functions the model may generate JSON inputs\n   * for. A max of 128 functions are supported.\n   */\n  tools?: Array<ChatCompletionTool>;\n\n  /**\n   * An integer between 0 and 20 specifying the number of most likely tokens to\n   * return at each token position, each with an associated log probability.\n   * `logprobs` must be set to `true` if this parameter is used.\n   */\n  top_logprobs?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ChatCompletionCreateParams {\n  /**\n   * @deprecated\n   */\n  export interface Function {\n    /**\n     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\n     * underscores and dashes, with a maximum length of 64.\n     */\n    name: string;\n\n    /**\n     * A description of what the function does, used by the model to choose when and\n     * how to call the function.\n     */\n    description?: string;\n\n    /**\n     * The parameters the functions accepts, described as a JSON Schema object. See the\n     * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n     * and the\n     * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n     * documentation about the format.\n     *\n     * Omitting `parameters` defines a function with an empty parameter list.\n     */\n    parameters?: Shared.FunctionParameters;\n  }\n\n  export type ChatCompletionCreateParamsNonStreaming =\n    ChatCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export type ChatCompletionCreateParamsStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsStreaming;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParams instead\n */\nexport type CompletionCreateParams = ChatCompletionCreateParams;\n\nexport interface ChatCompletionCreateParamsNonStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsNonStreaming instead\n */\nexport type CompletionCreateParamsNonStreaming = ChatCompletionCreateParamsNonStreaming;\n\nexport interface ChatCompletionCreateParamsStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsStreaming instead\n */\nexport type CompletionCreateParamsStreaming = ChatCompletionCreateParamsStreaming;\n\nexport declare namespace Completions {\n  export {\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type CreateChatCompletionRequestMessage as CreateChatCompletionRequestMessage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type CompletionCreateParams as CompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as CompletionsAPI from './completions';\nimport {\n  ChatCompletion,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionMessage,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionPredictionContent,\n  ChatCompletionRole,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUserMessageParam,\n  CompletionCreateParams,\n  CompletionCreateParamsNonStreaming,\n  CompletionCreateParamsStreaming,\n  Completions,\n  CreateChatCompletionRequestMessage,\n} from './completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport type ChatModel =\n  | 'o1-preview'\n  | 'o1-preview-2024-09-12'\n  | 'o1-mini'\n  | 'o1-mini-2024-09-12'\n  | 'gpt-4o'\n  | 'gpt-4o-2024-11-20'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-realtime-preview'\n  | 'gpt-4o-realtime-preview-2024-10-01'\n  | 'gpt-4o-audio-preview'\n  | 'gpt-4o-audio-preview-2024-10-01'\n  | 'chatgpt-4o-latest'\n  | 'gpt-4o-mini'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4-turbo'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4-0125-preview'\n  | 'gpt-4-turbo-preview'\n  | 'gpt-4-1106-preview'\n  | 'gpt-4-vision-preview'\n  | 'gpt-4'\n  | 'gpt-4-0314'\n  | 'gpt-4-0613'\n  | 'gpt-4-32k'\n  | 'gpt-4-32k-0314'\n  | 'gpt-4-32k-0613'\n  | 'gpt-3.5-turbo'\n  | 'gpt-3.5-turbo-16k'\n  | 'gpt-3.5-turbo-0301'\n  | 'gpt-3.5-turbo-0613'\n  | 'gpt-3.5-turbo-1106'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo-16k-0613';\n\nChat.Completions = Completions;\n\nexport declare namespace Chat {\n  export { type ChatModel as ChatModel };\n\n  export {\n    Completions as Completions,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type CreateChatCompletionRequestMessage as CreateChatCompletionRequestMessage,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type CompletionCreateParams as CompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport { type Response } from '../../_shims/index';\n\nexport class Speech extends APIResource {\n  /**\n   * Generates audio from the input text.\n   */\n  create(body: SpeechCreateParams, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.post('/audio/speech', { body, ...options, __binaryResponse: true });\n  }\n}\n\nexport type SpeechModel = 'tts-1' | 'tts-1-hd';\n\nexport interface SpeechCreateParams {\n  /**\n   * The text to generate audio for. The maximum length is 4096 characters.\n   */\n  input: string;\n\n  /**\n   * One of the available [TTS models](https://platform.openai.com/docs/models#tts):\n   * `tts-1` or `tts-1-hd`\n   */\n  model: (string & {}) | SpeechModel;\n\n  /**\n   * The voice to use when generating the audio. Supported voices are `alloy`,\n   * `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are\n   * available in the\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech#voice-options).\n   */\n  voice: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';\n\n  /**\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`,\n   * `wav`, and `pcm`.\n   */\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac' | 'wav' | 'pcm';\n\n  /**\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\n   * the default.\n   */\n  speed?: number;\n}\n\nexport declare namespace Speech {\n  export { type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as AudioAPI from './audio';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(\n    body: TranscriptionCreateParams<'json' | undefined>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParams<'verbose_json'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranscriptionVerbose>;\n  create(\n    body: TranscriptionCreateParams<'srt' | 'vtt' | 'text'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<string>;\n  create(body: TranscriptionCreateParams, options?: Core.RequestOptions): Core.APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranscriptionCreateResponse | string> {\n    return this._client.post('/audio/transcriptions', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport interface Transcription {\n  /**\n   * The transcribed text.\n   */\n  text: string;\n}\n\nexport interface TranscriptionSegment {\n  /**\n   * Unique identifier of the segment.\n   */\n  id: number;\n\n  /**\n   * Average logprob of the segment. If the value is lower than -1, consider the\n   * logprobs failed.\n   */\n  avg_logprob: number;\n\n  /**\n   * Compression ratio of the segment. If the value is greater than 2.4, consider the\n   * compression failed.\n   */\n  compression_ratio: number;\n\n  /**\n   * End time of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Probability of no speech in the segment. If the value is higher than 1.0 and the\n   * `avg_logprob` is below -1, consider this segment silent.\n   */\n  no_speech_prob: number;\n\n  /**\n   * Seek offset of the segment.\n   */\n  seek: number;\n\n  /**\n   * Start time of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Temperature parameter used for generating the segment.\n   */\n  temperature: number;\n\n  /**\n   * Text content of the segment.\n   */\n  text: string;\n\n  /**\n   * Array of token IDs for the text content.\n   */\n  tokens: Array<number>;\n}\n\n/**\n * Represents a verbose json transcription response returned by model, based on the\n * provided input.\n */\nexport interface TranscriptionVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: string;\n\n  /**\n   * The language of the input audio.\n   */\n  language: string;\n\n  /**\n   * The transcribed text.\n   */\n  text: string;\n\n  /**\n   * Segments of the transcribed text and their corresponding details.\n   */\n  segments?: Array<TranscriptionSegment>;\n\n  /**\n   * Extracted words and their corresponding timestamps.\n   */\n  words?: Array<TranscriptionWord>;\n}\n\nexport interface TranscriptionWord {\n  /**\n   * End time of the word in seconds.\n   */\n  end: number;\n\n  /**\n   * Start time of the word in seconds.\n   */\n  start: number;\n\n  /**\n   * The text content of the word.\n   */\n  word: string;\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport type TranscriptionCreateResponse = Transcription | TranscriptionVerbose;\n\nexport interface TranscriptionCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will\n   * improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should match the audio language.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * `response_format` must be set `verbose_json` to use timestamp granularities.\n   * Either or both of these options are supported: `word`, or `segment`. Note: There\n   * is no additional latency for segment timestamps, but generating word timestamps\n   * incurs additional latency.\n   */\n  timestamp_granularities?: Array<'word' | 'segment'>;\n}\n\nexport declare namespace Transcriptions {\n  export {\n    type Transcription as Transcription,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as AudioAPI from './audio';\nimport * as TranscriptionsAPI from './transcriptions';\n\nexport class Translations extends APIResource {\n  /**\n   * Translates audio into English.\n   */\n  create(\n    body: TranslationCreateParams<'json' | undefined>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams<'verbose_json'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranslationVerbose>;\n  create(\n    body: TranslationCreateParams<'text' | 'srt' | 'vtt'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<string>;\n  create(body: TranslationCreateParams, options?: Core.RequestOptions): Core.APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranslationCreateResponse | string> {\n    return this._client.post('/audio/translations', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\nexport interface Translation {\n  text: string;\n}\n\nexport interface TranslationVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: string;\n\n  /**\n   * The language of the output translation (always `english`).\n   */\n  language: string;\n\n  /**\n   * The translated text.\n   */\n  text: string;\n\n  /**\n   * Segments of the translated text and their corresponding details.\n   */\n  segments?: Array<TranscriptionsAPI.TranscriptionSegment>;\n}\n\nexport type TranslationCreateResponse = Translation | TranslationVerbose;\n\nexport interface TranslationCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) translate, in one of these formats: flac,\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text#prompting)\n   * should be in English.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport declare namespace Translations {\n  export {\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as SpeechAPI from './speech';\nimport { Speech, SpeechCreateParams, SpeechModel } from './speech';\nimport * as TranscriptionsAPI from './transcriptions';\nimport {\n  Transcription,\n  TranscriptionCreateParams,\n  TranscriptionCreateResponse,\n  TranscriptionSegment,\n  TranscriptionVerbose,\n  TranscriptionWord,\n  Transcriptions,\n} from './transcriptions';\nimport * as TranslationsAPI from './translations';\nimport {\n  Translation,\n  TranslationCreateParams,\n  TranslationCreateResponse,\n  TranslationVerbose,\n  Translations,\n} from './translations';\n\nexport class Audio extends APIResource {\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\n}\n\nexport type AudioModel = 'whisper-1';\n\n/**\n * The format of the output, in one of these options: `json`, `text`, `srt`,\n * `verbose_json`, or `vtt`.\n */\nexport type AudioResponseFormat = 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\n\nAudio.Transcriptions = Transcriptions;\nAudio.Translations = Translations;\nAudio.Speech = Speech;\n\nexport declare namespace Audio {\n  export { type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Transcriptions as Transcriptions,\n    type Transcription as Transcription,\n    type TranscriptionSegment as TranscriptionSegment,\n    type TranscriptionVerbose as TranscriptionVerbose,\n    type TranscriptionWord as TranscriptionWord,\n    type TranscriptionCreateResponse as TranscriptionCreateResponse,\n    type TranscriptionCreateParams as TranscriptionCreateParams,\n  };\n\n  export {\n    Translations as Translations,\n    type Translation as Translation,\n    type TranslationVerbose as TranslationVerbose,\n    type TranslationCreateResponse as TranslationCreateResponse,\n    type TranslationCreateParams as TranslationCreateParams,\n  };\n\n  export { Speech as Speech, type SpeechModel as SpeechModel, type SpeechCreateParams as SpeechCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport * as Core from '../core';\nimport * as BatchesAPI from './batches';\nimport { CursorPage, type CursorPageParams } from '../pagination';\n\nexport class Batches extends APIResource {\n  /**\n   * Creates and executes a batch from an uploaded file of requests\n   */\n  create(body: BatchCreateParams, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post('/batches', { body, ...options });\n  }\n\n  /**\n   * Retrieves a batch.\n   */\n  retrieve(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.get(`/batches/${batchId}`, options);\n  }\n\n  /**\n   * List your organization's batches.\n   */\n  list(query?: BatchListParams, options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(\n    query: BatchListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<BatchesPage, Batch> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/batches', BatchesPage, { query, ...options });\n  }\n\n  /**\n   * Cancels an in-progress batch. The batch will be in status `cancelling` for up to\n   * 10 minutes, before changing to `cancelled`, where it will have partial results\n   * (if any) available in the output file.\n   */\n  cancel(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post(`/batches/${batchId}/cancel`, options);\n  }\n}\n\nexport class BatchesPage extends CursorPage<Batch> {}\n\nexport interface Batch {\n  id: string;\n\n  /**\n   * The time frame within which the batch should be processed.\n   */\n  completion_window: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was created.\n   */\n  created_at: number;\n\n  /**\n   * The OpenAI API endpoint used by the batch.\n   */\n  endpoint: string;\n\n  /**\n   * The ID of the input file for the batch.\n   */\n  input_file_id: string;\n\n  /**\n   * The object type, which is always `batch`.\n   */\n  object: 'batch';\n\n  /**\n   * The current status of the batch.\n   */\n  status:\n    | 'validating'\n    | 'failed'\n    | 'in_progress'\n    | 'finalizing'\n    | 'completed'\n    | 'expired'\n    | 'cancelling'\n    | 'cancelled';\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was cancelled.\n   */\n  cancelled_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started cancelling.\n   */\n  cancelling_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was completed.\n   */\n  completed_at?: number;\n\n  /**\n   * The ID of the file containing the outputs of requests with errors.\n   */\n  error_file_id?: string;\n\n  errors?: Batch.Errors;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch expired.\n   */\n  expired_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch failed.\n   */\n  failed_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started finalizing.\n   */\n  finalizing_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started processing.\n   */\n  in_progress_at?: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the file containing the outputs of successfully executed requests.\n   */\n  output_file_id?: string;\n\n  /**\n   * The request counts for different statuses within the batch.\n   */\n  request_counts?: BatchRequestCounts;\n}\n\nexport namespace Batch {\n  export interface Errors {\n    data?: Array<BatchesAPI.BatchError>;\n\n    /**\n     * The object type, which is always `list`.\n     */\n    object?: string;\n  }\n}\n\nexport interface BatchError {\n  /**\n   * An error code identifying the error type.\n   */\n  code?: string;\n\n  /**\n   * The line number of the input file where the error occurred, if applicable.\n   */\n  line?: number | null;\n\n  /**\n   * A human-readable message providing more details about the error.\n   */\n  message?: string;\n\n  /**\n   * The name of the parameter that caused the error, if applicable.\n   */\n  param?: string | null;\n}\n\n/**\n * The request counts for different statuses within the batch.\n */\nexport interface BatchRequestCounts {\n  /**\n   * Number of requests that have been completed successfully.\n   */\n  completed: number;\n\n  /**\n   * Number of requests that have failed.\n   */\n  failed: number;\n\n  /**\n   * Total number of requests in the batch.\n   */\n  total: number;\n}\n\nexport interface BatchCreateParams {\n  /**\n   * The time frame within which the batch should be processed. Currently only `24h`\n   * is supported.\n   */\n  completion_window: '24h';\n\n  /**\n   * The endpoint to be used for all requests in the batch. Currently\n   * `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.\n   * Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000\n   * embedding inputs across all requests in the batch.\n   */\n  endpoint: '/v1/chat/completions' | '/v1/embeddings' | '/v1/completions';\n\n  /**\n   * The ID of an uploaded file that contains requests for the new batch.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your input file must be formatted as a\n   * [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input),\n   * and must be uploaded with the purpose `batch`. The file can contain up to 50,000\n   * requests, and can be up to 200 MB in size.\n   */\n  input_file_id: string;\n\n  /**\n   * Optional custom metadata for the batch.\n   */\n  metadata?: Record<string, string> | null;\n}\n\nexport interface BatchListParams extends CursorPageParams {}\n\nBatches.BatchesPage = BatchesPage;\n\nexport declare namespace Batches {\n  export {\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { isRequestOptions } from '../../core';\nimport * as Core from '../../core';\nimport * as Shared from '../shared';\nimport * as ChatAPI from '../chat/chat';\nimport * as MessagesAPI from './threads/messages';\nimport * as ThreadsAPI from './threads/threads';\nimport * as VectorStoresAPI from './vector-stores/vector-stores';\nimport * as RunsAPI from './threads/runs/runs';\nimport * as StepsAPI from './threads/runs/steps';\nimport { CursorPage, type CursorPageParams } from '../../pagination';\n\nexport class Assistants extends APIResource {\n  /**\n   * Create an assistant with a model and instructions.\n   */\n  create(body: AssistantCreateParams, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.post('/assistants', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves an assistant.\n   */\n  retrieve(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.get(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies an assistant.\n   */\n  update(\n    assistantId: string,\n    body: AssistantUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Assistant> {\n    return this._client.post(`/assistants/${assistantId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of assistants.\n   */\n  list(\n    query?: AssistantListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant>;\n  list(options?: Core.RequestOptions): Core.PagePromise<AssistantsPage, Assistant>;\n  list(\n    query: AssistantListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/assistants', AssistantsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete an assistant.\n   */\n  del(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<AssistantDeleted> {\n    return this._client.delete(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class AssistantsPage extends CursorPage<Assistant> {}\n\n/**\n * Represents an `assistant` that can call the model and use tools.\n */\nexport interface Assistant {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the assistant was created.\n   */\n  created_at: number;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name: string | null;\n\n  /**\n   * The object type, which is always `assistant`.\n   */\n  object: 'assistant';\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools: Array<AssistantTool>;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: Assistant.ToolResources | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Assistant {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter`` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'assistant.deleted';\n}\n\n/**\n * Represents an event emitted when streaming a Run.\n *\n * Each event in a server-sent events stream has an `event` and `data` property:\n *\n * ```\n * event: thread.created\n * data: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n * ```\n *\n * We emit events whenever a new object is created, transitions to a new state, or\n * is being streamed in parts (deltas). For example, we emit `thread.run.created`\n * when a new run is created, `thread.run.completed` when a run completes, and so\n * on. When an Assistant chooses to create a message during a run, we emit a\n * `thread.message.created event`, a `thread.message.in_progress` event, many\n * `thread.message.delta` events, and finally a `thread.message.completed` event.\n *\n * We may add additional events over time, so we recommend handling unknown events\n * gracefully in your code. See the\n * [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview)\n * to learn how to integrate the Assistants API with streaming.\n */\nexport type AssistantStreamEvent =\n  | AssistantStreamEvent.ThreadCreated\n  | AssistantStreamEvent.ThreadRunCreated\n  | AssistantStreamEvent.ThreadRunQueued\n  | AssistantStreamEvent.ThreadRunInProgress\n  | AssistantStreamEvent.ThreadRunRequiresAction\n  | AssistantStreamEvent.ThreadRunCompleted\n  | AssistantStreamEvent.ThreadRunIncomplete\n  | AssistantStreamEvent.ThreadRunFailed\n  | AssistantStreamEvent.ThreadRunCancelling\n  | AssistantStreamEvent.ThreadRunCancelled\n  | AssistantStreamEvent.ThreadRunExpired\n  | AssistantStreamEvent.ThreadRunStepCreated\n  | AssistantStreamEvent.ThreadRunStepInProgress\n  | AssistantStreamEvent.ThreadRunStepDelta\n  | AssistantStreamEvent.ThreadRunStepCompleted\n  | AssistantStreamEvent.ThreadRunStepFailed\n  | AssistantStreamEvent.ThreadRunStepCancelled\n  | AssistantStreamEvent.ThreadRunStepExpired\n  | AssistantStreamEvent.ThreadMessageCreated\n  | AssistantStreamEvent.ThreadMessageInProgress\n  | AssistantStreamEvent.ThreadMessageDelta\n  | AssistantStreamEvent.ThreadMessageCompleted\n  | AssistantStreamEvent.ThreadMessageIncomplete\n  | AssistantStreamEvent.ErrorEvent;\n\nexport namespace AssistantStreamEvent {\n  /**\n   * Occurs when a new\n   * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n   * created.\n   */\n  export interface ThreadCreated {\n    /**\n     * Represents a thread that contains\n     * [messages](https://platform.openai.com/docs/api-reference/messages).\n     */\n    data: ThreadsAPI.Thread;\n\n    event: 'thread.created';\n\n    /**\n     * Whether to enable input audio transcription.\n     */\n    enabled?: boolean;\n  }\n\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n\n  /**\n   * Occurs when an\n   * [error](https://platform.openai.com/docs/guides/error-codes#api-errors) occurs.\n   * This can happen due to an internal server error or a timeout.\n   */\n  export interface ErrorEvent {\n    data: Shared.ErrorObject;\n\n    event: 'error';\n  }\n}\n\nexport type AssistantTool = CodeInterpreterTool | FileSearchTool | FunctionTool;\n\nexport interface CodeInterpreterTool {\n  /**\n   * The type of tool being defined: `code_interpreter`\n   */\n  type: 'code_interpreter';\n}\n\nexport interface FileSearchTool {\n  /**\n   * The type of tool being defined: `file_search`\n   */\n  type: 'file_search';\n\n  /**\n   * Overrides for the file search tool.\n   */\n  file_search?: FileSearchTool.FileSearch;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Overrides for the file search tool.\n   */\n  export interface FileSearch {\n    /**\n     * The maximum number of results the file search tool should output. The default is\n     * 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between\n     * 1 and 50 inclusive.\n     *\n     * Note that the file search tool may output fewer than `max_num_results` results.\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    max_num_results?: number;\n\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n     * for more information.\n     */\n    export interface RankingOptions {\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n\n      /**\n       * The ranker to use for the file search. If not specified will use the `auto`\n       * ranker.\n       */\n      ranker?: 'auto' | 'default_2024_08_21';\n    }\n  }\n}\n\nexport interface FunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of tool being defined: `function`\n   */\n  type: 'function';\n}\n\n/**\n * Occurs when a\n * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n * created.\n */\nexport type MessageStreamEvent =\n  | MessageStreamEvent.ThreadMessageCreated\n  | MessageStreamEvent.ThreadMessageInProgress\n  | MessageStreamEvent.ThreadMessageDelta\n  | MessageStreamEvent.ThreadMessageCompleted\n  | MessageStreamEvent.ThreadMessageIncomplete;\n\nexport namespace MessageStreamEvent {\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n}\n\n/**\n * Occurs when a\n * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n * is created.\n */\nexport type RunStepStreamEvent =\n  | RunStepStreamEvent.ThreadRunStepCreated\n  | RunStepStreamEvent.ThreadRunStepInProgress\n  | RunStepStreamEvent.ThreadRunStepDelta\n  | RunStepStreamEvent.ThreadRunStepCompleted\n  | RunStepStreamEvent.ThreadRunStepFailed\n  | RunStepStreamEvent.ThreadRunStepCancelled\n  | RunStepStreamEvent.ThreadRunStepExpired;\n\nexport namespace RunStepStreamEvent {\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n */\nexport type RunStreamEvent =\n  | RunStreamEvent.ThreadRunCreated\n  | RunStreamEvent.ThreadRunQueued\n  | RunStreamEvent.ThreadRunInProgress\n  | RunStreamEvent.ThreadRunRequiresAction\n  | RunStreamEvent.ThreadRunCompleted\n  | RunStreamEvent.ThreadRunIncomplete\n  | RunStreamEvent.ThreadRunFailed\n  | RunStreamEvent.ThreadRunCancelling\n  | RunStreamEvent.ThreadRunCancelled\n  | RunStreamEvent.ThreadRunExpired;\n\nexport namespace RunStreamEvent {\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n * created.\n */\nexport interface ThreadStreamEvent {\n  /**\n   * Represents a thread that contains\n   * [messages](https://platform.openai.com/docs/api-reference/messages).\n   */\n  data: ThreadsAPI.Thread;\n\n  event: 'thread.created';\n\n  /**\n   * Whether to enable input audio transcription.\n   */\n  enabled?: boolean;\n}\n\nexport interface AssistantCreateParams {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | ChatAPI.ChatModel;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantCreateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantCreateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this assistant. There can be a maximum of 1\n       * vector store attached to the assistant.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy. Only applicable if `file_ids` is non-empty.\n         */\n        chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to a vector store. This can be\n         * useful for storing additional information about the vector store in a structured\n         * format. Keys can be a maximum of 64 characters long and values can be a maxium\n         * of 512 characters long.\n         */\n        metadata?: unknown;\n      }\n    }\n  }\n}\n\nexport interface AssistantUpdateParams {\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model?: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantUpdateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantUpdateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * Overrides the list of\n       * [file](https://platform.openai.com/docs/api-reference/files) IDs made available\n       * to the `code_interpreter` tool. There can be a maximum of 20 files associated\n       * with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * Overrides the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nAssistants.AssistantsPage = AssistantsPage;\n\nexport declare namespace Assistants {\n  export {\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n}\n","import { type ChatCompletionRunner } from './ChatCompletionRunner';\nimport { type ChatCompletionStreamingRunner } from './ChatCompletionStreamingRunner';\nimport { JSONSchema } from './jsonschema';\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\nexport type RunnableFunctionWithParse<Args extends object> = {\n  /**\n   * @param args the return value from `parse`.\n   * @param runner the runner evaluating this callback.\n   * @returns a string to send back to OpenAI.\n   */\n  function: (\n    args: Args,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * @param input the raw args from the OpenAI function call.\n   * @returns the parsed arguments to pass to `function`\n   */\n  parse: (input: string) => PromiseOrValue<Args>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunctionWithoutParse = {\n  /**\n   * @param args the raw args from the OpenAI function call.\n   * @returns a string to send back to OpenAI\n   */\n  function: (\n    args: string,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunction<Args extends object | string> =\n  Args extends string ? RunnableFunctionWithoutParse\n  : Args extends object ? RunnableFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunction<Args extends object | string> =\n  Args extends string ? RunnableToolFunctionWithoutParse\n  : Args extends object ? RunnableToolFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunctionWithoutParse = {\n  type: 'function';\n  function: RunnableFunctionWithoutParse;\n};\nexport type RunnableToolFunctionWithParse<Args extends object> = {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n};\n\nexport function isRunnableFunctionWithParse<Args extends object>(\n  fn: any,\n): fn is RunnableFunctionWithParse<Args> {\n  return typeof (fn as any).parse === 'function';\n}\n\nexport type BaseFunctionsArgs = readonly (object | string)[];\n\nexport type RunnableFunctions<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\nexport type RunnableTools<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableToolFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableToolFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n *\n * @deprecated - please use ParsingToolFunction instead.\n */\nexport class ParsingFunction<Args extends object> {\n  function: RunnableFunctionWithParse<Args>['function'];\n  parse: RunnableFunctionWithParse<Args>['parse'];\n  parameters: RunnableFunctionWithParse<Args>['parameters'];\n  description: RunnableFunctionWithParse<Args>['description'];\n  name?: RunnableFunctionWithParse<Args>['name'];\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.function = input.function;\n    this.parse = input.parse;\n    this.parameters = input.parameters;\n    this.description = input.description;\n    this.name = input.name;\n  }\n}\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n */\nexport class ParsingToolFunction<Args extends object> {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.type = 'function';\n    this.function = input;\n  }\n}\n","import {\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionFunctionMessageParam,\n  type ChatCompletionMessageParam,\n  type ChatCompletionToolMessageParam,\n} from '../resources';\n\nexport const isAssistantMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionAssistantMessageParam => {\n  return message?.role === 'assistant';\n};\n\nexport const isFunctionMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionFunctionMessageParam => {\n  return message?.role === 'function';\n};\n\nexport const isToolMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionToolMessageParam => {\n  return message?.role === 'tool';\n};\n\nexport function isPresent<T>(obj: T | null | undefined): obj is T {\n  return obj != null;\n}\n","import { APIUserAbortError, OpenAIError } from '../error';\n\nexport class EventStream<EventTypes extends BaseEvents> {\n  controller: AbortController = new AbortController();\n\n  #connectedPromise: Promise<void>;\n  #resolveConnectedPromise: () => void = () => {};\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\n\n  #endPromise: Promise<void>;\n  #resolveEndPromise: () => void = () => {};\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\n\n  #listeners: {\n    [Event in keyof EventTypes]?: EventListeners<EventTypes, Event>;\n  } = {};\n\n  #ended = false;\n  #errored = false;\n  #aborted = false;\n  #catchingPromiseCreated = false;\n\n  constructor() {\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveConnectedPromise = resolve;\n      this.#rejectConnectedPromise = reject;\n    });\n\n    this.#endPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveEndPromise = resolve;\n      this.#rejectEndPromise = reject;\n    });\n\n    // Don't let these promises cause unhandled rejection errors.\n    // we will manually cause an unhandled rejection error later\n    // if the user hasn't registered any error listener or called\n    // any promise-returning method.\n    this.#connectedPromise.catch(() => {});\n    this.#endPromise.catch(() => {});\n  }\n\n  protected _run(this: EventStream<EventTypes>, executor: () => Promise<any>) {\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\n    // references to `this` before the `super()` constructor call returns.\n    setTimeout(() => {\n      executor().then(() => {\n        this._emitFinal();\n        this._emit('end');\n      }, this.#handleError.bind(this));\n    }, 0);\n  }\n\n  protected _connected(this: EventStream<EventTypes>) {\n    if (this.ended) return;\n    this.#resolveConnectedPromise();\n    this._emit('connect');\n  }\n\n  get ended(): boolean {\n    return this.#ended;\n  }\n\n  get errored(): boolean {\n    return this.#errored;\n  }\n\n  get aborted(): boolean {\n    return this.#aborted;\n  }\n\n  abort() {\n    this.controller.abort();\n  }\n\n  /**\n   * Adds the listener function to the end of the listeners array for the event.\n   * No checks are made to see if the listener has already been added. Multiple calls passing\n   * the same combination of event and listener will result in the listener being added, and\n   * called, multiple times.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  on<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener });\n    return this;\n  }\n\n  /**\n   * Removes the specified listener from the listener array for the event.\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\n   * listener has been added multiple times to the listener array for the specified event, then\n   * off() must be called multiple times to remove each instance.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  off<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners = this.#listeners[event];\n    if (!listeners) return this;\n    const index = listeners.findIndex((l) => l.listener === listener);\n    if (index >= 0) listeners.splice(index, 1);\n    return this;\n  }\n\n  /**\n   * Adds a one-time listener function for the event. The next time the event is triggered,\n   * this listener is removed and then invoked.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  once<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener, once: true });\n    return this;\n  }\n\n  /**\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\n   * the event is triggered, instead of calling a listener callback.\n   * @returns a Promise that resolves the next time given event is triggered,\n   * or rejects if an error is emitted.  (If you request the 'error' event,\n   * returns a promise that resolves with the error).\n   *\n   * Example:\n   *\n   *   const message = await stream.emitted('message') // rejects if the stream errors\n   */\n  emitted<Event extends keyof EventTypes>(\n    event: Event,\n  ): Promise<\n    EventParameters<EventTypes, Event> extends [infer Param] ? Param\n    : EventParameters<EventTypes, Event> extends [] ? void\n    : EventParameters<EventTypes, Event>\n  > {\n    return new Promise((resolve, reject) => {\n      this.#catchingPromiseCreated = true;\n      if (event !== 'error') this.once('error', reject);\n      this.once(event, resolve as any);\n    });\n  }\n\n  async done(): Promise<void> {\n    this.#catchingPromiseCreated = true;\n    await this.#endPromise;\n  }\n\n  #handleError(this: EventStream<EventTypes>, error: unknown) {\n    this.#errored = true;\n    if (error instanceof Error && error.name === 'AbortError') {\n      error = new APIUserAbortError();\n    }\n    if (error instanceof APIUserAbortError) {\n      this.#aborted = true;\n      return this._emit('abort', error);\n    }\n    if (error instanceof OpenAIError) {\n      return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n      const openAIError: OpenAIError = new OpenAIError(error.message);\n      // @ts-ignore\n      openAIError.cause = error;\n      return this._emit('error', openAIError);\n    }\n    return this._emit('error', new OpenAIError(String(error)));\n  }\n\n  _emit<Event extends keyof BaseEvents>(event: Event, ...args: EventParameters<BaseEvents, Event>): void;\n  _emit<Event extends keyof EventTypes>(event: Event, ...args: EventParameters<EventTypes, Event>): void;\n  _emit<Event extends keyof EventTypes>(\n    this: EventStream<EventTypes>,\n    event: Event,\n    ...args: EventParameters<EventTypes, Event>\n  ) {\n    // make sure we don't emit any events after end\n    if (this.#ended) {\n      return;\n    }\n\n    if (event === 'end') {\n      this.#ended = true;\n      this.#resolveEndPromise();\n    }\n\n    const listeners: EventListeners<EventTypes, Event> | undefined = this.#listeners[event];\n    if (listeners) {\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\n      listeners.forEach(({ listener }: any) => listener(...(args as any)));\n    }\n\n    if (event === 'abort') {\n      const error = args[0] as APIUserAbortError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n      return;\n    }\n\n    if (event === 'error') {\n      // NOTE: _emit('error', error) should only be called from #handleError().\n\n      const error = args[0] as OpenAIError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n        // If you are seeing stack traces here, make sure to handle errors via either:\n        // - runner.on('error', () => ...)\n        // - await runner.done()\n        // - await runner.finalChatCompletion()\n        // - etc.\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n    }\n  }\n\n  protected _emitFinal(): void {}\n}\n\ntype EventListener<Events, EventType extends keyof Events> = Events[EventType];\n\ntype EventListeners<Events, EventType extends keyof Events> = Array<{\n  listener: EventListener<Events, EventType>;\n  once?: boolean;\n}>;\n\nexport type EventParameters<Events, EventType extends keyof Events> = {\n  [Event in EventType]: EventListener<Events, EventType> extends (...args: infer P) => any ? P : never;\n}[EventType];\n\nexport interface BaseEvents {\n  connect: () => void;\n  error: (error: OpenAIError) => void;\n  abort: (error: APIUserAbortError) => void;\n  end: () => void;\n}\n","import {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionMessageToolCall,\n  ChatCompletionTool,\n} from '../resources/chat/completions';\nimport {\n  ChatCompletionStreamingToolRunnerParams,\n  ChatCompletionStreamParams,\n  ChatCompletionToolRunnerParams,\n  ParsedChatCompletion,\n  ParsedChoice,\n  ParsedFunctionToolCall,\n} from '../resources/beta/chat/completions';\nimport { ResponseFormatJSONSchema } from '../resources/shared';\nimport { ContentFilterFinishReasonError, LengthFinishReasonError, OpenAIError } from '../error';\n\ntype AnyChatCompletionCreateParams =\n  | ChatCompletionCreateParams\n  | ChatCompletionToolRunnerParams<any>\n  | ChatCompletionStreamingToolRunnerParams<any>\n  | ChatCompletionStreamParams;\n\nexport type ExtractParsedContentFromParams<Params extends AnyChatCompletionCreateParams> =\n  Params['response_format'] extends AutoParseableResponseFormat<infer P> ? P : null;\n\nexport type AutoParseableResponseFormat<ParsedT> = ResponseFormatJSONSchema & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableResponseFormat<ParsedT>(\n  response_format: ResponseFormatJSONSchema,\n  parser: (content: string) => ParsedT,\n): AutoParseableResponseFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseFormat<ParsedT>;\n}\n\nexport function isAutoParsableResponseFormat<ParsedT>(\n  response_format: any,\n): response_format is AutoParseableResponseFormat<ParsedT> {\n  return response_format?.['$brand'] === 'auto-parseable-response-format';\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = ChatCompletionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n  __hasFunction: HasFunction; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableTool<OptionsT extends ToolOptions>(\n  tool: ChatCompletionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nexport function maybeParseChatCompletion<\n  Params extends ChatCompletionCreateParams | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...completion,\n      choices: completion.choices.map((choice) => ({\n        ...choice,\n        message: { ...choice.message, parsed: null, tool_calls: choice.message.tool_calls ?? [] },\n      })),\n    };\n  }\n\n  return parseChatCompletion(completion, params);\n}\n\nexport function parseChatCompletion<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  const choices: Array<ParsedChoice<ParsedT>> = completion.choices.map((choice): ParsedChoice<ParsedT> => {\n    if (choice.finish_reason === 'length') {\n      throw new LengthFinishReasonError();\n    }\n\n    if (choice.finish_reason === 'content_filter') {\n      throw new ContentFilterFinishReasonError();\n    }\n\n    return {\n      ...choice,\n      message: {\n        ...choice.message,\n        tool_calls: choice.message.tool_calls?.map((toolCall) => parseToolCall(params, toolCall)) ?? [],\n        parsed:\n          choice.message.content && !choice.message.refusal ?\n            parseResponseFormat(params, choice.message.content)\n          : null,\n      },\n    };\n  });\n\n  return { ...completion, choices };\n}\n\nfunction parseResponseFormat<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.response_format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if (params.response_format?.type === 'json_schema') {\n    if ('$parseRaw' in params.response_format) {\n      const response_format = params.response_format as AutoParseableResponseFormat<ParsedT>;\n\n      return response_format.$parseRaw(content);\n    }\n\n    return JSON.parse(content);\n  }\n\n  return null;\n}\n\nfunction parseToolCall<Params extends ChatCompletionCreateParams>(\n  params: Params,\n  toolCall: ChatCompletionMessageToolCall,\n): ParsedFunctionToolCall {\n  const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n  return {\n    ...toolCall,\n    function: {\n      ...toolCall.function,\n      parsed_arguments:\n        isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.function.arguments)\n        : inputTool?.function.strict ? JSON.parse(toolCall.function.arguments)\n        : null,\n    },\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ChatCompletionCreateParams | null | undefined,\n  toolCall: ChatCompletionMessageToolCall,\n): boolean {\n  if (!params) {\n    return false;\n  }\n\n  const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n  return isAutoParsableTool(inputTool) || inputTool?.function.strict || false;\n}\n\nexport function hasAutoParseableInput(params: AnyChatCompletionCreateParams): boolean {\n  if (isAutoParsableResponseFormat(params.response_format)) {\n    return true;\n  }\n\n  return (\n    params.tools?.some(\n      (t) => isAutoParsableTool(t) || (t.type === 'function' && t.function.strict === true),\n    ) ?? false\n  );\n}\n\nexport function validateInputTools(tools: ChatCompletionTool[] | undefined) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n","import * as Core from '../core';\nimport { type CompletionUsage } from '../resources/completions';\nimport {\n  type ChatCompletion,\n  type ChatCompletionMessage,\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParams,\n  type ChatCompletionTool,\n} from '../resources/chat/completions';\nimport { OpenAIError } from '../error';\nimport {\n  type RunnableFunction,\n  isRunnableFunctionWithParse,\n  type BaseFunctionsArgs,\n  RunnableToolFunction,\n} from './RunnableFunction';\nimport { ChatCompletionFunctionRunnerParams, ChatCompletionToolRunnerParams } from './ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingFunctionRunnerParams,\n  ChatCompletionStreamingToolRunnerParams,\n} from './ChatCompletionStreamingRunner';\nimport { isAssistantMessage, isFunctionMessage, isToolMessage } from './chatCompletionUtils';\nimport { BaseEvents, EventStream } from './EventStream';\nimport { ParsedChatCompletion } from '../resources/beta/chat/completions';\nimport OpenAI from '../index';\nimport { isAutoParsableTool, parseChatCompletion } from '../lib/parser';\n\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\nexport interface RunnerOptions extends Core.RequestOptions {\n  /** How many requests to make before canceling. Default 10. */\n  maxChatCompletions?: number;\n}\n\nexport class AbstractChatCompletionRunner<\n  EventTypes extends AbstractChatCompletionRunnerEvents,\n  ParsedT,\n> extends EventStream<EventTypes> {\n  protected _chatCompletions: ParsedChatCompletion<ParsedT>[] = [];\n  messages: ChatCompletionMessageParam[] = [];\n\n  protected _addChatCompletion(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    chatCompletion: ParsedChatCompletion<ParsedT>,\n  ): ParsedChatCompletion<ParsedT> {\n    this._chatCompletions.push(chatCompletion);\n    this._emit('chatCompletion', chatCompletion);\n    const message = chatCompletion.choices[0]?.message;\n    if (message) this._addMessage(message as ChatCompletionMessageParam);\n    return chatCompletion;\n  }\n\n  protected _addMessage(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit = true,\n  ) {\n    if (!('content' in message)) message.content = null;\n\n    this.messages.push(message);\n\n    if (emit) {\n      this._emit('message', message);\n      if ((isFunctionMessage(message) || isToolMessage(message)) && message.content) {\n        // Note, this assumes that {role: 'tool', content: …} is always the result of a call of tool of type=function.\n        this._emit('functionCallResult', message.content as string);\n      } else if (isAssistantMessage(message) && message.function_call) {\n        this._emit('functionCall', message.function_call);\n      } else if (isAssistantMessage(message) && message.tool_calls) {\n        for (const tool_call of message.tool_calls) {\n          if (tool_call.type === 'function') {\n            this._emit('functionCall', tool_call.function);\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * @returns a promise that resolves with the final ChatCompletion, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\n   */\n  async finalChatCompletion(): Promise<ParsedChatCompletion<ParsedT>> {\n    await this.done();\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (!completion) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return completion;\n  }\n\n  #getFinalContent(): string | null {\n    return this.#getFinalMessage().content ?? null;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalContent(): Promise<string | null> {\n    await this.done();\n    return this.#getFinalContent();\n  }\n\n  #getFinalMessage(): ChatCompletionMessage {\n    let i = this.messages.length;\n    while (i-- > 0) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message)) {\n        const { function_call, ...rest } = message;\n\n        // TODO: support audio here\n        const ret: Omit<ChatCompletionMessage, 'audio'> = {\n          ...rest,\n          content: (message as ChatCompletionMessage).content ?? null,\n          refusal: (message as ChatCompletionMessage).refusal ?? null,\n        };\n        if (function_call) {\n          ret.function_call = function_call;\n        }\n        return ret;\n      }\n    }\n    throw new OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\n  }\n\n  /**\n   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\n   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalMessage(): Promise<ChatCompletionMessage> {\n    await this.done();\n    return this.#getFinalMessage();\n  }\n\n  #getFinalFunctionCall(): ChatCompletionMessage.FunctionCall | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message) && message?.function_call) {\n        return message.function_call;\n      }\n      if (isAssistantMessage(message) && message?.tool_calls?.length) {\n        return message.tool_calls.at(-1)?.function;\n      }\n    }\n\n    return;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final FunctionCall, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalFunctionCall(): Promise<ChatCompletionMessage.FunctionCall | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCall();\n  }\n\n  #getFinalFunctionCallResult(): string | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isFunctionMessage(message) && message.content != null) {\n        return message.content;\n      }\n      if (\n        isToolMessage(message) &&\n        message.content != null &&\n        typeof message.content === 'string' &&\n        this.messages.some(\n          (x) =>\n            x.role === 'assistant' &&\n            x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id),\n        )\n      ) {\n        return message.content;\n      }\n    }\n\n    return;\n  }\n\n  async finalFunctionCallResult(): Promise<string | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCallResult();\n  }\n\n  #calculateTotalUsage(): CompletionUsage {\n    const total: CompletionUsage = {\n      completion_tokens: 0,\n      prompt_tokens: 0,\n      total_tokens: 0,\n    };\n    for (const { usage } of this._chatCompletions) {\n      if (usage) {\n        total.completion_tokens += usage.completion_tokens;\n        total.prompt_tokens += usage.prompt_tokens;\n        total.total_tokens += usage.total_tokens;\n      }\n    }\n    return total;\n  }\n\n  async totalUsage(): Promise<CompletionUsage> {\n    await this.done();\n    return this.#calculateTotalUsage();\n  }\n\n  allChatCompletions(): ChatCompletion[] {\n    return [...this._chatCompletions];\n  }\n\n  protected override _emitFinal(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n  ) {\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (completion) this._emit('finalChatCompletion', completion);\n    const finalMessage = this.#getFinalMessage();\n    if (finalMessage) this._emit('finalMessage', finalMessage);\n    const finalContent = this.#getFinalContent();\n    if (finalContent) this._emit('finalContent', finalContent);\n\n    const finalFunctionCall = this.#getFinalFunctionCall();\n    if (finalFunctionCall) this._emit('finalFunctionCall', finalFunctionCall);\n\n    const finalFunctionCallResult = this.#getFinalFunctionCallResult();\n    if (finalFunctionCallResult != null) this._emit('finalFunctionCallResult', finalFunctionCallResult);\n\n    if (this._chatCompletions.some((c) => c.usage)) {\n      this._emit('totalUsage', this.#calculateTotalUsage());\n    }\n  }\n\n  #validateParams(params: ChatCompletionCreateParams): void {\n    if (params.n != null && params.n > 1) {\n      throw new OpenAIError(\n        'ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.',\n      );\n    }\n  }\n\n  protected async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#validateParams(params);\n\n    const chatCompletion = await client.chat.completions.create(\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addChatCompletion(parseChatCompletion(chatCompletion, params));\n  }\n\n  protected async _runChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n    return await this._createChatCompletion(client, params, options);\n  }\n\n  protected async _runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'function' as const;\n    const { function_call = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof function_call !== 'string' && function_call?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of params.functions) {\n      functionsByName[f.name || f.function.name] = f;\n    }\n\n    const functions: ChatCompletionCreateParams.Function[] = params.functions.map(\n      (f): ChatCompletionCreateParams.Function => ({\n        name: f.name || f.function.name,\n        parameters: f.parameters as Record<string, unknown>,\n        description: f.description,\n      }),\n    );\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          function_call,\n          functions,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.function_call) return;\n      const { name, arguments: args } = message.function_call;\n      const fn = functionsByName[name];\n      if (!fn) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. Available options are: ${functions\n          .map((f) => JSON.stringify(f.name))\n          .join(', ')}. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. ${JSON.stringify(\n          singleFunctionToCall,\n        )} requested. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      }\n\n      let parsed;\n      try {\n        parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n      } catch (error) {\n        this._addMessage({\n          role,\n          name,\n          content: error instanceof Error ? error.message : String(error),\n        });\n        continue;\n      }\n\n      // @ts-expect-error it can't rule out `never` type.\n      const rawContent = await fn.function(parsed, this);\n      const content = this.#stringifyFunctionCallResult(rawContent);\n\n      this._addMessage({ role, name, content });\n\n      if (singleFunctionToCall) return;\n    }\n  }\n\n  protected async _runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'tool' as const;\n    const { tool_choice = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof tool_choice !== 'string' && tool_choice?.function?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    // TODO(someday): clean this logic up\n    const inputTools = params.tools.map((tool): RunnableToolFunction<any> => {\n      if (isAutoParsableTool(tool)) {\n        if (!tool.$callback) {\n          throw new OpenAIError('Tool given to `.runTools()` that does not have an associated function');\n        }\n\n        return {\n          type: 'function',\n          function: {\n            function: tool.$callback,\n            name: tool.function.name,\n            description: tool.function.description || '',\n            parameters: tool.function.parameters as any,\n            parse: tool.$parseRaw,\n            strict: true,\n          },\n        };\n      }\n\n      return tool as any as RunnableToolFunction<any>;\n    });\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of inputTools) {\n      if (f.type === 'function') {\n        functionsByName[f.function.name || f.function.function.name] = f.function;\n      }\n    }\n\n    const tools: ChatCompletionTool[] =\n      'tools' in params ?\n        inputTools.map((t) =>\n          t.type === 'function' ?\n            {\n              type: 'function',\n              function: {\n                name: t.function.name || t.function.function.name,\n                parameters: t.function.parameters as Record<string, unknown>,\n                description: t.function.description,\n                strict: t.function.strict,\n              },\n            }\n          : (t as unknown as ChatCompletionTool),\n        )\n      : (undefined as any);\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          tool_choice,\n          tools,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.tool_calls?.length) {\n        return;\n      }\n\n      for (const tool_call of message.tool_calls) {\n        if (tool_call.type !== 'function') continue;\n        const tool_call_id = tool_call.id;\n        const { name, arguments: args } = tool_call.function;\n        const fn = functionsByName[name];\n\n        if (!fn) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${Object.keys(\n            functionsByName,\n          )\n            .map((name) => JSON.stringify(name))\n            .join(', ')}. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(\n            singleFunctionToCall,\n          )} requested. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        let parsed;\n        try {\n          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n        } catch (error) {\n          const content = error instanceof Error ? error.message : String(error);\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        // @ts-expect-error it can't rule out `never` type.\n        const rawContent = await fn.function(parsed, this);\n        const content = this.#stringifyFunctionCallResult(rawContent);\n        this._addMessage({ role, tool_call_id, content });\n\n        if (singleFunctionToCall) {\n          return;\n        }\n      }\n    }\n\n    return;\n  }\n\n  #stringifyFunctionCallResult(rawContent: unknown): string {\n    return (\n      typeof rawContent === 'string' ? rawContent\n      : rawContent === undefined ? 'undefined'\n      : JSON.stringify(rawContent)\n    );\n  }\n}\n\nexport interface AbstractChatCompletionRunnerEvents extends BaseEvents {\n  functionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  message: (message: ChatCompletionMessageParam) => void;\n  chatCompletion: (completion: ChatCompletion) => void;\n  finalContent: (contentSnapshot: string) => void;\n  finalMessage: (message: ChatCompletionMessageParam) => void;\n  finalChatCompletion: (completion: ChatCompletion) => void;\n  finalFunctionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  functionCallResult: (content: string) => void;\n  finalFunctionCallResult: (content: string) => void;\n  totalUsage: (usage: CompletionUsage) => void;\n}\n","import {\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParamsNonStreaming,\n} from '../resources/chat/completions';\nimport { type RunnableFunctions, type BaseFunctionsArgs, RunnableTools } from './RunnableFunction';\nimport {\n  AbstractChatCompletionRunner,\n  AbstractChatCompletionRunnerEvents,\n  RunnerOptions,\n} from './AbstractChatCompletionRunner';\nimport { isAssistantMessage } from './chatCompletionUtils';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionRunnerEvents extends AbstractChatCompletionRunnerEvents {\n  content: (content: string) => void;\n}\n\nexport type ChatCompletionFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionRunner<ParsedT = null> extends AbstractChatCompletionRunner<\n  ChatCompletionRunnerEvents,\n  ParsedT\n> {\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions(\n    client: OpenAI,\n    params: ChatCompletionFunctionRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<null> {\n    const runner = new ChatCompletionRunner();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(client, params, opts));\n    return runner;\n  }\n\n  static runTools<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionToolRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> {\n    const runner = new ChatCompletionRunner<ParsedT>();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n\n  override _addMessage(\n    this: ChatCompletionRunner<ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit: boolean = true,\n  ) {\n    super._addMessage(message, emit);\n    if (isAssistantMessage(message) && message.content) {\n      this._emit('content', message.content as string);\n    }\n  }\n}\n","const STR = 0b000000001;\nconst NUM = 0b000000010;\nconst ARR = 0b000000100;\nconst OBJ = 0b000001000;\nconst NULL = 0b000010000;\nconst BOOL = 0b000100000;\nconst NAN = 0b001000000;\nconst INFINITY = 0b010000000;\nconst MINUS_INFINITY = 0b100000000;\n\nconst INF = INFINITY | MINUS_INFINITY;\nconst SPECIAL = NULL | BOOL | INF | NAN;\nconst ATOM = STR | NUM | SPECIAL;\nconst COLLECTION = ARR | OBJ;\nconst ALL = ATOM | COLLECTION;\n\nconst Allow = {\n  STR,\n  NUM,\n  ARR,\n  OBJ,\n  NULL,\n  BOOL,\n  NAN,\n  INFINITY,\n  MINUS_INFINITY,\n  INF,\n  SPECIAL,\n  ATOM,\n  COLLECTION,\n  ALL,\n};\n\n// The JSON string segment was unable to be parsed completely\nclass PartialJSON extends Error {}\n\nclass MalformedJSON extends Error {}\n\n/**\n * Parse incomplete JSON\n * @param {string} jsonString Partial JSON to be parsed\n * @param {number} allowPartial Specify what types are allowed to be partial, see {@link Allow} for details\n * @returns The parsed JSON\n * @throws {PartialJSON} If the JSON is incomplete (related to the `allow` parameter)\n * @throws {MalformedJSON} If the JSON is malformed\n */\nfunction parseJSON(jsonString: string, allowPartial: number = Allow.ALL): any {\n  if (typeof jsonString !== 'string') {\n    throw new TypeError(`expecting str, got ${typeof jsonString}`);\n  }\n  if (!jsonString.trim()) {\n    throw new Error(`${jsonString} is empty`);\n  }\n  return _parseJSON(jsonString.trim(), allowPartial);\n}\n\nconst _parseJSON = (jsonString: string, allow: number) => {\n  const length = jsonString.length;\n  let index = 0;\n\n  const markPartialJSON = (msg: string) => {\n    throw new PartialJSON(`${msg} at position ${index}`);\n  };\n\n  const throwMalformedError = (msg: string) => {\n    throw new MalformedJSON(`${msg} at position ${index}`);\n  };\n\n  const parseAny: () => any = () => {\n    skipBlank();\n    if (index >= length) markPartialJSON('Unexpected end of input');\n    if (jsonString[index] === '\"') return parseStr();\n    if (jsonString[index] === '{') return parseObj();\n    if (jsonString[index] === '[') return parseArr();\n    if (\n      jsonString.substring(index, index + 4) === 'null' ||\n      (Allow.NULL & allow && length - index < 4 && 'null'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return null;\n    }\n    if (\n      jsonString.substring(index, index + 4) === 'true' ||\n      (Allow.BOOL & allow && length - index < 4 && 'true'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return true;\n    }\n    if (\n      jsonString.substring(index, index + 5) === 'false' ||\n      (Allow.BOOL & allow && length - index < 5 && 'false'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 5;\n      return false;\n    }\n    if (\n      jsonString.substring(index, index + 8) === 'Infinity' ||\n      (Allow.INFINITY & allow && length - index < 8 && 'Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 8;\n      return Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 9) === '-Infinity' ||\n      (Allow.MINUS_INFINITY & allow &&\n        1 < length - index &&\n        length - index < 9 &&\n        '-Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 9;\n      return -Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 3) === 'NaN' ||\n      (Allow.NAN & allow && length - index < 3 && 'NaN'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 3;\n      return NaN;\n    }\n    return parseNum();\n  };\n\n  const parseStr: () => string = () => {\n    const start = index;\n    let escape = false;\n    index++; // skip initial quote\n    while (index < length && (jsonString[index] !== '\"' || (escape && jsonString[index - 1] === '\\\\'))) {\n      escape = jsonString[index] === '\\\\' ? !escape : false;\n      index++;\n    }\n    if (jsonString.charAt(index) == '\"') {\n      try {\n        return JSON.parse(jsonString.substring(start, ++index - Number(escape)));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    } else if (Allow.STR & allow) {\n      try {\n        return JSON.parse(jsonString.substring(start, index - Number(escape)) + '\"');\n      } catch (e) {\n        // SyntaxError: Invalid escape sequence\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('\\\\')) + '\"');\n      }\n    }\n    markPartialJSON('Unterminated string literal');\n  };\n\n  const parseObj = () => {\n    index++; // skip initial brace\n    skipBlank();\n    const obj: Record<string, any> = {};\n    try {\n      while (jsonString[index] !== '}') {\n        skipBlank();\n        if (index >= length && Allow.OBJ & allow) return obj;\n        const key = parseStr();\n        skipBlank();\n        index++; // skip colon\n        try {\n          const value = parseAny();\n          Object.defineProperty(obj, key, { value, writable: true, enumerable: true, configurable: true });\n        } catch (e) {\n          if (Allow.OBJ & allow) return obj;\n          else throw e;\n        }\n        skipBlank();\n        if (jsonString[index] === ',') index++; // skip comma\n      }\n    } catch (e) {\n      if (Allow.OBJ & allow) return obj;\n      else markPartialJSON(\"Expected '}' at end of object\");\n    }\n    index++; // skip final brace\n    return obj;\n  };\n\n  const parseArr = () => {\n    index++; // skip initial bracket\n    const arr = [];\n    try {\n      while (jsonString[index] !== ']') {\n        arr.push(parseAny());\n        skipBlank();\n        if (jsonString[index] === ',') {\n          index++; // skip comma\n        }\n      }\n    } catch (e) {\n      if (Allow.ARR & allow) {\n        return arr;\n      }\n      markPartialJSON(\"Expected ']' at end of array\");\n    }\n    index++; // skip final bracket\n    return arr;\n  };\n\n  const parseNum = () => {\n    if (index === 0) {\n      if (jsonString === '-' && Allow.NUM & allow) markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString);\n      } catch (e) {\n        if (Allow.NUM & allow) {\n          try {\n            if ('.' === jsonString[jsonString.length - 1])\n              return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('.')));\n            return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('e')));\n          } catch (e) {}\n        }\n        throwMalformedError(String(e));\n      }\n    }\n\n    const start = index;\n\n    if (jsonString[index] === '-') index++;\n    while (jsonString[index] && !',]}'.includes(jsonString[index]!)) index++;\n\n    if (index == length && !(Allow.NUM & allow)) markPartialJSON('Unterminated number literal');\n\n    try {\n      return JSON.parse(jsonString.substring(start, index));\n    } catch (e) {\n      if (jsonString.substring(start, index) === '-' && Allow.NUM & allow)\n        markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('e')));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    }\n  };\n\n  const skipBlank = () => {\n    while (index < length && ' \\n\\r\\t'.includes(jsonString[index]!)) {\n      index++;\n    }\n  };\n\n  return parseAny();\n};\n\n// using this function with malformed JSON is undefined behavior\nconst partialParse = (input: string) => parseJSON(input, Allow.ALL ^ Allow.NUM);\n\nexport { partialParse, PartialJSON, MalformedJSON };\n","import * as Core from '../core';\nimport {\n  OpenAIError,\n  APIUserAbortError,\n  LengthFinishReasonError,\n  ContentFilterFinishReasonError,\n} from '../error';\nimport {\n  ChatCompletionTokenLogprob,\n  type ChatCompletion,\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsStreaming,\n  type ChatCompletionCreateParamsBase,\n} from '../resources/chat/completions';\nimport {\n  AbstractChatCompletionRunner,\n  type AbstractChatCompletionRunnerEvents,\n} from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from '../_shims/index';\nimport { Stream } from '../streaming';\nimport OpenAI from '../index';\nimport { ParsedChatCompletion } from '../resources/beta/chat/completions';\nimport {\n  AutoParseableResponseFormat,\n  hasAutoParseableInput,\n  isAutoParsableResponseFormat,\n  isAutoParsableTool,\n  maybeParseChatCompletion,\n  shouldParseToolCall,\n} from '../lib/parser';\nimport { partialParse } from '../_vendor/partial-json-parser/parser';\n\nexport interface ContentDeltaEvent {\n  delta: string;\n  snapshot: string;\n  parsed: unknown | null;\n}\n\nexport interface ContentDoneEvent<ParsedT = null> {\n  content: string;\n  parsed: ParsedT | null;\n}\n\nexport interface RefusalDeltaEvent {\n  delta: string;\n  snapshot: string;\n}\n\nexport interface RefusalDoneEvent {\n  refusal: string;\n}\n\nexport interface FunctionToolCallArgumentsDeltaEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n\n  arguments_delta: string;\n}\n\nexport interface FunctionToolCallArgumentsDoneEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n}\n\nexport interface LogProbsContentDeltaEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsContentDoneEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDeltaEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDoneEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface ChatCompletionStreamEvents<ParsedT = null> extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n\n  'content.delta': (props: ContentDeltaEvent) => void;\n  'content.done': (props: ContentDoneEvent<ParsedT>) => void;\n\n  'refusal.delta': (props: RefusalDeltaEvent) => void;\n  'refusal.done': (props: RefusalDoneEvent) => void;\n\n  'tool_calls.function.arguments.delta': (props: FunctionToolCallArgumentsDeltaEvent) => void;\n  'tool_calls.function.arguments.done': (props: FunctionToolCallArgumentsDoneEvent) => void;\n\n  'logprobs.content.delta': (props: LogProbsContentDeltaEvent) => void;\n  'logprobs.content.done': (props: LogProbsContentDoneEvent) => void;\n\n  'logprobs.refusal.delta': (props: LogProbsRefusalDeltaEvent) => void;\n  'logprobs.refusal.done': (props: LogProbsRefusalDoneEvent) => void;\n}\n\nexport type ChatCompletionStreamParams = Omit<ChatCompletionCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\ninterface ChoiceEventState {\n  content_done: boolean;\n  refusal_done: boolean;\n  logprobs_content_done: boolean;\n  logprobs_refusal_done: boolean;\n  current_tool_call_index: number | null;\n  done_tool_calls: Set<number>;\n}\n\nexport class ChatCompletionStream<ParsedT = null>\n  extends AbstractChatCompletionRunner<ChatCompletionStreamEvents<ParsedT>, ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  #params: ChatCompletionCreateParams | null;\n  #choiceEventStates: ChoiceEventState[];\n  #currentChatCompletionSnapshot: ChatCompletionSnapshot | undefined;\n\n  constructor(params: ChatCompletionCreateParams | null) {\n    super();\n    this.#params = params;\n    this.#choiceEventStates = [];\n  }\n\n  get currentChatCompletionSnapshot(): ChatCompletionSnapshot | undefined {\n    return this.#currentChatCompletionSnapshot;\n  }\n\n  /**\n   * Intended for use on the frontend, consuming a stream produced with\n   * `.toReadableStream()` on the backend.\n   *\n   * Note that messages sent to the model do not appear in `.on('message')`\n   * in this context.\n   */\n  static fromReadableStream(stream: ReadableStream): ChatCompletionStream<null> {\n    const runner = new ChatCompletionStream(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static createChatCompletion<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionStreamParams,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    const runner = new ChatCompletionStream<ParsedT>(params as ChatCompletionCreateParamsStreaming);\n    runner._run(() =>\n      runner._runChatCompletion(\n        client,\n        { ...params, stream: true },\n        { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } },\n      ),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentChatCompletionSnapshot = undefined;\n  }\n\n  #getChoiceEventState(choice: ChatCompletionSnapshot.Choice): ChoiceEventState {\n    let state = this.#choiceEventStates[choice.index];\n    if (state) {\n      return state;\n    }\n\n    state = {\n      content_done: false,\n      refusal_done: false,\n      logprobs_content_done: false,\n      logprobs_refusal_done: false,\n      done_tool_calls: new Set(),\n      current_tool_call_index: null,\n    };\n    this.#choiceEventStates[choice.index] = state;\n    return state;\n  }\n\n  #addChunk(this: ChatCompletionStream<ParsedT>, chunk: ChatCompletionChunk) {\n    if (this.ended) return;\n\n    const completion = this.#accumulateChatCompletion(chunk);\n    this._emit('chunk', chunk, completion);\n\n    for (const choice of chunk.choices) {\n      const choiceSnapshot = completion.choices[choice.index]!;\n\n      if (\n        choice.delta.content != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.content\n      ) {\n        this._emit('content', choice.delta.content, choiceSnapshot.message.content);\n        this._emit('content.delta', {\n          delta: choice.delta.content,\n          snapshot: choiceSnapshot.message.content,\n          parsed: choiceSnapshot.message.parsed,\n        });\n      }\n\n      if (\n        choice.delta.refusal != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.refusal\n      ) {\n        this._emit('refusal.delta', {\n          delta: choice.delta.refusal,\n          snapshot: choiceSnapshot.message.refusal,\n        });\n      }\n\n      if (choice.logprobs?.content != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.content.delta', {\n          content: choice.logprobs?.content,\n          snapshot: choiceSnapshot.logprobs?.content ?? [],\n        });\n      }\n\n      if (choice.logprobs?.refusal != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.refusal.delta', {\n          refusal: choice.logprobs?.refusal,\n          snapshot: choiceSnapshot.logprobs?.refusal ?? [],\n        });\n      }\n\n      const state = this.#getChoiceEventState(choiceSnapshot);\n\n      if (choiceSnapshot.finish_reason) {\n        this.#emitContentDoneEvents(choiceSnapshot);\n\n        if (state.current_tool_call_index != null) {\n          this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n        }\n      }\n\n      for (const toolCall of choice.delta.tool_calls ?? []) {\n        if (state.current_tool_call_index !== toolCall.index) {\n          this.#emitContentDoneEvents(choiceSnapshot);\n\n          // new tool call started, the previous one is done\n          if (state.current_tool_call_index != null) {\n            this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n          }\n        }\n\n        state.current_tool_call_index = toolCall.index;\n      }\n\n      for (const toolCallDelta of choice.delta.tool_calls ?? []) {\n        const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallDelta.index];\n        if (!toolCallSnapshot?.type) {\n          continue;\n        }\n\n        if (toolCallSnapshot?.type === 'function') {\n          this._emit('tool_calls.function.arguments.delta', {\n            name: toolCallSnapshot.function?.name,\n            index: toolCallDelta.index,\n            arguments: toolCallSnapshot.function.arguments,\n            parsed_arguments: toolCallSnapshot.function.parsed_arguments,\n            arguments_delta: toolCallDelta.function?.arguments ?? '',\n          });\n        } else {\n          assertNever(toolCallSnapshot?.type);\n        }\n      }\n    }\n  }\n\n  #emitToolCallDoneEvent(choiceSnapshot: ChatCompletionSnapshot.Choice, toolCallIndex: number) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n    if (state.done_tool_calls.has(toolCallIndex)) {\n      // we've already fired the done event\n      return;\n    }\n\n    const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallIndex];\n    if (!toolCallSnapshot) {\n      throw new Error('no tool call snapshot');\n    }\n    if (!toolCallSnapshot.type) {\n      throw new Error('tool call snapshot missing `type`');\n    }\n\n    if (toolCallSnapshot.type === 'function') {\n      const inputTool = this.#params?.tools?.find(\n        (tool) => tool.type === 'function' && tool.function.name === toolCallSnapshot.function.name,\n      );\n\n      this._emit('tool_calls.function.arguments.done', {\n        name: toolCallSnapshot.function.name,\n        index: toolCallIndex,\n        arguments: toolCallSnapshot.function.arguments,\n        parsed_arguments:\n          isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCallSnapshot.function.arguments)\n          : inputTool?.function.strict ? JSON.parse(toolCallSnapshot.function.arguments)\n          : null,\n      });\n    } else {\n      assertNever(toolCallSnapshot.type);\n    }\n  }\n\n  #emitContentDoneEvents(choiceSnapshot: ChatCompletionSnapshot.Choice) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n\n    if (choiceSnapshot.message.content && !state.content_done) {\n      state.content_done = true;\n\n      const responseFormat = this.#getAutoParseableResponseFormat();\n\n      this._emit('content.done', {\n        content: choiceSnapshot.message.content,\n        parsed: responseFormat ? responseFormat.$parseRaw(choiceSnapshot.message.content) : (null as any),\n      });\n    }\n\n    if (choiceSnapshot.message.refusal && !state.refusal_done) {\n      state.refusal_done = true;\n\n      this._emit('refusal.done', { refusal: choiceSnapshot.message.refusal });\n    }\n\n    if (choiceSnapshot.logprobs?.content && !state.logprobs_content_done) {\n      state.logprobs_content_done = true;\n\n      this._emit('logprobs.content.done', { content: choiceSnapshot.logprobs.content });\n    }\n\n    if (choiceSnapshot.logprobs?.refusal && !state.logprobs_refusal_done) {\n      state.logprobs_refusal_done = true;\n\n      this._emit('logprobs.refusal.done', { refusal: choiceSnapshot.logprobs.refusal });\n    }\n  }\n\n  #endRequest(): ParsedChatCompletion<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentChatCompletionSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any chunks`);\n    }\n    this.#currentChatCompletionSnapshot = undefined;\n    this.#choiceEventStates = [];\n    return finalizeChatCompletion(snapshot, this.#params);\n  }\n\n  protected override async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    super._createChatCompletion;\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    const stream = await client.chat.completions.create(\n      { ...params, stream: true },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    for await (const chunk of stream) {\n      this.#addChunk(chunk);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n    this._connected();\n    const stream = Stream.fromReadableStream<ChatCompletionChunk>(readableStream, this.controller);\n    let chatId;\n    for await (const chunk of stream) {\n      if (chatId && chatId !== chunk.id) {\n        // A new request has been made.\n        this._addChatCompletion(this.#endRequest());\n      }\n\n      this.#addChunk(chunk);\n      chatId = chunk.id;\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  #getAutoParseableResponseFormat(): AutoParseableResponseFormat<ParsedT> | null {\n    const responseFormat = this.#params?.response_format;\n    if (isAutoParsableResponseFormat<ParsedT>(responseFormat)) {\n      return responseFormat;\n    }\n\n    return null;\n  }\n\n  #accumulateChatCompletion(chunk: ChatCompletionChunk): ChatCompletionSnapshot {\n    let snapshot = this.#currentChatCompletionSnapshot;\n    const { choices, ...rest } = chunk;\n    if (!snapshot) {\n      snapshot = this.#currentChatCompletionSnapshot = {\n        ...rest,\n        choices: [],\n      };\n    } else {\n      Object.assign(snapshot, rest);\n    }\n\n    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\n      let choice = snapshot.choices[index];\n      if (!choice) {\n        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\n      }\n\n      if (logprobs) {\n        if (!choice.logprobs) {\n          choice.logprobs = Object.assign({}, logprobs);\n        } else {\n          const { content, refusal, ...rest } = logprobs;\n          assertIsEmpty(rest);\n          Object.assign(choice.logprobs, rest);\n\n          if (content) {\n            choice.logprobs.content ??= [];\n            choice.logprobs.content.push(...content);\n          }\n\n          if (refusal) {\n            choice.logprobs.refusal ??= [];\n            choice.logprobs.refusal.push(...refusal);\n          }\n        }\n      }\n\n      if (finish_reason) {\n        choice.finish_reason = finish_reason;\n\n        if (this.#params && hasAutoParseableInput(this.#params)) {\n          if (finish_reason === 'length') {\n            throw new LengthFinishReasonError();\n          }\n\n          if (finish_reason === 'content_filter') {\n            throw new ContentFilterFinishReasonError();\n          }\n        }\n      }\n\n      Object.assign(choice, other);\n\n      if (!delta) continue; // Shouldn't happen; just in case.\n\n      const { content, refusal, function_call, role, tool_calls, ...rest } = delta;\n      assertIsEmpty(rest);\n      Object.assign(choice.message, rest);\n\n      if (refusal) {\n        choice.message.refusal = (choice.message.refusal || '') + refusal;\n      }\n\n      if (role) choice.message.role = role;\n      if (function_call) {\n        if (!choice.message.function_call) {\n          choice.message.function_call = function_call;\n        } else {\n          if (function_call.name) choice.message.function_call.name = function_call.name;\n          if (function_call.arguments) {\n            choice.message.function_call.arguments ??= '';\n            choice.message.function_call.arguments += function_call.arguments;\n          }\n        }\n      }\n      if (content) {\n        choice.message.content = (choice.message.content || '') + content;\n\n        if (!choice.message.refusal && this.#getAutoParseableResponseFormat()) {\n          choice.message.parsed = partialParse(choice.message.content);\n        }\n      }\n\n      if (tool_calls) {\n        if (!choice.message.tool_calls) choice.message.tool_calls = [];\n\n        for (const { index, id, type, function: fn, ...rest } of tool_calls) {\n          const tool_call = (choice.message.tool_calls[index] ??=\n            {} as ChatCompletionSnapshot.Choice.Message.ToolCall);\n          Object.assign(tool_call, rest);\n          if (id) tool_call.id = id;\n          if (type) tool_call.type = type;\n          if (fn) tool_call.function ??= { name: fn.name ?? '', arguments: '' };\n          if (fn?.name) tool_call.function!.name = fn.name;\n          if (fn?.arguments) {\n            tool_call.function!.arguments += fn.arguments;\n\n            if (shouldParseToolCall(this.#params, tool_call)) {\n              tool_call.function!.parsed_arguments = partialParse(tool_call.function!.arguments);\n            }\n          }\n        }\n      }\n    }\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ChatCompletionStream<ParsedT>): AsyncIterator<ChatCompletionChunk> {\n    const pushQueue: ChatCompletionChunk[] = [];\n    const readQueue: {\n      resolve: (chunk: ChatCompletionChunk | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('chunk', (chunk) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(chunk);\n      } else {\n        pushQueue.push(chunk);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ChatCompletionChunk>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ChatCompletionChunk | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n}\n\nfunction finalizeChatCompletion<ParsedT>(\n  snapshot: ChatCompletionSnapshot,\n  params: ChatCompletionCreateParams | null,\n): ParsedChatCompletion<ParsedT> {\n  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\n  const completion: ChatCompletion = {\n    ...rest,\n    id,\n    choices: choices.map(\n      ({ message, finish_reason, index, logprobs, ...choiceRest }): ChatCompletion.Choice => {\n        if (!finish_reason) {\n          throw new OpenAIError(`missing finish_reason for choice ${index}`);\n        }\n\n        const { content = null, function_call, tool_calls, ...messageRest } = message;\n        const role = message.role as 'assistant'; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\n        if (!role) {\n          throw new OpenAIError(`missing role for choice ${index}`);\n        }\n\n        if (function_call) {\n          const { arguments: args, name } = function_call;\n          if (args == null) {\n            throw new OpenAIError(`missing function_call.arguments for choice ${index}`);\n          }\n\n          if (!name) {\n            throw new OpenAIError(`missing function_call.name for choice ${index}`);\n          }\n\n          return {\n            ...choiceRest,\n            message: {\n              content,\n              function_call: { arguments: args, name },\n              role,\n              refusal: message.refusal ?? null,\n            },\n            finish_reason,\n            index,\n            logprobs,\n          };\n        }\n\n        if (tool_calls) {\n          return {\n            ...choiceRest,\n            index,\n            finish_reason,\n            logprobs,\n            message: {\n              ...messageRest,\n              role,\n              content,\n              refusal: message.refusal ?? null,\n              tool_calls: tool_calls.map((tool_call, i) => {\n                const { function: fn, type, id, ...toolRest } = tool_call;\n                const { arguments: args, name, ...fnRest } = fn || {};\n                if (id == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\n                }\n                if (type == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\n                }\n                if (name == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`,\n                  );\n                }\n                if (args == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`,\n                  );\n                }\n\n                return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\n              }),\n            },\n          };\n        }\n        return {\n          ...choiceRest,\n          message: { ...messageRest, content, role, refusal: message.refusal ?? null },\n          finish_reason,\n          index,\n          logprobs,\n        };\n      },\n    ),\n    created,\n    model,\n    object: 'chat.completion',\n    ...(system_fingerprint ? { system_fingerprint } : {}),\n  };\n\n  return maybeParseChatCompletion(completion, params);\n}\n\nfunction str(x: unknown) {\n  return JSON.stringify(x);\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionSnapshot {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletionSnapshot.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  // Note we do not include an \"object\" type on the snapshot,\n  // because the object is not a valid \"chat.completion\" until finalized.\n  // object: 'chat.completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n}\n\nexport namespace ChatCompletionSnapshot {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    message: Choice.Message;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, or `function_call`\n     * if the model called a function.\n     */\n    finish_reason: ChatCompletion.Choice['finish_reason'] | null;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: ChatCompletion.Choice.Logprobs | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Message {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      refusal?: string | null;\n\n      parsed?: unknown | null;\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      function_call?: Message.FunctionCall;\n\n      tool_calls?: Array<Message.ToolCall>;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'system' | 'user' | 'assistant' | 'function' | 'tool';\n    }\n\n    export namespace Message {\n      export interface ToolCall {\n        /**\n         * The ID of the tool call.\n         */\n        id: string;\n\n        function: ToolCall.Function;\n\n        /**\n         * The type of the tool.\n         */\n        type: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments: string;\n\n          parsed_arguments?: unknown;\n\n          /**\n           * The name of the function to call.\n           */\n          name: string;\n        }\n      }\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n    }\n  }\n}\n\ntype AssertIsEmpty<T extends {}> = keyof T extends never ? T : never;\n\n/**\n * Ensures the given argument is an empty object, useful for\n * asserting that all known properties on an object have been\n * destructured.\n */\nfunction assertIsEmpty<T extends {}>(obj: AssertIsEmpty<T>): asserts obj is AssertIsEmpty<T> {\n  return;\n}\n\nfunction assertNever(_x: never) {}\n","import {\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParamsStreaming,\n} from '../resources/chat/completions';\nimport { RunnerOptions, type AbstractChatCompletionRunnerEvents } from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from '../_shims/index';\nimport { RunnableTools, type BaseFunctionsArgs, type RunnableFunctions } from './RunnableFunction';\nimport { ChatCompletionSnapshot, ChatCompletionStream } from './ChatCompletionStream';\nimport OpenAI from '../index';\nimport { AutoParseableTool } from '../lib/parser';\n\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n}\n\nexport type ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionStreamingToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionStreamingRunner<ParsedT = null>\n  extends ChatCompletionStream<ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  static override fromReadableStream(stream: ReadableStream): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions<T extends (string | object)[]>(\n    client: OpenAI,\n    params: ChatCompletionStreamingFunctionRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(client, params, opts));\n    return runner;\n  }\n\n  static runTools<T extends (string | object)[], ParsedT = null>(\n    client: OpenAI,\n    params: ChatCompletionStreamingToolRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<ParsedT> {\n    const runner = new ChatCompletionStreamingRunner<ParsedT>(\n      // @ts-expect-error TODO these types are incompatible\n      params,\n    );\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingRunner,\n  ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nimport { BaseFunctionsArgs } from '../../../lib/RunnableFunction';\nimport { RunnerOptions } from '../../../lib/AbstractChatCompletionRunner';\nimport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nimport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nimport {\n  ChatCompletion,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionMessage,\n  ChatCompletionMessageToolCall,\n} from '../../chat/completions';\nimport { ExtractParsedContentFromParams, parseChatCompletion, validateInputTools } from '../../../lib/parser';\n\nexport {\n  ChatCompletionStreamingRunner,\n  type ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nexport {\n  type RunnableFunction,\n  type RunnableFunctions,\n  type RunnableFunctionWithParse,\n  type RunnableFunctionWithoutParse,\n  ParsingFunction,\n  ParsingToolFunction,\n} from '../../../lib/RunnableFunction';\nexport { type ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { type ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nexport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nexport {\n  ChatCompletionRunner,\n  type ChatCompletionFunctionRunnerParams,\n} from '../../../lib/ChatCompletionRunner';\n\nexport interface ParsedFunction extends ChatCompletionMessageToolCall.Function {\n  parsed_arguments?: unknown;\n}\n\nexport interface ParsedFunctionToolCall extends ChatCompletionMessageToolCall {\n  function: ParsedFunction;\n}\n\nexport interface ParsedChatCompletionMessage<ParsedT> extends ChatCompletionMessage {\n  parsed: ParsedT | null;\n  tool_calls: Array<ParsedFunctionToolCall>;\n}\n\nexport interface ParsedChoice<ParsedT> extends ChatCompletion.Choice {\n  message: ParsedChatCompletionMessage<ParsedT>;\n}\n\nexport interface ParsedChatCompletion<ParsedT> extends ChatCompletion {\n  choices: Array<ParsedChoice<ParsedT>>;\n}\n\nexport type ChatCompletionParseParams = ChatCompletionCreateParamsNonStreaming;\n\nexport class Completions extends APIResource {\n  parse<Params extends ChatCompletionParseParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ParsedChatCompletion<ParsedT>> {\n    validateInputTools(body.tools);\n\n    return this._client.chat.completions\n      .create(body, {\n        ...options,\n        headers: {\n          ...options?.headers,\n          'X-Stainless-Helper-Method': 'beta.chat.completions.parse',\n        },\n      })\n      ._thenUnwrap((completion) => parseChatCompletion(completion, body));\n  }\n\n  /**\n   * @deprecated - use `runTools` instead.\n   */\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner<null>;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStreamingRunner<null>;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner<null> | ChatCompletionStreamingRunner<null> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runFunctions(\n        this._client,\n        body as ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n        options,\n      );\n    }\n    return ChatCompletionRunner.runFunctions(\n      this._client,\n      body as ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n      options,\n    );\n  }\n\n  /**\n   * A convenience helper for using tool calls with the /chat/completions endpoint\n   * which automatically calls the JavaScript functions you provide and sends their\n   * results back to the /chat/completions endpoint, looping as long as the model\n   * requests function calls.\n   *\n   * For more details and examples, see\n   * [the docs](https://github.com/openai/openai-node#automated-function-calls)\n   */\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionStreamingRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any> | ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(\n    body: Params,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> | ChatCompletionStreamingRunner<ParsedT> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runTools(\n        this._client,\n        body as ChatCompletionStreamingToolRunnerParams<any>,\n        options,\n      );\n    }\n\n    return ChatCompletionRunner.runTools(this._client, body as ChatCompletionToolRunnerParams<any>, options);\n  }\n\n  /**\n   * Creates a chat completion stream\n   */\n  stream<Params extends ChatCompletionStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    return ChatCompletionStream.createChatCompletion(this._client, body, options);\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport * as CompletionsAPI from './completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport namespace Chat {\n  export import Completions = CompletionsAPI.Completions;\n}\n","import {\n  TextContentBlock,\n  ImageFileContentBlock,\n  Message,\n  MessageContentDelta,\n  Text,\n  ImageFile,\n  TextDelta,\n  MessageDelta,\n  MessageContent,\n} from '../resources/beta/threads/messages';\nimport * as Core from '../core';\nimport { RequestOptions } from '../core';\nimport {\n  Run,\n  RunCreateParamsBase,\n  RunCreateParamsStreaming,\n  Runs,\n  RunSubmitToolOutputsParamsBase,\n  RunSubmitToolOutputsParamsStreaming,\n} from '../resources/beta/threads/runs/runs';\nimport { type ReadableStream } from '../_shims/index';\nimport { Stream } from '../streaming';\nimport { APIUserAbortError, OpenAIError } from '../error';\nimport {\n  AssistantStreamEvent,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n} from '../resources/beta/assistants';\nimport { RunStep, RunStepDelta, ToolCall, ToolCallDelta } from '../resources/beta/threads/runs/steps';\nimport { ThreadCreateAndRunParamsBase, Threads } from '../resources/beta/threads/threads';\nimport { BaseEvents, EventStream } from './EventStream';\n\nexport interface AssistantStreamEvents extends BaseEvents {\n  run: (run: Run) => void;\n\n  //New event structure\n  messageCreated: (message: Message) => void;\n  messageDelta: (message: MessageDelta, snapshot: Message) => void;\n  messageDone: (message: Message) => void;\n\n  runStepCreated: (runStep: RunStep) => void;\n  runStepDelta: (delta: RunStepDelta, snapshot: Runs.RunStep) => void;\n  runStepDone: (runStep: Runs.RunStep, snapshot: Runs.RunStep) => void;\n\n  toolCallCreated: (toolCall: ToolCall) => void;\n  toolCallDelta: (delta: ToolCallDelta, snapshot: ToolCall) => void;\n  toolCallDone: (toolCall: ToolCall) => void;\n\n  textCreated: (content: Text) => void;\n  textDelta: (delta: TextDelta, snapshot: Text) => void;\n  textDone: (content: Text, snapshot: Message) => void;\n\n  //No created or delta as this is not streamed\n  imageFileDone: (content: ImageFile, snapshot: Message) => void;\n\n  event: (event: AssistantStreamEvent) => void;\n}\n\nexport type ThreadCreateAndRunParamsBaseStream = Omit<ThreadCreateAndRunParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunCreateParamsBaseStream = Omit<RunCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunSubmitToolOutputsParamsStream = Omit<RunSubmitToolOutputsParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class AssistantStream\n  extends EventStream<AssistantStreamEvents>\n  implements AsyncIterable<AssistantStreamEvent>\n{\n  //Track all events in a single list for reference\n  #events: AssistantStreamEvent[] = [];\n\n  //Used to accumulate deltas\n  //We are accumulating many types so the value here is not strict\n  #runStepSnapshots: { [id: string]: Runs.RunStep } = {};\n  #messageSnapshots: { [id: string]: Message } = {};\n  #messageSnapshot: Message | undefined;\n  #finalRun: Run | undefined;\n  #currentContentIndex: number | undefined;\n  #currentContent: MessageContent | undefined;\n  #currentToolCallIndex: number | undefined;\n  #currentToolCall: ToolCall | undefined;\n\n  //For current snapshot methods\n  #currentEvent: AssistantStreamEvent | undefined;\n  #currentRunSnapshot: Run | undefined;\n  #currentRunStepSnapshot: Runs.RunStep | undefined;\n\n  [Symbol.asyncIterator](): AsyncIterator<AssistantStreamEvent> {\n    const pushQueue: AssistantStreamEvent[] = [];\n    const readQueue: {\n      resolve: (chunk: AssistantStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    //Catch all for passing along all events\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<AssistantStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<AssistantStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  static fromReadableStream(stream: ReadableStream): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this._connected();\n    const stream = Stream.fromReadableStream<AssistantStreamEvent>(readableStream, this.controller);\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addRun(this.#endRequest());\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n\n  static createToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options: RequestOptions | undefined,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runToolAssistantStream(threadId, runId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  protected async _createToolAssistantStream(\n    run: Runs,\n    threadId: string,\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunSubmitToolOutputsParamsStreaming = { ...params, stream: true };\n    const stream = await run.submitToolOutputs(threadId, runId, body, {\n      ...options,\n      signal: this.controller.signal,\n    });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  static createThreadAssistantStream(\n    params: ThreadCreateAndRunParamsBaseStream,\n    thread: Threads,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._threadAssistantStream(params, thread, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  static createAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runAssistantStream(threadId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  currentEvent(): AssistantStreamEvent | undefined {\n    return this.#currentEvent;\n  }\n\n  currentRun(): Run | undefined {\n    return this.#currentRunSnapshot;\n  }\n\n  currentMessageSnapshot(): Message | undefined {\n    return this.#messageSnapshot;\n  }\n\n  currentRunStepSnapshot(): Runs.RunStep | undefined {\n    return this.#currentRunStepSnapshot;\n  }\n\n  async finalRunSteps(): Promise<Runs.RunStep[]> {\n    await this.done();\n\n    return Object.values(this.#runStepSnapshots);\n  }\n\n  async finalMessages(): Promise<Message[]> {\n    await this.done();\n\n    return Object.values(this.#messageSnapshots);\n  }\n\n  async finalRun(): Promise<Run> {\n    await this.done();\n    if (!this.#finalRun) throw Error('Final run was not received.');\n\n    return this.#finalRun;\n  }\n\n  protected async _createThreadAssistantStream(\n    thread: Threads,\n    params: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  protected async _createAssistantStream(\n    run: Runs,\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  #addEvent(event: AssistantStreamEvent) {\n    if (this.ended) return;\n\n    this.#currentEvent = event;\n\n    this.#handleEvent(event);\n\n    switch (event.event) {\n      case 'thread.created':\n        //No action on this event.\n        break;\n\n      case 'thread.run.created':\n      case 'thread.run.queued':\n      case 'thread.run.in_progress':\n      case 'thread.run.requires_action':\n      case 'thread.run.completed':\n      case 'thread.run.failed':\n      case 'thread.run.cancelling':\n      case 'thread.run.cancelled':\n      case 'thread.run.expired':\n        this.#handleRun(event);\n        break;\n\n      case 'thread.run.step.created':\n      case 'thread.run.step.in_progress':\n      case 'thread.run.step.delta':\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#handleRunStep(event);\n        break;\n\n      case 'thread.message.created':\n      case 'thread.message.in_progress':\n      case 'thread.message.delta':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        this.#handleMessage(event);\n        break;\n\n      case 'error':\n        //This is included for completeness, but errors are processed in the SSE event processing so this should not occur\n        throw new Error(\n          'Encountered an error event in event processing - errors should be processed earlier',\n        );\n    }\n  }\n\n  #endRequest(): Run {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n\n    if (!this.#finalRun) throw Error('Final run has not been received');\n\n    return this.#finalRun;\n  }\n\n  #handleMessage(this: AssistantStream, event: MessageStreamEvent) {\n    const [accumulatedMessage, newContent] = this.#accumulateMessage(event, this.#messageSnapshot);\n    this.#messageSnapshot = accumulatedMessage;\n    this.#messageSnapshots[accumulatedMessage.id] = accumulatedMessage;\n\n    for (const content of newContent) {\n      const snapshotContent = accumulatedMessage.content[content.index];\n      if (snapshotContent?.type == 'text') {\n        this._emit('textCreated', snapshotContent.text);\n      }\n    }\n\n    switch (event.event) {\n      case 'thread.message.created':\n        this._emit('messageCreated', event.data);\n        break;\n\n      case 'thread.message.in_progress':\n        break;\n\n      case 'thread.message.delta':\n        this._emit('messageDelta', event.data.delta, accumulatedMessage);\n\n        if (event.data.delta.content) {\n          for (const content of event.data.delta.content) {\n            //If it is text delta, emit a text delta event\n            if (content.type == 'text' && content.text) {\n              let textDelta = content.text;\n              let snapshot = accumulatedMessage.content[content.index];\n              if (snapshot && snapshot.type == 'text') {\n                this._emit('textDelta', textDelta, snapshot.text);\n              } else {\n                throw Error('The snapshot associated with this text delta is not text or missing');\n              }\n            }\n\n            if (content.index != this.#currentContentIndex) {\n              //See if we have in progress content\n              if (this.#currentContent) {\n                switch (this.#currentContent.type) {\n                  case 'text':\n                    this._emit('textDone', this.#currentContent.text, this.#messageSnapshot);\n                    break;\n                  case 'image_file':\n                    this._emit('imageFileDone', this.#currentContent.image_file, this.#messageSnapshot);\n                    break;\n                }\n              }\n\n              this.#currentContentIndex = content.index;\n            }\n\n            this.#currentContent = accumulatedMessage.content[content.index];\n          }\n        }\n\n        break;\n\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //We emit the latest content we were working on on completion (including incomplete)\n        if (this.#currentContentIndex !== undefined) {\n          const currentContent = event.data.content[this.#currentContentIndex];\n          if (currentContent) {\n            switch (currentContent.type) {\n              case 'image_file':\n                this._emit('imageFileDone', currentContent.image_file, this.#messageSnapshot);\n                break;\n              case 'text':\n                this._emit('textDone', currentContent.text, this.#messageSnapshot);\n                break;\n            }\n          }\n        }\n\n        if (this.#messageSnapshot) {\n          this._emit('messageDone', event.data);\n        }\n\n        this.#messageSnapshot = undefined;\n    }\n  }\n\n  #handleRunStep(this: AssistantStream, event: RunStepStreamEvent) {\n    const accumulatedRunStep = this.#accumulateRunStep(event);\n    this.#currentRunStepSnapshot = accumulatedRunStep;\n\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this._emit('runStepCreated', event.data);\n        break;\n      case 'thread.run.step.delta':\n        const delta = event.data.delta;\n        if (\n          delta.step_details &&\n          delta.step_details.type == 'tool_calls' &&\n          delta.step_details.tool_calls &&\n          accumulatedRunStep.step_details.type == 'tool_calls'\n        ) {\n          for (const toolCall of delta.step_details.tool_calls) {\n            if (toolCall.index == this.#currentToolCallIndex) {\n              this._emit(\n                'toolCallDelta',\n                toolCall,\n                accumulatedRunStep.step_details.tool_calls[toolCall.index] as ToolCall,\n              );\n            } else {\n              if (this.#currentToolCall) {\n                this._emit('toolCallDone', this.#currentToolCall);\n              }\n\n              this.#currentToolCallIndex = toolCall.index;\n              this.#currentToolCall = accumulatedRunStep.step_details.tool_calls[toolCall.index];\n              if (this.#currentToolCall) this._emit('toolCallCreated', this.#currentToolCall);\n            }\n          }\n        }\n\n        this._emit('runStepDelta', event.data.delta, accumulatedRunStep);\n        break;\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#currentRunStepSnapshot = undefined;\n        const details = event.data.step_details;\n        if (details.type == 'tool_calls') {\n          if (this.#currentToolCall) {\n            this._emit('toolCallDone', this.#currentToolCall as ToolCall);\n            this.#currentToolCall = undefined;\n          }\n        }\n        this._emit('runStepDone', event.data, accumulatedRunStep);\n        break;\n      case 'thread.run.step.in_progress':\n        break;\n    }\n  }\n\n  #handleEvent(this: AssistantStream, event: AssistantStreamEvent) {\n    this.#events.push(event);\n    this._emit('event', event);\n  }\n\n  #accumulateRunStep(event: RunStepStreamEvent): Runs.RunStep {\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        return event.data;\n\n      case 'thread.run.step.delta':\n        let snapshot = this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n        if (!snapshot) {\n          throw Error('Received a RunStepDelta before creation of a snapshot');\n        }\n\n        let data = event.data;\n\n        if (data.delta) {\n          const accumulated = AssistantStream.accumulateDelta(snapshot, data.delta) as Runs.RunStep;\n          this.#runStepSnapshots[event.data.id] = accumulated;\n        }\n\n        return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n      case 'thread.run.step.in_progress':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        break;\n    }\n\n    if (this.#runStepSnapshots[event.data.id]) return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n    throw new Error('No snapshot available');\n  }\n\n  #accumulateMessage(\n    event: AssistantStreamEvent,\n    snapshot: Message | undefined,\n  ): [Message, MessageContentDelta[]] {\n    let newContent: MessageContentDelta[] = [];\n\n    switch (event.event) {\n      case 'thread.message.created':\n        //On creation the snapshot is just the initial message\n        return [event.data, newContent];\n\n      case 'thread.message.delta':\n        if (!snapshot) {\n          throw Error(\n            'Received a delta with no existing snapshot (there should be one from message creation)',\n          );\n        }\n\n        let data = event.data;\n\n        //If this delta does not have content, nothing to process\n        if (data.delta.content) {\n          for (const contentElement of data.delta.content) {\n            if (contentElement.index in snapshot.content) {\n              let currentContent = snapshot.content[contentElement.index];\n              snapshot.content[contentElement.index] = this.#accumulateContent(\n                contentElement,\n                currentContent,\n              );\n            } else {\n              snapshot.content[contentElement.index] = contentElement as MessageContent;\n              // This is a new element\n              newContent.push(contentElement);\n            }\n          }\n        }\n\n        return [snapshot, newContent];\n\n      case 'thread.message.in_progress':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //No changes on other thread events\n        if (snapshot) {\n          return [snapshot, newContent];\n        } else {\n          throw Error('Received thread message event with no existing snapshot');\n        }\n    }\n    throw Error('Tried to accumulate a non-message event');\n  }\n\n  #accumulateContent(\n    contentElement: MessageContentDelta,\n    currentContent: MessageContent | undefined,\n  ): TextContentBlock | ImageFileContentBlock {\n    return AssistantStream.accumulateDelta(currentContent as unknown as Record<any, any>, contentElement) as\n      | TextContentBlock\n      | ImageFileContentBlock;\n  }\n\n  static accumulateDelta(acc: Record<string, any>, delta: Record<string, any>): Record<string, any> {\n    for (const [key, deltaValue] of Object.entries(delta)) {\n      if (!acc.hasOwnProperty(key)) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      let accValue = acc[key];\n      if (accValue === null || accValue === undefined) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // We don't accumulate these special properties\n      if (key === 'index' || key === 'type') {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // Type-specific accumulation logic\n      if (typeof accValue === 'string' && typeof deltaValue === 'string') {\n        accValue += deltaValue;\n      } else if (typeof accValue === 'number' && typeof deltaValue === 'number') {\n        accValue += deltaValue;\n      } else if (Core.isObj(accValue) && Core.isObj(deltaValue)) {\n        accValue = this.accumulateDelta(accValue as Record<string, any>, deltaValue as Record<string, any>);\n      } else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {\n        if (accValue.every((x) => typeof x === 'string' || typeof x === 'number')) {\n          accValue.push(...deltaValue); // Use spread syntax for efficient addition\n          continue;\n        }\n\n        for (const deltaEntry of deltaValue) {\n          if (!Core.isObj(deltaEntry)) {\n            throw new Error(`Expected array delta entry to be an object but got: ${deltaEntry}`);\n          }\n\n          const index = deltaEntry['index'];\n          if (index == null) {\n            console.error(deltaEntry);\n            throw new Error('Expected array delta entry to have an `index` property');\n          }\n\n          if (typeof index !== 'number') {\n            throw new Error(`Expected array delta entry \\`index\\` property to be a number but got ${index}`);\n          }\n\n          const accEntry = accValue[index];\n          if (accEntry == null) {\n            accValue.push(deltaEntry);\n          } else {\n            accValue[index] = this.accumulateDelta(accEntry, deltaEntry);\n          }\n        }\n        continue;\n      } else {\n        throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);\n      }\n      acc[key] = accValue;\n    }\n\n    return acc;\n  }\n\n  #handleRun(this: AssistantStream, event: RunStreamEvent) {\n    this.#currentRunSnapshot = event.data;\n    switch (event.event) {\n      case 'thread.run.created':\n        break;\n      case 'thread.run.queued':\n        break;\n      case 'thread.run.in_progress':\n        break;\n      case 'thread.run.requires_action':\n      case 'thread.run.cancelled':\n      case 'thread.run.failed':\n      case 'thread.run.completed':\n      case 'thread.run.expired':\n        this.#finalRun = event.data;\n        if (this.#currentToolCall) {\n          this._emit('toolCallDone', this.#currentToolCall);\n          this.#currentToolCall = undefined;\n        }\n        break;\n      case 'thread.run.cancelling':\n        break;\n    }\n  }\n\n  protected _addRun(run: Run): Run {\n    return run;\n  }\n\n  protected async _threadAssistantStream(\n    params: ThreadCreateAndRunParamsBase,\n    thread: Threads,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createThreadAssistantStream(thread, params, options);\n  }\n\n  protected async _runAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createAssistantStream(runs, threadId, params, options);\n  }\n\n  protected async _runToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createToolAssistantStream(runs, threadId, runId, params, options);\n  }\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as AssistantsAPI from '../assistants';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Messages extends APIResource {\n  /**\n   * Create a message.\n   */\n  create(\n    threadId: string,\n    body: MessageCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieve a message.\n   */\n  retrieve(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<Message> {\n    return this._client.get(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a message.\n   */\n  update(\n    threadId: string,\n    messageId: string,\n    body: MessageUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages/${messageId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of messages for a given thread.\n   */\n  list(\n    threadId: string,\n    query?: MessageListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<MessagesPage, Message>;\n  list(\n    threadId: string,\n    query: MessageListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/messages`, MessagesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Deletes a message.\n   */\n  del(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<MessageDeleted> {\n    return this._client.delete(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class MessagesPage extends CursorPage<Message> {}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type Annotation = FileCitationAnnotation | FilePathAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type AnnotationDelta = FileCitationDeltaAnnotation | FilePathDeltaAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationAnnotation {\n  end_index: number;\n\n  file_citation: FileCitationAnnotation.FileCitation;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n}\n\nexport namespace FileCitationAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n\n  end_index?: number;\n\n  file_citation?: FileCitationDeltaAnnotation.FileCitation;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FileCitationDeltaAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id?: string;\n\n    /**\n     * The specific quote in the file.\n     */\n    quote?: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathAnnotation {\n  end_index: number;\n\n  file_path: FilePathAnnotation.FilePath;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n}\n\nexport namespace FilePathAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n\n  end_index?: number;\n\n  file_path?: FilePathDeltaAnnotation.FilePath;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FilePathDeltaAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id?: string;\n  }\n}\n\nexport interface ImageFile {\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id: string;\n\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileContentBlock {\n  image_file: ImageFile;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n}\n\nexport interface ImageFileDelta {\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id?: string;\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n\n  image_file?: ImageFileDelta;\n}\n\nexport interface ImageURL {\n  /**\n   * The external URL of the image, must be a supported image types: jpeg, jpg, png,\n   * gif, webp.\n   */\n  url: string;\n\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`. Default value is `auto`\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLContentBlock {\n  image_url: ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport interface ImageURLDelta {\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The URL of the image, must be a supported image types: jpeg, jpg, png, gif,\n   * webp.\n   */\n  url?: string;\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n\n  image_url?: ImageURLDelta;\n}\n\n/**\n * Represents a message within a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Message {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * If applicable, the ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) that\n   * authored this message.\n   */\n  assistant_id: string | null;\n\n  /**\n   * A list of files attached to the message, and the tools they were added to.\n   */\n  attachments: Array<Message.Attachment> | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content: Array<MessageContent>;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was marked as incomplete.\n   */\n  incomplete_at: number | null;\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  incomplete_details: Message.IncompleteDetails | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread.message`.\n   */\n  object: 'thread.message';\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs)\n   * associated with the creation of this message. Value is `null` when messages are\n   * created manually using the create message or create thread endpoints.\n   */\n  run_id: string | null;\n\n  /**\n   * The status of the message, which can be either `in_progress`, `incomplete`, or\n   * `completed`.\n   */\n  status: 'in_progress' | 'incomplete' | 'completed';\n\n  /**\n   * The [thread](https://platform.openai.com/docs/api-reference/threads) ID that\n   * this message belongs to.\n   */\n  thread_id: string;\n}\n\nexport namespace Message {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.AssistantToolsFileSearchTypeOnly>;\n  }\n\n  export namespace Attachment {\n    export interface AssistantToolsFileSearchTypeOnly {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason the message is incomplete.\n     */\n    reason: 'content_filter' | 'max_tokens' | 'run_cancelled' | 'run_expired' | 'run_failed';\n  }\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContent =\n  | ImageFileContentBlock\n  | ImageURLContentBlock\n  | TextContentBlock\n  | RefusalContentBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentDelta =\n  | ImageFileDeltaBlock\n  | TextDeltaBlock\n  | RefusalDeltaBlock\n  | ImageURLDeltaBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentPartParam = ImageFileContentBlock | ImageURLContentBlock | TextContentBlockParam;\n\nexport interface MessageDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.message.deleted';\n}\n\n/**\n * The delta containing the fields that have changed on the Message.\n */\nexport interface MessageDelta {\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content?: Array<MessageContentDelta>;\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role?: 'user' | 'assistant';\n}\n\n/**\n * Represents a message delta i.e. any changed fields on a message during\n * streaming.\n */\nexport interface MessageDeltaEvent {\n  /**\n   * The identifier of the message, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the Message.\n   */\n  delta: MessageDelta;\n\n  /**\n   * The object type, which is always `thread.message.delta`.\n   */\n  object: 'thread.message.delta';\n}\n\n/**\n * The refusal content generated by the assistant.\n */\nexport interface RefusalContentBlock {\n  refusal: string;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * The refusal content that is part of a message.\n */\nexport interface RefusalDeltaBlock {\n  /**\n   * The index of the refusal part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n\n  refusal?: string;\n}\n\nexport interface Text {\n  annotations: Array<Annotation>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlock {\n  text: Text;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlockParam {\n  /**\n   * Text content to be sent to the model\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\nexport interface TextDelta {\n  annotations?: Array<AnnotationDelta>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value?: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n\n  text?: TextDelta;\n}\n\nexport interface MessageCreateParams {\n  /**\n   * The text contents of the message.\n   */\n  content: string | Array<MessageContentPartParam>;\n\n  /**\n   * The role of the entity that is creating the message. Allowed values include:\n   *\n   * - `user`: Indicates the message is sent by an actual user and should be used in\n   *   most cases to represent user-generated messages.\n   * - `assistant`: Indicates the message is generated by the assistant. Use this\n   *   value to insert messages from the assistant into the conversation.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * A list of files attached to the message, and the tools they should be added to.\n   */\n  attachments?: Array<MessageCreateParams.Attachment> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport namespace MessageCreateParams {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n  }\n\n  export namespace Attachment {\n    export interface FileSearch {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n}\n\nexport interface MessageUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter messages by the run ID that generated them.\n   */\n  run_id?: string;\n}\n\nMessages.MessagesPage = MessagesPage;\n\nexport declare namespace Messages {\n  export {\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type Message as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport * as Core from '../../../../core';\nimport * as StepsAPI from './steps';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\n\nexport class Steps extends APIResource {\n  /**\n   * Retrieves a run step.\n   */\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    query?: StepRetrieveParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep>;\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep>;\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    query: StepRetrieveParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep> {\n    if (isRequestOptions(query)) {\n      return this.retrieve(threadId, runId, stepId, {}, query);\n    }\n    return this._client.get(`/threads/${threadId}/runs/${runId}/steps/${stepId}`, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of run steps belonging to a run.\n   */\n  list(\n    threadId: string,\n    runId: string,\n    query?: StepListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    query: StepListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, runId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs/${runId}/steps`, RunStepsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class RunStepsPage extends CursorPage<RunStep> {}\n\n/**\n * Text output from the Code Interpreter tool call as part of a run step.\n */\nexport interface CodeInterpreterLogs {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `logs`.\n   */\n  type: 'logs';\n\n  /**\n   * The text output from the Code Interpreter tool call.\n   */\n  logs?: string;\n}\n\nexport interface CodeInterpreterOutputImage {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `image`.\n   */\n  type: 'image';\n\n  image?: CodeInterpreterOutputImage.Image;\n}\n\nexport namespace CodeInterpreterOutputImage {\n  export interface Image {\n    /**\n     * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n     * image.\n     */\n    file_id?: string;\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter: CodeInterpreterToolCall.CodeInterpreter;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n}\n\nexport namespace CodeInterpreterToolCall {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs: Array<CodeInterpreter.Logs | CodeInterpreter.Image>;\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Text output from the Code Interpreter tool call as part of a run step.\n     */\n    export interface Logs {\n      /**\n       * The text output from the Code Interpreter tool call.\n       */\n      logs: string;\n\n      /**\n       * Always `logs`.\n       */\n      type: 'logs';\n    }\n\n    export interface Image {\n      image: Image.Image;\n\n      /**\n       * Always `image`.\n       */\n      type: 'image';\n    }\n\n    export namespace Image {\n      export interface Image {\n        /**\n         * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n         * image.\n         */\n        file_id: string;\n      }\n    }\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n\n  /**\n   * The ID of the tool call.\n   */\n  id?: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter?: CodeInterpreterToolCallDelta.CodeInterpreter;\n}\n\nexport namespace CodeInterpreterToolCallDelta {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input?: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs?: Array<StepsAPI.CodeInterpreterLogs | StepsAPI.CodeInterpreterOutputImage>;\n  }\n}\n\nexport interface FileSearchToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: FileSearchToolCall.FileSearch;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n}\n\nexport namespace FileSearchToolCall {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  export interface FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n\n    /**\n     * The results of the file search.\n     */\n    results?: Array<FileSearch.Result>;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    export interface RankingOptions {\n      /**\n       * The ranker used for the file search.\n       */\n      ranker: 'default_2024_08_21';\n\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n    }\n\n    /**\n     * A result instance of the file search.\n     */\n    export interface Result {\n      /**\n       * The ID of the file that result was found in.\n       */\n      file_id: string;\n\n      /**\n       * The name of the file that result was found in.\n       */\n      file_name: string;\n\n      /**\n       * The score of the result. All values must be a floating point number between 0\n       * and 1.\n       */\n      score: number;\n\n      /**\n       * The content of the result that was found. The content is only included if\n       * requested via the include query parameter.\n       */\n      content?: Array<Result.Content>;\n    }\n\n    export namespace Result {\n      export interface Content {\n        /**\n         * The text content of the file.\n         */\n        text?: string;\n\n        /**\n         * The type of the content.\n         */\n        type?: 'text';\n      }\n    }\n  }\n}\n\nexport interface FileSearchToolCallDelta {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: unknown;\n\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n}\n\nexport interface FunctionToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function: FunctionToolCall.Function;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n}\n\nexport namespace FunctionToolCall {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output: string | null;\n  }\n}\n\nexport interface FunctionToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function?: FunctionToolCallDelta.Function;\n}\n\nexport namespace FunctionToolCallDelta {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output?: string | null;\n  }\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface MessageCreationStepDetails {\n  message_creation: MessageCreationStepDetails.MessageCreation;\n\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n}\n\nexport namespace MessageCreationStepDetails {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id: string;\n  }\n}\n\n/**\n * Represents a step in execution of a run.\n */\nexport interface RunStep {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants)\n   * associated with the run step.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step expired. A step is\n   * considered expired if the parent run is expired.\n   */\n  expired_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  last_error: RunStep.LastError | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread.run.step`.\n   */\n  object: 'thread.run.step';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that\n   * this run step is a part of.\n   */\n  run_id: string;\n\n  /**\n   * The status of the run step, which can be either `in_progress`, `cancelled`,\n   * `failed`, `completed`, or `expired`.\n   */\n  status: 'in_progress' | 'cancelled' | 'failed' | 'completed' | 'expired';\n\n  /**\n   * The details of the run step.\n   */\n  step_details: MessageCreationStepDetails | ToolCallsStepDetails;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n\n  /**\n   * The type of run step, which can be either `message_creation` or `tool_calls`.\n   */\n  type: 'message_creation' | 'tool_calls';\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  usage: RunStep.Usage | null;\n}\n\nexport namespace RunStep {\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run step.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run step.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The delta containing the fields that have changed on the run step.\n */\nexport interface RunStepDelta {\n  /**\n   * The details of the run step.\n   */\n  step_details?: RunStepDeltaMessageDelta | ToolCallDeltaObject;\n}\n\n/**\n * Represents a run step delta i.e. any changed fields on a run step during\n * streaming.\n */\nexport interface RunStepDeltaEvent {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the run step.\n   */\n  delta: RunStepDelta;\n\n  /**\n   * The object type, which is always `thread.run.step.delta`.\n   */\n  object: 'thread.run.step.delta';\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface RunStepDeltaMessageDelta {\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n\n  message_creation?: RunStepDeltaMessageDelta.MessageCreation;\n}\n\nexport namespace RunStepDeltaMessageDelta {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id?: string;\n  }\n}\n\nexport type RunStepInclude = 'step_details.tool_calls[*].file_search.results[*].content';\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCall = CodeInterpreterToolCall | FileSearchToolCall | FunctionToolCall;\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCallDelta = CodeInterpreterToolCallDelta | FileSearchToolCallDelta | FunctionToolCallDelta;\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallDeltaObject {\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls?: Array<ToolCallDelta>;\n}\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallsStepDetails {\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls: Array<ToolCall>;\n\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n}\n\nexport interface StepRetrieveParams {\n  /**\n   * A list of additional fields to include in the response. Currently the only\n   * supported value is `step_details.tool_calls[*].file_search.results[*].content`\n   * to fetch the file search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n}\n\nexport interface StepListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * A list of additional fields to include in the response. Currently the only\n   * supported value is `step_details.tool_calls[*].file_search.results[*].content`\n   * to fetch the file search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nSteps.RunStepsPage = RunStepsPage;\n\nexport declare namespace Steps {\n  export {\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport { APIPromise } from '../../../../core';\nimport * as Core from '../../../../core';\nimport { AssistantStream, RunCreateParamsBaseStream } from '../../../../lib/AssistantStream';\nimport { sleep } from '../../../../core';\nimport { RunSubmitToolOutputsParamsStream } from '../../../../lib/AssistantStream';\nimport * as RunsAPI from './runs';\nimport * as AssistantsAPI from '../../assistants';\nimport * as ChatAPI from '../../../chat/chat';\nimport * as MessagesAPI from '../messages';\nimport * as ThreadsAPI from '../threads';\nimport * as StepsAPI from './steps';\nimport {\n  CodeInterpreterLogs,\n  CodeInterpreterOutputImage,\n  CodeInterpreterToolCall,\n  CodeInterpreterToolCallDelta,\n  FileSearchToolCall,\n  FileSearchToolCallDelta,\n  FunctionToolCall,\n  FunctionToolCallDelta,\n  MessageCreationStepDetails,\n  RunStep,\n  RunStepDelta,\n  RunStepDeltaEvent,\n  RunStepDeltaMessageDelta,\n  RunStepInclude,\n  RunStepsPage,\n  StepListParams,\n  StepRetrieveParams,\n  Steps,\n  ToolCall,\n  ToolCallDelta,\n  ToolCallDeltaObject,\n  ToolCallsStepDetails,\n} from './steps';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\nimport { Stream } from '../../../../streaming';\n\nexport class Runs extends APIResource {\n  steps: StepsAPI.Steps = new StepsAPI.Steps(this._client);\n\n  /**\n   * Create a run.\n   */\n  create(\n    threadId: string,\n    params: RunCreateParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run>;\n  create(\n    threadId: string,\n    params: RunCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  create(\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  create(\n    threadId: string,\n    params: RunCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    const { include, ...body } = params;\n    return this._client.post(`/threads/${threadId}/runs`, {\n      query: { include },\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: params.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a run.\n   */\n  retrieve(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.get(`/threads/${threadId}/runs/${runId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a run.\n   */\n  update(\n    threadId: string,\n    runId: string,\n    body: RunUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of runs belonging to a thread.\n   */\n  list(\n    threadId: string,\n    query?: RunListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<RunsPage, Run>;\n  list(\n    threadId: string,\n    query: RunListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs`, RunsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancels a run that is `in_progress`.\n   */\n  cancel(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * A helper to create a run an poll for a terminal state. More information on Run\n   * lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndPoll(\n    threadId: string,\n    body: RunCreateParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.create(threadId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Create a Run stream\n   *\n   * @deprecated use `stream` instead\n   */\n  createAndStream(\n    threadId: string,\n    body: RunCreateParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * A helper to poll a run status until it reaches a terminal state. More\n   * information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async poll(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: run, response } = await this.retrieve(threadId, runId, {\n        ...options,\n        headers: { ...options?.headers, ...headers },\n      }).withResponse();\n\n      switch (run.status) {\n        //If we are in any sort of intermediate state we poll\n        case 'queued':\n        case 'in_progress':\n        case 'cancelling':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        //We return the run in any terminal state.\n        case 'requires_action':\n        case 'incomplete':\n        case 'cancelled':\n        case 'completed':\n        case 'failed':\n        case 'expired':\n          return run;\n      }\n    }\n  }\n\n  /**\n   * Create a Run stream\n   */\n  stream(threadId: string, body: RunCreateParamsBaseStream, options?: Core.RequestOptions): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * When a run has the `status: \"requires_action\"` and `required_action.type` is\n   * `submit_tool_outputs`, this endpoint can be used to submit the outputs from the\n   * tool calls once they're all completed. All outputs must be submitted in a single\n   * request.\n   */\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/submit_tool_outputs`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to submit a tool output to a run and poll for a terminal run state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async submitToolOutputsAndPoll(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.submitToolOutputs(threadId, runId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Submit the tool outputs from a previous run and stream the run to a terminal\n   * state. More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  submitToolOutputsStream(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createToolAssistantStream(\n      threadId,\n      runId,\n      this._client.beta.threads.runs,\n      body,\n      options,\n    );\n  }\n}\n\nexport class RunsPage extends CursorPage<Run> {}\n\n/**\n * Tool call objects\n */\nexport interface RequiredActionFunctionToolCall {\n  /**\n   * The ID of the tool call. This ID must be referenced when you submit the tool\n   * outputs in using the\n   * [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n   * endpoint.\n   */\n  id: string;\n\n  /**\n   * The function definition.\n   */\n  function: RequiredActionFunctionToolCall.Function;\n\n  /**\n   * The type of tool call the output is required for. For now, this is always\n   * `function`.\n   */\n  type: 'function';\n}\n\nexport namespace RequiredActionFunctionToolCall {\n  /**\n   * The function definition.\n   */\n  export interface Function {\n    /**\n     * The arguments that the model expects you to pass to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents an execution run on a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Run {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * execution of this run.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run will expire.\n   */\n  expires_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  incomplete_details: Run.IncompleteDetails | null;\n\n  /**\n   * The instructions that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  instructions: string;\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  last_error: Run.LastError | null;\n\n  /**\n   * The maximum number of completion tokens specified to have been used over the\n   * course of the run.\n   */\n  max_completion_tokens: number | null;\n\n  /**\n   * The maximum number of prompt tokens specified to have been used over the course\n   * of the run.\n   */\n  max_prompt_tokens: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The model that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `thread.run`.\n   */\n  object: 'thread.run';\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  required_action: Run.RequiredAction | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was started.\n   */\n  started_at: number | null;\n\n  /**\n   * The status of the run, which can be either `queued`, `in_progress`,\n   * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n   * `incomplete`, or `expired`.\n   */\n  status: RunStatus;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was executed on as a part of this run.\n   */\n  thread_id: string;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * The list of tools that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  tools: Array<AssistantsAPI.AssistantTool>;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy: Run.TruncationStrategy | null;\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  usage: Run.Usage | null;\n\n  /**\n   * The sampling temperature used for this run. If not set, defaults to 1.\n   */\n  temperature?: number | null;\n\n  /**\n   * The nucleus sampling value used for this run. If not set, defaults to 1.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Run {\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the run is incomplete. This will point to which specific token\n     * limit was reached over the course of the run.\n     */\n    reason?: 'max_completion_tokens' | 'max_prompt_tokens';\n  }\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded' | 'invalid_prompt';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  export interface RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    submit_tool_outputs: RequiredAction.SubmitToolOutputs;\n\n    /**\n     * For now, this is always `submit_tool_outputs`.\n     */\n    type: 'submit_tool_outputs';\n  }\n\n  export namespace RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    export interface SubmitToolOutputs {\n      /**\n       * A list of the relevant tool calls.\n       */\n      tool_calls: Array<RunsAPI.RequiredActionFunctionToolCall>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The status of the run, which can be either `queued`, `in_progress`,\n * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n * `incomplete`, or `expired`.\n */\nexport type RunStatus =\n  | 'queued'\n  | 'in_progress'\n  | 'requires_action'\n  | 'cancelling'\n  | 'cancelled'\n  | 'failed'\n  | 'completed'\n  | 'incomplete'\n  | 'expired';\n\nexport type RunCreateParams = RunCreateParamsNonStreaming | RunCreateParamsStreaming;\n\nexport interface RunCreateParamsBase {\n  /**\n   * Body param: The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<StepsAPI.RunStepInclude>;\n\n  /**\n   * Body param: Appends additional instructions at the end of the instructions for\n   * the run. This is useful for modifying the behavior on a per-run basis without\n   * overriding other instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Body param: Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateParams.AdditionalMessage> | null;\n\n  /**\n   * Body param: Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * Body param: The maximum number of completion tokens that may be used over the\n   * course of the run. The run will make a best effort to use only the number of\n   * completion tokens specified, across multiple turns of the run. If the run\n   * exceeds the number of completion tokens specified, the run will end with status\n   * `incomplete`. See `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * Body param: The maximum number of prompt tokens that may be used over the course\n   * of the run. The run will make a best effort to use only the number of prompt\n   * tokens specified, across multiple turns of the run. If the run exceeds the\n   * number of prompt tokens specified, the run will end with status `incomplete`.\n   * See `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format. Keys can be a maximum of 64 characters long and values can be\n   * a maxium of 512 characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * Body param: The ID of the\n   * [Model](https://platform.openai.com/docs/api-reference/models) to be used to\n   * execute this run. If a value is provided here, it will override the model\n   * associated with the assistant. If not, the model associated with the assistant\n   * will be used.\n   */\n  model?: (string & {}) | ChatAPI.ChatModel | null;\n\n  /**\n   * Body param: Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Body param: Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Body param: What sampling temperature to use, between 0 and 2. Higher values\n   * like 0.8 will make the output more random, while lower values like 0.2 will make\n   * it more focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Body param: Controls which (if any) tool is called by the model. `none` means\n   * the model will not call any tools and instead generates a message. `auto` is the\n   * default value and means the model can pick between generating a message or\n   * calling one or more tools. `required` means the model must call one or more\n   * tools before responding to the user. Specifying a particular tool like\n   * `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Body param: Override the tools the assistant can use for this run. This is\n   * useful for modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * Body param: An alternative to sampling with temperature, called nucleus\n   * sampling, where the model considers the results of the tokens with top_p\n   * probability mass. So 0.1 means only the tokens comprising the top 10%\n   * probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Body param: Controls for how a thread will be truncated prior to the run. Use\n   * this to control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export type RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n}\n\nexport interface RunCreateParamsNonStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunCreateParamsStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream: true;\n}\n\nexport interface RunUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface RunCreateAndPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndPollParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndPollParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndPollParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunCreateAndStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport type RunSubmitToolOutputsParams =\n  | RunSubmitToolOutputsParamsNonStreaming\n  | RunSubmitToolOutputsParamsStreaming;\n\nexport interface RunSubmitToolOutputsParamsBase {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsParams.ToolOutput>;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n}\n\nexport namespace RunSubmitToolOutputsParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n\n  export type RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export type RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n}\n\nexport interface RunSubmitToolOutputsParamsNonStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunSubmitToolOutputsParamsStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface RunSubmitToolOutputsAndPollParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsAndPollParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsAndPollParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nexport interface RunSubmitToolOutputsStreamParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsStreamParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsStreamParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nRuns.RunsPage = RunsPage;\nRuns.Steps = Steps;\nRuns.RunStepsPage = RunStepsPage;\n\nexport declare namespace Runs {\n  export {\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Steps as Steps,\n    type CodeInterpreterLogs as CodeInterpreterLogs,\n    type CodeInterpreterOutputImage as CodeInterpreterOutputImage,\n    type CodeInterpreterToolCall as CodeInterpreterToolCall,\n    type CodeInterpreterToolCallDelta as CodeInterpreterToolCallDelta,\n    type FileSearchToolCall as FileSearchToolCall,\n    type FileSearchToolCallDelta as FileSearchToolCallDelta,\n    type FunctionToolCall as FunctionToolCall,\n    type FunctionToolCallDelta as FunctionToolCallDelta,\n    type MessageCreationStepDetails as MessageCreationStepDetails,\n    type RunStep as RunStep,\n    type RunStepDelta as RunStepDelta,\n    type RunStepDeltaEvent as RunStepDeltaEvent,\n    type RunStepDeltaMessageDelta as RunStepDeltaMessageDelta,\n    type RunStepInclude as RunStepInclude,\n    type ToolCall as ToolCall,\n    type ToolCallDelta as ToolCallDelta,\n    type ToolCallDeltaObject as ToolCallDeltaObject,\n    type ToolCallsStepDetails as ToolCallsStepDetails,\n    RunStepsPage as RunStepsPage,\n    type StepRetrieveParams as StepRetrieveParams,\n    type StepListParams as StepListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { AssistantStream, ThreadCreateAndRunParamsBaseStream } from '../../../lib/AssistantStream';\nimport { APIPromise } from '../../../core';\nimport * as Core from '../../../core';\nimport * as ThreadsAPI from './threads';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport * as ChatAPI from '../../chat/chat';\nimport * as MessagesAPI from './messages';\nimport {\n  Annotation,\n  AnnotationDelta,\n  FileCitationAnnotation,\n  FileCitationDeltaAnnotation,\n  FilePathAnnotation,\n  FilePathDeltaAnnotation,\n  ImageFile,\n  ImageFileContentBlock,\n  ImageFileDelta,\n  ImageFileDeltaBlock,\n  ImageURL,\n  ImageURLContentBlock,\n  ImageURLDelta,\n  ImageURLDeltaBlock,\n  Message as MessagesAPIMessage,\n  MessageContent,\n  MessageContentDelta,\n  MessageContentPartParam,\n  MessageCreateParams,\n  MessageDeleted,\n  MessageDelta,\n  MessageDeltaEvent,\n  MessageListParams,\n  MessageUpdateParams,\n  Messages,\n  MessagesPage,\n  RefusalContentBlock,\n  RefusalDeltaBlock,\n  Text,\n  TextContentBlock,\n  TextContentBlockParam,\n  TextDelta,\n  TextDeltaBlock,\n} from './messages';\nimport * as VectorStoresAPI from '../vector-stores/vector-stores';\nimport * as RunsAPI from './runs/runs';\nimport {\n  RequiredActionFunctionToolCall,\n  Run,\n  RunCreateAndPollParams,\n  RunCreateAndStreamParams,\n  RunCreateParams,\n  RunCreateParamsNonStreaming,\n  RunCreateParamsStreaming,\n  RunListParams,\n  RunStatus,\n  RunStreamParams,\n  RunSubmitToolOutputsAndPollParams,\n  RunSubmitToolOutputsParams,\n  RunSubmitToolOutputsParamsNonStreaming,\n  RunSubmitToolOutputsParamsStreaming,\n  RunSubmitToolOutputsStreamParams,\n  RunUpdateParams,\n  Runs,\n  RunsPage,\n} from './runs/runs';\nimport { Stream } from '../../../streaming';\n\nexport class Threads extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * Create a thread.\n   */\n  create(body?: ThreadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(\n    body: ThreadCreateParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Thread> {\n    if (isRequestOptions(body)) {\n      return this.create({}, body);\n    }\n    return this._client.post('/threads', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a thread.\n   */\n  retrieve(threadId: string, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.get(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a thread.\n   */\n  update(threadId: string, body: ThreadUpdateParams, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.post(`/threads/${threadId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a thread.\n   */\n  del(threadId: string, options?: Core.RequestOptions): Core.APIPromise<ThreadDeleted> {\n    return this._client.delete(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a thread and run it in one request.\n   */\n  createAndRun(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post('/threads/runs', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to create a thread, start a run and then poll for a terminal state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndRunPoll(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Threads.Run> {\n    const run = await this.createAndRun(body, options);\n    return await this.runs.poll(run.thread_id, run.id, options);\n  }\n\n  /**\n   * Create a thread and stream the run back\n   */\n  createAndRunStream(\n    body: ThreadCreateAndRunParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n  }\n}\n\n/**\n * Specifies the format that the model must output. Compatible with\n * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n *\n * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n * Outputs which ensures the model will match your supplied JSON schema. Learn more\n * in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n * message the model generates is valid JSON.\n *\n * **Important:** when using JSON mode, you **must** also instruct the model to\n * produce JSON yourself via a system or user message. Without this, the model may\n * generate an unending stream of whitespace until the generation reaches the token\n * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n * the message content may be partially cut off if `finish_reason=\"length\"`, which\n * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n * max context length.\n */\nexport type AssistantResponseFormatOption =\n  | 'auto'\n  | Shared.ResponseFormatText\n  | Shared.ResponseFormatJSONObject\n  | Shared.ResponseFormatJSONSchema;\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * tool.\n */\nexport interface AssistantToolChoice {\n  /**\n   * The type of the tool. If type is `function`, the function name must be set\n   */\n  type: 'function' | 'code_interpreter' | 'file_search';\n\n  function?: AssistantToolChoiceFunction;\n}\n\nexport interface AssistantToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tools and instead generates a message. `auto` is the default value\n * and means the model can pick between generating a message or calling one or more\n * tools. `required` means the model must call one or more tools before responding\n * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n */\nexport type AssistantToolChoiceOption = 'none' | 'auto' | 'required' | AssistantToolChoice;\n\n/**\n * Represents a thread that contains\n * [messages](https://platform.openai.com/docs/api-reference/messages).\n */\nexport interface Thread {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread`.\n   */\n  object: 'thread';\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources: Thread.ToolResources | null;\n}\n\nexport namespace Thread {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface ThreadDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.deleted';\n}\n\nexport interface ThreadCreateParams {\n  /**\n   * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n   * start the thread with.\n   */\n  messages?: Array<ThreadCreateParams.Message>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadCreateParams.ToolResources | null;\n}\n\nexport namespace ThreadCreateParams {\n  export interface Message {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<Message.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace Message {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n       * store attached to the thread.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy. Only applicable if `file_ids` is non-empty.\n         */\n        chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to a vector store. This can be\n         * useful for storing additional information about the vector store in a structured\n         * format. Keys can be a maximum of 64 characters long and values can be a maxium\n         * of 512 characters long.\n         */\n        metadata?: unknown;\n      }\n    }\n  }\n}\n\nexport interface ThreadUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadUpdateParams.ToolResources | null;\n}\n\nexport namespace ThreadUpdateParams {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport type ThreadCreateAndRunParams =\n  | ThreadCreateAndRunParamsNonStreaming\n  | ThreadCreateAndRunParamsStreaming;\n\nexport interface ThreadCreateAndRunParamsBase {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?: (string & {}) | ChatAPI.ChatModel | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models#gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n      }\n\n      export namespace Attachment {\n        export interface FileSearch {\n          /**\n           * The type of tool being defined: `file_search`\n           */\n          type: 'file_search';\n        }\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n           * strategy. Only applicable if `file_ids` is non-empty.\n           */\n          chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export type ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n}\n\nexport interface ThreadCreateAndRunParamsNonStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface ThreadCreateAndRunParamsStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface ThreadCreateAndRunPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunPollParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunPollParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunPollParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunPollParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface ThreadCreateAndRunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunStreamParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunStreamParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunStreamParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nThreads.Runs = Runs;\nThreads.RunsPage = RunsPage;\nThreads.Messages = Messages;\nThreads.MessagesPage = MessagesPage;\n\nexport declare namespace Threads {\n  export {\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n\n  export {\n    Runs as Runs,\n    type RequiredActionFunctionToolCall as RequiredActionFunctionToolCall,\n    type Run as Run,\n    type RunStatus as RunStatus,\n    RunsPage as RunsPage,\n    type RunCreateParams as RunCreateParams,\n    type RunCreateParamsNonStreaming as RunCreateParamsNonStreaming,\n    type RunCreateParamsStreaming as RunCreateParamsStreaming,\n    type RunUpdateParams as RunUpdateParams,\n    type RunListParams as RunListParams,\n    type RunCreateAndPollParams,\n    type RunCreateAndStreamParams,\n    type RunStreamParams,\n    type RunSubmitToolOutputsParams as RunSubmitToolOutputsParams,\n    type RunSubmitToolOutputsParamsNonStreaming as RunSubmitToolOutputsParamsNonStreaming,\n    type RunSubmitToolOutputsParamsStreaming as RunSubmitToolOutputsParamsStreaming,\n    type RunSubmitToolOutputsAndPollParams,\n    type RunSubmitToolOutputsStreamParams,\n  };\n\n  export {\n    Messages as Messages,\n    type Annotation as Annotation,\n    type AnnotationDelta as AnnotationDelta,\n    type FileCitationAnnotation as FileCitationAnnotation,\n    type FileCitationDeltaAnnotation as FileCitationDeltaAnnotation,\n    type FilePathAnnotation as FilePathAnnotation,\n    type FilePathDeltaAnnotation as FilePathDeltaAnnotation,\n    type ImageFile as ImageFile,\n    type ImageFileContentBlock as ImageFileContentBlock,\n    type ImageFileDelta as ImageFileDelta,\n    type ImageFileDeltaBlock as ImageFileDeltaBlock,\n    type ImageURL as ImageURL,\n    type ImageURLContentBlock as ImageURLContentBlock,\n    type ImageURLDelta as ImageURLDelta,\n    type ImageURLDeltaBlock as ImageURLDeltaBlock,\n    type MessagesAPIMessage as Message,\n    type MessageContent as MessageContent,\n    type MessageContentDelta as MessageContentDelta,\n    type MessageContentPartParam as MessageContentPartParam,\n    type MessageDeleted as MessageDeleted,\n    type MessageDelta as MessageDelta,\n    type MessageDeltaEvent as MessageDeltaEvent,\n    type RefusalContentBlock as RefusalContentBlock,\n    type RefusalDeltaBlock as RefusalDeltaBlock,\n    type Text as Text,\n    type TextContentBlock as TextContentBlock,\n    type TextContentBlockParam as TextContentBlockParam,\n    type TextDelta as TextDelta,\n    type TextDeltaBlock as TextDeltaBlock,\n    MessagesPage as MessagesPage,\n    type MessageCreateParams as MessageCreateParams,\n    type MessageUpdateParams as MessageUpdateParams,\n    type MessageListParams as MessageListParams,\n  };\n}\n","/**\n * Like `Promise.allSettled()` but throws an error if any promises are rejected.\n */\nexport const allSettledWithThrow = async <R>(promises: Promise<R>[]): Promise<R[]> => {\n  const results = await Promise.allSettled(promises);\n  const rejected = results.filter((result): result is PromiseRejectedResult => result.status === 'rejected');\n  if (rejected.length) {\n    for (const result of rejected) {\n      console.error(result.reason);\n    }\n\n    throw new Error(`${rejected.length} promise(s) failed - see the above errors`);\n  }\n\n  // Note: TS was complaining about using `.filter().map()` here for some reason\n  const values: R[] = [];\n  for (const result of results) {\n    if (result.status === 'fulfilled') {\n      values.push(result.value);\n    }\n  }\n  return values;\n};\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { sleep, Uploadable, isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as VectorStoresAPI from './vector-stores';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Files extends APIResource {\n  /**\n   * Create a vector store file by attaching a\n   * [File](https://platform.openai.com/docs/api-reference/files) to a\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n   */\n  create(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/files`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file.\n   */\n  retrieve(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector store files.\n   */\n  list(\n    vectorStoreId: string,\n    query?: FileListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.list(vectorStoreId, {}, query);\n    }\n    return this._client.getAPIList(`/vector_stores/${vectorStoreId}/files`, VectorStoreFilesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store file. This will remove the file from the vector store but\n   * the file itself will not be deleted. To delete the file, use the\n   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n   * endpoint.\n   */\n  del(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Attach a file to the given vector store and wait for it to be processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const file = await this.create(vectorStoreId, body, options);\n    return await this.poll(vectorStoreId, file.id, options);\n  }\n\n  /**\n   * Wait for the vector store file to finish processing.\n   *\n   * Note: this will return even if the file failed to process, you need to check\n   * file.last_error and file.status to handle these cases\n   */\n  async poll(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n    while (true) {\n      const fileResponse = await this.retrieve(vectorStoreId, fileId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      const file = fileResponse.data;\n\n      switch (file.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'completed':\n          return file;\n      }\n    }\n  }\n\n  /**\n   * Upload a file to the `files` API and then attach it to the given vector store.\n   *\n   * Note the file will be asynchronously processed (you can use the alternative\n   * polling helper method to wait for processing to complete).\n   */\n  async upload(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions,\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n  }\n\n  /**\n   * Add a file to a vector store and poll until processing is complete.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this.upload(vectorStoreId, file, options);\n    return await this.poll(vectorStoreId, fileInfo.id, options);\n  }\n}\n\nexport class VectorStoreFilesPage extends CursorPage<VectorStoreFile> {}\n\n/**\n * A list of files attached to a vector store.\n */\nexport interface VectorStoreFile {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store file was created.\n   */\n  created_at: number;\n\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  last_error: VectorStoreFile.LastError | null;\n\n  /**\n   * The object type, which is always `vector_store.file`.\n   */\n  object: 'vector_store.file';\n\n  /**\n   * The status of the vector store file, which can be either `in_progress`,\n   * `completed`, `cancelled`, or `failed`. The status `completed` indicates that the\n   * vector store file is ready for use.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The total vector store usage in bytes. Note that this may be different from the\n   * original file size.\n   */\n  usage_bytes: number;\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n\n  /**\n   * The strategy used to chunk the file.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategy;\n}\n\nexport namespace VectorStoreFile {\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'unsupported_file' | 'invalid_file';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n}\n\nexport interface VectorStoreFileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.file.deleted';\n}\n\nexport interface FileCreateParams {\n  /**\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n   * vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_id: string;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nFiles.VectorStoreFilesPage = VectorStoreFilesPage;\n\nexport declare namespace Files {\n  export {\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    VectorStoreFilesPage as VectorStoreFilesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { sleep } from '../../../core';\nimport { Uploadable } from '../../../core';\nimport { allSettledWithThrow } from '../../../lib/Util';\nimport * as Core from '../../../core';\nimport * as FilesAPI from './files';\nimport { VectorStoreFilesPage } from './files';\nimport * as VectorStoresAPI from './vector-stores';\nimport { type CursorPageParams } from '../../../pagination';\n\nexport class FileBatches extends APIResource {\n  /**\n   * Create a vector store file batch.\n   */\n  create(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file batch.\n   */\n  retrieve(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/file_batches/${batchId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancel a vector store file batch. This attempts to cancel the processing of\n   * files in this batch as soon as possible.\n   */\n  cancel(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches/${batchId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a vector store batch and poll until all files have been processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const batch = await this.create(vectorStoreId, body);\n    return await this.poll(vectorStoreId, batch.id, options);\n  }\n\n  /**\n   * Returns a list of vector store files in a batch.\n   */\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query?: FileBatchListFilesParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query: FileBatchListFilesParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.listFiles(vectorStoreId, batchId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/vector_stores/${vectorStoreId}/file_batches/${batchId}/files`,\n      VectorStoreFilesPage,\n      { query, ...options, headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers } },\n    );\n  }\n\n  /**\n   * Wait for the given file batch to be processed.\n   *\n   * Note: this will return even if one of the files failed to process, you need to\n   * check batch.file_counts.failed_count to handle this case.\n   */\n  async poll(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: batch, response } = await this.retrieve(vectorStoreId, batchId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      switch (batch.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'cancelled':\n        case 'completed':\n          return batch;\n      }\n    }\n  }\n\n  /**\n   * Uploads the given files concurrently and then creates a vector store file batch.\n   *\n   * The concurrency limit is configurable using the `maxConcurrency` parameter.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    { files, fileIds = [] }: { files: Uploadable[]; fileIds?: string[] },\n    options?: Core.RequestOptions & { pollIntervalMs?: number; maxConcurrency?: number },\n  ): Promise<VectorStoreFileBatch> {\n    if (files == null || files.length == 0) {\n      throw new Error(\n        `No \\`files\\` provided to process. If you've already uploaded files you should use \\`.createAndPoll()\\` instead`,\n      );\n    }\n\n    const configuredConcurrency = options?.maxConcurrency ?? 5;\n\n    // We cap the number of workers at the number of files (so we don't start any unnecessary workers)\n    const concurrencyLimit = Math.min(configuredConcurrency, files.length);\n\n    const client = this._client;\n    const fileIterator = files.values();\n    const allFileIds: string[] = [...fileIds];\n\n    // This code is based on this design. The libraries don't accommodate our environment limits.\n    // https://stackoverflow.com/questions/40639432/what-is-the-best-way-to-limit-concurrency-when-using-es6s-promise-all\n    async function processFiles(iterator: IterableIterator<Uploadable>) {\n      for (let item of iterator) {\n        const fileObj = await client.files.create({ file: item, purpose: 'assistants' }, options);\n        allFileIds.push(fileObj.id);\n      }\n    }\n\n    // Start workers to process results\n    const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);\n\n    // Wait for all processing to complete.\n    await allSettledWithThrow(workers);\n\n    return await this.createAndPoll(vectorStoreId, {\n      file_ids: allFileIds,\n    });\n  }\n}\n\n/**\n * A batch of files attached to a vector store.\n */\nexport interface VectorStoreFileBatch {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store files batch was\n   * created.\n   */\n  created_at: number;\n\n  file_counts: VectorStoreFileBatch.FileCounts;\n\n  /**\n   * The object type, which is always `vector_store.file_batch`.\n   */\n  object: 'vector_store.files_batch';\n\n  /**\n   * The status of the vector store files batch, which can be either `in_progress`,\n   * `completed`, `cancelled` or `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n}\n\nexport namespace VectorStoreFileBatch {\n  export interface FileCounts {\n    /**\n     * The number of files that where cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n}\n\nexport interface FileBatchCreateParams {\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids: Array<string>;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileBatchListFilesParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport declare namespace FileBatches {\n  export {\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n\nexport { VectorStoreFilesPage };\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as FileBatchesAPI from './file-batches';\nimport {\n  FileBatchCreateParams,\n  FileBatchListFilesParams,\n  FileBatches,\n  VectorStoreFileBatch,\n} from './file-batches';\nimport * as FilesAPI from './files';\nimport {\n  FileCreateParams,\n  FileListParams,\n  Files,\n  VectorStoreFile,\n  VectorStoreFileDeleted,\n  VectorStoreFilesPage,\n} from './files';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class VectorStores extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n  fileBatches: FileBatchesAPI.FileBatches = new FileBatchesAPI.FileBatches(this._client);\n\n  /**\n   * Create a vector store.\n   */\n  create(body: VectorStoreCreateParams, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.post('/vector_stores', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store.\n   */\n  retrieve(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.get(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a vector store.\n   */\n  update(\n    vectorStoreId: string,\n    body: VectorStoreUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStore> {\n    return this._client.post(`/vector_stores/${vectorStoreId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector stores.\n   */\n  list(\n    query?: VectorStoreListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(options?: Core.RequestOptions): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(\n    query: VectorStoreListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/vector_stores', VectorStoresPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store.\n   */\n  del(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStoreDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class VectorStoresPage extends CursorPage<VectorStore> {}\n\n/**\n * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n * `800` and `chunk_overlap_tokens` of `400`.\n */\nexport interface AutoFileChunkingStrategyParam {\n  /**\n   * Always `auto`.\n   */\n  type: 'auto';\n}\n\n/**\n * The strategy used to chunk the file.\n */\nexport type FileChunkingStrategy = StaticFileChunkingStrategyObject | OtherFileChunkingStrategyObject;\n\n/**\n * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n * strategy. Only applicable if `file_ids` is non-empty.\n */\nexport type FileChunkingStrategyParam = AutoFileChunkingStrategyParam | StaticFileChunkingStrategyParam;\n\n/**\n * This is returned when the chunking strategy is unknown. Typically, this is\n * because the file was indexed before the `chunking_strategy` concept was\n * introduced in the API.\n */\nexport interface OtherFileChunkingStrategyObject {\n  /**\n   * Always `other`.\n   */\n  type: 'other';\n}\n\nexport interface StaticFileChunkingStrategy {\n  /**\n   * The number of tokens that overlap between chunks. The default value is `400`.\n   *\n   * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n   */\n  chunk_overlap_tokens: number;\n\n  /**\n   * The maximum number of tokens in each chunk. The default value is `800`. The\n   * minimum value is `100` and the maximum value is `4096`.\n   */\n  max_chunk_size_tokens: number;\n}\n\nexport interface StaticFileChunkingStrategyObject {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\nexport interface StaticFileChunkingStrategyParam {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * A vector store is a collection of processed files can be used by the\n * `file_search` tool.\n */\nexport interface VectorStore {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was created.\n   */\n  created_at: number;\n\n  file_counts: VectorStore.FileCounts;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was last active.\n   */\n  last_active_at: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `vector_store`.\n   */\n  object: 'vector_store';\n\n  /**\n   * The status of the vector store, which can be either `expired`, `in_progress`, or\n   * `completed`. A status of `completed` indicates that the vector store is ready\n   * for use.\n   */\n  status: 'expired' | 'in_progress' | 'completed';\n\n  /**\n   * The total number of bytes used by the files in the vector store.\n   */\n  usage_bytes: number;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStore.ExpiresAfter;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store will expire.\n   */\n  expires_at?: number | null;\n}\n\nexport namespace VectorStore {\n  export interface FileCounts {\n    /**\n     * The number of files that were cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been successfully processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.deleted';\n}\n\nexport interface VectorStoreCreateParams {\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: FileChunkingStrategyParam;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreCreateParams.ExpiresAfter;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string;\n}\n\nexport namespace VectorStoreCreateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreUpdateParams.ExpiresAfter | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string | null;\n}\n\nexport namespace VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * starting with obj_foo, your subsequent call can include before=obj_foo in order\n   * to fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nVectorStores.VectorStoresPage = VectorStoresPage;\nVectorStores.Files = Files;\nVectorStores.VectorStoreFilesPage = VectorStoreFilesPage;\nVectorStores.FileBatches = FileBatches;\n\nexport declare namespace VectorStores {\n  export {\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyParam as StaticFileChunkingStrategyParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    VectorStoresPage as VectorStoresPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n  };\n\n  export {\n    Files as Files,\n    type VectorStoreFile as VectorStoreFile,\n    type VectorStoreFileDeleted as VectorStoreFileDeleted,\n    VectorStoreFilesPage as VectorStoreFilesPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n\n  export {\n    FileBatches as FileBatches,\n    type VectorStoreFileBatch as VectorStoreFileBatch,\n    type FileBatchCreateParams as FileBatchCreateParams,\n    type FileBatchListFilesParams as FileBatchListFilesParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as AssistantsAPI from './assistants';\nimport * as ChatAPI from './chat/chat';\nimport {\n  Assistant,\n  AssistantCreateParams,\n  AssistantDeleted,\n  AssistantListParams,\n  AssistantStreamEvent,\n  AssistantTool,\n  AssistantUpdateParams,\n  Assistants,\n  AssistantsPage,\n  CodeInterpreterTool,\n  FileSearchTool,\n  FunctionTool,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n  ThreadStreamEvent,\n} from './assistants';\nimport * as ThreadsAPI from './threads/threads';\nimport {\n  AssistantResponseFormatOption,\n  AssistantToolChoice,\n  AssistantToolChoiceFunction,\n  AssistantToolChoiceOption,\n  Thread,\n  ThreadCreateAndRunParams,\n  ThreadCreateAndRunParamsNonStreaming,\n  ThreadCreateAndRunParamsStreaming,\n  ThreadCreateAndRunPollParams,\n  ThreadCreateAndRunStreamParams,\n  ThreadCreateParams,\n  ThreadDeleted,\n  ThreadUpdateParams,\n  Threads,\n} from './threads/threads';\nimport * as VectorStoresAPI from './vector-stores/vector-stores';\nimport {\n  AutoFileChunkingStrategyParam,\n  FileChunkingStrategy,\n  FileChunkingStrategyParam,\n  OtherFileChunkingStrategyObject,\n  StaticFileChunkingStrategy,\n  StaticFileChunkingStrategyObject,\n  StaticFileChunkingStrategyParam,\n  VectorStore,\n  VectorStoreCreateParams,\n  VectorStoreDeleted,\n  VectorStoreListParams,\n  VectorStoreUpdateParams,\n  VectorStores,\n  VectorStoresPage,\n} from './vector-stores/vector-stores';\nimport { Chat } from './chat/chat';\n\nexport class Beta extends APIResource {\n  vectorStores: VectorStoresAPI.VectorStores = new VectorStoresAPI.VectorStores(this._client);\n  chat: ChatAPI.Chat = new ChatAPI.Chat(this._client);\n  assistants: AssistantsAPI.Assistants = new AssistantsAPI.Assistants(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\nBeta.VectorStores = VectorStores;\nBeta.VectorStoresPage = VectorStoresPage;\nBeta.Assistants = Assistants;\nBeta.AssistantsPage = AssistantsPage;\nBeta.Threads = Threads;\n\nexport declare namespace Beta {\n  export {\n    VectorStores as VectorStores,\n    type AutoFileChunkingStrategyParam as AutoFileChunkingStrategyParam,\n    type FileChunkingStrategy as FileChunkingStrategy,\n    type FileChunkingStrategyParam as FileChunkingStrategyParam,\n    type OtherFileChunkingStrategyObject as OtherFileChunkingStrategyObject,\n    type StaticFileChunkingStrategy as StaticFileChunkingStrategy,\n    type StaticFileChunkingStrategyObject as StaticFileChunkingStrategyObject,\n    type StaticFileChunkingStrategyParam as StaticFileChunkingStrategyParam,\n    type VectorStore as VectorStore,\n    type VectorStoreDeleted as VectorStoreDeleted,\n    VectorStoresPage as VectorStoresPage,\n    type VectorStoreCreateParams as VectorStoreCreateParams,\n    type VectorStoreUpdateParams as VectorStoreUpdateParams,\n    type VectorStoreListParams as VectorStoreListParams,\n  };\n\n  export { Chat };\n\n  export {\n    Assistants as Assistants,\n    type Assistant as Assistant,\n    type AssistantDeleted as AssistantDeleted,\n    type AssistantStreamEvent as AssistantStreamEvent,\n    type AssistantTool as AssistantTool,\n    type CodeInterpreterTool as CodeInterpreterTool,\n    type FileSearchTool as FileSearchTool,\n    type FunctionTool as FunctionTool,\n    type MessageStreamEvent as MessageStreamEvent,\n    type RunStepStreamEvent as RunStepStreamEvent,\n    type RunStreamEvent as RunStreamEvent,\n    type ThreadStreamEvent as ThreadStreamEvent,\n    AssistantsPage as AssistantsPage,\n    type AssistantCreateParams as AssistantCreateParams,\n    type AssistantUpdateParams as AssistantUpdateParams,\n    type AssistantListParams as AssistantListParams,\n  };\n\n  export {\n    Threads as Threads,\n    type AssistantResponseFormatOption as AssistantResponseFormatOption,\n    type AssistantToolChoice as AssistantToolChoice,\n    type AssistantToolChoiceFunction as AssistantToolChoiceFunction,\n    type AssistantToolChoiceOption as AssistantToolChoiceOption,\n    type Thread as Thread,\n    type ThreadDeleted as ThreadDeleted,\n    type ThreadCreateParams as ThreadCreateParams,\n    type ThreadUpdateParams as ThreadUpdateParams,\n    type ThreadCreateAndRunParams as ThreadCreateAndRunParams,\n    type ThreadCreateAndRunParamsNonStreaming as ThreadCreateAndRunParamsNonStreaming,\n    type ThreadCreateAndRunParamsStreaming as ThreadCreateAndRunParamsStreaming,\n    type ThreadCreateAndRunPollParams,\n    type ThreadCreateAndRunStreamParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { APIPromise } from '../core';\nimport * as Core from '../core';\nimport * as CompletionsAPI from './completions';\nimport * as ChatCompletionsAPI from './chat/completions';\nimport { Stream } from '../streaming';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a completion for the provided prompt and parameters.\n   */\n  create(body: CompletionCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Completion>;\n  create(\n    body: CompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion>>;\n  create(\n    body: CompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion> | Completion>;\n  create(\n    body: CompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\n    return this._client.post('/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<Completion>\n      | APIPromise<Stream<Completion>>;\n  }\n}\n\n/**\n * Represents a completion response from the API. Note: both the streamed and\n * non-streamed response objects share the same shape (unlike the chat endpoint).\n */\nexport interface Completion {\n  /**\n   * A unique identifier for the completion.\n   */\n  id: string;\n\n  /**\n   * The list of completion choices the model generated for the input prompt.\n   */\n  choices: Array<CompletionChoice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"text_completion\"\n   */\n  object: 'text_completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionUsage;\n}\n\nexport interface CompletionChoice {\n  /**\n   * The reason the model stopped generating tokens. This will be `stop` if the model\n   * hit a natural stop point or a provided stop sequence, `length` if the maximum\n   * number of tokens specified in the request was reached, or `content_filter` if\n   * content was omitted due to a flag from our content filters.\n   */\n  finish_reason: 'stop' | 'length' | 'content_filter';\n\n  index: number;\n\n  logprobs: CompletionChoice.Logprobs | null;\n\n  text: string;\n}\n\nexport namespace CompletionChoice {\n  export interface Logprobs {\n    text_offset?: Array<number>;\n\n    token_logprobs?: Array<number>;\n\n    tokens?: Array<string>;\n\n    top_logprobs?: Array<Record<string, number>>;\n  }\n}\n\n/**\n * Usage statistics for the completion request.\n */\nexport interface CompletionUsage {\n  /**\n   * Number of tokens in the generated completion.\n   */\n  completion_tokens: number;\n\n  /**\n   * Number of tokens in the prompt.\n   */\n  prompt_tokens: number;\n\n  /**\n   * Total number of tokens used in the request (prompt + completion).\n   */\n  total_tokens: number;\n\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  completion_tokens_details?: CompletionUsage.CompletionTokensDetails;\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  prompt_tokens_details?: CompletionUsage.PromptTokensDetails;\n}\n\nexport namespace CompletionUsage {\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  export interface CompletionTokensDetails {\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that\n     * appeared in the completion.\n     */\n    accepted_prediction_tokens?: number;\n\n    /**\n     * Audio input tokens generated by the model.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Tokens generated by the model for reasoning.\n     */\n    reasoning_tokens?: number;\n\n    /**\n     * When using Predicted Outputs, the number of tokens in the prediction that did\n     * not appear in the completion. However, like reasoning tokens, these tokens are\n     * still counted in the total completion tokens for purposes of billing, output,\n     * and context window limits.\n     */\n    rejected_prediction_tokens?: number;\n  }\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  export interface PromptTokensDetails {\n    /**\n     * Audio input tokens present in the prompt.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Cached tokens present in the prompt.\n     */\n    cached_tokens?: number;\n  }\n}\n\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\n\nexport interface CompletionCreateParamsBase {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | 'gpt-3.5-turbo-instruct' | 'davinci-002' | 'babbage-002';\n\n  /**\n   * The prompt(s) to generate completions for, encoded as a string, array of\n   * strings, array of tokens, or array of token arrays.\n   *\n   * Note that <|endoftext|> is the document separator that the model sees during\n   * training, so if a prompt is not specified the model will generate as if from the\n   * beginning of a new document.\n   */\n  prompt: string | Array<string> | Array<number> | Array<Array<number>> | null;\n\n  /**\n   * Generates `best_of` completions server-side and returns the \"best\" (the one with\n   * the highest log probability per token). Results cannot be streamed.\n   *\n   * When used with `n`, `best_of` controls the number of candidate completions and\n   * `n` specifies how many to return – `best_of` must be greater than `n`.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  best_of?: number | null;\n\n  /**\n   * Echo back the prompt in addition to the completion\n   */\n  echo?: boolean | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the GPT\n   * tokenizer) to an associated bias value from -100 to 100. You can use this\n   * [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs.\n   * Mathematically, the bias is added to the logits generated by the model prior to\n   * sampling. The exact effect will vary per model, but values between -1 and 1\n   * should decrease or increase likelihood of selection; values like -100 or 100\n   * should result in a ban or exclusive selection of the relevant token.\n   *\n   * As an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token\n   * from being generated.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Include the log probabilities on the `logprobs` most likely output tokens, as\n   * well the chosen tokens. For example, if `logprobs` is 5, the API will return a\n   * list of the 5 most likely tokens. The API will always return the `logprob` of\n   * the sampled token, so there may be up to `logprobs+1` elements in the response.\n   *\n   * The maximum value for `logprobs` is 5.\n   */\n  logprobs?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the\n   * completion.\n   *\n   * The token count of your prompt plus `max_tokens` cannot exceed the model's\n   * context length.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  max_tokens?: number | null;\n\n  /**\n   * How many completions to generate for each prompt.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  n?: number | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * If specified, our system will make a best effort to sample deterministically,\n   * such that repeated requests with the same `seed` and parameters should return\n   * the same result.\n   *\n   * Determinism is not guaranteed, and you should refer to the `system_fingerprint`\n   * response parameter to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionsAPI.ChatCompletionStreamOptions | null;\n\n  /**\n   * The suffix that comes after a completion of inserted text.\n   *\n   * This parameter is only supported for `gpt-3.5-turbo-instruct`.\n   */\n  suffix?: string | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace CompletionCreateParams {\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\nexport declare namespace Completions {\n  export {\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\n\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   */\n  create(\n    body: EmbeddingCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<CreateEmbeddingResponse> {\n    return this._client.post('/embeddings', { body, ...options });\n  }\n}\n\nexport interface CreateEmbeddingResponse {\n  /**\n   * The list of embeddings generated by the model.\n   */\n  data: Array<Embedding>;\n\n  /**\n   * The name of the model used to generate the embedding.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"list\".\n   */\n  object: 'list';\n\n  /**\n   * The usage information for the request.\n   */\n  usage: CreateEmbeddingResponse.Usage;\n}\n\nexport namespace CreateEmbeddingResponse {\n  /**\n   * The usage information for the request.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens used by the prompt.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used by the request.\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * Represents an embedding vector returned by embedding endpoint.\n */\nexport interface Embedding {\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on\n   * the model as listed in the\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n   */\n  embedding: Array<number>;\n\n  /**\n   * The index of the embedding in the list of embeddings.\n   */\n  index: number;\n\n  /**\n   * The object type, which is always \"embedding\".\n   */\n  object: 'embedding';\n}\n\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\n\nexport interface EmbeddingCreateParams {\n  /**\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\n   * inputs in a single request, pass an array of strings or array of token arrays.\n   * The input must not exceed the max input tokens for the model (8192 tokens for\n   * `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048\n   * dimensions or less.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | EmbeddingModel;\n\n  /**\n   * The number of dimensions the resulting output embeddings should have. Only\n   * supported in `text-embedding-3` and later models.\n   */\n  dimensions?: number;\n\n  /**\n   * The format to return the embeddings in. Can be either `float` or\n   * [`base64`](https://pypi.org/project/pybase64/).\n   */\n  encoding_format?: 'float' | 'base64';\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport declare namespace Embeddings {\n  export {\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport { sleep } from '../core';\nimport { APIConnectionTimeoutError } from '../error';\nimport * as Core from '../core';\nimport { CursorPage, type CursorPageParams } from '../pagination';\nimport { type Response } from '../_shims/index';\n\nexport class Files extends APIResource {\n  /**\n   * Upload a file that can be used across various endpoints. Individual files can be\n   * up to 512 MB, and the size of all files uploaded by one organization can be up\n   * to 100 GB.\n   *\n   * The Assistants API supports files up to 2 million tokens and of specific file\n   * types. See the\n   * [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools) for\n   * details.\n   *\n   * The Fine-tuning API only supports `.jsonl` files. The input also has certain\n   * required formats for fine-tuning\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * models.\n   *\n   * The Batch API only supports `.jsonl` files up to 200 MB in size. The input also\n   * has a specific required\n   * [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n   *\n   * Please [contact us](https://help.openai.com/) if you need to increase these\n   * storage limits.\n   */\n  create(body: FileCreateParams, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.post('/files', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Returns information about a specific file.\n   */\n  retrieve(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.get(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns a list of files.\n   */\n  list(query?: FileListParams, options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FileObjectsPage, FileObject> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/files', FileObjectsPage, { query, ...options });\n  }\n\n  /**\n   * Delete a file.\n   */\n  del(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileDeleted> {\n    return this._client.delete(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   */\n  content(fileId: string, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.get(`/files/${fileId}/content`, { ...options, __binaryResponse: true });\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   *\n   * @deprecated The `.content()` method should be used instead\n   */\n  retrieveContent(fileId: string, options?: Core.RequestOptions): Core.APIPromise<string> {\n    return this._client.get(`/files/${fileId}/content`, {\n      ...options,\n      headers: { Accept: 'application/json', ...options?.headers },\n    });\n  }\n\n  /**\n   * Waits for the given file to be processed, default timeout is 30 mins.\n   */\n  async waitForProcessing(\n    id: string,\n    { pollInterval = 5000, maxWait = 30 * 60 * 1000 }: { pollInterval?: number; maxWait?: number } = {},\n  ): Promise<FileObject> {\n    const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\n\n    const start = Date.now();\n    let file = await this.retrieve(id);\n\n    while (!file.status || !TERMINAL_STATES.has(file.status)) {\n      await sleep(pollInterval);\n\n      file = await this.retrieve(id);\n      if (Date.now() - start > maxWait) {\n        throw new APIConnectionTimeoutError({\n          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\n        });\n      }\n    }\n\n    return file;\n  }\n}\n\nexport class FileObjectsPage extends CursorPage<FileObject> {}\n\nexport type FileContent = string;\n\nexport interface FileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'file';\n}\n\n/**\n * The `File` object represents a document that has been uploaded to OpenAI.\n */\nexport interface FileObject {\n  /**\n   * The file identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The size of the file, in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the file.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always `file`.\n   */\n  object: 'file';\n\n  /**\n   * The intended purpose of the file. Supported values are `assistants`,\n   * `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\n   * and `vision`.\n   */\n  purpose:\n    | 'assistants'\n    | 'assistants_output'\n    | 'batch'\n    | 'batch_output'\n    | 'fine-tune'\n    | 'fine-tune-results'\n    | 'vision';\n\n  /**\n   * @deprecated: Deprecated. The current status of the file, which can be either\n   * `uploaded`, `processed`, or `error`.\n   */\n  status: 'uploaded' | 'processed' | 'error';\n\n  /**\n   * @deprecated: Deprecated. For details on why a fine-tuning training file failed\n   * validation, see the `error` field on `fine_tuning.job`.\n   */\n  status_details?: string;\n}\n\n/**\n * The intended purpose of the uploaded file.\n *\n * Use \"assistants\" for\n * [Assistants](https://platform.openai.com/docs/api-reference/assistants) and\n * [Message](https://platform.openai.com/docs/api-reference/messages) files,\n * \"vision\" for Assistants image file inputs, \"batch\" for\n * [Batch API](https://platform.openai.com/docs/guides/batch), and \"fine-tune\" for\n * [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning).\n */\nexport type FilePurpose = 'assistants' | 'batch' | 'fine-tune' | 'vision';\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * Use \"assistants\" for\n   * [Assistants](https://platform.openai.com/docs/api-reference/assistants) and\n   * [Message](https://platform.openai.com/docs/api-reference/messages) files,\n   * \"vision\" for Assistants image file inputs, \"batch\" for\n   * [Batch API](https://platform.openai.com/docs/guides/batch), and \"fine-tune\" for\n   * [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning).\n   */\n  purpose: FilePurpose;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Only return files with the given purpose.\n   */\n  purpose?: string;\n}\n\nFiles.FileObjectsPage = FileObjectsPage;\n\nexport declare namespace Files {\n  export {\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Checkpoints extends APIResource {\n  /**\n   * List checkpoints for a fine-tuning job.\n   */\n  list(\n    fineTuningJobId: string,\n    query?: CheckpointListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    query: CheckpointListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint> {\n    if (isRequestOptions(query)) {\n      return this.list(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/fine_tuning/jobs/${fineTuningJobId}/checkpoints`,\n      FineTuningJobCheckpointsPage,\n      { query, ...options },\n    );\n  }\n}\n\nexport class FineTuningJobCheckpointsPage extends CursorPage<FineTuningJobCheckpoint> {}\n\n/**\n * The `fine_tuning.job.checkpoint` object represents a model checkpoint for a\n * fine-tuning job that is ready to use.\n */\nexport interface FineTuningJobCheckpoint {\n  /**\n   * The checkpoint identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the checkpoint was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the fine-tuned checkpoint model that is created.\n   */\n  fine_tuned_model_checkpoint: string;\n\n  /**\n   * The name of the fine-tuning job that this checkpoint was created from.\n   */\n  fine_tuning_job_id: string;\n\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  metrics: FineTuningJobCheckpoint.Metrics;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.checkpoint\".\n   */\n  object: 'fine_tuning.job.checkpoint';\n\n  /**\n   * The step number that the checkpoint was created at.\n   */\n  step_number: number;\n}\n\nexport namespace FineTuningJobCheckpoint {\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  export interface Metrics {\n    full_valid_loss?: number;\n\n    full_valid_mean_token_accuracy?: number;\n\n    step?: number;\n\n    train_loss?: number;\n\n    train_mean_token_accuracy?: number;\n\n    valid_loss?: number;\n\n    valid_mean_token_accuracy?: number;\n  }\n}\n\nexport interface CheckpointListParams extends CursorPageParams {}\n\nCheckpoints.FineTuningJobCheckpointsPage = FineTuningJobCheckpointsPage;\n\nexport declare namespace Checkpoints {\n  export {\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as CheckpointsAPI from './checkpoints';\nimport {\n  CheckpointListParams,\n  Checkpoints,\n  FineTuningJobCheckpoint,\n  FineTuningJobCheckpointsPage,\n} from './checkpoints';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Jobs extends APIResource {\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n\n  /**\n   * Creates a fine-tuning job which begins the process of creating a new model from\n   * a given dataset.\n   *\n   * Response includes details of the enqueued job including job status and the name\n   * of the fine-tuned models once complete.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  create(body: JobCreateParams, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post('/fine_tuning/jobs', { body, ...options });\n  }\n\n  /**\n   * Get info about a fine-tuning job.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  retrieve(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.get(`/fine_tuning/jobs/${fineTuningJobId}`, options);\n  }\n\n  /**\n   * List your organization's fine-tuning jobs\n   */\n  list(\n    query?: JobListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(\n    query: JobListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/fine_tuning/jobs', FineTuningJobsPage, { query, ...options });\n  }\n\n  /**\n   * Immediately cancel a fine-tune job.\n   */\n  cancel(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post(`/fine_tuning/jobs/${fineTuningJobId}/cancel`, options);\n  }\n\n  /**\n   * Get status updates for a fine-tuning job.\n   */\n  listEvents(\n    fineTuningJobId: string,\n    query?: JobListEventsParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    query: JobListEventsParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent> {\n    if (isRequestOptions(query)) {\n      return this.listEvents(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(`/fine_tuning/jobs/${fineTuningJobId}/events`, FineTuningJobEventsPage, {\n      query,\n      ...options,\n    });\n  }\n}\n\nexport class FineTuningJobsPage extends CursorPage<FineTuningJob> {}\n\nexport class FineTuningJobEventsPage extends CursorPage<FineTuningJobEvent> {}\n\n/**\n * The `fine_tuning.job` object represents a fine-tuning job that has been created\n * through the API.\n */\nexport interface FineTuningJob {\n  /**\n   * The object identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  error: FineTuningJob.Error | null;\n\n  /**\n   * The name of the fine-tuned model that is being created. The value will be null\n   * if the fine-tuning job is still running.\n   */\n  fine_tuned_model: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The\n   * value will be null if the fine-tuning job is still running.\n   */\n  finished_at: number | null;\n\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\n   * more details.\n   */\n  hyperparameters: FineTuningJob.Hyperparameters;\n\n  /**\n   * The base model that is being fine-tuned.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job\".\n   */\n  object: 'fine_tuning.job';\n\n  /**\n   * The organization that owns the fine-tuning job.\n   */\n  organization_id: string;\n\n  /**\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the\n   * results with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  result_files: Array<string>;\n\n  /**\n   * The seed used for the fine-tuning job.\n   */\n  seed: number;\n\n  /**\n   * The current status of the fine-tuning job, which can be either\n   * `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\n   */\n  status: 'validating_files' | 'queued' | 'running' | 'succeeded' | 'failed' | 'cancelled';\n\n  /**\n   * The total number of billable tokens processed by this fine-tuning job. The value\n   * will be null if the fine-tuning job is still running.\n   */\n  trained_tokens: number | null;\n\n  /**\n   * The file ID used for training. You can retrieve the training data with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  training_file: string;\n\n  /**\n   * The file ID used for validation. You can retrieve the validation results with\n   * the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  validation_file: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job is estimated to\n   * finish. The value will be null if the fine-tuning job is not running.\n   */\n  estimated_finish?: number | null;\n\n  /**\n   * A list of integrations to enable for this fine-tuning job.\n   */\n  integrations?: Array<FineTuningJobWandbIntegrationObject> | null;\n}\n\nexport namespace FineTuningJob {\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  export interface Error {\n    /**\n     * A machine-readable error code.\n     */\n    code: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The parameter that was invalid, usually `training_file` or `validation_file`.\n     * This field will be null if the failure was not parameter-specific.\n     */\n    param: string | null;\n  }\n\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\n   * more details.\n   */\n  export interface Hyperparameters {\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset. \"auto\" decides the optimal number of epochs based\n     * on the size of the dataset. If setting the number manually, we support any\n     * number between 1 and 50 epochs.\n     */\n    n_epochs: 'auto' | number;\n  }\n}\n\n/**\n * Fine-tuning job event object\n */\nexport interface FineTuningJobEvent {\n  id: string;\n\n  created_at: number;\n\n  level: 'info' | 'warn' | 'error';\n\n  message: string;\n\n  object: 'fine_tuning.job.event';\n}\n\nexport type FineTuningJobIntegration = FineTuningJobWandbIntegrationObject;\n\n/**\n * The settings for your integration with Weights and Biases. This payload\n * specifies the project that metrics will be sent to. Optionally, you can set an\n * explicit display name for your run, add tags to your run, and set a default\n * entity (team, username, etc) to be associated with your run.\n */\nexport interface FineTuningJobWandbIntegration {\n  /**\n   * The name of the project that the new run will be created under.\n   */\n  project: string;\n\n  /**\n   * The entity to use for the run. This allows you to set the team or username of\n   * the WandB user that you would like associated with the run. If not set, the\n   * default entity for the registered WandB API key is used.\n   */\n  entity?: string | null;\n\n  /**\n   * A display name to set for the run. If not set, we will use the Job ID as the\n   * name.\n   */\n  name?: string | null;\n\n  /**\n   * A list of tags to be attached to the newly created run. These tags are passed\n   * through directly to WandB. Some default tags are generated by OpenAI:\n   * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n   */\n  tags?: Array<string>;\n}\n\nexport interface FineTuningJobWandbIntegrationObject {\n  /**\n   * The type of the integration being enabled for the fine-tuning job\n   */\n  type: 'wandb';\n\n  /**\n   * The settings for your integration with Weights and Biases. This payload\n   * specifies the project that metrics will be sent to. Optionally, you can set an\n   * explicit display name for your run, add tags to your run, and set a default\n   * entity (team, username, etc) to be associated with your run.\n   */\n  wandb: FineTuningJobWandbIntegration;\n}\n\nexport interface JobCreateParams {\n  /**\n   * The name of the model to fine-tune. You can select one of the\n   * [supported models](https://platform.openai.com/docs/guides/fine-tuning#which-models-can-be-fine-tuned).\n   */\n  model: (string & {}) | 'babbage-002' | 'davinci-002' | 'gpt-3.5-turbo' | 'gpt-4o-mini';\n\n  /**\n   * The ID of an uploaded file that contains training data.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your dataset must be formatted as a JSONL file. Additionally, you must upload\n   * your file with the purpose `fine-tune`.\n   *\n   * The contents of the file should differ depending on if the model uses the\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * format.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  training_file: string;\n\n  /**\n   * The hyperparameters used for the fine-tuning job.\n   */\n  hyperparameters?: JobCreateParams.Hyperparameters;\n\n  /**\n   * A list of integrations to enable for your fine-tuning job.\n   */\n  integrations?: Array<JobCreateParams.Integration> | null;\n\n  /**\n   * The seed controls the reproducibility of the job. Passing in the same seed and\n   * job parameters should produce the same results, but may differ in rare cases. If\n   * a seed is not specified, one will be generated for you.\n   */\n  seed?: number | null;\n\n  /**\n   * A string of up to 64 characters that will be added to your fine-tuned model\n   * name.\n   *\n   * For example, a `suffix` of \"custom-model-name\" would produce a model name like\n   * `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n   */\n  suffix?: string | null;\n\n  /**\n   * The ID of an uploaded file that contains validation data.\n   *\n   * If you provide this file, the data is used to generate validation metrics\n   * periodically during fine-tuning. These metrics can be viewed in the fine-tuning\n   * results file. The same data should not be present in both train and validation\n   * files.\n   *\n   * Your dataset must be formatted as a JSONL file. You must upload your file with\n   * the purpose `fine-tune`.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  validation_file?: string | null;\n}\n\nexport namespace JobCreateParams {\n  /**\n   * The hyperparameters used for the fine-tuning job.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  export interface Integration {\n    /**\n     * The type of integration to enable. Currently, only \"wandb\" (Weights and Biases)\n     * is supported.\n     */\n    type: 'wandb';\n\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    wandb: Integration.Wandb;\n  }\n\n  export namespace Integration {\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    export interface Wandb {\n      /**\n       * The name of the project that the new run will be created under.\n       */\n      project: string;\n\n      /**\n       * The entity to use for the run. This allows you to set the team or username of\n       * the WandB user that you would like associated with the run. If not set, the\n       * default entity for the registered WandB API key is used.\n       */\n      entity?: string | null;\n\n      /**\n       * A display name to set for the run. If not set, we will use the Job ID as the\n       * name.\n       */\n      name?: string | null;\n\n      /**\n       * A list of tags to be attached to the newly created run. These tags are passed\n       * through directly to WandB. Some default tags are generated by OpenAI:\n       * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n       */\n      tags?: Array<string>;\n    }\n  }\n}\n\nexport interface JobListParams extends CursorPageParams {}\n\nexport interface JobListEventsParams extends CursorPageParams {}\n\nJobs.FineTuningJobsPage = FineTuningJobsPage;\nJobs.FineTuningJobEventsPage = FineTuningJobEventsPage;\nJobs.Checkpoints = Checkpoints;\nJobs.FineTuningJobCheckpointsPage = FineTuningJobCheckpointsPage;\n\nexport declare namespace Jobs {\n  export {\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    FineTuningJobsPage as FineTuningJobsPage,\n    FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n\n  export {\n    Checkpoints as Checkpoints,\n    type FineTuningJobCheckpoint as FineTuningJobCheckpoint,\n    FineTuningJobCheckpointsPage as FineTuningJobCheckpointsPage,\n    type CheckpointListParams as CheckpointListParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as JobsAPI from './jobs/jobs';\nimport {\n  FineTuningJob,\n  FineTuningJobEvent,\n  FineTuningJobEventsPage,\n  FineTuningJobIntegration,\n  FineTuningJobWandbIntegration,\n  FineTuningJobWandbIntegrationObject,\n  FineTuningJobsPage,\n  JobCreateParams,\n  JobListEventsParams,\n  JobListParams,\n  Jobs,\n} from './jobs/jobs';\n\nexport class FineTuning extends APIResource {\n  jobs: JobsAPI.Jobs = new JobsAPI.Jobs(this._client);\n}\n\nFineTuning.Jobs = Jobs;\nFineTuning.FineTuningJobsPage = FineTuningJobsPage;\nFineTuning.FineTuningJobEventsPage = FineTuningJobEventsPage;\n\nexport declare namespace FineTuning {\n  export {\n    Jobs as Jobs,\n    type FineTuningJob as FineTuningJob,\n    type FineTuningJobEvent as FineTuningJobEvent,\n    type FineTuningJobIntegration as FineTuningJobIntegration,\n    type FineTuningJobWandbIntegration as FineTuningJobWandbIntegration,\n    type FineTuningJobWandbIntegrationObject as FineTuningJobWandbIntegrationObject,\n    FineTuningJobsPage as FineTuningJobsPage,\n    FineTuningJobEventsPage as FineTuningJobEventsPage,\n    type JobCreateParams as JobCreateParams,\n    type JobListParams as JobListParams,\n    type JobListEventsParams as JobListEventsParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\n\nexport class Images extends APIResource {\n  /**\n   * Creates a variation of a given image.\n   */\n  createVariation(\n    body: ImageCreateVariationParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/variations', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an edited or extended image given an original image and a prompt.\n   */\n  edit(body: ImageEditParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/edits', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an image given a prompt.\n   */\n  generate(body: ImageGenerateParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/generations', { body, ...options });\n  }\n}\n\n/**\n * Represents the url or the content of an image generated by the OpenAI API.\n */\nexport interface Image {\n  /**\n   * The base64-encoded JSON of the generated image, if `response_format` is\n   * `b64_json`.\n   */\n  b64_json?: string;\n\n  /**\n   * The prompt that was used to generate the image, if there was any revision to the\n   * prompt.\n   */\n  revised_prompt?: string;\n\n  /**\n   * The URL of the generated image, if `response_format` is `url` (default).\n   */\n  url?: string;\n}\n\nexport type ImageModel = 'dall-e-2' | 'dall-e-3';\n\nexport interface ImagesResponse {\n  created: number;\n\n  data: Array<Image>;\n}\n\nexport interface ImageCreateVariationParams {\n  /**\n   * The image to use as the basis for the variation(s). Must be a valid PNG file,\n   * less than 4MB, and square.\n   */\n  image: Core.Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageEditParams {\n  /**\n   * The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask\n   * is not provided, image must have transparency, which will be used as the mask.\n   */\n  image: Core.Uploadable;\n\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters.\n   */\n  prompt: string;\n\n  /**\n   * An additional image whose fully transparent areas (e.g. where alpha is zero)\n   * indicate where `image` should be edited. Must be a valid PNG file, less than\n   * 4MB, and have the same dimensions as `image`.\n   */\n  mask?: Core.Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageGenerateParams {\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters for `dall-e-2` and 4000 characters for `dall-e-3`.\n   */\n  prompt: string;\n\n  /**\n   * The model to use for image generation.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The quality of the image that will be generated. `hd` creates images with finer\n   * details and greater consistency across the image. This param is only supported\n   * for `dall-e-3`.\n   */\n  quality?: 'standard' | 'hd';\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or\n   * `1024x1792` for `dall-e-3` models.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | '1792x1024' | '1024x1792' | null;\n\n  /**\n   * The style of the generated images. Must be one of `vivid` or `natural`. Vivid\n   * causes the model to lean towards generating hyper-real and dramatic images.\n   * Natural causes the model to produce more natural, less hyper-real looking\n   * images. This param is only supported for `dall-e-3`.\n   */\n  style?: 'vivid' | 'natural' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport declare namespace Images {\n  export {\n    type Image as Image,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageGenerateParams as ImageGenerateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\nimport { Page } from '../pagination';\n\nexport class Models extends APIResource {\n  /**\n   * Retrieves a model instance, providing basic information about the model such as\n   * the owner and permissioning.\n   */\n  retrieve(model: string, options?: Core.RequestOptions): Core.APIPromise<Model> {\n    return this._client.get(`/models/${model}`, options);\n  }\n\n  /**\n   * Lists the currently available models, and provides basic information about each\n   * one such as the owner and availability.\n   */\n  list(options?: Core.RequestOptions): Core.PagePromise<ModelsPage, Model> {\n    return this._client.getAPIList('/models', ModelsPage, options);\n  }\n\n  /**\n   * Delete a fine-tuned model. You must have the Owner role in your organization to\n   * delete a model.\n   */\n  del(model: string, options?: Core.RequestOptions): Core.APIPromise<ModelDeleted> {\n    return this._client.delete(`/models/${model}`, options);\n  }\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class ModelsPage extends Page<Model> {}\n\n/**\n * Describes an OpenAI model offering that can be used with the API.\n */\nexport interface Model {\n  /**\n   * The model identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) when the model was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always \"model\".\n   */\n  object: 'model';\n\n  /**\n   * The organization that owns the model.\n   */\n  owned_by: string;\n}\n\nexport interface ModelDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: string;\n}\n\nModels.ModelsPage = ModelsPage;\n\nexport declare namespace Models {\n  export { type Model as Model, type ModelDeleted as ModelDeleted, ModelsPage as ModelsPage };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\n\nexport class Moderations extends APIResource {\n  /**\n   * Classifies if text and/or image inputs are potentially harmful. Learn more in\n   * the [moderation guide](https://platform.openai.com/docs/guides/moderation).\n   */\n  create(\n    body: ModerationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ModerationCreateResponse> {\n    return this._client.post('/moderations', { body, ...options });\n  }\n}\n\nexport interface Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  categories: Moderation.Categories;\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  category_applied_input_types: Moderation.CategoryAppliedInputTypes;\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  category_scores: Moderation.CategoryScores;\n\n  /**\n   * Whether any of the below categories are flagged.\n   */\n  flagged: boolean;\n}\n\nexport namespace Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  export interface Categories {\n    /**\n     * Content that expresses, incites, or promotes harassing language towards any\n     * target.\n     */\n    harassment: boolean;\n\n    /**\n     * Harassment content that also includes violence or serious harm towards any\n     * target.\n     */\n    'harassment/threatening': boolean;\n\n    /**\n     * Content that expresses, incites, or promotes hate based on race, gender,\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\n     * harassment.\n     */\n    hate: boolean;\n\n    /**\n     * Hateful content that also includes violence or serious harm towards the targeted\n     * group based on race, gender, ethnicity, religion, nationality, sexual\n     * orientation, disability status, or caste.\n     */\n    'hate/threatening': boolean;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing, or that gives advice or instruction on how to commit\n     * illicit acts. For example, \"how to shoplift\" would fit this category.\n     */\n    illicit: boolean;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing that also includes violence, or that gives advice or\n     * instruction on the procurement of any weapon.\n     */\n    'illicit/violent': boolean;\n\n    /**\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\n     * suicide, cutting, and eating disorders.\n     */\n    'self-harm': boolean;\n\n    /**\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\n     * and eating disorders, or that gives instructions or advice on how to commit such\n     * acts.\n     */\n    'self-harm/instructions': boolean;\n\n    /**\n     * Content where the speaker expresses that they are engaging or intend to engage\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\n     */\n    'self-harm/intent': boolean;\n\n    /**\n     * Content meant to arouse sexual excitement, such as the description of sexual\n     * activity, or that promotes sexual services (excluding sex education and\n     * wellness).\n     */\n    sexual: boolean;\n\n    /**\n     * Sexual content that includes an individual who is under 18 years old.\n     */\n    'sexual/minors': boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury.\n     */\n    violence: boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury in graphic detail.\n     */\n    'violence/graphic': boolean;\n  }\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  export interface CategoryAppliedInputTypes {\n    /**\n     * The applied input type(s) for the category 'harassment'.\n     */\n    harassment: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate'.\n     */\n    hate: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate/threatening'.\n     */\n    'hate/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit'.\n     */\n    illicit: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit/violent'.\n     */\n    'illicit/violent': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm'.\n     */\n    'self-harm': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual'.\n     */\n    sexual: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual/minors'.\n     */\n    'sexual/minors': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'violence'.\n     */\n    violence: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'violence/graphic'.\n     */\n    'violence/graphic': Array<'text' | 'image'>;\n  }\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  export interface CategoryScores {\n    /**\n     * The score for the category 'harassment'.\n     */\n    harassment: number;\n\n    /**\n     * The score for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': number;\n\n    /**\n     * The score for the category 'hate'.\n     */\n    hate: number;\n\n    /**\n     * The score for the category 'hate/threatening'.\n     */\n    'hate/threatening': number;\n\n    /**\n     * The score for the category 'illicit'.\n     */\n    illicit: number;\n\n    /**\n     * The score for the category 'illicit/violent'.\n     */\n    'illicit/violent': number;\n\n    /**\n     * The score for the category 'self-harm'.\n     */\n    'self-harm': number;\n\n    /**\n     * The score for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': number;\n\n    /**\n     * The score for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': number;\n\n    /**\n     * The score for the category 'sexual'.\n     */\n    sexual: number;\n\n    /**\n     * The score for the category 'sexual/minors'.\n     */\n    'sexual/minors': number;\n\n    /**\n     * The score for the category 'violence'.\n     */\n    violence: number;\n\n    /**\n     * The score for the category 'violence/graphic'.\n     */\n    'violence/graphic': number;\n  }\n}\n\n/**\n * An object describing an image to classify.\n */\nexport interface ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  image_url: ModerationImageURLInput.ImageURL;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n}\n\nexport namespace ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n  }\n}\n\nexport type ModerationModel =\n  | 'omni-moderation-latest'\n  | 'omni-moderation-2024-09-26'\n  | 'text-moderation-latest'\n  | 'text-moderation-stable';\n\n/**\n * An object describing an image to classify.\n */\nexport type ModerationMultiModalInput = ModerationImageURLInput | ModerationTextInput;\n\n/**\n * An object describing text to classify.\n */\nexport interface ModerationTextInput {\n  /**\n   * A string of text to classify.\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * Represents if a given text input is potentially harmful.\n */\nexport interface ModerationCreateResponse {\n  /**\n   * The unique identifier for the moderation request.\n   */\n  id: string;\n\n  /**\n   * The model used to generate the moderation results.\n   */\n  model: string;\n\n  /**\n   * A list of moderation objects.\n   */\n  results: Array<Moderation>;\n}\n\nexport interface ModerationCreateParams {\n  /**\n   * Input (or inputs) to classify. Can be a single string, an array of strings, or\n   * an array of multi-modal input objects similar to other models.\n   */\n  input: string | Array<string> | Array<ModerationMultiModalInput>;\n\n  /**\n   * The content moderation model you would like to use. Learn more in\n   * [the moderation guide](https://platform.openai.com/docs/guides/moderation), and\n   * learn about available models\n   * [here](https://platform.openai.com/docs/models#moderation).\n   */\n  model?: (string & {}) | ModerationModel;\n}\n\nexport declare namespace Moderations {\n  export {\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\n\nexport class Parts extends APIResource {\n  /**\n   * Adds a\n   * [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object.\n   * A Part represents a chunk of bytes from the file you are trying to upload.\n   *\n   * Each Part can be at most 64 MB, and you can add Parts until you hit the Upload\n   * maximum of 8 GB.\n   *\n   * It is possible to add multiple Parts in parallel. You can decide the intended\n   * order of the Parts when you\n   * [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).\n   */\n  create(\n    uploadId: string,\n    body: PartCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<UploadPart> {\n    return this._client.post(\n      `/uploads/${uploadId}/parts`,\n      Core.multipartFormRequestOptions({ body, ...options }),\n    );\n  }\n}\n\n/**\n * The upload Part represents a chunk of bytes we can add to an Upload object.\n */\nexport interface UploadPart {\n  /**\n   * The upload Part unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Part was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type, which is always `upload.part`.\n   */\n  object: 'upload.part';\n\n  /**\n   * The ID of the Upload object that this Part was added to.\n   */\n  upload_id: string;\n}\n\nexport interface PartCreateParams {\n  /**\n   * The chunk of bytes for this Part.\n   */\n  data: Core.Uploadable;\n}\n\nexport declare namespace Parts {\n  export { type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as FilesAPI from '../files';\nimport * as PartsAPI from './parts';\nimport { PartCreateParams, Parts, UploadPart } from './parts';\n\nexport class Uploads extends APIResource {\n  parts: PartsAPI.Parts = new PartsAPI.Parts(this._client);\n\n  /**\n   * Creates an intermediate\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object\n   * that you can add\n   * [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.\n   * Currently, an Upload can accept at most 8 GB in total and expires after an hour\n   * after you create it.\n   *\n   * Once you complete the Upload, we will create a\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * contains all the parts you uploaded. This File is usable in the rest of our\n   * platform as a regular File object.\n   *\n   * For certain `purpose`s, the correct `mime_type` must be specified. Please refer\n   * to documentation for the supported MIME types for your use case:\n   *\n   * - [Assistants](https://platform.openai.com/docs/assistants/tools/file-search#supported-files)\n   *\n   * For guidance on the proper filename extensions for each purpose, please follow\n   * the documentation on\n   * [creating a File](https://platform.openai.com/docs/api-reference/files/create).\n   */\n  create(body: UploadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Upload> {\n    return this._client.post('/uploads', { body, ...options });\n  }\n\n  /**\n   * Cancels the Upload. No Parts may be added after an Upload is cancelled.\n   */\n  cancel(uploadId: string, options?: Core.RequestOptions): Core.APIPromise<Upload> {\n    return this._client.post(`/uploads/${uploadId}/cancel`, options);\n  }\n\n  /**\n   * Completes the\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object).\n   *\n   * Within the returned Upload object, there is a nested\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * is ready to use in the rest of the platform.\n   *\n   * You can specify the order of the Parts by passing in an ordered list of the Part\n   * IDs.\n   *\n   * The number of bytes uploaded upon completion must match the number of bytes\n   * initially specified when creating the Upload object. No Parts may be added after\n   * an Upload is completed.\n   */\n  complete(\n    uploadId: string,\n    body: UploadCompleteParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Upload> {\n    return this._client.post(`/uploads/${uploadId}/complete`, { body, ...options });\n  }\n}\n\n/**\n * The Upload object can accept byte chunks in the form of Parts.\n */\nexport interface Upload {\n  /**\n   * The Upload unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The intended number of bytes to be uploaded.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload was created.\n   */\n  expires_at: number;\n\n  /**\n   * The name of the file to be uploaded.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always \"upload\".\n   */\n  object: 'upload';\n\n  /**\n   * The intended purpose of the file.\n   * [Please refer here](https://platform.openai.com/docs/api-reference/files/object#files/object-purpose)\n   * for acceptable values.\n   */\n  purpose: string;\n\n  /**\n   * The status of the Upload.\n   */\n  status: 'pending' | 'completed' | 'cancelled' | 'expired';\n\n  /**\n   * The ready File object after the Upload is completed.\n   */\n  file?: FilesAPI.FileObject | null;\n}\n\nexport interface UploadCreateParams {\n  /**\n   * The number of bytes in the file you are uploading.\n   */\n  bytes: number;\n\n  /**\n   * The name of the file to upload.\n   */\n  filename: string;\n\n  /**\n   * The MIME type of the file.\n   *\n   * This must fall within the supported MIME types for your file purpose. See the\n   * supported MIME types for assistants and vision.\n   */\n  mime_type: string;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * See the\n   * [documentation on File purposes](https://platform.openai.com/docs/api-reference/files/create#files-create-purpose).\n   */\n  purpose: FilesAPI.FilePurpose;\n}\n\nexport interface UploadCompleteParams {\n  /**\n   * The ordered list of Part IDs.\n   */\n  part_ids: Array<string>;\n\n  /**\n   * The optional md5 checksum for the file contents to verify if the bytes uploaded\n   * matches what you expect.\n   */\n  md5?: string;\n}\n\nUploads.Parts = Parts;\n\nexport declare namespace Uploads {\n  export {\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export { Parts as Parts, type UploadPart as UploadPart, type PartCreateParams as PartCreateParams };\n}\n","// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { type Agent, type RequestInit } from './_shims/index';\nimport * as qs from './internal/qs';\nimport * as Core from './core';\nimport * as Errors from './error';\nimport * as Pagination from './pagination';\nimport { type CursorPageParams, CursorPageResponse, PageResponse } from './pagination';\nimport * as Uploads from './uploads';\nimport * as API from './resources/index';\nimport {\n  Batch,\n  BatchCreateParams,\n  BatchError,\n  BatchListParams,\n  BatchRequestCounts,\n  Batches,\n  BatchesPage,\n} from './resources/batches';\nimport {\n  Completion,\n  CompletionChoice,\n  CompletionCreateParams,\n  CompletionCreateParamsNonStreaming,\n  CompletionCreateParamsStreaming,\n  CompletionUsage,\n  Completions,\n} from './resources/completions';\nimport {\n  CreateEmbeddingResponse,\n  Embedding,\n  EmbeddingCreateParams,\n  EmbeddingModel,\n  Embeddings,\n} from './resources/embeddings';\nimport {\n  FileContent,\n  FileCreateParams,\n  FileDeleted,\n  FileListParams,\n  FileObject,\n  FileObjectsPage,\n  FilePurpose,\n  Files,\n} from './resources/files';\nimport {\n  Image,\n  ImageCreateVariationParams,\n  ImageEditParams,\n  ImageGenerateParams,\n  ImageModel,\n  Images,\n  ImagesResponse,\n} from './resources/images';\nimport { Model, ModelDeleted, Models, ModelsPage } from './resources/models';\nimport {\n  Moderation,\n  ModerationCreateParams,\n  ModerationCreateResponse,\n  ModerationImageURLInput,\n  ModerationModel,\n  ModerationMultiModalInput,\n  ModerationTextInput,\n  Moderations,\n} from './resources/moderations';\nimport { Audio, AudioModel, AudioResponseFormat } from './resources/audio/audio';\nimport { Beta } from './resources/beta/beta';\nimport { Chat, ChatModel } from './resources/chat/chat';\nimport {\n  ChatCompletion,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionAudio,\n  ChatCompletionAudioParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartInputAudio,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionMessage,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionModality,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionPredictionContent,\n  ChatCompletionRole,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUserMessageParam,\n} from './resources/chat/completions';\nimport { FineTuning } from './resources/fine-tuning/fine-tuning';\nimport {\n  Upload,\n  UploadCompleteParams,\n  UploadCreateParams,\n  Uploads as UploadsAPIUploads,\n} from './resources/uploads/uploads';\n\nexport interface ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_ORG_ID'].\n   */\n  organization?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_PROJECT_ID'].\n   */\n  project?: string | null | undefined;\n\n  /**\n   * Override the default base URL for the API, e.g., \"https://api.example.com/v2/\"\n   *\n   * Defaults to process.env['OPENAI_BASE_URL'].\n   */\n  baseURL?: string | null | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * Note that request timeouts are retried by default, so in a worst-case scenario you may wait\n   * much longer than this timeout before the promise succeeds or fails.\n   */\n  timeout?: number;\n\n  /**\n   * An HTTP agent used to manage HTTP(S) connections.\n   *\n   * If not provided, an agent will be constructed by default in the Node.js environment,\n   * otherwise no agent is used.\n   */\n  httpAgent?: Agent;\n\n  /**\n   * Specify a custom `fetch` function implementation.\n   *\n   * If not provided, we use `node-fetch` on Node.js and otherwise expect that `fetch` is\n   * defined globally.\n   */\n  fetch?: Core.Fetch | undefined;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number;\n\n  /**\n   * Default headers to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * header to `undefined` or `null` in request options.\n   */\n  defaultHeaders?: Core.Headers;\n\n  /**\n   * Default query parameters to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * param to `undefined` in request options.\n   */\n  defaultQuery?: Core.DefaultQuery;\n\n  /**\n   * By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   * Only set this option to `true` if you understand the risks and have appropriate mitigations in place.\n   */\n  dangerouslyAllowBrowser?: boolean;\n}\n\n/**\n * API Client for interfacing with the OpenAI API.\n */\nexport class OpenAI extends Core.APIClient {\n  apiKey: string;\n  organization: string | null;\n  project: string | null;\n\n  private _options: ClientOptions;\n\n  /**\n   * API Client for interfacing with the OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('OPENAI_API_KEY'),\n    organization = Core.readEnv('OPENAI_ORG_ID') ?? null,\n    project = Core.readEnv('OPENAI_PROJECT_ID') ?? null,\n    ...opts\n  }: ClientOptions = {}) {\n    if (apiKey === undefined) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_KEY environment variable is missing or empty; either provide it, or instantiate the OpenAI client with an apiKey option, like new OpenAI({ apiKey: 'My API Key' }).\",\n      );\n    }\n\n    const options: ClientOptions = {\n      apiKey,\n      organization,\n      project,\n      ...opts,\n      baseURL: baseURL || `https://api.openai.com/v1`,\n    };\n\n    if (!options.dangerouslyAllowBrowser && Core.isRunningInBrowser()) {\n      throw new Errors.OpenAIError(\n        \"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\",\n      );\n    }\n\n    super({\n      baseURL: options.baseURL!,\n      timeout: options.timeout ?? 600000 /* 10 minutes */,\n      httpAgent: options.httpAgent,\n      maxRetries: options.maxRetries,\n      fetch: options.fetch,\n    });\n\n    this._options = options;\n\n    this.apiKey = apiKey;\n    this.organization = organization;\n    this.project = project;\n  }\n\n  completions: API.Completions = new API.Completions(this);\n  chat: API.Chat = new API.Chat(this);\n  embeddings: API.Embeddings = new API.Embeddings(this);\n  files: API.Files = new API.Files(this);\n  images: API.Images = new API.Images(this);\n  audio: API.Audio = new API.Audio(this);\n  moderations: API.Moderations = new API.Moderations(this);\n  models: API.Models = new API.Models(this);\n  fineTuning: API.FineTuning = new API.FineTuning(this);\n  beta: API.Beta = new API.Beta(this);\n  batches: API.Batches = new API.Batches(this);\n  uploads: API.Uploads = new API.Uploads(this);\n\n  protected override defaultQuery(): Core.DefaultQuery | undefined {\n    return this._options.defaultQuery;\n  }\n\n  protected override defaultHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {\n      ...super.defaultHeaders(opts),\n      'OpenAI-Organization': this.organization,\n      'OpenAI-Project': this.project,\n      ...this._options.defaultHeaders,\n    };\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return { Authorization: `Bearer ${this.apiKey}` };\n  }\n\n  protected override stringifyQuery(query: Record<string, unknown>): string {\n    return qs.stringify(query, { arrayFormat: 'brackets' });\n  }\n\n  static OpenAI = this;\n  static DEFAULT_TIMEOUT = 600000; // 10 minutes\n\n  static OpenAIError = Errors.OpenAIError;\n  static APIError = Errors.APIError;\n  static APIConnectionError = Errors.APIConnectionError;\n  static APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\n  static APIUserAbortError = Errors.APIUserAbortError;\n  static NotFoundError = Errors.NotFoundError;\n  static ConflictError = Errors.ConflictError;\n  static RateLimitError = Errors.RateLimitError;\n  static BadRequestError = Errors.BadRequestError;\n  static AuthenticationError = Errors.AuthenticationError;\n  static InternalServerError = Errors.InternalServerError;\n  static PermissionDeniedError = Errors.PermissionDeniedError;\n  static UnprocessableEntityError = Errors.UnprocessableEntityError;\n\n  static toFile = Uploads.toFile;\n  static fileFromPath = Uploads.fileFromPath;\n}\n\nOpenAI.Completions = Completions;\nOpenAI.Chat = Chat;\nOpenAI.Embeddings = Embeddings;\nOpenAI.Files = Files;\nOpenAI.FileObjectsPage = FileObjectsPage;\nOpenAI.Images = Images;\nOpenAI.Audio = Audio;\nOpenAI.Moderations = Moderations;\nOpenAI.Models = Models;\nOpenAI.ModelsPage = ModelsPage;\nOpenAI.FineTuning = FineTuning;\nOpenAI.Beta = Beta;\nOpenAI.Batches = Batches;\nOpenAI.BatchesPage = BatchesPage;\nOpenAI.Uploads = UploadsAPIUploads;\nexport declare namespace OpenAI {\n  export type RequestOptions = Core.RequestOptions;\n\n  export import Page = Pagination.Page;\n  export { type PageResponse as PageResponse };\n\n  export import CursorPage = Pagination.CursorPage;\n  export { type CursorPageParams as CursorPageParams, type CursorPageResponse as CursorPageResponse };\n\n  export {\n    Completions as Completions,\n    type Completion as Completion,\n    type CompletionChoice as CompletionChoice,\n    type CompletionUsage as CompletionUsage,\n    type CompletionCreateParams as CompletionCreateParams,\n    type CompletionCreateParamsNonStreaming as CompletionCreateParamsNonStreaming,\n    type CompletionCreateParamsStreaming as CompletionCreateParamsStreaming,\n  };\n\n  export {\n    Chat as Chat,\n    type ChatModel as ChatModel,\n    type ChatCompletion as ChatCompletion,\n    type ChatCompletionAssistantMessageParam as ChatCompletionAssistantMessageParam,\n    type ChatCompletionAudio as ChatCompletionAudio,\n    type ChatCompletionAudioParam as ChatCompletionAudioParam,\n    type ChatCompletionChunk as ChatCompletionChunk,\n    type ChatCompletionContentPart as ChatCompletionContentPart,\n    type ChatCompletionContentPartImage as ChatCompletionContentPartImage,\n    type ChatCompletionContentPartInputAudio as ChatCompletionContentPartInputAudio,\n    type ChatCompletionContentPartRefusal as ChatCompletionContentPartRefusal,\n    type ChatCompletionContentPartText as ChatCompletionContentPartText,\n    type ChatCompletionFunctionCallOption as ChatCompletionFunctionCallOption,\n    type ChatCompletionFunctionMessageParam as ChatCompletionFunctionMessageParam,\n    type ChatCompletionMessage as ChatCompletionMessage,\n    type ChatCompletionMessageParam as ChatCompletionMessageParam,\n    type ChatCompletionMessageToolCall as ChatCompletionMessageToolCall,\n    type ChatCompletionModality as ChatCompletionModality,\n    type ChatCompletionNamedToolChoice as ChatCompletionNamedToolChoice,\n    type ChatCompletionPredictionContent as ChatCompletionPredictionContent,\n    type ChatCompletionRole as ChatCompletionRole,\n    type ChatCompletionStreamOptions as ChatCompletionStreamOptions,\n    type ChatCompletionSystemMessageParam as ChatCompletionSystemMessageParam,\n    type ChatCompletionTokenLogprob as ChatCompletionTokenLogprob,\n    type ChatCompletionTool as ChatCompletionTool,\n    type ChatCompletionToolChoiceOption as ChatCompletionToolChoiceOption,\n    type ChatCompletionToolMessageParam as ChatCompletionToolMessageParam,\n    type ChatCompletionUserMessageParam as ChatCompletionUserMessageParam,\n    type ChatCompletionCreateParams as ChatCompletionCreateParams,\n    type ChatCompletionCreateParamsNonStreaming as ChatCompletionCreateParamsNonStreaming,\n    type ChatCompletionCreateParamsStreaming as ChatCompletionCreateParamsStreaming,\n  };\n\n  export {\n    Embeddings as Embeddings,\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n\n  export {\n    Files as Files,\n    type FileContent as FileContent,\n    type FileDeleted as FileDeleted,\n    type FileObject as FileObject,\n    type FilePurpose as FilePurpose,\n    FileObjectsPage as FileObjectsPage,\n    type FileCreateParams as FileCreateParams,\n    type FileListParams as FileListParams,\n  };\n\n  export {\n    Images as Images,\n    type Image as Image,\n    type ImageModel as ImageModel,\n    type ImagesResponse as ImagesResponse,\n    type ImageCreateVariationParams as ImageCreateVariationParams,\n    type ImageEditParams as ImageEditParams,\n    type ImageGenerateParams as ImageGenerateParams,\n  };\n\n  export { Audio as Audio, type AudioModel as AudioModel, type AudioResponseFormat as AudioResponseFormat };\n\n  export {\n    Moderations as Moderations,\n    type Moderation as Moderation,\n    type ModerationImageURLInput as ModerationImageURLInput,\n    type ModerationModel as ModerationModel,\n    type ModerationMultiModalInput as ModerationMultiModalInput,\n    type ModerationTextInput as ModerationTextInput,\n    type ModerationCreateResponse as ModerationCreateResponse,\n    type ModerationCreateParams as ModerationCreateParams,\n  };\n\n  export {\n    Models as Models,\n    type Model as Model,\n    type ModelDeleted as ModelDeleted,\n    ModelsPage as ModelsPage,\n  };\n\n  export { FineTuning as FineTuning };\n\n  export { Beta as Beta };\n\n  export {\n    Batches as Batches,\n    type Batch as Batch,\n    type BatchError as BatchError,\n    type BatchRequestCounts as BatchRequestCounts,\n    BatchesPage as BatchesPage,\n    type BatchCreateParams as BatchCreateParams,\n    type BatchListParams as BatchListParams,\n  };\n\n  export {\n    UploadsAPIUploads as Uploads,\n    type Upload as Upload,\n    type UploadCreateParams as UploadCreateParams,\n    type UploadCompleteParams as UploadCompleteParams,\n  };\n\n  export type ErrorObject = API.ErrorObject;\n  export type FunctionDefinition = API.FunctionDefinition;\n  export type FunctionParameters = API.FunctionParameters;\n  export type ResponseFormatJSONObject = API.ResponseFormatJSONObject;\n  export type ResponseFormatJSONSchema = API.ResponseFormatJSONSchema;\n  export type ResponseFormatText = API.ResponseFormatText;\n}\n\n// ---------------------- Azure ----------------------\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport interface AzureClientOptions extends ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_VERSION'].\n   */\n  apiVersion?: string | undefined;\n\n  /**\n   * Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   */\n  endpoint?: string | undefined;\n\n  /**\n   * A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * Note: this means you won't be able to use non-deployment endpoints. Not supported with Assistants APIs.\n   */\n  deployment?: string | undefined;\n\n  /**\n   * Defaults to process.env['AZURE_OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * A function that returns an access token for Microsoft Entra (formerly known as Azure Active Directory),\n   * which will be invoked on every request.\n   */\n  azureADTokenProvider?: (() => Promise<string>) | undefined;\n}\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport class AzureOpenAI extends OpenAI {\n  private _azureADTokenProvider: (() => Promise<string>) | undefined;\n  private _deployment: string | undefined;\n  apiVersion: string = '';\n  /**\n   * API Client for interfacing with the Azure OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]\n   * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]\n   * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API, e.g. `https://example-resource.azure.openai.com/openai/`.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('AZURE_OPENAI_API_KEY'),\n    apiVersion = Core.readEnv('OPENAI_API_VERSION'),\n    endpoint,\n    deployment,\n    azureADTokenProvider,\n    dangerouslyAllowBrowser,\n    ...opts\n  }: AzureClientOptions = {}) {\n    if (!apiVersion) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).\",\n      );\n    }\n\n    if (typeof azureADTokenProvider === 'function') {\n      dangerouslyAllowBrowser = true;\n    }\n\n    if (!azureADTokenProvider && !apiKey) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    if (azureADTokenProvider && apiKey) {\n      throw new Errors.OpenAIError(\n        'The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.',\n      );\n    }\n\n    // define a sentinel value to avoid any typing issues\n    apiKey ??= API_KEY_SENTINEL;\n\n    opts.defaultQuery = { ...opts.defaultQuery, 'api-version': apiVersion };\n\n    if (!baseURL) {\n      if (!endpoint) {\n        endpoint = process.env['AZURE_OPENAI_ENDPOINT'];\n      }\n\n      if (!endpoint) {\n        throw new Errors.OpenAIError(\n          'Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable',\n        );\n      }\n\n      baseURL = `${endpoint}/openai`;\n    } else {\n      if (endpoint) {\n        throw new Errors.OpenAIError('baseURL and endpoint are mutually exclusive');\n      }\n    }\n\n    super({\n      apiKey,\n      baseURL,\n      ...opts,\n      ...(dangerouslyAllowBrowser !== undefined ? { dangerouslyAllowBrowser } : {}),\n    });\n\n    this._azureADTokenProvider = azureADTokenProvider;\n    this.apiVersion = apiVersion;\n    this._deployment = deployment;\n  }\n\n  override buildRequest(options: Core.FinalRequestOptions<unknown>): {\n    req: RequestInit;\n    url: string;\n    timeout: number;\n  } {\n    if (_deployments_endpoints.has(options.path) && options.method === 'post' && options.body !== undefined) {\n      if (!Core.isObj(options.body)) {\n        throw new Error('Expected request body to be an object');\n      }\n      const model = this._deployment || options.body['model'];\n      if (model !== undefined && !this.baseURL.includes('/deployments')) {\n        options.path = `/deployments/${model}${options.path}`;\n      }\n    }\n    return super.buildRequest(options);\n  }\n\n  private async _getAzureADToken(): Promise<string | undefined> {\n    if (typeof this._azureADTokenProvider === 'function') {\n      const token = await this._azureADTokenProvider();\n      if (!token || typeof token !== 'string') {\n        throw new Errors.OpenAIError(\n          `Expected 'azureADTokenProvider' argument to return a string but it returned ${token}`,\n        );\n      }\n      return token;\n    }\n    return undefined;\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {};\n  }\n\n  protected override async prepareOptions(opts: Core.FinalRequestOptions<unknown>): Promise<void> {\n    /**\n     * The user should provide a bearer token provider if they want\n     * to use Azure AD authentication. The user shouldn't set the\n     * Authorization header manually because the header is overwritten\n     * with the Azure AD token if a bearer token provider is provided.\n     */\n    if (opts.headers?.['api-key']) {\n      return super.prepareOptions(opts);\n    }\n    const token = await this._getAzureADToken();\n    opts.headers ??= {};\n    if (token) {\n      opts.headers['Authorization'] = `Bearer ${token}`;\n    } else if (this.apiKey !== API_KEY_SENTINEL) {\n      opts.headers['api-key'] = this.apiKey;\n    } else {\n      throw new Errors.OpenAIError('Unable to handle auth');\n    }\n    return super.prepareOptions(opts);\n  }\n}\n\nconst _deployments_endpoints = new Set([\n  '/completions',\n  '/chat/completions',\n  '/embeddings',\n  '/audio/transcriptions',\n  '/audio/translations',\n  '/audio/speech',\n  '/images/generations',\n]);\n\nconst API_KEY_SENTINEL = '<Missing Key>';\n\n// ---------------------- End Azure ----------------------\n\nexport { toFile, fileFromPath } from './uploads';\nexport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n  NotFoundError,\n  ConflictError,\n  RateLimitError,\n  BadRequestError,\n  AuthenticationError,\n  InternalServerError,\n  PermissionDeniedError,\n  UnprocessableEntityError,\n} from './error';\n\nexport default OpenAI;\n","export class DeepgramError extends Error {\n  protected __dgError = true;\n\n  constructor(message: string) {\n    super(message);\n    this.name = \"DeepgramError\";\n  }\n}\n\nexport function isDeepgramError(error: unknown): error is DeepgramError {\n  return typeof error === \"object\" && error !== null && \"__dgError\" in error;\n}\n\nexport class DeepgramApiError extends DeepgramError {\n  status: number;\n\n  constructor(message: string, status: number) {\n    super(message);\n    this.name = \"DeepgramApiError\";\n    this.status = status;\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n    };\n  }\n}\n\nexport class DeepgramUnknownError extends DeepgramError {\n  originalError: unknown;\n\n  constructor(message: string, originalError: unknown) {\n    super(message);\n    this.name = \"DeepgramUnknownError\";\n    this.originalError = originalError;\n  }\n}\n\nexport class DeepgramVersionError extends DeepgramError {\n  constructor() {\n    super(\n      `You are attempting to use an old format for a newer SDK version. Read more here: https://dpgr.am/js-v3`\n    );\n\n    this.name = \"DeepgramVersionError\";\n  }\n}\n","import { EventEmitter } from \"events\";\nimport { DEFAULT_OPTIONS, DEFAULT_URL } from \"../lib/constants\";\nimport { DeepgramError } from \"../lib/errors\";\nimport { appendSearchParams, applyDefaults, convertLegacyOptions } from \"../lib/helpers\";\nimport type {\n  DeepgramClientOptions,\n  DefaultClientOptions,\n  DefaultNamespaceOptions,\n  NamespaceOptions,\n} from \"../lib/types\";\n\nexport const noop = () => {};\n\n/**\n * Represents an abstract Deepgram client that provides a base implementation for interacting with the Deepgram API.\n *\n * The `AbstractClient` class is responsible for:\n * - Initializing the Deepgram API key\n * - Applying default options for the client and namespace\n * - Providing a namespace for organizing API requests\n *\n * Subclasses of `AbstractClient` should implement the specific functionality for interacting with the Deepgram API.\n */\nexport abstract class AbstractClient extends EventEmitter {\n  protected factory: Function | undefined = undefined;\n  protected key: string;\n  protected options: DefaultClientOptions;\n  public namespace: string = \"global\";\n  public version: string = \"v1\";\n  public baseUrl: string = DEFAULT_URL;\n  public logger: Function = noop;\n\n  /**\n   * Constructs a new instance of the DeepgramClient class with the provided options.\n   *\n   * @param options - The options to configure the DeepgramClient instance.\n   * @param options.key - The Deepgram API key to use for authentication. If not provided, the `DEEPGRAM_API_KEY` environment variable will be used.\n   * @param options.global - Global options that apply to all requests made by the DeepgramClient instance.\n   * @param options.global.fetch - Options to configure the fetch requests made by the DeepgramClient instance.\n   * @param options.global.fetch.options - Additional options to pass to the fetch function, such as `url` and `headers`.\n   * @param options.namespace - Options specific to a particular namespace within the DeepgramClient instance.\n   */\n  constructor(options: DeepgramClientOptions) {\n    super();\n\n    let key;\n\n    if (typeof options.key === \"function\") {\n      this.factory = options.key;\n      key = this.factory();\n    } else {\n      key = options.key;\n    }\n\n    if (!key) {\n      key = process.env.DEEPGRAM_API_KEY as string;\n    }\n\n    if (!key) {\n      throw new DeepgramError(\"A deepgram API key is required.\");\n    }\n\n    this.key = key;\n\n    options = convertLegacyOptions(options);\n\n    /**\n     * Apply default options.\n     */\n    this.options = applyDefaults<DeepgramClientOptions, DefaultClientOptions>(\n      options,\n      DEFAULT_OPTIONS\n    );\n  }\n\n  /**\n   * Sets the version for the current instance of the Deepgram API and returns the instance.\n   *\n   * @param version - The version to set for the Deepgram API instance. Defaults to \"v1\" if not provided.\n   * @returns The current instance of the AbstractClient with the updated version.\n   */\n  public v(version: string = \"v1\"): this {\n    this.version = version;\n\n    return this;\n  }\n\n  /**\n   * Gets the namespace options for the current instance of the AbstractClient.\n   * The namespace options include the default options merged with the global options,\n   * and the API key for the current instance.\n   *\n   * @returns The namespace options for the current instance.\n   */\n  get namespaceOptions(): DefaultNamespaceOptions {\n    const defaults = applyDefaults<NamespaceOptions, DefaultNamespaceOptions>(\n      (this.options as any)[this.namespace],\n      this.options.global\n    );\n\n    return {\n      ...defaults,\n      key: this.key,\n    };\n  }\n\n  /**\n   * Generates a URL for an API endpoint with optional query parameters and transcription options.\n   *\n   * @param endpoint - The API endpoint URL, which may contain placeholders for fields.\n   * @param fields - An optional object containing key-value pairs to replace placeholders in the endpoint URL.\n   * @param transcriptionOptions - Optional transcription options to include as query parameters in the URL.\n   * @returns A URL object representing the constructed API request URL.\n   */\n  public getRequestUrl(\n    endpoint: string,\n    fields: { [key: string]: string } = { version: this.version },\n    transcriptionOptions?: {\n      [key: string]: unknown;\n    }\n  ): URL {\n    /**\n     * If we pass in fields without a version, set a version.\n     */\n    fields.version = this.version;\n\n    /**\n     * Version and template the endpoint for input argument..\n     */\n    endpoint = endpoint.replace(/:(\\w+)/g, function (_, key) {\n      return fields![key];\n    });\n\n    /**\n     * Create a URL object.\n     */\n    const url = new URL(endpoint as string, this.baseUrl);\n\n    /**\n     * If there are transcription options, append them to the request as URL querystring parameters\n     */\n    if (transcriptionOptions) {\n      appendSearchParams(url.searchParams, transcriptionOptions);\n    }\n\n    return url;\n  }\n\n  /**\n   * Logs the message.\n   *\n   * For customized logging, `this.logger` can be overridden.\n   */\n  public log(kind: string, msg: string, data?: any) {\n    this.logger(kind, msg, data);\n  }\n}\n","import {\n  DeepgramClientOptions,\n  FileSource,\n  PrerecordedSource,\n  UrlSource,\n  TextSource,\n  AnalyzeSource,\n  LiveSchema,\n  TranscriptionSchema,\n} from \"./types\";\nimport { Headers as CrossFetchHeaders } from \"cross-fetch\";\nimport { Readable } from \"stream\";\nimport merge from \"deepmerge\";\nimport { BROWSER_AGENT, BUN_VERSION, NODE_VERSION } from \"./constants\";\n\nexport function stripTrailingSlash(url: string): string {\n  return url.replace(/\\/$/, \"\");\n}\n\nexport const isBrowser = () => BROWSER_AGENT !== \"unknown\";\n\nexport const isNode = () => NODE_VERSION !== \"unknown\";\n\nexport const isBun = () => BUN_VERSION !== \"unknown\";\n\nexport function applyDefaults<O, S>(options: Partial<O> = {}, subordinate: Partial<S> = {}): S {\n  return merge(subordinate, options);\n}\n\nexport function appendSearchParams(\n  searchParams: URLSearchParams,\n  options: Record<string, unknown>\n): void {\n  Object.keys(options).forEach((i) => {\n    if (Array.isArray(options[i])) {\n      const arrayParams = options[i] as Array<any>;\n      arrayParams.forEach((param) => {\n        searchParams.append(i, String(param));\n      });\n    } else {\n      searchParams.append(i, String(options[i]));\n    }\n  });\n}\n\nexport const resolveHeadersConstructor = () => {\n  if (typeof Headers === \"undefined\") {\n    return CrossFetchHeaders;\n  }\n\n  return Headers;\n};\n\nexport const isUrlSource = (\n  providedSource: PrerecordedSource | AnalyzeSource\n): providedSource is UrlSource => {\n  if ((providedSource as UrlSource).url) return true;\n\n  return false;\n};\n\nexport const isTextSource = (\n  providedSource: PrerecordedSource | AnalyzeSource\n): providedSource is TextSource => {\n  if ((providedSource as TextSource).text) return true;\n\n  return false;\n};\n\nexport const isFileSource = (providedSource: PrerecordedSource): providedSource is FileSource => {\n  if (isReadStreamSource(providedSource) || isBufferSource(providedSource)) return true;\n\n  return false;\n};\n\nconst isBufferSource = (providedSource: PrerecordedSource): providedSource is Buffer => {\n  if (providedSource as Buffer) return true;\n\n  return false;\n};\n\nconst isReadStreamSource = (providedSource: PrerecordedSource): providedSource is Readable => {\n  if (providedSource as Readable) return true;\n\n  return false;\n};\n\nexport class CallbackUrl extends URL {\n  public callbackUrl = true;\n}\n\nexport const convertProtocolToWs = (url: string) => {\n  const convert = (string: string) => string.toLowerCase().replace(/^http/, \"ws\");\n\n  return convert(url);\n};\n\nexport const buildRequestUrl = (\n  endpoint: string,\n  baseUrl: string | URL,\n  transcriptionOptions: LiveSchema | TranscriptionSchema\n): URL => {\n  const url = new URL(endpoint, baseUrl);\n  appendSearchParams(url.searchParams, transcriptionOptions);\n\n  return url;\n};\n\nexport function isLiveSchema(arg: any): arg is LiveSchema {\n  return arg && typeof arg.interim_results !== \"undefined\";\n}\n\nexport function isDeepgramClientOptions(arg: any): arg is DeepgramClientOptions {\n  return arg && typeof arg.global !== \"undefined\";\n}\n\nexport const convertLegacyOptions = (optionsArg: DeepgramClientOptions): DeepgramClientOptions => {\n  const newOptions: DeepgramClientOptions = {};\n\n  if (optionsArg._experimentalCustomFetch) {\n    newOptions.global = {\n      fetch: {\n        client: optionsArg._experimentalCustomFetch,\n      },\n    };\n  }\n\n  optionsArg = merge(optionsArg, newOptions);\n\n  if (optionsArg.restProxy?.url) {\n    newOptions.global = {\n      fetch: {\n        options: {\n          proxy: {\n            url: optionsArg.restProxy?.url,\n          },\n        },\n      },\n    };\n  }\n\n  optionsArg = merge(optionsArg, newOptions);\n\n  if (optionsArg.global?.url) {\n    newOptions.global = {\n      fetch: {\n        options: {\n          url: optionsArg.global.url,\n        },\n      },\n      websocket: {\n        options: {\n          url: optionsArg.global.url,\n        },\n      },\n    };\n  }\n\n  optionsArg = merge(optionsArg, newOptions);\n\n  if (optionsArg.global?.headers) {\n    newOptions.global = {\n      fetch: {\n        options: {\n          headers: optionsArg.global?.headers,\n        },\n      },\n      websocket: {\n        options: {\n          _nodeOnlyHeaders: optionsArg.global?.headers,\n        },\n      },\n    };\n  }\n\n  optionsArg = merge(optionsArg, newOptions);\n\n  return optionsArg;\n};\n","export const version = \"3.9.0\";\n","import { convertProtocolToWs, isBrowser, isBun, isNode } from \"./helpers\";\nimport { version } from \"./version\";\nimport type { DefaultNamespaceOptions, DefaultClientOptions } from \"./types\";\n\nexport const NODE_VERSION =\n  typeof process !== \"undefined\" && process.versions && process.versions.node\n    ? process.versions.node\n    : \"unknown\";\n\nexport const BUN_VERSION =\n  typeof process !== \"undefined\" && process.versions && process.versions.bun\n    ? process.versions.bun\n    : \"unknown\";\n\nexport const BROWSER_AGENT =\n  typeof window !== \"undefined\" && window.navigator && window.navigator.userAgent\n    ? window.navigator.userAgent\n    : \"unknown\";\n\nconst getAgent = () => {\n  if (isNode()) {\n    return `node/${NODE_VERSION}`;\n  } else if (isBun()) {\n    return `bun/${BUN_VERSION}`;\n  } else if (isBrowser()) {\n    return `javascript ${BROWSER_AGENT}`;\n  } else {\n    return `unknown`;\n  }\n};\n\nexport const DEFAULT_HEADERS = {\n  \"Content-Type\": `application/json`,\n  \"X-Client-Info\": `@deepgram/sdk; ${isBrowser() ? \"browser\" : \"server\"}; v${version}`,\n  \"User-Agent\": `@deepgram/sdk/${version} ${getAgent()}`,\n};\n\nexport const DEFAULT_URL = \"https://api.deepgram.com\";\n\nexport const DEFAULT_GLOBAL_OPTIONS: Partial<DefaultNamespaceOptions> = {\n  fetch: { options: { url: DEFAULT_URL, headers: DEFAULT_HEADERS } },\n  websocket: {\n    options: { url: convertProtocolToWs(DEFAULT_URL), _nodeOnlyHeaders: DEFAULT_HEADERS },\n  },\n};\n\nexport const DEFAULT_OPTIONS: DefaultClientOptions = {\n  global: DEFAULT_GLOBAL_OPTIONS,\n};\n\nexport enum SOCKET_STATES {\n  connecting = 0,\n  open = 1,\n  closing = 2,\n  closed = 3,\n}\n\nexport enum CONNECTION_STATE {\n  Connecting = \"connecting\",\n  Open = \"open\",\n  Closing = \"closing\",\n  Closed = \"closed\",\n}\n","import { AbstractClient, noop } from \"./AbstractClient\";\nimport { CONNECTION_STATE, SOCKET_STATES } from \"../lib/constants\";\nimport type { DeepgramClientOptions, LiveSchema } from \"../lib/types\";\nimport type { WebSocket as WSWebSocket } from \"ws\";\nimport { isBun } from \"../lib/helpers\";\n\n/**\n * Represents a constructor for a WebSocket-like object that can be used in the application.\n * The constructor takes the following parameters:\n * @param address - The URL or address of the WebSocket server.\n * @param _ignored - An optional parameter that is ignored.\n * @param options - An optional object containing headers to be included in the WebSocket connection.\n * @returns A WebSocket-like object that implements the WebSocketLike interface.\n */\ninterface WebSocketLikeConstructor {\n  new (\n    address: string | URL,\n    _ignored?: any,\n    options?: { headers: object | undefined }\n  ): WebSocketLike;\n}\n\n/**\n * Represents the types of WebSocket-like connections that can be used in the application.\n * This type is used to provide a common interface for different WebSocket implementations,\n * such as the native WebSocket API, a WebSocket wrapper library, or a dummy implementation\n * for testing purposes.\n */\ntype WebSocketLike = WebSocket | WSWebSocket | WSWebSocketDummy;\n\n/**\n * Represents the types of data that can be sent or received over a WebSocket-like connection.\n */\ntype SocketDataLike = string | ArrayBufferLike | Blob;\n\n/**\n * Represents an error that occurred in a WebSocket-like connection.\n * @property {any} error - The underlying error object.\n * @property {string} message - A human-readable error message.\n * @property {string} type - The type of the error.\n */\n// interface WebSocketLikeError {\n//   error: any;\n//   message: string;\n//   type: string;\n// }\n\n/**\n * Indicates whether a native WebSocket implementation is available in the current environment.\n */\nconst NATIVE_WEBSOCKET_AVAILABLE = typeof WebSocket !== \"undefined\";\n\n/**\n * Represents an abstract live client that extends the AbstractClient class.\n * The AbstractLiveClient class provides functionality for connecting, reconnecting, and disconnecting a WebSocket connection, as well as sending data over the connection.\n * Subclasses of this class are responsible for setting up the connection event handlers.\n *\n * @abstract\n */\nexport abstract class AbstractLiveClient extends AbstractClient {\n  public headers: { [key: string]: string };\n  public transport: WebSocketLikeConstructor | null;\n  public conn: WebSocketLike | null = null;\n  public sendBuffer: Function[] = [];\n\n  constructor(options: DeepgramClientOptions) {\n    super(options);\n\n    const {\n      key,\n      websocket: { options: websocketOptions, client },\n    } = this.namespaceOptions;\n\n    if (this.proxy) {\n      this.baseUrl = websocketOptions.proxy!.url;\n    } else {\n      this.baseUrl = websocketOptions.url;\n    }\n\n    if (client) {\n      this.transport = client;\n    } else {\n      this.transport = null;\n    }\n\n    if (websocketOptions._nodeOnlyHeaders) {\n      this.headers = websocketOptions._nodeOnlyHeaders;\n    } else {\n      this.headers = {};\n    }\n\n    if (!(\"Authorization\" in this.headers)) {\n      this.headers[\"Authorization\"] = `Token ${key}`; // Add default token\n    }\n  }\n\n  /**\n   * Connects the socket, unless already connected.\n   *\n   * @protected Can only be called from within the class.\n   */\n  protected connect(transcriptionOptions: LiveSchema, endpoint: string): void {\n    if (this.conn) {\n      return;\n    }\n\n    this.reconnect = (options = transcriptionOptions) => {\n      this.connect(options, endpoint);\n    };\n\n    const requestUrl = this.getRequestUrl(endpoint, {}, transcriptionOptions);\n\n    /**\n     * Custom websocket transport\n     */\n    if (this.transport) {\n      this.conn = new this.transport(requestUrl, undefined, {\n        headers: this.headers,\n      });\n      return;\n    }\n\n    /**\n     * @summary Bun websocket transport has a bug where it's native WebSocket implementation messes up the headers\n     * @summary This is a workaround to use the WS package for the websocket connection instead of the native Bun WebSocket\n     * @summary you can track the issue here\n     * @link https://github.com/oven-sh/bun/issues/4529\n     */\n    if (isBun()) {\n      import(\"ws\").then(({ default: WS }) => {\n        this.conn = new WS(requestUrl, {\n          headers: this.headers,\n        });\n        console.log(`Using WS package`);\n        this.setupConnection();\n      });\n      return;\n    }\n\n    /**\n     * Native websocket transport (browser)\n     */\n    if (NATIVE_WEBSOCKET_AVAILABLE) {\n      this.conn = new WebSocket(requestUrl, [\"token\", this.namespaceOptions.key]);\n      this.setupConnection();\n      return;\n    }\n\n    /**\n     * Dummy websocket\n     */\n    this.conn = new WSWebSocketDummy(requestUrl, undefined, {\n      close: () => {\n        this.conn = null;\n      },\n    });\n\n    /**\n     * WS package for node environment\n     */\n    import(\"ws\").then(({ default: WS }) => {\n      this.conn = new WS(requestUrl, undefined, {\n        headers: this.headers,\n      });\n      this.setupConnection();\n    });\n  }\n\n  /**\n   * Reconnects the socket using new or existing transcription options.\n   *\n   * @param options - The transcription options to use when reconnecting the socket.\n   */\n  public reconnect: (options: LiveSchema) => void = noop;\n\n  /**\n   * Disconnects the socket from the client.\n   *\n   * @param code A numeric status code to send on disconnect.\n   * @param reason A custom reason for the disconnect.\n   */\n  public disconnect(code?: number, reason?: string): void {\n    if (this.conn) {\n      this.conn.onclose = function () {}; // noop\n      if (code) {\n        this.conn.close(code, reason ?? \"\");\n      } else {\n        this.conn.close();\n      }\n      this.conn = null;\n    }\n  }\n\n  /**\n   * Returns the current connection state of the WebSocket connection.\n   *\n   * @returns The current connection state of the WebSocket connection.\n   */\n  public connectionState(): CONNECTION_STATE {\n    switch (this.conn && this.conn.readyState) {\n      case SOCKET_STATES.connecting:\n        return CONNECTION_STATE.Connecting;\n      case SOCKET_STATES.open:\n        return CONNECTION_STATE.Open;\n      case SOCKET_STATES.closing:\n        return CONNECTION_STATE.Closing;\n      default:\n        return CONNECTION_STATE.Closed;\n    }\n  }\n\n  /**\n   * Returns the current ready state of the WebSocket connection.\n   *\n   * @returns The current ready state of the WebSocket connection.\n   */\n  public getReadyState(): SOCKET_STATES {\n    return this.conn?.readyState ?? SOCKET_STATES.closed;\n  }\n\n  /**\n   * Returns `true` is the connection is open.\n   */\n  public isConnected(): boolean {\n    return this.connectionState() === CONNECTION_STATE.Open;\n  }\n\n  /**\n   * Sends data to the Deepgram API via websocket connection\n   * @param data Audio data to send to Deepgram\n   *\n   * Conforms to RFC #146 for Node.js - does not send an empty byte.\n   * @see https://github.com/deepgram/deepgram-python-sdk/issues/146\n   */\n  send(data: SocketDataLike): void {\n    const callback = async () => {\n      if (data instanceof Blob) {\n        if (data.size === 0) {\n          this.log(\"warn\", \"skipping `send` for zero-byte blob\", data);\n\n          return;\n        }\n\n        data = await data.arrayBuffer();\n      }\n\n      if (typeof data !== \"string\") {\n        if (data.byteLength === 0) {\n          this.log(\"warn\", \"skipping `send` for zero-byte blob\", data);\n\n          return;\n        }\n      }\n\n      this.conn?.send(data);\n    };\n\n    if (this.isConnected()) {\n      callback();\n    } else {\n      this.sendBuffer.push(callback);\n    }\n  }\n\n  /**\n   * Determines whether the current instance should proxy requests.\n   * @returns {boolean} true if the current instance should proxy requests; otherwise, false\n   */\n  get proxy(): boolean {\n    return this.key === \"proxy\" && !!this.namespaceOptions.websocket.options.proxy?.url;\n  }\n\n  /**\n   * Sets up the connection event handlers.\n   *\n   * @abstract Requires subclasses to set up context aware event handlers.\n   */\n  abstract setupConnection(): void;\n}\n\nclass WSWebSocketDummy {\n  binaryType: string = \"arraybuffer\";\n  close: Function;\n  onclose: Function = () => {};\n  onerror: Function = () => {};\n  onmessage: Function = () => {};\n  onopen: Function = () => {};\n  readyState: number = SOCKET_STATES.connecting;\n  send: Function = () => {};\n  url: string | URL | null = null;\n\n  constructor(address: URL, _protocols: undefined, options: { close: Function }) {\n    this.url = address.toString();\n    this.close = options.close;\n  }\n}\n\nexport { AbstractLiveClient as AbstractWsClient };\n","import { resolveHeadersConstructor } from \"./helpers\";\nimport crossFetch from \"cross-fetch\";\nimport type { Fetch } from \"./types\";\n\n/**\n * Resolves the appropriate fetch function to use, either a custom fetch function provided as an argument, or the global fetch function if available, or the cross-fetch library if the global fetch function is not available.\n *\n * @param customFetch - An optional custom fetch function to use instead of the global fetch function.\n * @returns A fetch function that can be used to make HTTP requests.\n */\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  let _fetch: Fetch;\n\n  if (customFetch) {\n    _fetch = customFetch;\n  } else if (typeof fetch === \"undefined\") {\n    _fetch = crossFetch as unknown as Fetch;\n  } else {\n    _fetch = fetch;\n  }\n\n  return (...args) => _fetch(...args);\n};\n\n/**\n * Resolves a fetch function that includes an \"Authorization\" header with the provided API key.\n *\n * @param apiKey - The API key to include in the \"Authorization\" header.\n * @param customFetch - An optional custom fetch function to use instead of the global fetch function.\n * @returns A fetch function that can be used to make HTTP requests with the provided API key in the \"Authorization\" header.\n */\nexport const fetchWithAuth = (apiKey: string, customFetch?: Fetch): Fetch => {\n  const fetch = resolveFetch(customFetch);\n  const HeadersConstructor = resolveHeadersConstructor();\n\n  return async (input, init) => {\n    const headers = new HeadersConstructor(init?.headers);\n\n    if (!headers.has(\"Authorization\")) {\n      headers.set(\"Authorization\", `Token ${apiKey}`);\n    }\n\n    return fetch(input, { ...init, headers });\n  };\n};\n\n/**\n * Resolves the appropriate Response object to use, either the global Response object if available, or the Response object from the cross-fetch library if the global Response object is not available.\n *\n * @returns The appropriate Response object to use for making HTTP requests.\n */\nexport const resolveResponse = async () => {\n  if (typeof Response === \"undefined\") {\n    return (await import(\"cross-fetch\")).Response;\n  }\n\n  return Response;\n};\n","import { DeepgramApiError, DeepgramError, DeepgramUnknownError } from \"../lib/errors\";\nimport { Readable } from \"stream\";\nimport { fetchWithAuth, resolveResponse } from \"../lib/fetch\";\nimport type { Fetch, FetchOptions, RequestMethodType } from \"../lib/types/Fetch\";\nimport { AbstractClient } from \"./AbstractClient\";\nimport { DeepgramClientOptions } from \"../lib/types\";\nimport { isBrowser } from \"../lib/helpers\";\nimport merge from \"deepmerge\";\n\n/**\n * An abstract class that extends `AbstractClient` and provides a base implementation for a REST-based API client.\n * This class handles authentication, error handling, and other common functionality for REST API clients.\n */\nexport abstract class AbstractRestClient extends AbstractClient {\n  protected fetch: Fetch;\n\n  /**\n   * Constructs a new instance of the `AbstractRestClient` class with the provided options.\n   *\n   * @param options - The client options to use for this instance.\n   * @throws {DeepgramError} If the client is being used in a browser and no proxy is provided.\n   */\n  constructor(options: DeepgramClientOptions) {\n    super(options);\n\n    if (isBrowser() && !this.proxy) {\n      throw new DeepgramError(\n        \"Due to CORS we are unable to support REST-based API calls to our API from the browser. Please consider using a proxy: https://dpgr.am/js-proxy for more information.\"\n      );\n    }\n\n    this.fetch = fetchWithAuth(this.key, this.namespaceOptions.fetch.client);\n\n    if (this.proxy) {\n      this.baseUrl = this.namespaceOptions.fetch.options.proxy!.url;\n    } else {\n      this.baseUrl = this.namespaceOptions.fetch.options.url;\n    }\n  }\n\n  /**\n   * Constructs an error message from the provided error object.\n   *\n   * @param err - The error object to extract the error message from.\n   * @returns The constructed error message.\n   */\n  protected _getErrorMessage(err: any): string {\n    return err.msg || err.message || err.error_description || err.error || JSON.stringify(err);\n  }\n\n  /**\n   * Handles an error that occurred during a request.\n   *\n   * @param error - The error that occurred during the request.\n   * @param reject - The rejection function to call with the error.\n   * @returns A Promise that resolves when the error has been handled.\n   */\n  protected async _handleError(error: unknown, reject: (reason?: any) => void) {\n    const Res = await resolveResponse();\n\n    if (error instanceof Res) {\n      error\n        .json()\n        .then((err) => {\n          reject(new DeepgramApiError(this._getErrorMessage(err), error.status || 500));\n        })\n        .catch((err) => {\n          reject(new DeepgramUnknownError(this._getErrorMessage(err), err));\n        });\n    } else {\n      reject(new DeepgramUnknownError(this._getErrorMessage(error), error));\n    }\n  }\n\n  /**\n   * Constructs the options object to be used for a fetch request.\n   *\n   * @param method - The HTTP method to use for the request, such as \"GET\", \"POST\", \"PUT\", \"PATCH\", or \"DELETE\".\n   * @param bodyOrOptions - For \"POST\", \"PUT\", and \"PATCH\" requests, the request body as a string, Buffer, or Readable stream. For \"GET\" and \"DELETE\" requests, the fetch options to use.\n   * @param options - Additional fetch options to use for the request.\n   * @returns The constructed fetch options object.\n   */\n  protected _getRequestOptions(\n    method: RequestMethodType,\n    bodyOrOptions?: string | Buffer | Readable | FetchOptions,\n    options?: FetchOptions\n  ): FetchOptions {\n    let reqOptions: FetchOptions = { method };\n\n    if (method === \"GET\" || method === \"DELETE\") {\n      reqOptions = { ...reqOptions, ...(bodyOrOptions as FetchOptions) };\n    } else {\n      reqOptions = {\n        duplex: \"half\",\n        body: bodyOrOptions as BodyInit,\n        ...reqOptions,\n        ...options,\n      };\n    }\n\n    return merge(this.namespaceOptions.fetch.options, reqOptions, { clone: false });\n  }\n\n  /**\n   * Handles an HTTP request using the provided method, URL, and optional request body and options.\n   *\n   * @param method - The HTTP method to use for the request, such as \"GET\", \"POST\", \"PUT\", \"PATCH\", or \"DELETE\".\n   * @param url - The URL to send the request to.\n   * @param bodyOrOptions - For \"POST\", \"PUT\", and \"PATCH\" requests, the request body as a string, Buffer, or Readable stream. For \"GET\" and \"DELETE\" requests, the fetch options to use.\n   * @param options - Additional fetch options to use for the request.\n   * @returns A Promise that resolves to the Response object for the request.\n   */\n  protected async _handleRequest(\n    method: \"GET\" | \"DELETE\",\n    url: URL,\n    options?: FetchOptions\n  ): Promise<Response>;\n  protected async _handleRequest(\n    method: \"POST\" | \"PUT\" | \"PATCH\",\n    url: URL,\n    body: string | Buffer | Readable,\n    options?: FetchOptions\n  ): Promise<Response>;\n  protected async _handleRequest(\n    method: RequestMethodType,\n    url: URL,\n    bodyOrOptions?: string | Buffer | Readable | FetchOptions,\n    options?: FetchOptions\n  ): Promise<Response> {\n    return new Promise((resolve, reject) => {\n      const fetcher = this.fetch;\n\n      fetcher(url, this._getRequestOptions(method, bodyOrOptions, options))\n        .then((result) => {\n          if (!result.ok) throw result;\n          resolve(result);\n        })\n        .catch((error) => this._handleError(error, reject));\n    });\n  }\n\n  /**\n   * Handles an HTTP GET request using the provided URL and optional request options.\n   *\n   * @param url - The URL to send the GET request to.\n   * @param options - Additional fetch options to use for the GET request.\n   * @returns A Promise that resolves to the Response object for the GET request.\n   */\n  protected async get(url: URL, options?: FetchOptions): Promise<any> {\n    return this._handleRequest(\"GET\", url, options);\n  }\n\n  /**\n   * Handles an HTTP POST request using the provided URL, request body, and optional request options.\n   *\n   * @param url - The URL to send the POST request to.\n   * @param body - The request body as a string, Buffer, or Readable stream.\n   * @param options - Additional fetch options to use for the POST request.\n   * @returns A Promise that resolves to the Response object for the POST request.\n   */\n  protected async post(\n    url: URL,\n    body: string | Buffer | Readable,\n    options?: FetchOptions\n  ): Promise<any> {\n    return this._handleRequest(\"POST\", url, body, options);\n  }\n\n  /**\n   * Handles an HTTP PUT request using the provided URL, request body, and optional request options.\n   *\n   * @param url - The URL to send the PUT request to.\n   * @param body - The request body as a string, Buffer, or Readable stream.\n   * @param options - Additional fetch options to use for the PUT request.\n   * @returns A Promise that resolves to the Response object for the PUT request.\n   */\n  protected async put(\n    url: URL,\n    body: string | Buffer | Readable,\n    options?: FetchOptions\n  ): Promise<any> {\n    return this._handleRequest(\"PUT\", url, body, options);\n  }\n\n  /**\n   * Handles an HTTP PATCH request using the provided URL, request body, and optional request options.\n   *\n   * @param url - The URL to send the PATCH request to.\n   * @param body - The request body as a string, Buffer, or Readable stream.\n   * @param options - Additional fetch options to use for the PATCH request.\n   * @returns A Promise that resolves to the Response object for the PATCH request.\n   */\n  protected async patch(\n    url: URL,\n    body: string | Buffer | Readable,\n    options?: FetchOptions\n  ): Promise<any> {\n    return this._handleRequest(\"PATCH\", url, body, options);\n  }\n\n  /**\n   * Handles an HTTP DELETE request using the provided URL and optional request options.\n   *\n   * @param url - The URL to send the DELETE request to.\n   * @param options - Additional fetch options to use for the DELETE request.\n   * @returns A Promise that resolves to the Response object for the DELETE request.\n   */\n  protected async delete(url: URL, options?: FetchOptions): Promise<any> {\n    return this._handleRequest(\"DELETE\", url, options);\n  }\n\n  /**\n   * Determines whether the current instance should proxy requests.\n   * @returns {boolean} true if the current instance should proxy requests; otherwise, false\n   */\n  get proxy(): boolean {\n    return this.key === \"proxy\" && !!this.namespaceOptions.fetch.options.proxy?.url;\n  }\n}\n\nexport { AbstractRestClient as AbstractRestfulClient };\n","/**\n * Enumeration of events related to live transcription.\n *\n * - `Open`: Built-in socket event for when the connection is opened.\n * - `Close`: Built-in socket event for when the connection is closed.\n * - `Error`: Built-in socket event for when an error occurs.\n * - `Transcript`: Event for when a transcript message is received.\n * - `Metadata`: Event for when metadata is received.\n * - `UtteranceEnd`: Event for when an utterance ends.\n * - `SpeechStarted`: Event for when speech is detected.\n * - `Unhandled`: Catch-all event for any other message event.\n */\nexport enum LiveTranscriptionEvents {\n  /**\n   * Built in socket events.\n   */\n  Open = \"open\",\n  Close = \"close\",\n  Error = \"error\",\n\n  /**\n   * Message { type: string }\n   */\n  Transcript = \"Results\",\n  Metadata = \"Metadata\",\n  UtteranceEnd = \"UtteranceEnd\",\n  SpeechStarted = \"SpeechStarted\",\n\n  /**\n   * Catch all for any other message event\n   */\n  Unhandled = \"Unhandled\",\n}\n","/**\n * Enumeration of events related to live text-to-speech synthesis.\n *\n * - `Open`: Built-in socket event for when the connection is opened.\n * - `Close`: Built-in socket event for when the connection is closed.\n * - `Error`: Built-in socket event for when an error occurs.\n * - `Metadata`: Event for when metadata is received.\n * - `Flushed`: Event for when the server has flushed the buffer.\n * - `Warning`: Event for when a warning is received.\n * - `Unhandled`: Catch-all event for any other message event.\n */\nexport enum LiveTTSEvents {\n  /**\n   * Built in socket events.\n   */\n  Open = \"Open\",\n  Close = \"Close\",\n  Error = \"Error\",\n\n  /**\n   * Message { type: string }\n   */\n  Metadata = \"Metadata\",\n  Flushed = \"Flushed\",\n  Warning = \"Warning\",\n\n  /**\n   * Audio data event.\n   */\n  Audio = \"Audio\",\n\n  /**\n   * Catch all for any other message event\n   */\n  Unhandled = \"Unhandled\",\n}\n","import { AbstractLiveClient } from \"./AbstractLiveClient\";\nimport { LiveTranscriptionEvents } from \"../lib/enums\";\nimport type { LiveSchema, LiveConfigOptions, DeepgramClientOptions } from \"../lib/types\";\n\n/**\n * The `ListenLiveClient` class extends the `AbstractLiveClient` class and provides functionality for setting up and managing a WebSocket connection for live transcription.\n *\n * The constructor takes in `DeepgramClientOptions` and an optional `LiveSchema` object, as well as an optional `endpoint` string. It then calls the `connect` method of the parent `AbstractLiveClient` class to establish the WebSocket connection.\n *\n * The `setupConnection` method is responsible for handling the various events that can occur on the WebSocket connection, such as opening, closing, and receiving messages. It sets up event handlers for these events and emits the appropriate events based on the message type.\n *\n * The `configure` method allows you to send additional configuration options to the connected session, such as enabling numerals.\n *\n * The `keepAlive` method sends a \"KeepAlive\" message to the server to maintain the connection.\n *\n * The `requestClose` method requests the server to close the connection.\n *\n * The `finish` method is deprecated as of version 3.4 and will be removed in version 4.0. Use `requestClose` instead.\n */\nexport class ListenLiveClient extends AbstractLiveClient {\n  public namespace: string = \"listen\";\n\n  /**\n   * Constructs a new `ListenLiveClient` instance with the provided options.\n   *\n   * @param options - The `DeepgramClientOptions` to use for the client connection.\n   * @param transcriptionOptions - An optional `LiveSchema` object containing additional configuration options for the live transcription.\n   * @param endpoint - An optional string representing the WebSocket endpoint to connect to. Defaults to `:version/listen`.\n   */\n  constructor(\n    options: DeepgramClientOptions,\n    transcriptionOptions: LiveSchema = {},\n    endpoint: string = \":version/listen\"\n  ) {\n    super(options);\n\n    this.connect(transcriptionOptions, endpoint);\n  }\n\n  /**\n   * Sets up the connection event handlers.\n   * This method is responsible for handling the various events that can occur on the WebSocket connection, such as opening, closing, and receiving messages.\n   * - When the connection is opened, it emits the `LiveTranscriptionEvents.Open` event.\n   * - When the connection is closed, it emits the `LiveTranscriptionEvents.Close` event.\n   * - When an error occurs on the connection, it emits the `LiveTranscriptionEvents.Error` event.\n   * - When a message is received, it parses the message and emits the appropriate event based on the message type, such as `LiveTranscriptionEvents.Metadata`, `LiveTranscriptionEvents.Transcript`, `LiveTranscriptionEvents.UtteranceEnd`, and `LiveTranscriptionEvents.SpeechStarted`.\n   */\n  public setupConnection(): void {\n    if (this.conn) {\n      this.conn.onopen = () => {\n        this.emit(LiveTranscriptionEvents.Open, this);\n      };\n\n      this.conn.onclose = (event: any) => {\n        this.emit(LiveTranscriptionEvents.Close, event);\n      };\n\n      this.conn.onerror = (event: ErrorEvent) => {\n        this.emit(LiveTranscriptionEvents.Error, event);\n      };\n\n      this.conn.onmessage = (event: MessageEvent) => {\n        try {\n          const data: any = JSON.parse(event.data.toString());\n\n          if (data.type === LiveTranscriptionEvents.Metadata) {\n            this.emit(LiveTranscriptionEvents.Metadata, data);\n          } else if (data.type === LiveTranscriptionEvents.Transcript) {\n            this.emit(LiveTranscriptionEvents.Transcript, data);\n          } else if (data.type === LiveTranscriptionEvents.UtteranceEnd) {\n            this.emit(LiveTranscriptionEvents.UtteranceEnd, data);\n          } else if (data.type === LiveTranscriptionEvents.SpeechStarted) {\n            this.emit(LiveTranscriptionEvents.SpeechStarted, data);\n          } else {\n            this.emit(LiveTranscriptionEvents.Unhandled, data);\n          }\n        } catch (error) {\n          this.emit(LiveTranscriptionEvents.Error, {\n            event,\n            message: \"Unable to parse `data` as JSON.\",\n            error,\n          });\n        }\n      };\n    }\n  }\n\n  /**\n   * Sends additional config to the connected session.\n   *\n   * @param config - The configuration options to apply to the LiveClient.\n   * @param config.numerals - We currently only support numerals.\n   */\n  public configure(config: LiveConfigOptions): void {\n    this.send(\n      JSON.stringify({\n        type: \"Configure\",\n        processors: config,\n      })\n    );\n  }\n\n  /**\n   * Sends a \"KeepAlive\" message to the server to maintain the connection.\n   */\n  public keepAlive(): void {\n    this.send(\n      JSON.stringify({\n        type: \"KeepAlive\",\n      })\n    );\n  }\n\n  /**\n   * Sends a \"Finalize\" message to flush any transcription sitting in the server's buffer.\n   */\n  public finalize(): void {\n    this.send(\n      JSON.stringify({\n        type: \"Finalize\",\n      })\n    );\n  }\n\n  /**\n   * @deprecated Since version 3.4. Will be removed in version 4.0. Use `requestClose` instead.\n   */\n  public finish(): void {\n    this.requestClose();\n  }\n\n  /**\n   * Requests the server close the connection.\n   */\n  public requestClose(): void {\n    this.send(\n      JSON.stringify({\n        type: \"CloseStream\",\n      })\n    );\n  }\n}\n\nexport { ListenLiveClient as LiveClient };\n","import { CallbackUrl, isFileSource, isUrlSource } from \"../lib/helpers\";\nimport { DeepgramError, isDeepgramError } from \"../lib/errors\";\nimport type {\n  AsyncPrerecordedResponse,\n  DeepgramResponse,\n  FileSource,\n  PrerecordedSchema,\n  SyncPrerecordedResponse,\n  UrlSource,\n} from \"../lib/types\";\nimport { AbstractRestClient } from \"./AbstractRestClient\";\n\n/**\n * The `ListenRestClient` class extends the `AbstractRestClient` class and provides methods for transcribing audio from URLs or files using the Deepgram API.\n *\n * The `transcribeUrl` method is used to transcribe audio from a URL synchronously. It takes a `UrlSource` object as the source, an optional `PrerecordedSchema` object as options, and an optional endpoint string. It returns a `DeepgramResponse` object containing the transcription result or an error.\n *\n * The `transcribeFile` method is used to transcribe audio from a file synchronously. It takes a `FileSource` object as the source, an optional `PrerecordedSchema` object as options, and an optional endpoint string. It returns a `DeepgramResponse` object containing the transcription result or an error.\n *\n * The `transcribeUrlCallback` method is used to transcribe audio from a URL asynchronously. It takes a `UrlSource` object as the source, a `CallbackUrl` object as the callback, an optional `PrerecordedSchema` object as options, and an optional endpoint string. It returns a `DeepgramResponse` object containing the transcription result or an error.\n *\n * The `transcribeFileCallback` method is used to transcribe audio from a file asynchronously. It takes a `FileSource` object as the source, a `CallbackUrl` object as the callback, an optional `PrerecordedSchema` object as options, and an optional endpoint string. It returns a `DeepgramResponse` object containing the transcription result or an error.\n */\nexport class ListenRestClient extends AbstractRestClient {\n  public namespace: string = \"listen\";\n\n  /**\n   * Transcribes audio from a URL synchronously.\n   *\n   * @param source - The URL source object containing the audio URL to transcribe.\n   * @param options - An optional `PrerecordedSchema` object containing additional options for the transcription.\n   * @param endpoint - An optional endpoint string to use for the transcription request.\n   * @returns A `DeepgramResponse` object containing the transcription result or an error.\n   */\n  async transcribeUrl(\n    source: UrlSource,\n    options?: PrerecordedSchema,\n    endpoint = \":version/listen\"\n  ): Promise<DeepgramResponse<SyncPrerecordedResponse>> {\n    try {\n      let body;\n\n      if (isUrlSource(source)) {\n        body = JSON.stringify(source);\n      } else {\n        throw new DeepgramError(\"Unknown transcription source type\");\n      }\n\n      if (options !== undefined && \"callback\" in options) {\n        throw new DeepgramError(\n          \"Callback cannot be provided as an option to a synchronous transcription. Use `transcribeUrlCallback` or `transcribeFileCallback` instead.\"\n        );\n      }\n\n      const requestUrl = this.getRequestUrl(endpoint, {}, { ...{}, ...options });\n      const result: SyncPrerecordedResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Transcribes audio from a file asynchronously.\n   *\n   * @param source - The file source object containing the audio file to transcribe.\n   * @param options - An optional `PrerecordedSchema` object containing additional options for the transcription.\n   * @param endpoint - An optional endpoint string to use for the transcription request.\n   * @returns A `DeepgramResponse` object containing the transcription result or an error.\n   */\n  async transcribeFile(\n    source: FileSource,\n    options?: PrerecordedSchema,\n    endpoint = \":version/listen\"\n  ): Promise<DeepgramResponse<SyncPrerecordedResponse>> {\n    try {\n      let body;\n\n      if (isFileSource(source)) {\n        body = source;\n      } else {\n        throw new DeepgramError(\"Unknown transcription source type\");\n      }\n\n      if (options !== undefined && \"callback\" in options) {\n        throw new DeepgramError(\n          \"Callback cannot be provided as an option to a synchronous transcription. Use `transcribeUrlCallback` or `transcribeFileCallback` instead.\"\n        );\n      }\n\n      const requestUrl = this.getRequestUrl(endpoint, {}, { ...{}, ...options });\n      const result: SyncPrerecordedResponse = await this.post(requestUrl, body, {\n        headers: { \"Content-Type\": \"deepgram/audio+video\" },\n      }).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Transcribes audio from a URL asynchronously.\n   *\n   * @param source - The URL source object containing the audio file to transcribe.\n   * @param callback - The callback URL to receive the transcription result.\n   * @param options - An optional `PrerecordedSchema` object containing additional options for the transcription.\n   * @param endpoint - An optional endpoint string to use for the transcription request.\n   * @returns A `DeepgramResponse` object containing the transcription result or an error.\n   */\n  async transcribeUrlCallback(\n    source: UrlSource,\n    callback: CallbackUrl,\n    options?: PrerecordedSchema,\n    endpoint = \":version/listen\"\n  ): Promise<DeepgramResponse<AsyncPrerecordedResponse>> {\n    try {\n      let body;\n\n      if (isUrlSource(source)) {\n        body = JSON.stringify(source);\n      } else {\n        throw new DeepgramError(\"Unknown transcription source type\");\n      }\n\n      const requestUrl = this.getRequestUrl(\n        endpoint,\n        {},\n        { ...options, callback: callback.toString() }\n      );\n      const result: AsyncPrerecordedResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Transcribes audio from a file asynchronously.\n   *\n   * @param source - The file source object containing the audio file to transcribe.\n   * @param callback - The callback URL to receive the transcription result.\n   * @param options - An optional `PrerecordedSchema` object containing additional options for the transcription.\n   * @param endpoint - An optional endpoint string to use for the transcription request.\n   * @returns A `DeepgramResponse` object containing the transcription result or an error.\n   */\n  async transcribeFileCallback(\n    source: FileSource,\n    callback: CallbackUrl,\n    options?: PrerecordedSchema,\n    endpoint = \":version/listen\"\n  ): Promise<DeepgramResponse<AsyncPrerecordedResponse>> {\n    try {\n      let body;\n\n      if (isFileSource(source)) {\n        body = source;\n      } else {\n        throw new DeepgramError(\"Unknown transcription source type\");\n      }\n\n      const requestUrl = this.getRequestUrl(\n        endpoint,\n        {},\n        { ...options, callback: callback.toString() }\n      );\n      const result: AsyncPrerecordedResponse = await this.post(requestUrl, body, {\n        headers: { \"Content-Type\": \"deepgram/audio+video\" },\n      }).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n}\n\nexport { ListenRestClient as PrerecordedClient };\n","import { AbstractClient } from \"./AbstractClient\";\nimport { ListenLiveClient } from \"./ListenLiveClient\";\nimport { ListenRestClient } from \"./ListenRestClient\";\nimport { LiveSchema } from \"../lib/types\";\n\n/**\n * The `ListenClient` class extends the `AbstractClient` class and provides access to the \"listen\" namespace.\n * It exposes two methods:\n *\n * 1. `prerecorded()`: Returns a `ListenRestClient` instance for interacting with the prerecorded listen API.\n * 2. `live(transcriptionOptions: LiveSchema = {}, endpoint = \":version/listen\")`: Returns a `ListenLiveClient` instance for interacting with the live listen API, with the provided transcription options and endpoint.\n */\nexport class ListenClient extends AbstractClient {\n  public namespace: string = \"listen\";\n\n  /**\n   * Returns a `ListenRestClient` instance for interacting with the prerecorded listen API.\n   */\n  get prerecorded() {\n    return new ListenRestClient(this.options);\n  }\n\n  /**\n   * Returns a `ListenLiveClient` instance for interacting with the live listen API, with the provided transcription options and endpoint.\n   * @param {LiveSchema} [transcriptionOptions={}] - The transcription options to use for the live listen API.\n   * @param {string} [endpoint=\":version/listen\"] - The endpoint to use for the live listen API.\n   * @returns {ListenLiveClient} - A `ListenLiveClient` instance for interacting with the live listen API.\n   */\n  public live(\n    transcriptionOptions: LiveSchema = {},\n    endpoint: string = \":version/listen\"\n  ): ListenLiveClient {\n    return new ListenLiveClient(this.options, transcriptionOptions, endpoint);\n  }\n}\n","import { isDeepgramError } from \"../lib/errors\";\nimport type {\n  CreateProjectKeySchema,\n  CreateProjectKeyResponse,\n  DeepgramResponse,\n  GetProjectBalanceResponse,\n  GetProjectBalancesResponse,\n  GetProjectInvitesResponse,\n  GetProjectKeyResponse,\n  GetProjectKeysResponse,\n  GetProjectMemberScopesResponse,\n  GetProjectMembersResponse,\n  GetProjectResponse,\n  GetProjectsResponse,\n  GetProjectUsageFieldsSchema,\n  GetProjectUsageFieldsResponse,\n  GetProjectUsageRequestResponse,\n  GetProjectUsageRequestsSchema,\n  GetProjectUsageRequestsResponse,\n  GetProjectUsageSummarySchema,\n  GetProjectUsageSummaryResponse,\n  MessageResponse,\n  SendProjectInviteSchema,\n  UpdateProjectMemberScopeSchema,\n  UpdateProjectSchema,\n  VoidResponse,\n  GetTokenDetailsResponse,\n  GetModelsResponse,\n  GetModelResponse,\n  GetModelsSchema,\n} from \"../lib/types\";\nimport { AbstractRestClient } from \"./AbstractRestClient\";\n\n/**\n * The `ManageRestClient` class provides a set of methods for interacting with the Deepgram Manage API. It extends the `AbstractRestClient` class and provides functionality for managing projects, keys, members, invites, usage, and balances.\n *\n * The class has a `namespace` property that is set to `\"manage\"`, which is used in the construction of the request URLs.\n *\n * The methods in this class include:\n * - `getTokenDetails`: Retrieves the details of the current authentication token.\n * - `getProjects`: Retrieves a list of all projects associated with the authenticated account.\n * - `getProject`: Retrieves the details of a specific project.\n * - `updateProject`: Updates the details of a specific project.\n * - `deleteProject`: Deletes a specific project.\n * - `getProjectKeys`: Retrieves a list of all API keys associated with a specific project.\n * - `getProjectKey`: Retrieves the details of a specific API key.\n * - `createProjectKey`: Creates a new API key for a specific project.\n * - `deleteProjectKey`: Deletes a specific API key.\n * - `getProjectMembers`: Retrieves a list of all members associated with a specific project.\n * - `removeProjectMember`: Removes a specific member from a project.\n * - `getProjectMemberScopes`: Retrieves the scopes associated with a specific project member.\n * - `updateProjectMemberScope`: Updates the scopes associated with a specific project member.\n * - `getProjectInvites`: Retrieves a list of all pending invitations for a specific project.\n * - `sendProjectInvite`: Sends a new invitation to a specific email address for a project.\n * - `deleteProjectInvite`: Deletes a specific invitation for a project.\n * - `leaveProject`: Removes the authenticated user from a specific project.\n * - `getProjectUsageRequests`: Retrieves a list of all usage requests for a specific project.\n * - `getProjectUsageRequest`: Retrieves the details of a specific usage request.\n * - `getProjectUsageSummary`: Retrieves a summary of the usage for a specific project.\n * - `getProjectUsageFields`: Retrieves a list of the available usage fields for a specific project.\n * - `getProjectBalances`: Retrieves a list of all balances associated with a specific project.\n * - `getProjectBalance`: Retrieves the details of a specific balance for a project.\n */\n/**\n * The `ManageRestClient` class provides a set of methods for interacting with the Deepgram Manage API. It extends the `AbstractRestClient` class and provides functionality for managing projects, keys, members, invites, usage, and balances.\n *\n * The class has a `namespace` property that is set to `\"manage\"`, which is used in the construction of the request URLs.\n *\n * The methods in this class include:\n * - `getTokenDetails`: Retrieves the details of the current authentication token.\n * - `getProjects`: Retrieves a list of all projects associated with the authenticated account.\n * - `getProject`: Retrieves the details of a specific project.\n * - `updateProject`: Updates the details of a specific project.\n * - `deleteProject`: Deletes a specific project.\n * - `getProjectKeys`: Retrieves a list of all API keys associated with a specific project.\n * - `getProjectKey`: Retrieves the details of a specific API key.\n * - `createProjectKey`: Creates a new API key for a specific project.\n * - `deleteProjectKey`: Deletes a specific API key.\n * - `getProjectMembers`: Retrieves a list of all members associated with a specific project.\n * - `removeProjectMember`: Removes a specific member from a project.\n * - `getProjectMemberScopes`: Retrieves the scopes associated with a specific project member.\n * - `updateProjectMemberScope`: Updates the scopes associated with a specific project member.\n * - `getProjectInvites`: Retrieves a list of all pending invitations for a specific project.\n * - `sendProjectInvite`: Sends a new invitation to a specific email address for a project.\n * - `deleteProjectInvite`: Deletes a specific invitation for a project.\n * - `leaveProject`: Removes the authenticated user from a specific project.\n * - `getProjectUsageRequests`: Retrieves a list of all usage requests for a specific project.\n * - `getProjectUsageRequest`: Retrieves the details of a specific usage request.\n * - `getProjectUsageSummary`: Retrieves a summary of the usage for a specific project.\n * - `getProjectUsageFields`: Retrieves a list of the available usage fields for a specific project.\n * - `getProjectBalances`: Retrieves a list of all balances associated with a specific project.\n * - `getProjectBalance`: Retrieves the details of a specific balance for a project.\n */\nexport class ManageRestClient extends AbstractRestClient {\n  public namespace: string = \"manage\";\n\n  /**\n   * Retrieves the details of the current authentication token.\n   *\n   * @returns A promise that resolves to an object containing the token details, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/docs/authenticating#test-request\n   */\n  async getTokenDetails(\n    endpoint = \":version/auth/token\"\n  ): Promise<DeepgramResponse<GetTokenDetailsResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint);\n      const result: GetTokenDetailsResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves a list of all projects associated with the authenticated user.\n   *\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects\".\n   * @returns A promise that resolves to an object containing the list of projects, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/get-projects\n   */\n  async getProjects(\n    endpoint = \":version/projects\"\n  ): Promise<DeepgramResponse<GetProjectsResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint);\n      const result: GetProjectsResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the details of a specific project associated with the authenticated user.\n   *\n   * @param projectId - The ID of the project to retrieve.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId\".\n   * @returns A promise that resolves to an object containing the project details, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/get-project\n   */\n  async getProject(\n    projectId: string,\n    endpoint = \":version/projects/:projectId\"\n  ): Promise<DeepgramResponse<GetProjectResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const result: GetProjectResponse = await this.get(requestUrl).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Updates an existing project associated with the authenticated user.\n   *\n   * @param projectId - The ID of the project to update.\n   * @param options - An object containing the updated project details.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId\".\n   * @returns A promise that resolves to an object containing the response message, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/update-project\n   */\n  async updateProject(\n    projectId: string,\n    options: UpdateProjectSchema,\n    endpoint = \":version/projects/:projectId\"\n  ): Promise<DeepgramResponse<MessageResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId }, options);\n      const body = JSON.stringify(options);\n\n      const result: MessageResponse = await this.patch(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Deletes an existing project associated with the authenticated user.\n   *\n   * @param projectId - The ID of the project to delete.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId\".\n   * @returns A promise that resolves to an object containing the response message, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/delete-project\n   */\n  async deleteProject(\n    projectId: string,\n    endpoint = \":version/projects/:projectId\"\n  ): Promise<VoidResponse> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      await this.delete(requestUrl);\n\n      return { error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves a list of project keys associated with the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve the keys for.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/keys\".\n   * @returns A promise that resolves to an object containing the list of project keys, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/list-keys\n   */\n  async getProjectKeys(\n    projectId: string,\n    endpoint = \":version/projects/:projectId/keys\"\n  ): Promise<DeepgramResponse<GetProjectKeysResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const result: GetProjectKeysResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves a specific project key associated with the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve the key for.\n   * @param keyId - The ID of the project key to retrieve.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/keys/:keyId\".\n   * @returns A promise that resolves to an object containing the project key, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/get-key\n   */\n  async getProjectKey(\n    projectId: string,\n    keyId: string,\n    endpoint = \":version/projects/:projectId/keys/:keyId\"\n  ): Promise<DeepgramResponse<GetProjectKeyResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, keyId });\n      const result: GetProjectKeyResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Creates a new project key for the specified project.\n   *\n   * @param projectId - The ID of the project to create the key for.\n   * @param options - An object containing the options for creating the project key.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/keys\".\n   * @returns A promise that resolves to an object containing the created project key, or an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/create-key\n   */\n  async createProjectKey(\n    projectId: string,\n    options: CreateProjectKeySchema,\n    endpoint = \":version/projects/:projectId/keys\"\n  ): Promise<DeepgramResponse<CreateProjectKeyResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId }, options);\n      const body = JSON.stringify(options);\n\n      const result: CreateProjectKeyResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Deletes the specified project key.\n   *\n   * @param projectId - The ID of the project the key belongs to.\n   * @param keyId - The ID of the key to delete.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/keys/:keyId\".\n   * @returns A promise that resolves to an object containing a null result and an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/delete-key\n   */\n  async deleteProjectKey(\n    projectId: string,\n    keyId: string,\n    endpoint = \":version/projects/:projectId/keys/:keyId\"\n  ): Promise<VoidResponse> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, keyId });\n      await this.delete(requestUrl);\n\n      return { error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the members of the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve members for.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/members\".\n   * @returns A promise that resolves to an object containing the project members and an error object if an error occurs.\n   * @see https://developers.deepgram.com/reference/get-members\n   */\n  async getProjectMembers(\n    projectId: string,\n    endpoint = \":version/projects/:projectId/members\"\n  ): Promise<DeepgramResponse<GetProjectMembersResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const result: GetProjectMembersResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Removes a member from the specified project.\n   *\n   * @param projectId - The ID of the project to remove the member from.\n   * @param memberId - The ID of the member to remove.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/members/:memberId\".\n   * @returns A promise that resolves to an object containing a null error if the operation was successful, or an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/remove-member\n   */\n  async removeProjectMember(\n    projectId: string,\n    memberId: string,\n    endpoint = \":version/projects/:projectId/members/:memberId\"\n  ): Promise<VoidResponse> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, memberId });\n      await this.delete(requestUrl);\n\n      return { error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the scopes for the specified project member.\n   *\n   * @param projectId - The ID of the project to retrieve the member scopes for.\n   * @param memberId - The ID of the member to retrieve the scopes for.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/members/:memberId/scopes\".\n   * @returns A promise that resolves to an object containing the retrieved scopes or an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/get-member-scopes\n   */\n  async getProjectMemberScopes(\n    projectId: string,\n    memberId: string,\n    endpoint = \":version/projects/:projectId/members/:memberId/scopes\"\n  ): Promise<DeepgramResponse<GetProjectMemberScopesResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, memberId });\n      const result: GetProjectMemberScopesResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Updates the scopes for the specified project member.\n   *\n   * @param projectId - The ID of the project to update the member scopes for.\n   * @param memberId - The ID of the member to update the scopes for.\n   * @param options - An object containing the new scopes to apply to the member.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/members/:memberId/scopes\".\n   * @returns A promise that resolves to an object containing the result of the update operation or an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/update-scope\n   */\n  async updateProjectMemberScope(\n    projectId: string,\n    memberId: string,\n    options: UpdateProjectMemberScopeSchema,\n    endpoint = \":version/projects/:projectId/members/:memberId/scopes\"\n  ): Promise<DeepgramResponse<MessageResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, memberId }, options);\n      const body = JSON.stringify(options);\n\n      const result: MessageResponse = await this.put(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the project invites for the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve the invites for.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/invites\".\n   * @returns A promise that resolves to an object containing the result of the get operation or an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/list-invites\n   */\n  async getProjectInvites(\n    projectId: string,\n    endpoint = \":version/projects/:projectId/invites\"\n  ): Promise<DeepgramResponse<GetProjectInvitesResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const result: GetProjectInvitesResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Sends a project invite to the specified email addresses.\n   *\n   * @param projectId - The ID of the project to send the invite for.\n   * @param options - An object containing the email addresses to invite and any additional options.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/invites\".\n   * @returns A promise that resolves to an object containing the result of the post operation or an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/send-invites\n   */\n  async sendProjectInvite(\n    projectId: string,\n    options: SendProjectInviteSchema,\n    endpoint = \":version/projects/:projectId/invites\"\n  ): Promise<DeepgramResponse<MessageResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId }, options);\n      const body = JSON.stringify(options);\n\n      const result: MessageResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Deletes a project invite for the specified email address.\n   *\n   * @param projectId - The ID of the project to delete the invite for.\n   * @param email - The email address of the invite to delete.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/invites/:email\".\n   * @returns A promise that resolves to an object containing a null result and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/delete-invite\n   */\n  async deleteProjectInvite(\n    projectId: string,\n    email: string,\n    endpoint = \":version/projects/:projectId/invites/:email\"\n  ): Promise<VoidResponse> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, email });\n      await this.delete(requestUrl).then((result) => result.json());\n\n      return { error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Leaves the specified project.\n   *\n   * @param projectId - The ID of the project to leave.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/leave\".\n   * @returns A promise that resolves to an object containing a null result and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/leave-project\n   */\n  async leaveProject(\n    projectId: string,\n    endpoint = \":version/projects/:projectId/leave\"\n  ): Promise<DeepgramResponse<MessageResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const result: MessageResponse = await this.delete(requestUrl).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves a list of usage requests for the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve usage requests for.\n   * @param options - An object containing options to filter the usage requests, such as pagination parameters.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/requests\".\n   * @returns A promise that resolves to an object containing the list of usage requests and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/get-all-requests\n   */\n  async getProjectUsageRequests(\n    projectId: string,\n    options: GetProjectUsageRequestsSchema,\n    endpoint = \":version/projects/:projectId/requests\"\n  ): Promise<DeepgramResponse<GetProjectUsageRequestsResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId }, options);\n      const result: GetProjectUsageRequestsResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the details of a specific usage request for the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve the usage request for.\n   * @param requestId - The ID of the usage request to retrieve.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/requests/:requestId\".\n   * @returns A promise that resolves to an object containing the usage request details and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/get-request\n   */\n  async getProjectUsageRequest(\n    projectId: string,\n    requestId: string,\n    endpoint = \":version/projects/:projectId/requests/:requestId\"\n  ): Promise<DeepgramResponse<GetProjectUsageRequestResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, requestId });\n      const result: GetProjectUsageRequestResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the usage summary for the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve the usage summary for.\n   * @param options - An object containing optional parameters for the request, such as filters and pagination options.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/usage\".\n   * @returns A promise that resolves to an object containing the usage summary and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/get-usage\n   */\n  async getProjectUsageSummary(\n    projectId: string,\n    options: GetProjectUsageSummarySchema,\n    endpoint = \":version/projects/:projectId/usage\"\n  ): Promise<DeepgramResponse<GetProjectUsageSummaryResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId }, options);\n      const result: GetProjectUsageSummaryResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the usage fields for the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve the usage fields for.\n   * @param options - An object containing optional parameters for the request, such as filters and pagination options.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/usage/fields\".\n   * @returns A promise that resolves to an object containing the usage fields and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/get-fields\n   */\n  async getProjectUsageFields(\n    projectId: string,\n    options: GetProjectUsageFieldsSchema,\n    endpoint = \":version/projects/:projectId/usage/fields\"\n  ): Promise<DeepgramResponse<GetProjectUsageFieldsResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId }, options);\n      const result: GetProjectUsageFieldsResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the balances for the specified project.\n   *\n   * @param projectId - The ID of the project to retrieve the balances for.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/balances\".\n   * @returns A promise that resolves to an object containing the project balances and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/get-all-balances\n   */\n  async getProjectBalances(\n    projectId: string,\n    endpoint = \":version/projects/:projectId/balances\"\n  ): Promise<DeepgramResponse<GetProjectBalancesResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const result: GetProjectBalancesResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the balance for the specified project and balance ID.\n   *\n   * @param projectId - The ID of the project to retrieve the balance for.\n   * @param balanceId - The ID of the balance to retrieve.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/projects/:projectId/balances/:balanceId\".\n   * @returns A promise that resolves to an object containing the project balance and an error object if an error occurred.\n   * @see https://developers.deepgram.com/reference/get-balance\n   */\n  async getProjectBalance(\n    projectId: string,\n    balanceId: string,\n    endpoint = \":version/projects/:projectId/balances/:balanceId\"\n  ): Promise<DeepgramResponse<GetProjectBalanceResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, balanceId });\n      const result: GetProjectBalanceResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves all models for a given project.\n   *\n   * @param projectId - The ID of the project.\n   * @param endpoint - (optional) The endpoint URL for retrieving models. Defaults to \":version/projects/:projectId/models\".\n   * @returns A promise that resolves to a DeepgramResponse containing the GetModelsResponse.\n   * @example\n   * ```typescript\n   * import { createClient } from \"@deepgram/sdk\";\n   *\n   * const deepgram = createClient(DEEPGRAM_API_KEY);\n   * const { result: models, error } = deepgram.manage.getAllModels(\"projectId\");\n   *\n   * if (error) {\n   *   console.error(error);\n   * } else {\n   *   console.log(models);\n   * }\n   * ```\n   */\n  async getAllModels(\n    projectId: string,\n    options: GetModelsSchema = {},\n    endpoint = \":version/projects/:projectId/models\"\n  ): Promise<DeepgramResponse<GetModelsResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId }, options);\n      const result: GetModelsResponse = await this.get(requestUrl).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves a model from the specified project.\n   *\n   * @param projectId - The ID of the project.\n   * @param modelId - The ID of the model.\n   * @param endpoint - (optional) The endpoint URL for the request. Default value is \":version/projects/:projectId/models/:modelId\".\n   * @returns A promise that resolves to a DeepgramResponse containing the GetModelResponse.\n   * @example\n   * ```typescript\n   * import { createClient } from \"@deepgram/sdk\";\n   *\n   * const deepgram = createClient(DEEPGRAM_API_KEY);\n   * const { result: model, error } = deepgram.models.getModel(\"projectId\", \"modelId\");\n   *\n   * if (error) {\n   *   console.error(error);\n   * } else {\n   *   console.log(model);\n   * }\n   * ```\n   */\n  async getModel(\n    projectId: string,\n    modelId: string,\n    endpoint = \":version/projects/:projectId/models/:modelId\"\n  ): Promise<DeepgramResponse<GetModelResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, modelId });\n      const result: GetModelResponse = await this.get(requestUrl).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n}\n\nexport { ManageRestClient as ManageClient };\n","import { isDeepgramError } from \"../lib/errors\";\nimport {\n  DeepgramResponse,\n  GetModelResponse,\n  GetModelsResponse,\n  GetModelsSchema,\n} from \"../lib/types\";\nimport { AbstractRestClient } from \"./AbstractRestClient\";\n\n/**\n * Represents a REST client for interacting with the Deepgram API.\n *\n * The `ModelsRestClient` class provides methods for interacting with the Deepgram API to retrieve information about available models.\n * @extends AbstractRestClient\n */\nexport class ModelsRestClient extends AbstractRestClient {\n  public namespace: string = \"models\";\n\n  /**\n   * Retrieves a list of all available models.\n   *\n   * @param endpoint - (optional) The endpoint to request.\n   * @returns A promise that resolves with the response from the Deepgram API.\n   * @example\n   * ```typescript\n   * import { createClient } from \"@deepgram/sdk\";\n   *\n   * const deepgram = createClient(DEEPGRAM_API_KEY);\n   * const { result: models, error } = deepgram.models.getAll();\n   *\n   * if (error) {\n   *   console.error(error);\n   * } else {\n   *   console.log(models);\n   * }\n   * ```\n   */\n  async getAll(\n    endpoint = \":version/models\",\n    options: GetModelsSchema = {}\n  ): Promise<DeepgramResponse<GetModelsResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, {}, options);\n      const result: GetModelsResponse = await this.get(requestUrl).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves information about a specific model.\n   *\n   * @param modelId - The UUID of the model to retrieve.\n   * @param endpoint - (optional) The endpoint to request.\n   * @returns A promise that resolves with the response from the Deepgram API.\n   * @example\n   * ```typescript\n   * import { createClient } from \"@deepgram/sdk\";\n   *\n   * const deepgram = createClient(DEEPGRAM_API_KEY);\n   * const { result: model, error } = deepgram.models.getModel(\"modelId\");\n   *\n   * if (error) {\n   *   console.error(error);\n   * } else {\n   *   console.log(model);\n   * }\n   * ```\n   */\n  async getModel(\n    modelId: string,\n    endpoint = \":version/models/:modelId\"\n  ): Promise<DeepgramResponse<GetModelResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { modelId });\n      const result: GetModelResponse = await this.get(requestUrl).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n}\n","import { CallbackUrl, isTextSource, isUrlSource } from \"../lib/helpers\";\nimport { DeepgramError, isDeepgramError } from \"../lib/errors\";\nimport type {\n  AnalyzeSchema,\n  AsyncAnalyzeResponse,\n  DeepgramResponse,\n  SyncAnalyzeResponse,\n  TextSource,\n  UrlSource,\n} from \"../lib/types\";\nimport { AbstractRestClient } from \"./AbstractRestClient\";\n\n/**\n * The `ReadRestClient` class extends the `AbstractRestClient` class and provides methods for analyzing audio sources synchronously and asynchronously.\n *\n * The `analyzeUrl` method analyzes a URL-based audio source synchronously, returning a promise that resolves to the analysis response or an error.\n *\n * The `analyzeText` method analyzes a text-based audio source synchronously, returning a promise that resolves to the analysis response or an error.\n *\n * The `analyzeUrlCallback` method analyzes a URL-based audio source asynchronously, returning a promise that resolves to the analysis response or an error.\n *\n * The `analyzeTextCallback` method analyzes a text-based audio source asynchronously, returning a promise that resolves to the analysis response or an error.\n */\nexport class ReadRestClient extends AbstractRestClient {\n  public namespace: string = \"read\";\n\n  /**\n   * Analyzes a URL-based audio source synchronously.\n   *\n   * @param source - The URL-based audio source to analyze.\n   * @param options - Optional analysis options.\n   * @param endpoint - The API endpoint to use for the analysis. Defaults to \":version/read\".\n   * @returns A promise that resolves to the analysis response, or an error if the analysis fails.\n   */\n  async analyzeUrl(\n    source: UrlSource,\n    options?: AnalyzeSchema,\n    endpoint = \":version/read\"\n  ): Promise<DeepgramResponse<SyncAnalyzeResponse>> {\n    try {\n      let body;\n\n      if (isUrlSource(source)) {\n        body = JSON.stringify(source);\n      } else {\n        throw new DeepgramError(\"Unknown source type\");\n      }\n\n      if (options !== undefined && \"callback\" in options) {\n        throw new DeepgramError(\n          \"Callback cannot be provided as an option to a synchronous transcription. Use `analyzeUrlCallback` or `analyzeTextCallback` instead.\"\n        );\n      }\n\n      const requestUrl = this.getRequestUrl(endpoint, {}, { ...{}, ...options });\n      const result: SyncAnalyzeResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Analyzes a text-based audio source synchronously.\n   *\n   * @param source - The text-based audio source to analyze.\n   * @param options - Optional analysis options.\n   * @param endpoint - The API endpoint to use for the analysis. Defaults to \":version/read\".\n   * @returns A promise that resolves to the analysis response, or an error if the analysis fails.\n   */\n  async analyzeText(\n    source: TextSource,\n    options?: AnalyzeSchema,\n    endpoint = \":version/read\"\n  ): Promise<DeepgramResponse<SyncAnalyzeResponse>> {\n    try {\n      let body;\n\n      if (isTextSource(source)) {\n        body = JSON.stringify(source);\n      } else {\n        throw new DeepgramError(\"Unknown source type\");\n      }\n\n      if (options !== undefined && \"callback\" in options) {\n        throw new DeepgramError(\n          \"Callback cannot be provided as an option to a synchronous requests. Use `analyzeUrlCallback` or `analyzeTextCallback` instead.\"\n        );\n      }\n\n      const requestUrl = this.getRequestUrl(endpoint, {}, { ...{}, ...options });\n      const result: SyncAnalyzeResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Analyzes a URL-based audio source asynchronously.\n   *\n   * @param source - The URL-based audio source to analyze.\n   * @param callback - The URL to call back with the analysis results.\n   * @param options - Optional analysis options.\n   * @param endpoint - The API endpoint to use for the analysis. Defaults to \":version/read\".\n   * @returns A promise that resolves to the analysis response, or an error if the analysis fails.\n   */\n  async analyzeUrlCallback(\n    source: UrlSource,\n    callback: CallbackUrl,\n    options?: AnalyzeSchema,\n    endpoint = \":version/read\"\n  ): Promise<DeepgramResponse<AsyncAnalyzeResponse>> {\n    try {\n      let body;\n\n      if (isUrlSource(source)) {\n        body = JSON.stringify(source);\n      } else {\n        throw new DeepgramError(\"Unknown source type\");\n      }\n\n      const requestUrl = this.getRequestUrl(\n        endpoint,\n        {},\n        { ...options, callback: callback.toString() }\n      );\n      const result: AsyncAnalyzeResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Analyzes a text-based audio source asynchronously.\n   *\n   * @param source - The text-based audio source to analyze.\n   * @param callback - The URL to call back with the analysis results.\n   * @param options - Optional analysis options.\n   * @param endpoint - The API endpoint to use for the analysis. Defaults to \":version/read\".\n   * @returns A promise that resolves to the analysis response, or an error if the analysis fails.\n   */\n  async analyzeTextCallback(\n    source: TextSource,\n    callback: CallbackUrl,\n    options?: AnalyzeSchema,\n    endpoint = \":version/read\"\n  ): Promise<DeepgramResponse<AsyncAnalyzeResponse>> {\n    try {\n      let body;\n\n      if (isTextSource(source)) {\n        body = JSON.stringify(source);\n      } else {\n        throw new DeepgramError(\"Unknown source type\");\n      }\n\n      const requestUrl = this.getRequestUrl(\n        endpoint,\n        {},\n        { ...options, callback: callback.toString() }\n      );\n      const result: AsyncAnalyzeResponse = await this.post(requestUrl, body, {\n        headers: { \"Content-Type\": \"deepgram/audio+video\" },\n      }).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n}\n\nexport { ReadRestClient as ReadClient };\n","import { isDeepgramError } from \"../lib/errors\";\nimport type {\n  CreateOnPremCredentialsSchema,\n  DeepgramResponse,\n  ListOnPremCredentialsResponse,\n  MessageResponse,\n  OnPremCredentialResponse,\n} from \"../lib/types\";\nimport { AbstractRestClient } from \"./AbstractRestClient\";\n\n/**\n * The `SelfHostedRestClient` class extends the `AbstractRestClient` class and provides methods for interacting with the Deepgram self-hosted API.\n *\n * This class is used to list, retrieve, create, and delete self-hosted credentials for a Deepgram project.\n */\nexport class SelfHostedRestClient extends AbstractRestClient {\n  public namespace: string = \"selfhosted\";\n\n  /**\n   * Lists the self-hosted credentials for a Deepgram project.\n   *\n   * @param projectId - The ID of the Deepgram project.\n   * @returns A promise that resolves to an object containing the list of self-hosted credentials and any error that occurred.\n   * @see https://developers.deepgram.com/reference/list-credentials\n   */\n  async listCredentials(\n    projectId: string,\n    endpoint = \":version/projects/:projectId/onprem/distribution/credentials\"\n  ): Promise<DeepgramResponse<ListOnPremCredentialsResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const result: ListOnPremCredentialsResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Retrieves the self-hosted credentials for a specific Deepgram project and credentials ID.\n   *\n   * @param projectId - The ID of the Deepgram project.\n   * @param credentialsId - The ID of the self-hosted credentials to retrieve.\n   * @returns A promise that resolves to an object containing the self-hosted credentials and any error that occurred.\n   * @see https://developers.deepgram.com/reference/get-credentials\n   */\n  async getCredentials(\n    projectId: string,\n    credentialsId: string,\n    endpoint = \":version/projects/:projectId/onprem/distribution/credentials/:credentialsId\"\n  ): Promise<DeepgramResponse<OnPremCredentialResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, credentialsId });\n      const result: OnPremCredentialResponse = await this.get(requestUrl).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Creates self-hosted credentials for a specific Deepgram project.\n   *\n   * @param projectId - The ID of the Deepgram project.\n   * @param options - The options for creating the self-hosted credentials.\n   * @returns A promise that resolves to an object containing the created self-hosted credentials and any error that occurred.\n   * @see https://developers.deepgram.com/reference/create-credentials\n   */\n  async createCredentials(\n    projectId: string,\n    options: CreateOnPremCredentialsSchema,\n    endpoint = \":version/projects/:projectId/onprem/distribution/credentials\"\n  ): Promise<DeepgramResponse<OnPremCredentialResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId });\n      const body = JSON.stringify(options);\n\n      const result: OnPremCredentialResponse = await this.post(requestUrl, body).then((result) =>\n        result.json()\n      );\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n\n  /**\n   * Deletes self-hosted credentials for a specific Deepgram project.\n   *\n   * @param projectId - The ID of the Deepgram project.\n   * @param credentialsId - The ID of the self-hosted credentials to delete.\n   * @returns A promise that resolves to an object containing a message response and any error that occurred.\n   * @see https://developers.deepgram.com/reference/delete-credentials\n   */\n  async deleteCredentials(\n    projectId: string,\n    credentialsId: string,\n    endpoint = \":version/projects/:projectId/onprem/distribution/credentials/:credentialsId\"\n  ): Promise<DeepgramResponse<MessageResponse>> {\n    try {\n      const requestUrl = this.getRequestUrl(endpoint, { projectId, credentialsId });\n      const result: MessageResponse = await this.delete(requestUrl).then((result) => result.json());\n\n      return { result, error: null };\n    } catch (error) {\n      if (isDeepgramError(error)) {\n        return { result: null, error };\n      }\n\n      throw error;\n    }\n  }\n}\n\nexport { SelfHostedRestClient as OnPremClient };\n","import { AbstractLiveClient } from \"./AbstractLiveClient\";\nimport { LiveTTSEvents } from \"../lib/enums\";\nimport type { SpeakSchema, DeepgramClientOptions } from \"../lib/types\";\n\n/**\n * The `SpeakLiveClient` class extends the `AbstractLiveClient` class and provides functionality for setting up and managing a WebSocket connection for live text-to-speech synthesis.\n *\n * The constructor takes in `DeepgramClientOptions` and an optional `SpeakSchema` object, as well as an optional `endpoint` string. It then calls the `connect` method of the parent `AbstractLiveClient` class to establish the WebSocket connection.\n *\n * The `setupConnection` method is responsible for handling the various events that can occur on the WebSocket connection, such as opening, closing, and receiving messages. It sets up event handlers for these events and emits the appropriate events based on the message type.\n *\n * The `configure` method allows you to send additional configuration options to the connected session.\n *\n * The `requestClose` method requests the server to close the connection.\n */\nexport class SpeakLiveClient extends AbstractLiveClient {\n  public namespace: string = \"speak\";\n\n  /**\n   * Constructs a new `SpeakLiveClient` instance with the provided options.\n   *\n   * @param options - The `DeepgramClientOptions` to use for the client connection.\n   * @param speakOptions - An optional `SpeakSchema` object containing additional configuration options for the text-to-speech.\n   * @param endpoint - An optional string representing the WebSocket endpoint to connect to. Defaults to `:version/speak`.\n   */\n  constructor(\n    options: DeepgramClientOptions,\n    speakOptions: Omit<SpeakSchema, \"container\"> = {},\n    endpoint: string = \":version/speak\"\n  ) {\n    super(options);\n\n    this.connect(speakOptions, endpoint);\n  }\n\n  /**\n   * Sets up the connection event handlers.\n   * This method is responsible for handling the various events that can occur on the WebSocket connection, such as opening, closing, and receiving data.\n   * - When the connection is opened, it emits the `LiveTTSEvents.Open` event.\n   * - When the connection is closed, it emits the `LiveTTSEvents.Close` event.\n   * - When an error occurs on the connection, it emits the `LiveTTSEvents.Error` event.\n   * - When a message is received, it parses the message and emits the appropriate event based on the message type, such as `LiveTTSEvents.Metadata`, `LiveTTSEvents.Flushed`, and `LiveTTSEvents.Warning`.\n   */\n  public setupConnection(): void {\n    if (this.conn) {\n      this.conn.onopen = () => {\n        this.emit(LiveTTSEvents.Open, this);\n      };\n\n      this.conn.onclose = (event: any) => {\n        this.emit(LiveTTSEvents.Close, event);\n      };\n\n      this.conn.onerror = (event: ErrorEvent) => {\n        this.emit(LiveTTSEvents.Error, event);\n      };\n\n      this.conn.onmessage = (event: MessageEvent) => {\n        this.handleMessage(event);\n      };\n    }\n  }\n\n  /**\n   * Handles text messages received from the WebSocket connection.\n   * @param data - The parsed JSON data.\n   */\n  protected handleTextMessage(data: any): void {\n    if (data.type === LiveTTSEvents.Metadata) {\n      this.emit(LiveTTSEvents.Metadata, data);\n    } else if (data.type === LiveTTSEvents.Flushed) {\n      this.emit(LiveTTSEvents.Flushed, data);\n    } else if (data.type === LiveTTSEvents.Warning) {\n      this.emit(LiveTTSEvents.Warning, data);\n    } else {\n      this.emit(LiveTTSEvents.Unhandled, data);\n    }\n  }\n\n  /**\n   * Handles binary messages received from the WebSocket connection.\n   * @param data - The binary data.\n   */\n  protected handleBinaryMessage(data: Buffer): void {\n    this.emit(LiveTTSEvents.Audio, data);\n  }\n\n  /**\n   * Sends a text input message to the server.\n   *\n   * @param {string} text - The text to convert to speech.\n   */\n  public sendText(text: string): void {\n    this.send(\n      JSON.stringify({\n        type: \"Speak\",\n        text,\n      })\n    );\n  }\n\n  /**\n   * Requests the server flush the current buffer and return generated audio.\n   */\n  public flush(): void {\n    this.send(\n      JSON.stringify({\n        type: \"Flush\",\n      })\n    );\n  }\n\n  /**\n   * Requests the server clear the current buffer.\n   */\n  public clear(): void {\n    this.send(\n      JSON.stringify({\n        type: \"Clear\",\n      })\n    );\n  }\n\n  /**\n   * Requests the server close the connection.\n   */\n  public requestClose(): void {\n    this.send(\n      JSON.stringify({\n        type: \"Close\",\n      })\n    );\n  }\n\n  /**\n   * Handles incoming messages from the WebSocket connection.\n   * @param event - The MessageEvent object representing the received message.\n   */\n  protected handleMessage(event: MessageEvent): void {\n    if (typeof event.data === \"string\") {\n      try {\n        const data = JSON.parse(event.data);\n        this.handleTextMessage(data);\n      } catch (error) {\n        this.emit(LiveTTSEvents.Error, {\n          event,\n          message: \"Unable to parse `data` as JSON.\",\n          error,\n        });\n      }\n    } else if (event.data instanceof Blob) {\n      event.data.arrayBuffer().then((buffer) => {\n        this.handleBinaryMessage(Buffer.from(buffer));\n      });\n    } else if (event.data instanceof ArrayBuffer) {\n      this.handleBinaryMessage(Buffer.from(event.data));\n    } else if (Buffer.isBuffer(event.data)) {\n      this.handleBinaryMessage(event.data);\n    } else {\n      console.log(\"Received unknown data type\", event.data);\n      this.emit(LiveTTSEvents.Error, {\n        event,\n        message: \"Received unknown data type.\",\n      });\n    }\n  }\n}\n","import { DeepgramError, DeepgramUnknownError } from \"../lib/errors\";\nimport { isTextSource } from \"../lib/helpers\";\nimport { SpeakSchema, TextSource } from \"../lib/types\";\nimport { AbstractRestClient } from \"./AbstractRestClient\";\n\n/**\n * Provides a client for interacting with the Deepgram Text-to-Speech API.\n */\nexport class SpeakRestClient extends AbstractRestClient {\n  public namespace: string = \"speak\";\n  public result: undefined | Response;\n\n  /**\n   * Sends a request to the Deepgram Text-to-Speech API to generate audio from the provided text source.\n   *\n   * @param source - The text source to be converted to audio.\n   * @param options - Optional configuration options for the text-to-speech request.\n   * @param endpoint - The API endpoint to use for the request. Defaults to \":version/speak\".\n   * @returns A promise that resolves to the SpeakRestClient instance, which can be used to retrieve the response headers and body.\n   * @throws {DeepgramError} If the text source type is unknown.\n   * @throws {DeepgramUnknownError} If the request was made before a previous request completed.\n   * @see https://developers.deepgram.com/reference/text-to-speech-api\n   */\n  async request(\n    source: TextSource,\n    options?: SpeakSchema,\n    endpoint = \":version/speak\"\n  ): Promise<SpeakRestClient> {\n    let body;\n\n    if (isTextSource(source)) {\n      body = JSON.stringify(source);\n    } else {\n      throw new DeepgramError(\"Unknown transcription source type\");\n    }\n\n    const requestUrl = this.getRequestUrl(\n      endpoint,\n      {},\n      { ...{ model: \"aura-asteria-en\" }, ...options }\n    );\n    this.result = await this.post(requestUrl, body, {\n      headers: { Accept: \"audio/*\", \"Content-Type\": \"application/json\" },\n    });\n\n    return this;\n  }\n\n  /**\n   * Retrieves the response body as a readable stream.\n   *\n   * @returns A promise that resolves to the response body as a readable stream, or `null` if no request has been made yet.\n   * @throws {DeepgramUnknownError} If a request has not been made yet.\n   */\n  async getStream(): Promise<ReadableStream<Uint8Array> | null> {\n    if (!this.result)\n      throw new DeepgramUnknownError(\"Tried to get stream before making request\", \"\");\n\n    return this.result.body;\n  }\n\n  /**\n   * Retrieves the response headers from the previous request.\n   *\n   * @returns A promise that resolves to the response headers, or throws a `DeepgramUnknownError` if no request has been made yet.\n   */\n  async getHeaders(): Promise<Headers> {\n    if (!this.result)\n      throw new DeepgramUnknownError(\"Tried to get headers before making request\", \"\");\n\n    return this.result.headers;\n  }\n}\n","import { AbstractClient } from \"./AbstractClient\";\nimport { SpeakLiveClient } from \"./SpeakLiveClient\";\nimport { SpeakRestClient } from \"./SpeakRestClient\";\nimport { SpeakSchema } from \"../lib/types\";\nimport { TextSource } from \"../lib/types\";\n\n/**\n * The `SpeakClient` class extends the `AbstractClient` class and provides access to the \"speak\" namespace.\n * It exposes two methods:\n *\n * 1. `request()`: Returns a `SpeakRestClient` instance for interacting with the rest speak API.\n * 2. `live(ttsOptions: SpeakSchema = {}, endpoint = \":version/speak\")`: Returns a `SpeakLiveClient` instance for interacting with the live speak API, with the provided TTS options and endpoint.\n */\nexport class SpeakClient extends AbstractClient {\n  public namespace: string = \"speak\";\n\n  /**\n   * Returns a `SpeakRestClient` instance for interacting with the rest speak API.\n   */\n  public request(source: TextSource, options?: SpeakSchema, endpoint = \":version/speak\") {\n    const client = new SpeakRestClient(this.options);\n\n    return client.request(source, options, endpoint);\n  }\n\n  /**\n   * Returns a `SpeakLiveClient` instance for interacting with the live speak API, with the provided TTS options and endpoint.\n   * @param {SpeakSchema} [ttsOptions={}] - The TTS options to use for the live speak API.\n   * @param {string} [endpoint=\":version/speak\"] - The endpoint to use for the live speak API.\n   * @returns {SpeakLiveClient} - A `SpeakLiveClient` instance for interacting with the live speak API.\n   */\n  public live(ttsOptions: SpeakSchema = {}, endpoint: string = \":version/speak\"): SpeakLiveClient {\n    return new SpeakLiveClient(this.options, ttsOptions, endpoint);\n  }\n}\n","import { DeepgramVersionError } from \"./lib/errors\";\nimport {\n  AbstractClient,\n  ListenClient,\n  ManageClient,\n  ReadClient,\n  OnPremClient,\n  SelfHostedRestClient,\n  SpeakClient,\n  ModelsRestClient,\n} from \"./packages\";\n\n/**\n * The DeepgramClient class provides access to various Deepgram API clients, including ListenClient, ManageClient, SelfHostedRestClient, ReadClient, and SpeakClient.\n *\n * @see https://github.com/deepgram/deepgram-js-sdk\n */\nexport default class DeepgramClient extends AbstractClient {\n  /**\n   * Returns a new instance of the ListenClient, which provides access to the Deepgram API's listening functionality.\n   *\n   * @returns {ListenClient} A new instance of the ListenClient.\n   */\n  get listen(): ListenClient {\n    return new ListenClient(this.options);\n  }\n\n  /**\n   * Returns a new instance of the ManageClient, which provides access to the Deepgram API's management functionality.\n   *\n   * @returns {ManageClient} A new instance of the ManageClient.\n   */\n  get manage(): ManageClient {\n    return new ManageClient(this.options);\n  }\n\n  /**\n   * Returns a new instance of the ModelsRestClient, which provides access to the Deepgram API's model functionality.\n   *\n   * @returns {ModelsRestClient} A new instance of the ModelsRestClient.\n   */\n  get models(): ModelsRestClient {\n    return new ModelsRestClient(this.options);\n  }\n\n  /**\n   * Returns a new instance of the SelfHostedRestClient, which provides access to the Deepgram API's self-hosted functionality.\n   *\n   * @returns {OnPremClient} A new instance of the SelfHostedRestClient named as OnPremClient.\n   * @deprecated use selfhosted() instead\n   */\n  get onprem(): OnPremClient {\n    return this.selfhosted;\n  }\n\n  /**\n   * Returns a new instance of the SelfHostedRestClient, which provides access to the Deepgram API's self-hosted functionality.\n   *\n   * @returns {SelfHostedRestClient} A new instance of the SelfHostedRestClient.\n   */\n  get selfhosted(): SelfHostedRestClient {\n    return new SelfHostedRestClient(this.options);\n  }\n\n  /**\n   * Returns a new instance of the ReadClient, which provides access to the Deepgram API's reading functionality.\n   *\n   * @returns {ReadClient} A new instance of the ReadClient.\n   */\n  get read(): ReadClient {\n    return new ReadClient(this.options);\n  }\n\n  /**\n   * Returns a new instance of the SpeakClient, which provides access to the Deepgram API's speaking functionality.\n   *\n   * @returns {SpeakClient} A new instance of the SpeakClient.\n   */\n  get speak(): SpeakClient {\n    return new SpeakClient(this.options);\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get transcription(): any {\n    throw new DeepgramVersionError();\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get projects(): any {\n    throw new DeepgramVersionError();\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get keys(): any {\n    throw new DeepgramVersionError();\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get members(): any {\n    throw new DeepgramVersionError();\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get scopes(): any {\n    throw new DeepgramVersionError();\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get invitation(): any {\n    throw new DeepgramVersionError();\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get usage(): any {\n    throw new DeepgramVersionError();\n  }\n\n  /**\n   * @deprecated\n   * @see https://dpgr.am/js-v3\n   */\n  get billing(): any {\n    throw new DeepgramVersionError();\n  }\n}\n","import { DeepgramClientOptions, IKeyFactory } from \"./lib/types/DeepgramClientOptions\";\nimport { DeepgramVersionError } from \"./lib/errors\";\nimport DeepgramClient from \"./DeepgramClient\";\n\n/**\n * This class is deprecated and should not be used. It throws a `DeepgramVersionError` when instantiated.\n *\n * @deprecated\n * @see https://dpgr.am/js-v3\n */\nclass Deepgram {\n  constructor(protected apiKey: string, protected apiUrl?: string, protected requireSSL?: boolean) {\n    throw new DeepgramVersionError();\n  }\n}\n\n/**\n * Creates a new Deepgram client instance.\n *\n * @param {DeepgramClientArgs} args - Arguments to pass to the Deepgram client constructor.\n * @returns A new Deepgram client instance.\n */\nfunction createClient(): DeepgramClient;\nfunction createClient(key?: string | IKeyFactory): DeepgramClient;\nfunction createClient(options?: DeepgramClientOptions): DeepgramClient;\nfunction createClient(key?: string | IKeyFactory, options?: DeepgramClientOptions): DeepgramClient;\nfunction createClient(\n  keyOrOptions?: string | IKeyFactory | DeepgramClientOptions,\n  options?: DeepgramClientOptions\n): DeepgramClient {\n  let resolvedOptions: DeepgramClientOptions = {};\n\n  if (typeof keyOrOptions === \"string\" || typeof keyOrOptions === \"function\") {\n    if (typeof options === \"object\") {\n      resolvedOptions = options;\n    }\n\n    resolvedOptions.key = keyOrOptions;\n  } else if (typeof keyOrOptions === \"object\") {\n    resolvedOptions = keyOrOptions;\n  }\n\n  return new DeepgramClient(resolvedOptions);\n}\n\nexport { createClient, DeepgramClient, Deepgram };\n\n/**\n * Helpful exports.\n */\nexport * from \"./packages\";\nexport * from \"./lib/types\";\nexport * from \"./lib/enums\";\nexport * from \"./lib/constants\";\nexport * from \"./lib/errors\";\nexport * from \"./lib/helpers\";\n\n/**\n * Captions. These will be tree-shaken if unused.\n *\n * @see https://github.com/deepgram/deepgram-node-captions\n *\n * import/export declarations don't do anything but set up an alias to the\n * exported variable, they do not count as a \"use\". Given their semantics,\n * they are tracked specially by any bundler and will not adversely affect\n * tree-shaking.\n */\nexport { webvtt, srt } from \"@deepgram/captions\";\n","import {\n    IAgentRuntime,\n    ITranscriptionService,\n    IVideoService,\n    Media,\n    Service,\n    ServiceType,\n    stringToUuid,\n} from \"@elizaos/core\";\nimport ffmpeg from \"fluent-ffmpeg\";\nimport fs from \"fs\";\nimport { tmpdir } from \"os\";\nimport path from \"path\";\nimport youtubeDl from \"youtube-dl-exec\";\n\nexport class VideoService extends Service implements IVideoService {\n    static serviceType: ServiceType = ServiceType.VIDEO;\n    private cacheKey = \"content/video\";\n    private dataDir = \"./content_cache\";\n\n    private queue: string[] = [];\n    private processing: boolean = false;\n\n    constructor() {\n        super();\n        this.ensureDataDirectoryExists();\n    }\n\n    getInstance(): IVideoService {\n        return VideoService.getInstance();\n    }\n\n    async initialize(_runtime: IAgentRuntime): Promise<void> {}\n\n    private ensureDataDirectoryExists() {\n        if (!fs.existsSync(this.dataDir)) {\n            fs.mkdirSync(this.dataDir);\n        }\n    }\n\n    public isVideoUrl(url: string): boolean {\n        return (\n            url.includes(\"youtube.com\") ||\n            url.includes(\"youtu.be\") ||\n            url.includes(\"vimeo.com\")\n        );\n    }\n\n    public async downloadMedia(url: string): Promise<string> {\n        const videoId = this.getVideoId(url);\n        const outputFile = path.join(this.dataDir, `${videoId}.mp4`);\n\n        // if it already exists, return it\n        if (fs.existsSync(outputFile)) {\n            return outputFile;\n        }\n\n        try {\n            await youtubeDl(url, {\n                verbose: true,\n                output: outputFile,\n                writeInfoJson: true,\n            });\n            return outputFile;\n        } catch (error) {\n            console.error(\"Error downloading media:\", error);\n            throw new Error(\"Failed to download media\");\n        }\n    }\n\n    public async downloadVideo(videoInfo: any): Promise<string> {\n        const videoId = this.getVideoId(videoInfo.webpage_url);\n        const outputFile = path.join(this.dataDir, `${videoId}.mp4`);\n\n        // if it already exists, return it\n        if (fs.existsSync(outputFile)) {\n            return outputFile;\n        }\n\n        try {\n            await youtubeDl(videoInfo.webpage_url, {\n                verbose: true,\n                output: outputFile,\n                format: \"bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best\",\n                writeInfoJson: true,\n            });\n            return outputFile;\n        } catch (error) {\n            console.error(\"Error downloading video:\", error);\n            throw new Error(\"Failed to download video\");\n        }\n    }\n\n    public async processVideo(\n        url: string,\n        runtime: IAgentRuntime\n    ): Promise<Media> {\n        this.queue.push(url);\n        this.processQueue(runtime);\n\n        return new Promise((resolve, reject) => {\n            const checkQueue = async () => {\n                const index = this.queue.indexOf(url);\n                if (index !== -1) {\n                    setTimeout(checkQueue, 100);\n                } else {\n                    try {\n                        const result = await this.processVideoFromUrl(\n                            url,\n                            runtime\n                        );\n                        resolve(result);\n                    } catch (error) {\n                        reject(error);\n                    }\n                }\n            };\n            checkQueue();\n        });\n    }\n\n    private async processQueue(runtime): Promise<void> {\n        if (this.processing || this.queue.length === 0) {\n            return;\n        }\n\n        this.processing = true;\n\n        while (this.queue.length > 0) {\n            const url = this.queue.shift()!;\n            await this.processVideoFromUrl(url, runtime);\n        }\n\n        this.processing = false;\n    }\n\n    private async processVideoFromUrl(\n        url: string,\n        runtime: IAgentRuntime\n    ): Promise<Media> {\n        const videoId =\n            url.match(\n                /(?:youtu\\.be\\/|youtube\\.com(?:\\/embed\\/|\\/v\\/|\\/watch\\?v=|\\/watch\\?.+&v=))([^\\/&?]+)/ // eslint-disable-line\n            )?.[1] || \"\";\n        const videoUuid = this.getVideoId(videoId);\n        const cacheKey = `${this.cacheKey}/${videoUuid}`;\n\n        const cached = await runtime.cacheManager.get<Media>(cacheKey);\n\n        if (cached) {\n            console.log(\"Returning cached video file\");\n            return cached;\n        }\n\n        console.log(\"Cache miss, processing video\");\n        console.log(\"Fetching video info\");\n        const videoInfo = await this.fetchVideoInfo(url);\n        console.log(\"Getting transcript\");\n        const transcript = await this.getTranscript(url, videoInfo, runtime);\n\n        const result: Media = {\n            id: videoUuid,\n            url: url,\n            title: videoInfo.title,\n            source: videoInfo.channel,\n            description: videoInfo.description,\n            text: transcript,\n        };\n\n        await runtime.cacheManager.set(cacheKey, result);\n\n        return result;\n    }\n\n    private getVideoId(url: string): string {\n        return stringToUuid(url);\n    }\n\n    async fetchVideoInfo(url: string): Promise<any> {\n        if (url.endsWith(\".mp4\") || url.includes(\".mp4?\")) {\n            try {\n                const response = await fetch(url);\n                if (response.ok) {\n                    // If the URL is a direct link to an MP4 file, return a simplified video info object\n                    return {\n                        title: path.basename(url),\n                        description: \"\",\n                        channel: \"\",\n                    };\n                }\n            } catch (error) {\n                console.error(\"Error downloading MP4 file:\", error);\n                // Fall back to using youtube-dl if direct download fails\n            }\n        }\n\n        try {\n            const result = await youtubeDl(url, {\n                dumpJson: true,\n                verbose: true,\n                callHome: false,\n                noCheckCertificates: true,\n                preferFreeFormats: true,\n                youtubeSkipDashManifest: true,\n                writeSub: true,\n                writeAutoSub: true,\n                subLang: \"en\",\n                skipDownload: true,\n            });\n            return result;\n        } catch (error) {\n            console.error(\"Error fetching video info:\", error);\n            throw new Error(\"Failed to fetch video information\");\n        }\n    }\n\n    private async getTranscript(\n        url: string,\n        videoInfo: any,\n        runtime: IAgentRuntime\n    ): Promise<string> {\n        console.log(\"Getting transcript\");\n        try {\n            // Check for manual subtitles\n            if (videoInfo.subtitles && videoInfo.subtitles.en) {\n                console.log(\"Manual subtitles found\");\n                const srtContent = await this.downloadSRT(\n                    videoInfo.subtitles.en[0].url\n                );\n                return this.parseSRT(srtContent);\n            }\n\n            // Check for automatic captions\n            if (\n                videoInfo.automatic_captions &&\n                videoInfo.automatic_captions.en\n            ) {\n                console.log(\"Automatic captions found\");\n                const captionUrl = videoInfo.automatic_captions.en[0].url;\n                const captionContent = await this.downloadCaption(captionUrl);\n                return this.parseCaption(captionContent);\n            }\n\n            // Check if it's a music video\n            if (\n                videoInfo.categories &&\n                videoInfo.categories.includes(\"Music\")\n            ) {\n                console.log(\"Music video detected, no lyrics available\");\n                return \"No lyrics available.\";\n            }\n\n            // Fall back to audio transcription\n            console.log(\n                \"No captions found, falling back to audio transcription\"\n            );\n            return this.transcribeAudio(url, runtime);\n        } catch (error) {\n            console.error(\"Error in getTranscript:\", error);\n            throw error;\n        }\n    }\n\n    private async downloadCaption(url: string): Promise<string> {\n        console.log(\"Downloading caption from:\", url);\n        const response = await fetch(url);\n        if (!response.ok) {\n            throw new Error(\n                `Failed to download caption: ${response.statusText}`\n            );\n        }\n        return await response.text();\n    }\n\n    private parseCaption(captionContent: string): string {\n        console.log(\"Parsing caption\");\n        try {\n            const jsonContent = JSON.parse(captionContent);\n            if (jsonContent.events) {\n                return jsonContent.events\n                    .filter((event) => event.segs)\n                    .map((event) => event.segs.map((seg) => seg.utf8).join(\"\"))\n                    .join(\"\")\n                    .replace(\"\\n\", \" \");\n            } else {\n                console.error(\"Unexpected caption format:\", jsonContent);\n                return \"Error: Unable to parse captions\";\n            }\n        } catch (error) {\n            console.error(\"Error parsing caption:\", error);\n            return \"Error: Unable to parse captions\";\n        }\n    }\n\n    private parseSRT(srtContent: string): string {\n        // Simple SRT parser (replace with a more robust solution if needed)\n        return srtContent\n            .split(\"\\n\\n\")\n            .map((block) => block.split(\"\\n\").slice(2).join(\" \"))\n            .join(\" \");\n    }\n\n    private async downloadSRT(url: string): Promise<string> {\n        console.log(\"downloadSRT\");\n        const response = await fetch(url);\n        return await response.text();\n    }\n\n    async transcribeAudio(\n        url: string,\n        runtime: IAgentRuntime\n    ): Promise<string> {\n        console.log(\"Preparing audio for transcription...\");\n        const mp4FilePath = path.join(\n            this.dataDir,\n            `${this.getVideoId(url)}.mp4`\n        );\n\n        const mp3FilePath = path.join(\n            this.dataDir,\n            `${this.getVideoId(url)}.mp3`\n        );\n\n        if (!fs.existsSync(mp3FilePath)) {\n            if (fs.existsSync(mp4FilePath)) {\n                console.log(\"MP4 file found. Converting to MP3...\");\n                await this.convertMp4ToMp3(mp4FilePath, mp3FilePath);\n            } else {\n                console.log(\"Downloading audio...\");\n                await this.downloadAudio(url, mp3FilePath);\n            }\n        }\n\n        console.log(`Audio prepared at ${mp3FilePath}`);\n\n        const audioBuffer = fs.readFileSync(mp3FilePath);\n        console.log(`Audio file size: ${audioBuffer.length} bytes`);\n\n        console.log(\"Starting transcription...\");\n        const startTime = Date.now();\n        const transcriptionService = runtime.getService<ITranscriptionService>(\n            ServiceType.TRANSCRIPTION\n        );\n\n        if (!transcriptionService) {\n            throw new Error(\"Transcription service not found\");\n        }\n\n        const transcript = await transcriptionService.transcribe(audioBuffer);\n\n        const endTime = Date.now();\n        console.log(\n            `Transcription completed in ${(endTime - startTime) / 1000} seconds`\n        );\n\n        // Don't delete the MP3 file as it might be needed for future use\n        return transcript || \"Transcription failed\";\n    }\n\n    private async convertMp4ToMp3(\n        inputPath: string,\n        outputPath: string\n    ): Promise<void> {\n        return new Promise((resolve, reject) => {\n            ffmpeg(inputPath)\n                .output(outputPath)\n                .noVideo()\n                .audioCodec(\"libmp3lame\")\n                .on(\"end\", () => {\n                    console.log(\"Conversion to MP3 complete\");\n                    resolve();\n                })\n                .on(\"error\", (err) => {\n                    console.error(\"Error converting to MP3:\", err);\n                    reject(err);\n                })\n                .run();\n        });\n    }\n\n    private async downloadAudio(\n        url: string,\n        outputFile: string\n    ): Promise<string> {\n        console.log(\"Downloading audio\");\n        outputFile =\n            outputFile ??\n            path.join(this.dataDir, `${this.getVideoId(url)}.mp3`);\n\n        try {\n            if (url.endsWith(\".mp4\") || url.includes(\".mp4?\")) {\n                console.log(\n                    \"Direct MP4 file detected, downloading and converting to MP3\"\n                );\n                const tempMp4File = path.join(\n                    tmpdir(),\n                    `${this.getVideoId(url)}.mp4`\n                );\n                const response = await fetch(url);\n                const arrayBuffer = await response.arrayBuffer();\n                const buffer = Buffer.from(arrayBuffer);\n                fs.writeFileSync(tempMp4File, buffer);\n\n                await new Promise<void>((resolve, reject) => {\n                    ffmpeg(tempMp4File)\n                        .output(outputFile)\n                        .noVideo()\n                        .audioCodec(\"libmp3lame\")\n                        .on(\"end\", () => {\n                            fs.unlinkSync(tempMp4File);\n                            resolve();\n                        })\n                        .on(\"error\", (err) => {\n                            reject(err);\n                        })\n                        .run();\n                });\n            } else {\n                console.log(\n                    \"YouTube video detected, downloading audio with youtube-dl\"\n                );\n                await youtubeDl(url, {\n                    verbose: true,\n                    extractAudio: true,\n                    audioFormat: \"mp3\",\n                    output: outputFile,\n                    writeInfoJson: true,\n                });\n            }\n            return outputFile;\n        } catch (error) {\n            console.error(\"Error downloading audio:\", error);\n            throw new Error(\"Failed to download audio\");\n        }\n    }\n}\n","import {\n    IAgentRuntime,\n    IAwsS3Service,\n    Service,\n    ServiceType,\n} from \"@elizaos/core\";\nimport {\n    GetObjectCommand,\n    PutObjectCommand,\n    S3Client,\n} from \"@aws-sdk/client-s3\";\nimport { getSignedUrl } from \"@aws-sdk/s3-request-presigner\";\nimport * as fs from \"fs\";\nimport * as path from \"path\";\n\ninterface UploadResult {\n    success: boolean;\n    url?: string;\n    error?: string;\n}\n\ninterface JsonUploadResult extends UploadResult {\n    key?: string; // Add storage key\n}\n\nexport class AwsS3Service extends Service implements IAwsS3Service {\n    static serviceType: ServiceType = ServiceType.AWS_S3;\n\n    private s3Client: S3Client | null = null;\n    private bucket: string = \"\";\n    private fileUploadPath: string = \"\";\n    private runtime: IAgentRuntime | null = null;\n\n    async initialize(runtime: IAgentRuntime): Promise<void> {\n        console.log(\"Initializing AwsS3Service\");\n        this.runtime = runtime;\n        this.fileUploadPath = runtime.getSetting(\"AWS_S3_UPLOAD_PATH\") ?? \"\";\n    }\n\n    private async initializeS3Client(): Promise<boolean> {\n        if (this.s3Client) return true;\n        if (!this.runtime) return false;\n\n        const AWS_ACCESS_KEY_ID = this.runtime.getSetting(\"AWS_ACCESS_KEY_ID\");\n        const AWS_SECRET_ACCESS_KEY = this.runtime.getSetting(\n            \"AWS_SECRET_ACCESS_KEY\"\n        );\n        const AWS_REGION = this.runtime.getSetting(\"AWS_REGION\");\n        const AWS_S3_BUCKET = this.runtime.getSetting(\"AWS_S3_BUCKET\");\n\n        if (\n            !AWS_ACCESS_KEY_ID ||\n            !AWS_SECRET_ACCESS_KEY ||\n            !AWS_REGION ||\n            !AWS_S3_BUCKET\n        ) {\n            return false;\n        }\n\n        this.s3Client = new S3Client({\n            region: AWS_REGION,\n            credentials: {\n                accessKeyId: AWS_ACCESS_KEY_ID,\n                secretAccessKey: AWS_SECRET_ACCESS_KEY,\n            },\n        });\n        this.bucket = AWS_S3_BUCKET;\n        return true;\n    }\n\n    async uploadFile(\n        filePath: string,\n        subDirectory: string = \"\",\n        useSignedUrl: boolean = false,\n        expiresIn: number = 900\n    ): Promise<UploadResult> {\n        try {\n            if (!(await this.initializeS3Client())) {\n                return {\n                    success: false,\n                    error: \"AWS S3 credentials not configured\",\n                };\n            }\n\n            if (!fs.existsSync(filePath)) {\n                return {\n                    success: false,\n                    error: \"File does not exist\",\n                };\n            }\n\n            const fileContent = fs.readFileSync(filePath);\n\n            const baseFileName = `${Date.now()}-${path.basename(filePath)}`;\n            // Determine storage path based on public access\n            const fileName =\n                `${this.fileUploadPath}${subDirectory}/${baseFileName}`.replaceAll(\n                    \"//\",\n                    \"/\"\n                );\n            // Set upload parameters\n            const uploadParams = {\n                Bucket: this.bucket,\n                Key: fileName,\n                Body: fileContent,\n                ContentType: this.getContentType(filePath),\n            };\n\n            // Upload file\n            await this.s3Client.send(new PutObjectCommand(uploadParams));\n\n            // Build result object\n            const result: UploadResult = {\n                success: true,\n            };\n\n            // If not using signed URL, return public access URL\n            if (!useSignedUrl) {\n                result.url = `https://${this.bucket}.s3.${process.env.AWS_REGION}.amazonaws.com/${fileName}`;\n            } else {\n                const getObjectCommand = new GetObjectCommand({\n                    Bucket: this.bucket,\n                    Key: fileName,\n                });\n                result.url = await getSignedUrl(\n                    this.s3Client,\n                    getObjectCommand,\n                    {\n                        expiresIn, // 15 minutes in seconds\n                    }\n                );\n            }\n\n            return result;\n        } catch (error) {\n            return {\n                success: false,\n                error:\n                    error instanceof Error\n                        ? error.message\n                        : \"Unknown error occurred\",\n            };\n        }\n    }\n\n    /**\n     * Generate signed URL for existing file\n     */\n    async generateSignedUrl(\n        fileName: string,\n        expiresIn: number = 900\n    ): Promise<string> {\n        if (!(await this.initializeS3Client())) {\n            throw new Error(\"AWS S3 credentials not configured\");\n        }\n\n        const command = new GetObjectCommand({\n            Bucket: this.bucket,\n            Key: fileName,\n        });\n\n        return await getSignedUrl(this.s3Client, command, { expiresIn });\n    }\n\n    private getContentType(filePath: string): string {\n        const ext = path.extname(filePath).toLowerCase();\n        const contentTypes: { [key: string]: string } = {\n            \".png\": \"image/png\",\n            \".jpg\": \"image/jpeg\",\n            \".jpeg\": \"image/jpeg\",\n            \".gif\": \"image/gif\",\n            \".webp\": \"image/webp\",\n        };\n        return contentTypes[ext] || \"application/octet-stream\";\n    }\n\n    /**\n     * Upload JSON object to S3\n     * @param jsonData JSON data to upload\n     * @param fileName File name (optional, without path)\n     * @param subDirectory Subdirectory (optional)\n     * @param useSignedUrl Whether to use signed URL\n     * @param expiresIn Signed URL expiration time (seconds)\n     */\n    async uploadJson(\n        jsonData: any,\n        fileName?: string,\n        subDirectory?: string,\n        useSignedUrl: boolean = false,\n        expiresIn: number = 900\n    ): Promise<JsonUploadResult> {\n        try {\n            if (!(await this.initializeS3Client())) {\n                return {\n                    success: false,\n                    error: \"AWS S3 credentials not configured\",\n                };\n            }\n\n            // Validate input\n            if (!jsonData) {\n                return {\n                    success: false,\n                    error: \"JSON data is required\",\n                };\n            }\n\n            // Generate filename (if not provided)\n            const timestamp = Date.now();\n            const actualFileName = fileName || `${timestamp}.json`;\n\n            // Build complete file path\n            let fullPath = this.fileUploadPath || \"\";\n            if (subDirectory) {\n                fullPath = `${fullPath}/${subDirectory}`.replace(/\\/+/g, \"/\");\n            }\n            const key = `${fullPath}/${actualFileName}`.replace(/\\/+/g, \"/\");\n\n            // Convert JSON to string\n            const jsonString = JSON.stringify(jsonData, null, 2);\n\n            // Set upload parameters\n            const uploadParams = {\n                Bucket: this.bucket,\n                Key: key,\n                Body: jsonString,\n                ContentType: \"application/json\",\n            };\n\n            // Upload file\n            await this.s3Client.send(new PutObjectCommand(uploadParams));\n\n            // Build result\n            const result: JsonUploadResult = {\n                success: true,\n                key: key,\n            };\n\n            // Return corresponding URL based on requirements\n            if (!useSignedUrl) {\n                result.url = `https://${this.bucket}.s3.${process.env.AWS_REGION}.amazonaws.com/${key}`;\n            } else {\n                const getObjectCommand = new GetObjectCommand({\n                    Bucket: this.bucket,\n                    Key: key,\n                });\n                result.url = await getSignedUrl(\n                    this.s3Client,\n                    getObjectCommand,\n                    { expiresIn }\n                );\n            }\n\n            return result;\n        } catch (error) {\n            return {\n                success: false,\n                error:\n                    error instanceof Error\n                        ? error.message\n                        : \"Unknown error occurred\",\n            };\n        }\n    }\n}\n\nexport default AwsS3Service;\n","import {\n    Action,\n    IAgentRuntime,\n    Memory,\n    State,\n    HandlerCallback,\n    composeContext,\n    generateObject,\n    ActionExample,\n    ModelClass,\n    elizaLogger,\n    ServiceType,\n    IImageDescriptionService,\n} from \"@elizaos/core\";\nimport { getFileLocationTemplate } from \"../templates\";\nimport { FileLocationResultSchema, isFileLocationResult } from \"../types\";\n\nexport const describeImage: Action = {\n    name: \"DESCRIBE_IMAGE\",\n    similes: [\"DESCRIBE_PICTURE\", \"EXPLAIN_PICTURE\", \"EXPLAIN_IMAGE\"],\n    validate: async (_runtime: IAgentRuntime, _message: Memory) => {\n        return true;\n    },\n    description: \"Describe an image\",\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: { [key: string]: unknown },\n        callback?: HandlerCallback\n    ): Promise<boolean> => {\n        // Create context with attachments and URL\n        const getFileLocationContext = composeContext({\n            state,\n            template: getFileLocationTemplate,\n        });\n\n        const fileLocationResultObject = await generateObject({\n            runtime,\n            context: getFileLocationContext,\n            modelClass: ModelClass.SMALL,\n            schema: FileLocationResultSchema,\n            stop: [\"\\n\"],\n        });\n\n        if (!isFileLocationResult(fileLocationResultObject?.object)) {\n            elizaLogger.error(\"Failed to generate file location\");\n            return false;\n        }\n\n        const { fileLocation } = fileLocationResultObject.object;\n\n        const { description } = await runtime\n            .getService<IImageDescriptionService>(ServiceType.IMAGE_DESCRIPTION)\n            .describeImage(fileLocation);\n\n        runtime.messageManager.createMemory({\n            userId: message.agentId,\n            agentId: message.agentId,\n            roomId: message.roomId,\n            content: {\n                text: description,\n            },\n        });\n\n        callback({\n            text: description,\n        });\n\n        return true;\n    },\n    examples: [\n        [\n            {\n                user: \"{{user1}}\",\n                content: {\n                    text: \"Can you describe this image for me?\",\n                },\n            },\n            {\n                user: \"{{user2}}\",\n                content: {\n                    text: \"Let me analyze this image for you...\",\n                    action: \"DESCRIBE_IMAGE\",\n                },\n            },\n            {\n                user: \"{{user2}}\",\n                content: {\n                    text: \"I see an orange tabby cat sitting on a windowsill. The cat appears to be relaxed and looking out the window at birds flying by. The lighting suggests it's a sunny afternoon.\",\n                },\n            },\n        ],\n        [\n            {\n                user: \"{{user1}}\",\n                content: {\n                    text: \"What's in this picture?\",\n                },\n            },\n            {\n                user: \"{{user2}}\",\n                content: {\n                    text: \"I'll take a look at that image...\",\n                    action: \"DESCRIBE_IMAGE\",\n                },\n            },\n            {\n                user: \"{{user2}}\",\n                content: {\n                    text: \"The image shows a modern kitchen with stainless steel appliances. There's a large island counter in the center with marble countertops. The cabinets are white with sleek handles, and there's pendant lighting hanging above the island.\",\n                },\n            },\n        ],\n        [\n            {\n                user: \"{{user1}}\",\n                content: {\n                    text: \"Could you tell me what this image depicts?\",\n                },\n            },\n            {\n                user: \"{{user2}}\",\n                content: {\n                    text: \"I'll describe this image for you...\",\n                    action: \"DESCRIBE_IMAGE\",\n                },\n            },\n            {\n                user: \"{{user2}}\",\n                content: {\n                    text: \"This is a scenic mountain landscape at sunset. The peaks are snow-capped and reflected in a calm lake below. The sky is painted in vibrant oranges and purples, with a few wispy clouds catching the last rays of sunlight.\",\n                },\n            },\n        ],\n    ] as ActionExample[][],\n} as Action;\n","export const getFileLocationTemplate = `\n{{recentMessages}}\n\nextract the file location from the users message or the attachment in the message history that they are referring to.\nyour job is to infer the correct attachment based on the recent messages, the users most recent message, and the attachments in the message\nimage attachments are the result of the users uploads, or images you have created.\nonly respond with the file location, no other text.\ntypically the file location is in the form of a URL or a file path.\n\n\\`\\`\\`json\n{\n    \"fileLocation\": \"file location text goes here\"\n}\n\\`\\`\\`\n`;\n","import { z } from \"zod\";\n\nexport const FileLocationResultSchema = z.object({\n    fileLocation: z.string().min(1),\n});\n\nexport type FileLocationResult = z.infer<typeof FileLocationResultSchema>;\n\nexport function isFileLocationResult(obj: unknown): obj is FileLocationResult {\n    return FileLocationResultSchema.safeParse(obj).success;\n}\n","export * from \"./services/index.ts\";\n\nimport { Plugin } from \"@elizaos/core\";\n\nimport {\n    BrowserService,\n    ImageDescriptionService,\n    LlamaService,\n    PdfService,\n    SpeechService,\n    TranscriptionService,\n    VideoService,\n    AwsS3Service,\n} from \"./services/index.ts\";\nimport { describeImage } from \"./actions/describe-image.ts\";\n\nexport type NodePlugin = ReturnType<typeof createNodePlugin>;\n\nexport function createNodePlugin() {\n    return {\n        name: \"default\",\n        description: \"Default plugin, with basic actions and evaluators\",\n        services: [\n            new BrowserService(),\n            new ImageDescriptionService(),\n            new LlamaService(),\n            new PdfService(),\n            new SpeechService(),\n            new TranscriptionService(),\n            new VideoService(),\n            new AwsS3Service(),\n        ],\n        actions: [describeImage],\n    } as const satisfies Plugin;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;AAmBA,QAAM,cAAc,oBAAI,QAAO;AAO/B,QAAM,WAAW,oBAAI,QAAO;AAQ5B,aAAS,GAAG,OAAO;AACf,YAAM,OAAO,YAAY,IAAI,KAAK;AAClC,cAAQ;QACJ,QAAQ;QACR;QACA;;AAEJ,aAAO;;AAOX,aAAS,cAAc,MAAM;AACzB,UAAI,KAAK,mBAAmB,MAAM;AAC9B,YACI,OAAO,YAAY,eACnB,OAAO,QAAQ,UAAU,YAC3B;AACE,kBAAQ;YACJ;YACA,KAAK;;;AAGb;;AAEJ,UAAI,CAAC,KAAK,MAAM,YAAY;AACxB;;AAGJ,WAAK,WAAW;AAChB,UAAI,OAAO,KAAK,MAAM,mBAAmB,YAAY;AACjD,aAAK,MAAM,eAAc;;;AAcjC,aAAS,MAAM,aAAa,OAAO;AAC/B,kBAAY,IAAI,MAAM;QAClB;QACA;QACA,YAAY;QACZ,eAAe;QACf,UAAU;QACV,SAAS;QACT,kBAAkB;QAClB,iBAAiB;QACjB,WAAW,MAAM,aAAa,KAAK,IAAG;OACzC;AAGD,aAAO,eAAe,MAAM,aAAa,EAAE,OAAO,OAAO,YAAY,KAAI,CAAE;AAG3E,YAAM,OAAO,OAAO,KAAK,KAAK;AAC9B,eAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE,GAAG;AAClC,cAAM,MAAM,KAAK,CAAC;AAClB,YAAI,EAAE,OAAO,OAAO;AAChB,iBAAO,eAAe,MAAM,KAAK,yBAAyB,GAAG,CAAC;;;;AAM1E,UAAM,YAAY;;;;;MAKd,IAAI,OAAO;AACP,eAAO,GAAG,IAAI,EAAE,MAAM;;;;;;MAO1B,IAAI,SAAS;AACT,eAAO,GAAG,IAAI,EAAE;;;;;;MAOpB,IAAI,gBAAgB;AAChB,eAAO,GAAG,IAAI,EAAE;;;;;MAMpB,eAAe;AACX,cAAM,gBAAgB,GAAG,IAAI,EAAE;AAC/B,YAAI,iBAAiB,MAAM;AACvB,iBAAO,CAAA;;AAEX,eAAO,CAAC,aAAa;;;;;;MAOzB,IAAI,OAAO;AACP,eAAO;;;;;;MAOX,IAAI,kBAAkB;AAClB,eAAO;;;;;;MAOX,IAAI,YAAY;AACZ,eAAO;;;;;;MAOX,IAAI,iBAAiB;AACjB,eAAO;;;;;;MAOX,IAAI,aAAa;AACb,eAAO,GAAG,IAAI,EAAE;;;;;;MAOpB,kBAAkB;AACd,cAAM,OAAO,GAAG,IAAI;AAEpB,aAAK,UAAU;AACf,YAAI,OAAO,KAAK,MAAM,oBAAoB,YAAY;AAClD,eAAK,MAAM,gBAAe;;;;;;;MAQlC,2BAA2B;AACvB,cAAM,OAAO,GAAG,IAAI;AAEpB,aAAK,UAAU;AACf,aAAK,mBAAmB;AACxB,YAAI,OAAO,KAAK,MAAM,6BAA6B,YAAY;AAC3D,eAAK,MAAM,yBAAwB;;;;;;;MAQ3C,IAAI,UAAU;AACV,eAAO,QAAQ,GAAG,IAAI,EAAE,MAAM,OAAO;;;;;;MAOzC,IAAI,aAAa;AACb,eAAO,QAAQ,GAAG,IAAI,EAAE,MAAM,UAAU;;;;;;MAO5C,iBAAiB;AACb,sBAAc,GAAG,IAAI,CAAC;;;;;;MAO1B,IAAI,mBAAmB;AACnB,eAAO,GAAG,IAAI,EAAE;;;;;;MAOpB,IAAI,WAAW;AACX,eAAO,QAAQ,GAAG,IAAI,EAAE,MAAM,QAAQ;;;;;;MAO1C,IAAI,YAAY;AACZ,eAAO,GAAG,IAAI,EAAE;;;;;;;MAQpB,IAAI,aAAa;AACb,eAAO,GAAG,IAAI,EAAE;;;;;;;MAQpB,IAAI,eAAe;AACf,eAAO,GAAG,IAAI,EAAE;;MAEpB,IAAI,aAAa,OAAO;AACpB,YAAI,CAAC,OAAO;AACR;;AAEJ,cAAM,OAAO,GAAG,IAAI;AAEpB,aAAK,UAAU;AACf,YAAI,OAAO,KAAK,MAAM,iBAAiB,WAAW;AAC9C,eAAK,MAAM,eAAe;;;;;;;;MASlC,IAAI,cAAc;AACd,eAAO,CAAC,GAAG,IAAI,EAAE;;MAErB,IAAI,YAAY,OAAO;AACnB,YAAI,CAAC,OAAO;AACR,wBAAc,GAAG,IAAI,CAAC;;;;;;;;;;MAW9B,YAAY;;;AAMhB,WAAO,eAAe,MAAM,WAAW,eAAe;MAClD,OAAO;MACP,cAAc;MACd,UAAU;KACb;AAGD,QAAI,OAAO,WAAW,eAAe,OAAO,OAAO,UAAU,aAAa;AACtE,aAAO,eAAe,MAAM,WAAW,OAAO,MAAM,SAAS;AAG7D,eAAS,IAAI,OAAO,MAAM,WAAW,KAAK;;AAS9C,aAAS,yBAAyB,KAAK;AACnC,aAAO;QACH,MAAM;AACF,iBAAO,GAAG,IAAI,EAAE,MAAM,GAAG;;QAE7B,IAAI,OAAO;AACP,aAAG,IAAI,EAAE,MAAM,GAAG,IAAI;;QAE1B,cAAc;QACd,YAAY;;;AAUpB,aAAS,qBAAqB,KAAK;AAC/B,aAAO;QACH,QAAQ;AACJ,gBAAM,QAAQ,GAAG,IAAI,EAAE;AACvB,iBAAO,MAAM,GAAG,EAAE,MAAM,OAAO,SAAS;;QAE5C,cAAc;QACd,YAAY;;;AAWpB,aAAS,cAAc,WAAW,OAAO;AACrC,YAAM,OAAO,OAAO,KAAK,KAAK;AAC9B,UAAI,KAAK,WAAW,GAAG;AACnB,eAAO;;AAIX,eAAS,YAAY,aAAa,OAAO;AACrC,kBAAU,KAAK,MAAM,aAAa,KAAK;;AAG3C,kBAAY,YAAY,OAAO,OAAO,UAAU,WAAW;QACvD,aAAa,EAAE,OAAO,aAAa,cAAc,MAAM,UAAU,KAAI;OACxE;AAGD,eAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,EAAE,GAAG;AAClC,cAAM,MAAM,KAAK,CAAC;AAClB,YAAI,EAAE,OAAO,UAAU,YAAY;AAC/B,gBAAM,aAAa,OAAO,yBAAyB,OAAO,GAAG;AAC7D,gBAAM,SAAS,OAAO,WAAW,UAAU;AAC3C,iBAAO;YACH,YAAY;YACZ;YACA,SACM,qBAAqB,GAAG,IACxB,yBAAyB,GAAG;;;;AAK9C,aAAO;;AASX,aAAS,WAAW,OAAO;AACvB,UAAI,SAAS,QAAQ,UAAU,OAAO,WAAW;AAC7C,eAAO;;AAGX,UAAI,UAAU,SAAS,IAAI,KAAK;AAChC,UAAI,WAAW,MAAM;AACjB,kBAAU,cAAc,WAAW,OAAO,eAAe,KAAK,CAAC,GAAG,KAAK;AACvE,iBAAS,IAAI,OAAO,OAAO;;AAE/B,aAAO;;AAUJ,aAAS,UAAU,aAAa,OAAO;AAC1C,YAAM,UAAU,WAAW,OAAO,eAAe,KAAK,CAAC;AACvD,aAAO,IAAI,QAAQ,aAAa,KAAK;;AASlC,aAAS,UAAU,OAAO;AAC7B,aAAO,GAAG,KAAK,EAAE;;AAUd,aAAS,cAAc,OAAO,YAAY;AAC7C,SAAG,KAAK,EAAE,aAAa;;AAUpB,aAAS,iBAAiB,OAAO,eAAe;AACnD,SAAG,KAAK,EAAE,gBAAgB;;AAUvB,aAAS,mBAAmB,OAAO,iBAAiB;AACvD,SAAG,KAAK,EAAE,kBAAkB;;ACvchC,QAAM,eAAe,oBAAI,QAAO;AAGhC,QAAM,UAAU;AAChB,QAAM,SAAS;AACf,QAAM,YAAY;AAOlB,aAAS,SAAS,GAAG;AACjB,aAAO,MAAM,QAAQ,OAAO,MAAM;;AAStC,aAAS,aAAa,aAAa;AAC/B,YAAM,YAAY,aAAa,IAAI,WAAW;AAC9C,UAAI,aAAa,MAAM;AACnB,cAAM,IAAI;UACN;;;AAGR,aAAO;;AASX,aAAS,+BAA+B,WAAW;AAC/C,aAAO;QACH,MAAM;AACF,gBAAM,YAAY,aAAa,IAAI;AACnC,cAAI,OAAO,UAAU,IAAI,SAAS;AAClC,iBAAO,QAAQ,MAAM;AACjB,gBAAI,KAAK,iBAAiB,WAAW;AACjC,qBAAO,KAAK;;AAEhB,mBAAO,KAAK;;AAEhB,iBAAO;;QAGX,IAAI,UAAU;AACV,cAAI,OAAO,aAAa,cAAc,CAAC,SAAS,QAAQ,GAAG;AACvD,uBAAW;;AAEf,gBAAM,YAAY,aAAa,IAAI;AAGnC,cAAI,OAAO;AACX,cAAI,OAAO,UAAU,IAAI,SAAS;AAClC,iBAAO,QAAQ,MAAM;AACjB,gBAAI,KAAK,iBAAiB,WAAW;AAEjC,kBAAI,SAAS,MAAM;AACf,qBAAK,OAAO,KAAK;yBACV,KAAK,SAAS,MAAM;AAC3B,0BAAU,IAAI,WAAW,KAAK,IAAI;qBAC/B;AACH,0BAAU,OAAO,SAAS;;mBAE3B;AACH,qBAAO;;AAGX,mBAAO,KAAK;;AAIhB,cAAI,aAAa,MAAM;AACnB,kBAAM,UAAU;cACZ;cACA,cAAc;cACd,SAAS;cACT,MAAM;cACN,MAAM;;AAEV,gBAAI,SAAS,MAAM;AACf,wBAAU,IAAI,WAAW,OAAO;mBAC7B;AACH,mBAAK,OAAO;;;;QAIxB,cAAc;QACd,YAAY;;;AAUpB,aAAS,qBAAqB,sBAAsB,WAAW;AAC3D,aAAO;QACH;QACA,KAAK,SAAS;QACd,+BAA+B,SAAS;;;AAUhD,aAAS,wBAAwB,YAAY;AAEzC,eAAS,oBAAoB;AACzB,oBAAY,KAAK,IAAI;;AAGzB,wBAAkB,YAAY,OAAO,OAAO,YAAY,WAAW;QAC/D,aAAa;UACT,OAAO;UACP,cAAc;UACd,UAAU;;OAEjB;AAED,eAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,EAAE,GAAG;AACxC,6BAAqB,kBAAkB,WAAW,WAAW,CAAC,CAAC;;AAGnE,aAAO;;AAgBX,aAAS,cAAc;AAEnB,UAAI,gBAAgB,aAAa;AAC7B,qBAAa,IAAI,MAAM,oBAAI,IAAG,CAAE;AAChC;;AAEJ,UAAI,UAAU,WAAW,KAAK,MAAM,QAAQ,UAAU,CAAC,CAAC,GAAG;AACvD,eAAO,wBAAwB,UAAU,CAAC,CAAC;;AAE/C,UAAI,UAAU,SAAS,GAAG;AACtB,cAAM,QAAQ,IAAI,MAAM,UAAU,MAAM;AACxC,iBAAS,IAAI,GAAG,IAAI,UAAU,QAAQ,EAAE,GAAG;AACvC,gBAAM,CAAC,IAAI,UAAU,CAAC;;AAE1B,eAAO,wBAAwB,KAAK;;AAExC,YAAM,IAAI,UAAU,mCAAmC;;AAK3D,gBAAY,YAAY;;;;;;;;MAQpB,iBAAiB,WAAW,UAAU,SAAS;AAC3C,YAAI,YAAY,MAAM;AAClB;;AAEJ,YAAI,OAAO,aAAa,cAAc,CAAC,SAAS,QAAQ,GAAG;AACvD,gBAAM,IAAI,UAAU,+CAA+C;;AAGvE,cAAM,YAAY,aAAa,IAAI;AACnC,cAAM,eAAe,SAAS,OAAO;AACrC,cAAM,UAAU,eACV,QAAQ,QAAQ,OAAO,IACvB,QAAQ,OAAO;AACrB,cAAM,eAAe,UAAU,UAAU;AACzC,cAAM,UAAU;UACZ;UACA;UACA,SAAS,gBAAgB,QAAQ,QAAQ,OAAO;UAChD,MAAM,gBAAgB,QAAQ,QAAQ,IAAI;UAC1C,MAAM;;AAIV,YAAI,OAAO,UAAU,IAAI,SAAS;AAClC,YAAI,SAAS,QAAW;AACpB,oBAAU,IAAI,WAAW,OAAO;AAChC;;AAIJ,YAAI,OAAO;AACX,eAAO,QAAQ,MAAM;AACjB,cACI,KAAK,aAAa,YAClB,KAAK,iBAAiB,cACxB;AAEE;;AAEJ,iBAAO;AACP,iBAAO,KAAK;;AAIhB,aAAK,OAAO;;;;;;;;;MAUhB,oBAAoB,WAAW,UAAU,SAAS;AAC9C,YAAI,YAAY,MAAM;AAClB;;AAGJ,cAAM,YAAY,aAAa,IAAI;AACnC,cAAM,UAAU,SAAS,OAAO,IAC1B,QAAQ,QAAQ,OAAO,IACvB,QAAQ,OAAO;AACrB,cAAM,eAAe,UAAU,UAAU;AAEzC,YAAI,OAAO;AACX,YAAI,OAAO,UAAU,IAAI,SAAS;AAClC,eAAO,QAAQ,MAAM;AACjB,cACI,KAAK,aAAa,YAClB,KAAK,iBAAiB,cACxB;AACE,gBAAI,SAAS,MAAM;AACf,mBAAK,OAAO,KAAK;uBACV,KAAK,SAAS,MAAM;AAC3B,wBAAU,IAAI,WAAW,KAAK,IAAI;mBAC/B;AACH,wBAAU,OAAO,SAAS;;AAE9B;;AAGJ,iBAAO;AACP,iBAAO,KAAK;;;;;;;;MASpB,cAAc,OAAO;AACjB,YAAI,SAAS,QAAQ,OAAO,MAAM,SAAS,UAAU;AACjD,gBAAM,IAAI,UAAU,kCAAkC;;AAI1D,cAAM,YAAY,aAAa,IAAI;AACnC,cAAM,YAAY,MAAM;AACxB,YAAI,OAAO,UAAU,IAAI,SAAS;AAClC,YAAI,QAAQ,MAAM;AACd,iBAAO;;AAIX,cAAM,eAAe,UAAU,MAAM,KAAK;AAI1C,YAAI,OAAO;AACX,eAAO,QAAQ,MAAM;AAEjB,cAAI,KAAK,MAAM;AACX,gBAAI,SAAS,MAAM;AACf,mBAAK,OAAO,KAAK;uBACV,KAAK,SAAS,MAAM;AAC3B,wBAAU,IAAI,WAAW,KAAK,IAAI;mBAC/B;AACH,wBAAU,OAAO,SAAS;;iBAE3B;AACH,mBAAO;;AAIX;YACI;YACA,KAAK,UAAU,KAAK,WAAW;;AAEnC,cAAI,OAAO,KAAK,aAAa,YAAY;AACrC,gBAAI;AACA,mBAAK,SAAS,KAAK,MAAM,YAAY;qBAChC,KAAK;AACV,kBACI,OAAO,YAAY,eACnB,OAAO,QAAQ,UAAU,YAC3B;AACE,wBAAQ,MAAM,GAAG;;;qBAIzB,KAAK,iBAAiB,aACtB,OAAO,KAAK,SAAS,gBAAgB,YACvC;AACE,iBAAK,SAAS,YAAY,YAAY;;AAI1C,cAAI,UAAU,YAAY,GAAG;AACzB;;AAGJ,iBAAO,KAAK;;AAEhB,2BAAmB,cAAc,IAAI;AACrC,sBAAc,cAAc,CAAC;AAC7B,yBAAiB,cAAc,IAAI;AAEnC,eAAO,CAAC,aAAa;;;AAK7B,WAAO,eAAe,YAAY,WAAW,eAAe;MACxD,OAAO;MACP,cAAc;MACd,UAAU;KACb;AAGD,QACI,OAAO,WAAW,eAClB,OAAO,OAAO,gBAAgB,aAChC;AACE,aAAO,eAAe,YAAY,WAAW,OAAO,YAAY,SAAS;;;;;;;;;;;;;;;;;ACrW7E,QAAqB,cAArB,cAAyCA,gBAAAA,YAAoC;;;;MAIzE,cAAA;AACI,cAAK;AACL,cAAM,IAAI,UAAU,4CAA4C;;;;;MAMpE,IAAW,UAAO;AACd,cAAM,UAAU,aAAa,IAAI,IAAI;AACrC,YAAI,OAAO,YAAY,WAAW;AAC9B,gBAAM,IAAI,UACN,0DACI,SAAS,OAAO,SAAS,OAAO,IACpC,EAAE;;AAGV,eAAO;;;AAGfC,oBAAAA,qBAAqB,YAAY,WAAW,OAAO;AAKnD,aAAgB,oBAAiB;AAC7B,YAAM,SAAS,OAAO,OAAO,YAAY,SAAS;AAClDD,sBAAAA,YAAY,KAAK,MAAM;AACvB,mBAAa,IAAI,QAAQ,KAAK;AAC9B,aAAO;;AAMX,aAAgB,YAAY,QAAmB;AAC3C,UAAI,aAAa,IAAI,MAAM,MAAM,OAAO;AACpC;;AAGJ,mBAAa,IAAI,QAAQ,IAAI;AAC7B,aAAO,cAAuB,EAAE,MAAM,QAAO,CAAE;;AAMnD,QAAM,eAAe,oBAAI,QAAO;AAGhC,WAAO,iBAAiB,YAAY,WAAW;MAC3C,SAAS,EAAE,YAAY,KAAI;KAC9B;AAGD,QAAI,OAAO,WAAW,cAAc,OAAO,OAAO,gBAAgB,UAAU;AACxE,aAAO,eAAe,YAAY,WAAW,OAAO,aAAa;QAC7D,cAAc;QACd,OAAO;OACV;;AC/EL,QAAqBE,mBAArB,MAAoC;;;;MAIhC,cAAA;AACI,gBAAQ,IAAI,MAAM,kBAAiB,CAAE;;;;;MAMzC,IAAW,SAAM;AACb,eAAO,UAAU,IAAI;;;;;MAMlB,QAAK;AACR,oBAAY,UAAU,IAAI,CAAC;;;AAOnC,QAAM,UAAU,oBAAI,QAAO;AAK3B,aAAS,UAAU,YAA2B;AAC1C,YAAM,SAAS,QAAQ,IAAI,UAAU;AACrC,UAAI,UAAU,MAAM;AAChB,cAAM,IAAI,UACN,8DACI,eAAe,OAAO,SAAS,OAAO,UAC1C,EAAE;;AAGV,aAAO;;AAIX,WAAO,iBAAiBA,iBAAgB,WAAW;MAC/C,QAAQ,EAAE,YAAY,KAAI;MAC1B,OAAO,EAAE,YAAY,KAAI;KAC5B;AAED,QAAI,OAAO,WAAW,cAAc,OAAO,OAAO,gBAAgB,UAAU;AACxE,aAAO,eAAeA,iBAAgB,WAAW,OAAO,aAAa;QACjE,cAAc;QACd,OAAO;OACV;;;;;;;;;;;;AC3DL;AAAA;AAAA;AAEA,QAAI,oBAAoB,SAASC,mBAAkB,OAAO;AACzD,aAAO,gBAAgB,KAAK,KACxB,CAAC,UAAU,KAAK;AAAA,IACrB;AAEA,aAAS,gBAAgB,OAAO;AAC/B,aAAO,CAAC,CAAC,SAAS,OAAO,UAAU;AAAA,IACpC;AAEA,aAAS,UAAU,OAAO;AACzB,UAAI,cAAc,OAAO,UAAU,SAAS,KAAK,KAAK;AAEtD,aAAO,gBAAgB,qBACnB,gBAAgB,mBAChB,eAAe,KAAK;AAAA,IACzB;AAGA,QAAI,eAAe,OAAO,WAAW,cAAc,OAAO;AAC1D,QAAI,qBAAqB,eAAe,OAAO,IAAI,eAAe,IAAI;AAEtE,aAAS,eAAe,OAAO;AAC9B,aAAO,MAAM,aAAa;AAAA,IAC3B;AAEA,aAAS,YAAY,KAAK;AACzB,aAAO,MAAM,QAAQ,GAAG,IAAI,CAAC,IAAI,CAAC;AAAA,IACnC;AAEA,aAAS,8BAA8B,OAAO,SAAS;AACtD,aAAQ,QAAQ,UAAU,SAAS,QAAQ,kBAAkB,KAAK,IAC/D,UAAU,YAAY,KAAK,GAAG,OAAO,OAAO,IAC5C;AAAA,IACJ;AAEA,aAAS,kBAAkB,QAAQ,QAAQ,SAAS;AACnD,aAAO,OAAO,OAAO,MAAM,EAAE,IAAI,SAAS,SAAS;AAClD,eAAO,8BAA8B,SAAS,OAAO;AAAA,MACtD,CAAC;AAAA,IACF;AAEA,aAAS,iBAAiB,KAAK,SAAS;AACvC,UAAI,CAAC,QAAQ,aAAa;AACzB,eAAO;AAAA,MACR;AACA,UAAI,cAAc,QAAQ,YAAY,GAAG;AACzC,aAAO,OAAO,gBAAgB,aAAa,cAAc;AAAA,IAC1D;AAEA,aAAS,gCAAgC,QAAQ;AAChD,aAAO,OAAO,wBACX,OAAO,sBAAsB,MAAM,EAAE,OAAO,SAAS,QAAQ;AAC9D,eAAO,OAAO,qBAAqB,KAAK,QAAQ,MAAM;AAAA,MACvD,CAAC,IACC,CAAC;AAAA,IACL;AAEA,aAAS,QAAQ,QAAQ;AACxB,aAAO,OAAO,KAAK,MAAM,EAAE,OAAO,gCAAgC,MAAM,CAAC;AAAA,IAC1E;AAEA,aAAS,mBAAmB,QAAQ,UAAU;AAC7C,UAAI;AACH,eAAO,YAAY;AAAA,MACpB,SAAQ,GAAG;AACV,eAAO;AAAA,MACR;AAAA,IACD;AAGA,aAAS,iBAAiB,QAAQ,KAAK;AACtC,aAAO,mBAAmB,QAAQ,GAAG,KACjC,EAAE,OAAO,eAAe,KAAK,QAAQ,GAAG,KACvC,OAAO,qBAAqB,KAAK,QAAQ,GAAG;AAAA,IAClD;AAEA,aAAS,YAAY,QAAQ,QAAQ,SAAS;AAC7C,UAAI,cAAc,CAAC;AACnB,UAAI,QAAQ,kBAAkB,MAAM,GAAG;AACtC,gBAAQ,MAAM,EAAE,QAAQ,SAAS,KAAK;AACrC,sBAAY,GAAG,IAAI,8BAA8B,OAAO,GAAG,GAAG,OAAO;AAAA,QACtE,CAAC;AAAA,MACF;AACA,cAAQ,MAAM,EAAE,QAAQ,SAAS,KAAK;AACrC,YAAI,iBAAiB,QAAQ,GAAG,GAAG;AAClC;AAAA,QACD;AAEA,YAAI,mBAAmB,QAAQ,GAAG,KAAK,QAAQ,kBAAkB,OAAO,GAAG,CAAC,GAAG;AAC9E,sBAAY,GAAG,IAAI,iBAAiB,KAAK,OAAO,EAAE,OAAO,GAAG,GAAG,OAAO,GAAG,GAAG,OAAO;AAAA,QACpF,OAAO;AACN,sBAAY,GAAG,IAAI,8BAA8B,OAAO,GAAG,GAAG,OAAO;AAAA,QACtE;AAAA,MACD,CAAC;AACD,aAAO;AAAA,IACR;AAEA,aAAS,UAAU,QAAQ,QAAQ,SAAS;AAC3C,gBAAU,WAAW,CAAC;AACtB,cAAQ,aAAa,QAAQ,cAAc;AAC3C,cAAQ,oBAAoB,QAAQ,qBAAqB;AAGzD,cAAQ,gCAAgC;AAExC,UAAI,gBAAgB,MAAM,QAAQ,MAAM;AACxC,UAAI,gBAAgB,MAAM,QAAQ,MAAM;AACxC,UAAI,4BAA4B,kBAAkB;AAElD,UAAI,CAAC,2BAA2B;AAC/B,eAAO,8BAA8B,QAAQ,OAAO;AAAA,MACrD,WAAW,eAAe;AACzB,eAAO,QAAQ,WAAW,QAAQ,QAAQ,OAAO;AAAA,MAClD,OAAO;AACN,eAAO,YAAY,QAAQ,QAAQ,OAAO;AAAA,MAC3C;AAAA,IACD;AAEA,cAAU,MAAM,SAAS,aAAa,OAAO,SAAS;AACrD,UAAI,CAAC,MAAM,QAAQ,KAAK,GAAG;AAC1B,cAAM,IAAI,MAAM,mCAAmC;AAAA,MACpD;AAEA,aAAO,MAAM,OAAO,SAAS,MAAM,MAAM;AACxC,eAAO,UAAU,MAAM,MAAM,OAAO;AAAA,MACrC,GAAG,CAAC,CAAC;AAAA,IACN;AAEA,QAAI,cAAc;AAElB,WAAO,UAAU;AAAA;AAAA;;;ACpIjB,SAAS,cAA+B,kBAAkB;AAC1D,SAAS,+BAA+B;AACxC,SAAS,eAAe;AACxB,SAAS,gBAAgB;AACzB,SAAwB,YAAY,mBAAmB;AACvD,SAAS,oBAAoB;AAC7B,SAAS,yBAAyB;AAClC,OAAO,mBAAmB;AAC1B,SAAkC,gBAAsB;AAExD,eAAe,gBACX,SACA,MAC+C;AAE/C,SAAO,MAAM,WAAW,MAAM,KAAQ,OAAO;AAE7C,QAAM,SAAS;AAAA;AAAA;AAAA,IAGf,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAWJ,QAAM,WAAW,MAAM,aAAa;AAAA,IAChC;AAAA,IACA,SAAS;AAAA,IACT,YAAY,WAAW;AAAA,EAC3B,CAAC;AAED,QAAM,iBAAiB,wBAAwB,QAAQ;AAEvD,MAAI,gBAAgB;AAChB,WAAO;AAAA,MACH,OAAO,eAAe;AAAA,MACtB,aAAa,eAAe;AAAA,IAChC;AAAA,EACJ;AAEA,SAAO;AAAA,IACH,OAAO;AAAA,IACP,aAAa;AAAA,EACjB;AACJ;AAQO,IAAM,iBAAN,MAAM,wBAAuB,QAAmC;AAAA,EAC3D;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,WAAW;AAAA,EAEnB,OAAO,cAA2B,YAAY;AAAA,EAE9C,OAAO,SAAS,SAAuC;AAEnD,WAAO;AAAA,EACX;AAAA,EAEA,cAA+B;AAC3B,WAAO,gBAAe,YAAY;AAAA,EACtC;AAAA,EAEA,cAAc;AACV,UAAM;AACN,SAAK,UAAU;AACf,SAAK,UAAU;AACf,SAAK,UAAU;AACf,SAAK,gBAAgB,IAAI;AAAA,MACrB,SAAS,qBAAqB;AAAA,IAClC;AAAA,EACJ;AAAA,EAEA,MAAM,aAAa;AAAA,EAAC;AAAA,EAEpB,MAAM,oBAAoB;AACtB,QAAI,CAAC,KAAK,SAAS;AACf,WAAK,UAAU,MAAM,SAAS,OAAO;AAAA,QACjC,UAAU;AAAA,QACV,MAAM;AAAA,UACF;AAAA;AAAA,UACA;AAAA;AAAA,QACJ;AAAA,MACJ,CAAC;AAED,YAAM,WAAW,QAAQ;AACzB,UAAI,YAAY;AAGhB,cAAQ,UAAU;AAAA,QACd,KAAK;AACD,sBACI;AACJ;AAAA,QACJ,KAAK;AACD,sBACI;AACJ;AAAA,QACJ,KAAK;AACD,sBACI;AACJ;AAAA,QACJ;AACI,sBACI;AAAA,MACZ;AAEA,WAAK,UAAU,MAAM,KAAK,QAAQ,WAAW;AAAA,QACzC;AAAA,QACA,iBAAiB;AAAA,MACrB,CAAC;AAED,WAAK,UACD,MAAM,kBAAkB,2BAA2B,KAAK;AAAA,IAChE;AAAA,EACJ;AAAA,EAEA,MAAM,eAAe;AACjB,QAAI,KAAK,SAAS;AACd,YAAM,KAAK,QAAQ,MAAM;AACzB,WAAK,UAAU;AAAA,IACnB;AACA,QAAI,KAAK,SAAS;AACd,YAAM,KAAK,QAAQ,MAAM;AACzB,WAAK,UAAU;AAAA,IACnB;AAAA,EACJ;AAAA,EAEA,MAAM,eACF,KACA,SACoB;AACpB,UAAM,KAAK,kBAAkB;AAC7B,WAAO,MAAM,KAAK,iBAAiB,KAAK,OAAO;AAAA,EACnD;AAAA,EAEQ,YAAY,KAAqB;AACrC,WAAO,aAAa,GAAG;AAAA,EAC3B;AAAA,EAEA,MAAc,iBACV,KACA,SACoB;AACpB,UAAM,WAAW,KAAK,YAAY,GAAG;AACrC,UAAM,SAAS,MAAM,QAAQ,aAAa,IAGvC,GAAG,KAAK,QAAQ,IAAI,QAAQ,EAAE;AAEjC,QAAI,QAAQ;AACR,aAAO,OAAO;AAAA,IAClB;AAEA,QAAI;AAEJ,QAAI;AACA,UAAI,CAAC,KAAK,SAAS;AACf,gBAAQ;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AAEA,aAAO,MAAM,KAAK,QAAQ,QAAQ;AAGlC,YAAM,KAAK,oBAAoB;AAAA,QAC3B,mBAAmB;AAAA,MACvB,CAAC;AAGD,UAAI,KAAK,SAAS;AACd,cAAM,KAAK,QAAQ,qBAAqB,IAAI;AAAA,MAChD;AAEA,YAAM,WAAW,MAAM,KAAK,KAAK,KAAK,EAAE,WAAW,cAAc,CAAC;AAElE,UAAI,CAAC,UAAU;AACX,gBAAQ,IAAI,yBAAyB;AAAA,MACzC;AAEA,UAAI,SAAS,OAAO,MAAM,OAAO,SAAS,OAAO,MAAM,KAAK;AACxD,eAAO,MAAM,KAAK,sBAAsB,KAAK,OAAO;AAAA,MACxD;AAGA,YAAM,kBAAkB,MAAM,KAAK,cAAc,IAAI;AACrD,UAAI,iBAAiB;AACjB,cAAM,KAAK,aAAa,MAAM,GAAG;AAAA,MACrC;AACA,YAAM,gBAAgB,MAAM,KAAK,SAAS,MAAM,SAAS,KAAK;AAC9D,YAAM,cAAc,MAAM,KAAK;AAAA,QAC3B,MAAM,SAAS,KAAK;AAAA,MACxB;AACA,YAAM,EAAE,OAAO,aAAa,YAAY,IAAI,MAAM;AAAA,QAC9C;AAAA,QACA,gBAAgB,OAAO;AAAA,MAC3B;AACA,YAAM,UAAU,EAAE,OAAO,aAAa,aAAa,YAAY;AAC/D,YAAM,QAAQ,aAAa,IAAI,GAAG,KAAK,QAAQ,IAAI,QAAQ,IAAI;AAAA,QAC3D;AAAA,QACA;AAAA,MACJ,CAAC;AACD,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,cAAQ,MAAM,UAAU,KAAK;AAC7B,aAAO;AAAA,QACH,OAAO;AAAA,QACP,aAAa;AAAA,QACb,aAAa;AAAA,MACjB;AAAA,IACJ,UAAE;AACE,UAAI,MAAM;AACN,cAAM,KAAK,MAAM;AAAA,MACrB;AAAA,IACJ;AAAA,EACJ;AAAA,EAEA,MAAc,cAAc,MAA8B;AACtD,UAAM,mBAAmB;AAAA,MACrB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACJ;AAEA,eAAW,YAAY,kBAAkB;AACrC,YAAM,UAAU,MAAM,KAAK,EAAE,QAAQ;AACrC,UAAI,QAAS,QAAO;AAAA,IACxB;AAEA,WAAO;AAAA,EACX;AAAA,EAEA,MAAc,aAAa,MAAY,KAA4B;AAC/D,QAAI;AACA,YAAM,cAAc,MAAM,KAAK,sBAAsB,IAAI;AACzD,UAAI,aAAa;AACb,cAAM,WAAW,MAAM,KAAK,cAAc,kBAAkB;AAAA,UACxD,YAAY;AAAA,UACZ,YAAY;AAAA,QAChB,CAAC;AACD,cAAM,KAAK,SAAS,CAAC,UAAU;AAG3B,iBAAO,SAAS,YAAY,KAAK;AAAA,QACrC,GAAG,SAAS,kBAAkB;AAC9B;AAAA,MACJ;AAEA,YAAM,eAAe,MAAM,KAAK,uBAAuB,IAAI;AAC3D,UAAI,cAAc;AACd,cAAM,WAAW,MAAM,KAAK,cAAc,qBAAqB;AAAA,UAC3D,YAAY;AAAA,UACZ,YAAY;AAAA,QAChB,CAAC;AACD,cAAM,KAAK,SAAS,CAAC,UAAU;AAG3B,mBAAS,eAAe,sBAAsB,EAAE,YAC5C;AAAA,QACR,GAAG,SAAS,kBAAkB;AAAA,MAClC;AAAA,IACJ,SAAS,OAAO;AACZ,cAAQ,MAAM,0BAA0B,KAAK;AAAA,IACjD;AAAA,EACJ;AAAA,EAEA,MAAc,sBAAsB,MAA6B;AAC7D,WAAO,KAAK,SAAS,MAAM;AACvB,YAAM,iBAAiB,SAAS;AAAA,QAC5B;AAAA,MACJ;AACA,UAAI,gBAAgB;AAChB,cAAM,MAAM,eAAe,aAAa,KAAK;AAC7C,cAAM,QAAQ,KAAK,MAAM,iBAAiB;AAC1C,eAAO,QAAQ,MAAM,CAAC,IAAI;AAAA,MAC9B;AACA,aAAO;AAAA,IACX,CAAC;AAAA,EACL;AAAA,EAEA,MAAc,uBAAuB,MAA6B;AAC9D,WAAO,KAAK,SAAS,MAAM;AACvB,YAAM,mBAAmB,SAAS,cAAc,cAAc;AAC9D,aAAO,mBACD,iBAAiB,aAAa,cAAc,KAAK,KACjD;AAAA,IACV,CAAC;AAAA,EACL;AAAA,EAEA,MAAc,sBACV,KACA,SACoE;AAEpE,UAAM,aAAa,+BAA+B,GAAG;AACrD,QAAI;AACA,aAAO,MAAM,KAAK,iBAAiB,YAAY,OAAO;AAAA,IAC1D,SAAS,OAAO;AACZ,cAAQ,MAAM,yCAAyC,KAAK;AAAA,IAChE;AAGA,UAAM,kBAAkB,mCAAmC,mBAAmB,GAAG,CAAC;AAClF,QAAI;AACA,aAAO,MAAM,KAAK,iBAAiB,iBAAiB,OAAO;AAAA,IAC/D,SAAS,OAAO;AACZ,cAAQ,MAAM,sCAAsC,KAAK;AACzD,cAAQ,MAAM,kDAAkD;AAChE,aAAO;AAAA,QACH,OAAO;AAAA,QACP,aACI;AAAA,QACJ,aAAa;AAAA,MACjB;AAAA,IACJ;AAAA,EACJ;AACJ;;;AC5UA,SAAS,aAAa,cAAc;AACpC,SAAS,WAAAC,gBAAe;AACxB;AAAA,EAEI;AAAA,EACA,eAAAC;AAAA,OAEG;AACP;AAAA,EACI;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAIA;AAAA,OAEG;AACP,OAAO,QAAQ;AACf,OAAO,eAAe;AACtB,OAAO,QAAQ;AACf,OAAO,UAAU;AAEV,IAAM,0BAAN,MAAM,iCACDD,SAEZ;AAAA,EACI,OAAO,cAA2BC,aAAY;AAAA,EAEtC,UAAkB;AAAA,EAClB,SAAiB;AAAA,EACjB,QAAgC;AAAA,EAChC,YAAuC;AAAA,EACvC,YAAwC;AAAA,EACxC,cAAuB;AAAA,EACvB,UAAgC;AAAA,EAChC,QAAkB,CAAC;AAAA,EACnB,aAAsB;AAAA,EAE9B,cAAwC;AACpC,WAAO,yBAAwB,YAAY;AAAA,EAC/C;AAAA,EAEA,MAAM,WAAW,SAAuC;AACpD,gBAAY,IAAI,sCAAsC;AACtD,SAAK,UAAU;AAAA,EACnB;AAAA,EAEA,MAAc,uBAAsC;AAChD,QAAI,mBAAmB;AACvB,QAAI,oBAAoB;AACxB,QAAI,SAAS,KAAK,WAAW;AAC7B,QAAI,SAAS,KAAK,KAAK,QAAQ;AAC/B,QAAI,SAAS,KAAK,KAAK,aAAa;AAEpC,gBAAY,KAAK,+BAA+B;AAEhD,SAAK,QAAQ,MAAM,kCAAkC;AAAA,MACjD,KAAK;AAAA,MACL;AAAA,QACI,QAAQ;AAAA,QACR,mBAAmB,CAAC,aAAa;AAC7B,cAAI,SAAS,WAAW,eAAe;AACnC,kBAAM,WACD,SAAS,SAAS,SAAS,QAC5B,KACF,QAAQ,CAAC;AACX,kBAAM,OAAO,IAAI;AAAA,cACb,KAAK,MAAM,OAAO,OAAO,IAAI,CAAC;AAAA,YAClC;AACA,wBAAY;AAAA,cACR,gCAAgC,KAAK,OAAO,IAAI,GAAG,CAAC,KAAK,OAAO;AAAA,YACpE;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ;AAEA,gBAAY,QAAQ,wCAAwC;AAE5D,gBAAY,KAAK,0BAA0B;AAC3C,SAAK,YAAa,MAAM,cAAc;AAAA,MAClC,KAAK;AAAA,IACT;AAEA,gBAAY,KAAK,0BAA0B;AAC3C,SAAK,YAAY,MAAM,cAAc,gBAAgB,KAAK,OAAO;AACjE,gBAAY,QAAQ,uCAAuC;AAAA,EAC/D;AAAA,EAEA,MAAM,cACF,UAC+C;AAC/C,QAAI,CAAC,KAAK,aAAa;AACnB,YAAM,QAAQ,OAAO,KAAK,SAAS,WAAW,aAAa;AAE3D,UAAI,UAAU,OAAO,kBAAkB,UAAU,GAAG;AAChD,cAAM,KAAK,qBAAqB;AAAA,MACpC,OAAO;AACH,aAAK,UAAU;AACf,aAAK,SAAS;AAAA,MAClB;AAEA,WAAK,cAAc;AAAA,IACvB;AAEA,QAAI,KAAK,WAAW,SAAS;AACzB,UAAI,CAAC,KAAK,SAAS;AACf,cAAM,IAAI;AAAA,UACN;AAAA,QACJ;AAAA,MACJ;AACA,aAAO,KAAK,oBAAoB,QAAQ;AAAA,IAC5C;AAEA,SAAK,MAAM,KAAK,QAAQ;AACxB,SAAK,aAAa;AAElB,WAAO,IAAI,QAAQ,CAAC,SAAS,YAAY;AACrC,YAAM,aAAa,MAAM;AACrB,cAAM,QAAQ,KAAK,MAAM,QAAQ,QAAQ;AACzC,YAAI,UAAU,IAAI;AACd,qBAAW,YAAY,GAAG;AAAA,QAC9B,OAAO;AACH,kBAAQ,KAAK,aAAa,QAAQ,CAAC;AAAA,QACvC;AAAA,MACJ;AACA,iBAAW;AAAA,IACf,CAAC;AAAA,EACL;AAAA,EAEA,MAAc,oBACV,UAC+C;AAC/C,UAAM,QAAQ,SAAS,YAAY,EAAE,SAAS,MAAM;AACpD,QAAI,YAA2B;AAE/B,QAAI;AACA,UAAI,OAAO;AACP,cAAM,EAAE,SAAS,IACb,MAAM,KAAK,yBAAyB,QAAQ;AAChD,oBAAY,GAAG,aAAa,QAAQ;AAAA,MACxC,WAAW,GAAG,WAAW,QAAQ,GAAG;AAChC,oBAAY,GAAG,aAAa,QAAQ;AAAA,MACxC,OAAO;AACH,cAAM,WAAW,MAAM,MAAM,QAAQ;AACrC,YAAI,CAAC,SAAS,IAAI;AACd,gBAAM,IAAI;AAAA,YACN,0BAA0B,SAAS,UAAU;AAAA,UACjD;AAAA,QACJ;AACA,oBAAY,OAAO,KAAK,MAAM,SAAS,YAAY,CAAC;AAAA,MACxD;AAEA,UAAI,CAAC,aAAa,UAAU,WAAW,GAAG;AACtC,cAAM,IAAI,MAAM,4BAA4B;AAAA,MAChD;AAEA,YAAM,SACF;AACJ,YAAM,OAAO,MAAM,KAAK;AAAA,QACpB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACJ;AAEA,YAAM,CAAC,OAAO,GAAG,gBAAgB,IAAI,KAAK,MAAM,IAAI;AACpD,aAAO;AAAA,QACH;AAAA,QACA,aAAa,iBAAiB,KAAK,IAAI;AAAA,MAC3C;AAAA,IACJ,SAAS,OAAO;AACZ,kBAAY,MAAM,iCAAiC,KAAK;AACxD,YAAM;AAAA,IACV;AAAA,EACJ;AAAA,EAEA,MAAc,cACV,UACA,WACA,QACA,QAAiB,OACjB,cAAuB,OACR;AACf,aAAS,UAAU,GAAG,UAAU,GAAG,WAAW;AAC1C,UAAI;AACA,cAAM,mBAAmB,SAAS,gBAAe,EAAE,KAAK,QAAQ,uBAAuB,kBAAkB;AACzG,cAAM,WAAW,QACX,QACA,KAAK,QAAQ,QAAQ,EAAE,MAAM,CAAC,KAAK;AAEzC,cAAM,aAAa,UAAU,SAAS,QAAQ;AAC9C,cAAM,gBAAgB,kBAChB,cAAc,QAAQ,WAAW,UAAU,KAC3C;AAEN,cAAM,UAAU;AAAA,UACZ,EAAE,MAAM,QAAQ,MAAM,OAAO;AAAA,UAC7B;AAAA,YACI,MAAM;AAAA,YACN,WAAW;AAAA,cACP,KAAK;AAAA,YACT;AAAA,UACJ;AAAA,QACJ;AAEA,cAAM,WACF,KAAK,QAAQ,uBAAuB,kBAAkB,SACpD,OAAO,KAAK,QAAQ,kBAAkB,EAAE,WACxC;AACN,cAAM,WAAW,MAAM,MAAM,WAAW,qBAAqB;AAAA,UACzD,QAAQ;AAAA,UACR,SAAS;AAAA,YACL,gBAAgB;AAAA,YAChB,eAAe,UAAU,KAAK,QAAQ,WAAW,gBAAgB,CAAC;AAAA,UACtE;AAAA,UACA,MAAM,KAAK,UAAU;AAAA,YACjB,OAAO;AAAA,YACP,UAAU,CAAC,EAAE,MAAM,QAAQ,QAAQ,CAAC;AAAA,YACpC,YAAY,kBAAkB,MAAM;AAAA,UACxC,CAAC;AAAA,QACL,CAAC;AAED,YAAI,CAAC,SAAS,IAAI;AACd,gBAAM,eAAe,MAAM,SAAS,KAAK;AACzC,sBAAY;AAAA,YACR;AAAA,YACA,SAAS;AAAA,YACT;AAAA,YACA;AAAA,UACJ;AACA,gBAAM,IAAI,MAAM,uBAAuB,SAAS,MAAM,EAAE;AAAA,QAC5D;AAEA,cAAM,OAAO,MAAM,SAAS,KAAK;AACjC,eAAO,KAAK,QAAQ,CAAC,EAAE,QAAQ;AAAA,MACnC,SAAS,OAAO;AACZ,oBAAY;AAAA,UACR;AAAA,UACA,UAAU;AAAA,UACV;AAAA,UACA;AAAA,QACJ;AACA,YAAI,YAAY,EAAG,OAAM;AAAA,MAC7B;AAAA,IACJ;AACA,UAAM,IAAI;AAAA,MACN;AAAA,IACJ;AAAA,EACJ;AAAA,EAEA,MAAc,eAA8B;AACxC,QAAI,KAAK,cAAc,KAAK,MAAM,WAAW,EAAG;AAEhD,SAAK,aAAa;AAClB,WAAO,KAAK,MAAM,SAAS,GAAG;AAC1B,YAAM,WAAW,KAAK,MAAM,MAAM;AAClC,YAAM,KAAK,aAAa,QAAQ;AAAA,IACpC;AACA,SAAK,aAAa;AAAA,EACtB;AAAA,EAEA,MAAc,aACV,UAC+C;AAC/C,QAAI,CAAC,KAAK,SAAS,CAAC,KAAK,aAAa,CAAC,KAAK,WAAW;AACnD,YAAM,IAAI,MAAM,kCAAkC;AAAA,IACtD;AAEA,gBAAY,IAAI,qBAAqB,QAAQ;AAC7C,UAAM,QAAQ,SAAS,YAAY,EAAE,SAAS,MAAM;AACpD,QAAI,iBAAiB;AAErB,QAAI;AACA,UAAI,OAAO;AACP,oBAAY,IAAI,iCAAiC;AACjD,cAAM,EAAE,SAAS,IACb,MAAM,KAAK,yBAAyB,QAAQ;AAChD,yBAAiB;AAAA,MACrB;AAEA,YAAM,QAAQ,MAAM,SAAS,QAAQ,cAAc;AACnD,YAAM,eAAe,MAAM,KAAK,UAAU,KAAK;AAC/C,YAAM,UACF,KAAK,UAAU,kBAAkB,oBAAoB;AACzD,YAAM,aAAa,KAAK,UAAU,OAAO;AAEzC,kBAAY,IAAI,8BAA8B;AAC9C,YAAM,eAAgB,MAAM,KAAK,MAAM,SAAS;AAAA,QAC5C,GAAG;AAAA,QACH,GAAG;AAAA,QACH,gBAAgB;AAAA,MACpB,CAAC;AAED,YAAM,gBAAgB,KAAK,UAAU,aAAa,cAAc;AAAA,QAC5D,qBAAqB;AAAA,MACzB,CAAC,EAAE,CAAC;AAEJ,YAAM,SAAS,KAAK,UAAU;AAAA,QAC1B;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV;AAEA,YAAM,kBAAkB,OAAO,oBAAoB;AACnD,aAAO,EAAE,OAAO,iBAAiB,aAAa,gBAAgB;AAAA,IAClE,SAAS,OAAO;AACZ,kBAAY,MAAM,2BAA2B,KAAK;AAClD,YAAM;AAAA,IACV,UAAE;AACE,UAAI,SAAS,mBAAmB,UAAU;AACtC,WAAG,WAAW,cAAc;AAAA,MAChC;AAAA,IACJ;AAAA,EACJ;AAAA,EAEA,MAAc,yBACV,QAC6B;AAC7B,UAAM,YAAY,MAAM,UAAU;AAAA,MAC9B,KAAK;AAAA,MACL,QAAQ;AAAA,MACR,YAAY;AAAA,IAChB,CAAC;AAED,UAAM,eAAe,KAAK;AAAA,MACtB,GAAG,OAAO;AAAA,MACV,aAAa,KAAK,IAAI,CAAC;AAAA,IAC3B;AAEA,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,YAAM,cAAc,GAAG,kBAAkB,YAAY;AACrD,gBAAU,CAAC,EAAE,SAAS,EAAE,KAAK,WAAW;AACxC,kBAAY,GAAG,UAAU,MAAM,QAAQ,EAAE,UAAU,aAAa,CAAC,CAAC;AAClE,kBAAY,GAAG,SAAS,MAAM;AAAA,IAClC,CAAC;AAAA,EACL;AACJ;;;ACpVA;AAAA,EACI,eAAAC;AAAA,EAEA,eAAAC;AAAA,EACA,qBAAAC;AAAA,OACG;AACP,SAAS,WAAAC,gBAAe;AACxB,OAAOC,SAAQ;AACf,OAAO,WAAW;AAClB;AAAA,EAEI;AAAA,EAKA;AAAA,OAGG;AACP,OAAOC,WAAU;AACjB,OAAO,QAAQ;AACf,SAAS,qBAAqB;AAE9B,IAAM,gBAAgB;AAAA,EAClB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACJ;AAEA,IAAM,YAAYA,MAAK,QAAQ,cAAc,YAAY,GAAG,CAAC;AAE7D,IAAM,oBAUD;AAAA,EACD,MAAM;AAAA,EACN,YAAY;AAAA,IACR,MAAM;AAAA,MACF,MAAM;AAAA,IACV;AAAA,IACA,SAAS;AAAA,MACL,MAAM;AAAA,IACV;AAAA,EACJ;AACJ;AAcO,IAAM,eAAN,cAA2BF,SAAQ;AAAA,EAC9B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAEA,eAAgC,CAAC;AAAA,EACjC,eAAwB;AAAA,EACxB,mBAA4B;AAAA,EAC5B;AAAA,EAER,OAAO,cAA2BF,aAAY;AAAA,EAE9C,cAAc;AACV,UAAM;AACN,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,SAAK,WACD;AACJ,UAAM,YAAY;AAClB,SAAK,YAAYI,MAAK;AAAA,MAClB,QAAQ,IAAI,iBAAiB,KAAK,KAAK;AAAA,MACvC;AAAA,IACJ;AACA,SAAK,cAAc,QAAQ,IAAI;AAAA,EACnC;AAAA,EAEA,MAAM,WAAW,SAAuC;AACpD,IAAAL,aAAY,KAAK,8BAA8B;AAC/C,SAAK,UAAU;AAAA,EACnB;AAAA,EAEA,MAAc,oBAAoB;AAC9B,QAAI,CAAC,KAAK,kBAAkB;AACxB,MAAAA,aAAY;AAAA,QACR;AAAA,MACJ;AACA,YAAM,KAAK,gBAAgB;AAAA,IAC/B,OAAO;AACH,MAAAA,aAAY,KAAK,2BAA2B;AAAA,IAChD;AAAA,EACJ;AAAA,EAEA,MAAM,kBAAkB;AACpB,QAAI;AACA,MAAAA,aAAY,KAAK,wBAAwB;AACzC,YAAM,KAAK,WAAW;AAEtB,YAAM,aAAa,MAAM,GAAG,SAAS;AACrC,YAAM,UAAU,WAAW,YAAY;AAAA,QAAK,CAAC,eACzC,WAAW,OAAO,YAAY,EAAE,SAAS,QAAQ;AAAA,MACrD;AAEA,UAAI,SAAS;AACT,QAAAA,aAAY;AAAA,UACR;AAAA,QACJ;AAAA,MACJ,OAAO;AACH,QAAAA,aAAY;AAAA,UACR;AAAA,QACJ;AAAA,MACJ;AAEA,MAAAA,aAAY,KAAK,gCAAgC;AACjD,WAAK,QAAQ,MAAM,SAAS;AAAA,QACxB,KAAK,UAAU,SAAS;AAAA,MAC5B,CAAC;AAED,MAAAA,aAAY,KAAK,iCAAiC;AAClD,YAAM,UAAU,IAAI;AAAA,QAChB,KAAK;AAAA,QACL;AAAA,MACJ;AACA,WAAK,UAAU;AAEf,MAAAA,aAAY,KAAK,kBAAkB;AACnC,WAAK,QAAQ,MAAM,KAAK,MAAM,UAAU;AAAA,QACpC,WAAW,KAAK;AAAA,MACpB,CAAC;AAED,MAAAA,aAAY,KAAK,kCAAkC;AACnD,WAAK,MAAM,MAAM,KAAK,MAAM,cAAc,EAAE,aAAa,KAAK,CAAC;AAC/D,WAAK,WAAW,KAAK,IAAI,YAAY;AAErC,WAAK,mBAAmB;AACxB,MAAAA,aAAY,QAAQ,+BAA+B;AACnD,WAAK,aAAa;AAAA,IACtB,SAAS,OAAO;AACZ,MAAAA,aAAY;AAAA,QACR;AAAA,QACA;AAAA,MACJ;AACA,UAAI;AACA,QAAAA,aAAY;AAAA,UACR;AAAA,QACJ;AACA,cAAM,KAAK,YAAY;AACvB,cAAM,KAAK,gBAAgB;AAAA,MAC/B,SAAS,YAAY;AACjB,QAAAA,aAAY;AAAA,UACR;AAAA,UACA;AAAA,QACJ;AACA,cAAM,IAAI;AAAA,UACN,4CAA4C,WAAW,OAAO;AAAA,QAClE;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AAAA,EAEA,MAAM,aAAa;AACf,QAAI,CAACI,IAAG,WAAW,KAAK,SAAS,GAAG;AAChC,MAAAJ,aAAY,KAAK,4CAA4C;AAC7D,YAAM,IAAI,QAAc,CAAC,SAAS,WAAW;AACzC,cAAM,OAAOI,IAAG,kBAAkB,KAAK,SAAS;AAChD,YAAI,iBAAiB;AACrB,YAAI,YAAY;AAEhB,cAAM,gBAAgB,CAAC,QAAgB;AACnC,gBACK,IAAI,KAAK,CAAC,aAAa;AACpB,gBACI,SAAS,cAAc,OACvB,SAAS,aAAa,OACtB,SAAS,QAAQ,UACnB;AACE,cAAAJ,aAAY;AAAA,gBACR,0BAA0B,SAAS,QAAQ,QAAQ;AAAA,cACvD;AACA,4BAAc,SAAS,QAAQ,QAAQ;AACvC;AAAA,YACJ;AAEA,gBAAI,SAAS,eAAe,KAAK;AAC7B;AAAA,gBACI,IAAI;AAAA,kBACA,kCAAkC,SAAS,UAAU;AAAA,gBACzD;AAAA,cACJ;AACA;AAAA,YACJ;AAEA,wBAAY;AAAA,cACR,SAAS,QAAQ,gBAAgB,KAAK;AAAA,cACtC;AAAA,YACJ;AACA,YAAAA,aAAY;AAAA,cACR;AAAA,YACJ;AACA,YAAAA,aAAY;AAAA,cACR,sBAAsB,KAAK,SAAS;AAAA,YACxC;AACA,YAAAA,aAAY;AAAA,cACR,gBAAgB,YAAY,OAAO,MAAM,QAAQ,CAAC,CAAC;AAAA,YACvD;AAEA,qBAAS,KAAK,IAAI;AAElB,gBAAI,iBAAiB;AACrB,qBAAS,GAAG,QAAQ,CAAC,UAAU;AAC3B,gCAAkB,MAAM;AACxB,oBAAM,WACF,YAAY,KAED,iBAAiB,YAClB,KACF,QAAQ,CAAC,IACX;AACV,oBAAM,OAAO,IAAI;AAAA,gBACb,KAAK,MAAM,OAAO,QAAQ,IAAI,CAAC;AAAA,cACnC;AACA,+BAAiB,uBAAuB,KAAK,OAAO,IAAI,GAAG,CAAC,KAAK,QAAQ;AACzE,cAAAA,aAAY,SAAS,cAAc;AAAA,YACvC,CAAC;AAED,iBAAK,GAAG,UAAU,MAAM;AACpB,mBAAK,MAAM;AACX,cAAAA,aAAY,SAAS,EAAE;AACvB,cAAAA,aAAY,QAAQ,yBAAyB;AAC7C,sBAAQ;AAAA,YACZ,CAAC;AAED,qBAAS,GAAG,SAAS,CAAC,UAAU;AAC5B,cAAAI,IAAG,OAAO,KAAK,WAAW,MAAM;AAAA,cAAC,CAAC;AAClC;AAAA,gBACI,IAAI;AAAA,kBACA,0BAA0B,MAAM,OAAO;AAAA,gBAC3C;AAAA,cACJ;AAAA,YACJ,CAAC;AAAA,UACL,CAAC,EACA,GAAG,SAAS,CAAC,UAAU;AACpB,YAAAA,IAAG,OAAO,KAAK,WAAW,MAAM;AAAA,YAAC,CAAC;AAClC;AAAA,cACI,IAAI;AAAA,gBACA,kCAAkC,MAAM,OAAO;AAAA,cACnD;AAAA,YACJ;AAAA,UACJ,CAAC;AAAA,QACT;AAEA,sBAAc,KAAK,QAAQ;AAE3B,aAAK,GAAG,SAAS,CAAC,QAAQ;AACtB,UAAAA,IAAG,OAAO,KAAK,WAAW,MAAM;AAAA,UAAC,CAAC;AAClC,kBAAQ,MAAM,qBAAqB,IAAI,OAAO;AAC9C,iBAAO,GAAG;AAAA,QACd,CAAC;AAAA,MACL,CAAC;AAAA,IACL,OAAO;AACH,MAAAJ,aAAY,KAAK,uBAAuB;AAAA,IAC5C;AAAA,EACJ;AAAA,EAEA,MAAM,cAAc;AAChB,QAAII,IAAG,WAAW,KAAK,SAAS,GAAG;AAC/B,MAAAA,IAAG,WAAW,KAAK,SAAS;AAAA,IAChC;AAAA,EACJ;AAAA,EAEA,MAAM,uBACF,SACA,aACA,MACA,mBACA,kBACA,YACY;AACZ,UAAM,KAAK,kBAAkB;AAC7B,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,WAAK,aAAa,KAAK;AAAA,QACnB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA,YAAY;AAAA,QACZ;AAAA,QACA;AAAA,MACJ,CAAC;AACD,WAAK,aAAa;AAAA,IACtB,CAAC;AAAA,EACL;AAAA,EAEA,MAAM,oBACF,SACA,aACA,MACA,mBACA,kBACA,YACe;AACf,UAAM,KAAK,kBAAkB;AAE7B,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,WAAK,aAAa,KAAK;AAAA,QACnB;AAAA,QACA;AAAA,QACA;AAAA,QACA,mBAAmB,qBAAqB;AAAA,QACxC,kBAAkB,oBAAoB;AAAA,QACtC;AAAA,QACA,YAAY;AAAA,QACZ;AAAA,QACA;AAAA,MACJ,CAAC;AACD,WAAK,aAAa;AAAA,IACtB,CAAC;AAAA,EACL;AAAA,EAEA,MAAc,eAAe;AACzB,QACI,KAAK,gBACL,KAAK,aAAa,WAAW,KAC7B,CAAC,KAAK,kBACR;AACE;AAAA,IACJ;AAEA,SAAK,eAAe;AAEpB,WAAO,KAAK,aAAa,SAAS,GAAG;AACjC,YAAM,UAAU,KAAK,aAAa,MAAM;AACxC,UAAI,SAAS;AACT,YAAI;AACA,gBAAM,WAAW,MAAM,KAAK;AAAA,YACxB,QAAQ;AAAA,YACR,QAAQ;AAAA,YACR,QAAQ;AAAA,YACR,QAAQ;AAAA,YACR,QAAQ;AAAA,YACR,QAAQ;AAAA,YACR,QAAQ;AAAA,UACZ;AACA,kBAAQ,QAAQ,QAAQ;AAAA,QAC5B,SAAS,OAAO;AACZ,kBAAQ,OAAO,KAAK;AAAA,QACxB;AAAA,MACJ;AAAA,IACJ;AAEA,SAAK,eAAe;AAAA,EACxB;AAAA,EAEA,MAAM,WAAW,QAAgB,SAAyC;AACtE,QAAI;AACA,YAAM,KAAK,WAAW,OAAO;AAE7B,UAAI,QAAQ,kBAAkBF,mBAAkB,QAAQ;AACpD,eAAO,MAAM,KAAK,iBAAiB,MAAM;AAAA,MAC7C;AAEA,aAAO,MAAM,KAAK,gBAAgB,MAAM;AAAA,IAC5C,SAAS,OAAO;AACZ,MAAAF,aAAY,MAAM,wBAAwB,KAAK;AAC/C,YAAM;AAAA,IACV;AAAA,EACJ;AAAA,EAEA,MAAM,UAAU,MAAc,SAA2C;AACrE,QAAI;AACA,YAAM,KAAK,WAAW,OAAO;AAE7B,UAAI,QAAQ,kBAAkBE,mBAAkB,QAAQ;AACpD,eAAO,MAAM,KAAK,gBAAgB,IAAI;AAAA,MAC1C;AAEA,aAAO,MAAM,KAAK,eAAe,IAAI;AAAA,IACzC,SAAS,OAAO;AACZ,MAAAF,aAAY,MAAM,uBAAuB,KAAK;AAC9C,YAAM;AAAA,IACV;AAAA,EACJ;AAAA,EAEA,MAAc,sBACV,SACA,aACA,MACA,mBACA,kBACA,YACA,YACqB;AACrB,UAAM,cAAc,QAAQ,IAAI;AAChC,QAAI,aAAa;AACb,YAAM,YACF,QAAQ,IAAI,qBAAqB;AACrC,MAAAA,aAAY;AAAA,QACR,uBAAuB,SAAS,eAAe,WAAW;AAAA,MAC9D;AAEA,YAAMM,YAAW,MAAM,MAAM,GAAG,SAAS,iBAAiB;AAAA,QACtD,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,QAC9C,MAAM,KAAK,UAAU;AAAA,UACjB,OAAO;AAAA,UACP,QAAQ;AAAA,UACR,QAAQ;AAAA,UACR,SAAS;AAAA,YACL;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA,aAAa;AAAA,UACjB;AAAA,QACJ,CAAC;AAAA,MACL,CAAC;AAED,UAAI,CAACA,UAAS,IAAI;AACd,cAAM,IAAI;AAAA,UACN,0BAA0BA,UAAS,UAAU;AAAA,QACjD;AAAA,MACJ;AAEA,YAAM,SAAS,MAAMA,UAAS,KAAK;AACnC,aAAO,aAAa,EAAE,SAAS,OAAO,SAAS,IAAI,OAAO;AAAA,IAC9D;AAGA,QAAI,CAAC,KAAK,UAAU;AAChB,YAAM,IAAI,MAAM,wBAAwB;AAAA,IAC5C;AAEA,UAAM,SAAS,KAAK,MAAO,SAAS,OAAO;AAG3C,UAAM,sBAAsB,cACvB,IAAI,CAAC,SAAS,KAAK,MAAO,SAAS,IAAI,CAAC,EACxC,KAAK;AAEV,UAAM,gBAAmD;AAAA,MACrD,cAAc,MAAM;AAAA,MACpB,SAAS;AAAA,MACT,kBAAkB;AAAA,MAClB,iBAAiB;AAAA,IACrB;AAEA,UAAM,iBAA0B,CAAC;AAEjC,qBAAiB,SAAS,KAAK,SAAS,SAAS,QAAQ;AAAA,MACrD,aAAa,OAAO,WAAW;AAAA,MAC/B;AAAA,MACA,wBAAwB,aAAa,KAAK,UAAU;AAAA,MACpD,eAAe;AAAA,IACnB,CAAC,GAAG;AACA,YAAM,UAAU,KAAK,MAAM,WAAW,CAAC,GAAG,gBAAgB,KAAK,CAAC;AAChE,UAAI,CAAC,GAAG,IAAI,EAAE,KAAK,CAAC,MAAM,QAAQ,SAAS,CAAC,CAAC,GAAG;AAC5C,QAAAN,aAAY,KAAK,qBAAqB;AACtC;AAAA,MACJ;AAEA,qBAAe,KAAK,KAAK;AACzB,cAAQ,OAAO,MAAM,KAAK,MAAO,WAAW,CAAC,KAAK,CAAC,CAAC;AACpD,UAAI,YAAY;AACZ,YAAI,QAAQ,WAAW,MAAM,EAAE,EAAE,SAAS,MAAM,GAAG;AAC/C,UAAAA,aAAY,KAAK,kBAAkB;AACnC;AAAA,QACJ;AAAA,MACJ;AACA,UAAI,eAAe,SAAS,YAAY;AACpC,QAAAA,aAAY,KAAK,oBAAoB;AACrC;AAAA,MACJ;AAAA,IACJ;AAEA,UAAM,WAAW,KAAK,MAAO,WAAW,cAAc;AAEtD,QAAI,CAAC,UAAU;AACX,YAAM,IAAI,MAAM,uBAAuB;AAAA,IAC3C;AAEA,QAAI,YAAY;AAEZ,UAAI,aAAa,SAAS,MAAM,kBAAkB,IAAI,CAAC,EAAE,KAAK;AAC9D,UAAI,CAAC,YAAY;AAEb,YAAI;AACA,uBAAa,KAAK,UAAU,KAAK,MAAM,QAAQ,CAAC;AAAA,QACpD,QAAQ;AACJ,gBAAM,IAAI,MAAM,uBAAuB;AAAA,QAC3C;AAAA,MACJ;AACA,UAAI;AACA,cAAM,iBAAiB,KAAK,MAAM,UAAU;AAC5C,YAAI,CAAC,gBAAgB;AACjB,gBAAM,IAAI,MAAM,8BAA8B;AAAA,QAClD;AACA,cAAM,KAAK,SAAS,aAAa;AACjC,eAAO;AAAA,MACX,SAAS,OAAO;AACZ,QAAAA,aAAY,MAAM,uBAAuB,KAAK;AAAA,MAClD;AAAA,IACJ,OAAO;AACH,YAAM,KAAK,SAAS,aAAa;AACjC,aAAO;AAAA,IACX;AAAA,EACJ;AAAA,EAEA,MAAM,qBAAqB,OAA8C;AACrE,UAAM,cAAc,QAAQ,IAAI;AAChC,QAAI,aAAa;AACb,YAAMO,aACF,QAAQ,IAAI,qBAAqB;AACrC,YAAMC,kBACF,QAAQ,IAAI,0BAA0B;AAC1C,MAAAR,aAAY;AAAA,QACR,8CAA8CQ,eAAc,WAAW,WAAW;AAAA,MACtF;AAEA,YAAMF,YAAW,MAAM,MAAM,GAAGC,UAAS,mBAAmB;AAAA,QACxD,QAAQ;AAAA,QACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,QAC9C,MAAM,KAAK,UAAU;AAAA,UACjB,OAAOC;AAAA,UACP,QAAQ;AAAA,QACZ,CAAC;AAAA,MACL,CAAC;AAED,UAAI,CAACF,UAAS,IAAI;AACd,cAAM,IAAI;AAAA,UACN,qCAAqCA,UAAS,UAAU;AAAA,QAC5D;AAAA,MACJ;AAEA,YAAM,SAAS,MAAMA,UAAS,KAAK;AACnC,aAAO,OAAO;AAAA,IAClB;AAGA,QAAI,CAAC,KAAK,UAAU;AAChB,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC9C;AAEA,UAAM,YACF,QAAQ,IAAI,qBAAqB;AACrC,UAAM,iBACF,QAAQ,IAAI,0BAA0B;AAC1C,IAAAN,aAAY;AAAA,MACR,8CAA8C,cAAc,WAAW,KAAK,WAAW;AAAA,IAC3F;AAEA,UAAM,WAAW,MAAM,MAAM,GAAG,SAAS,mBAAmB;AAAA,MACxD,QAAQ;AAAA,MACR,SAAS;AAAA,QACL,gBAAgB;AAAA,MACpB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACjB;AAAA,QACA,OAAO;AAAA,MACX,CAAC;AAAA,IACL,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AACd,YAAM,IAAI,MAAM,4BAA4B,SAAS,UAAU,EAAE;AAAA,IACrE;AAEA,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,WAAO,UAAU;AAAA,EACrB;AAAA,EAEA,MAAc,iBAAiB,QAAiC;AAC5D,UAAM,cAAc,QAAQ,IAAI;AAChC,UAAM,YACF,QAAQ,IAAI,qBAAqB;AACrC,IAAAA,aAAY;AAAA,MACR,uBAAuB,SAAS,eAAe,WAAW;AAAA,IAC9D;AAEA,UAAM,WAAW,MAAM,MAAM,GAAG,SAAS,iBAAiB;AAAA,MACtD,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,MAAM,KAAK,UAAU;AAAA,QACjB,OAAO;AAAA,QACP;AAAA,QACA,QAAQ;AAAA,QACR,SAAS;AAAA,UACL,aAAa;AAAA,UACb,MAAM,CAAC,IAAI;AAAA,UACX,mBAAmB;AAAA,UACnB,kBAAkB;AAAA,UAClB,aAAa;AAAA,QACjB;AAAA,MACJ,CAAC;AAAA,IACL,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AACd,YAAM,IAAI,MAAM,0BAA0B,SAAS,UAAU,EAAE;AAAA,IACnE;AAEA,UAAM,SAAS,MAAM,SAAS,KAAK;AACnC,WAAO,OAAO;AAAA,EAClB;AAAA,EAEA,MAAc,gBAAgB,MAAiC;AAC3D,UAAM,cAAc,QAAQ,IAAI;AAChC,UAAM,YACF,QAAQ,IAAI,qBAAqB;AACrC,UAAM,iBACF,QAAQ,IAAI,0BAA0B;AAC1C,IAAAA,aAAY;AAAA,MACR,8CAA8C,cAAc,WAAW,WAAW;AAAA,IACtF;AAEA,UAAM,WAAW,MAAM,MAAM,GAAG,SAAS,mBAAmB;AAAA,MACxD,QAAQ;AAAA,MACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,MAC9C,MAAM,KAAK,UAAU;AAAA,QACjB,OAAO;AAAA,QACP,QAAQ;AAAA,MACZ,CAAC;AAAA,IACL,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AACd,YAAM,IAAI;AAAA,QACN,qCAAqC,SAAS,UAAU;AAAA,MAC5D;AAAA,IACJ;AAEA,UAAM,SAAS,MAAM,SAAS,KAAK;AACnC,WAAO,OAAO;AAAA,EAClB;AAAA,EAEA,MAAc,gBAAgB,QAAiC;AAC3D,QAAI,CAAC,KAAK,UAAU;AAChB,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC9C;AAEA,UAAM,SAAS,KAAK,MAAO,SAAS,MAAM;AAG1C,UAAM,sBAAsB,cACvB,IAAI,CAAC,SAAS,KAAK,MAAO,SAAS,IAAI,CAAC,EACxC,KAAK;AAEV,UAAM,gBAAmD;AAAA,MACrD,cAAc,MAAM;AAAA,MACpB,SAAS;AAAA,MACT,kBAAkB;AAAA,MAClB,iBAAiB;AAAA,IACrB;AAEA,UAAM,iBAA0B,CAAC;AAEjC,qBAAiB,SAAS,KAAK,SAAS,SAAS,QAAQ;AAAA,MACrD,aAAa;AAAA,MACb;AAAA,MACA,eAAe;AAAA,IACnB,CAAC,GAAG;AACA,YAAM,UAAU,KAAK,MAAM,WAAW,CAAC,GAAG,gBAAgB,KAAK,CAAC;AAChE,UAAI,QAAQ,SAAS,IAAI,GAAG;AACxB,QAAAA,aAAY,KAAK,qBAAqB;AACtC;AAAA,MACJ;AAEA,qBAAe,KAAK,KAAK;AACzB,cAAQ,OAAO,MAAM,KAAK,MAAO,WAAW,CAAC,KAAK,CAAC,CAAC;AACpD,UAAI,eAAe,SAAS,KAAK;AAC7B,QAAAA,aAAY,KAAK,oBAAoB;AACrC;AAAA,MACJ;AAAA,IACJ;AAEA,UAAM,WAAW,KAAK,MAAO,WAAW,cAAc;AAEtD,QAAI,CAAC,UAAU;AACX,YAAM,IAAI,MAAM,uBAAuB;AAAA,IAC3C;AAEA,UAAM,KAAK,SAAS,aAAa;AACjC,WAAO;AAAA,EACX;AAAA,EAEA,MAAc,eAAe,MAAiC;AAC1D,QAAI,CAAC,KAAK,UAAU;AAChB,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC9C;AAEA,UAAM,mBAAmB,MAAM,KAAK,MAAM,uBAAuB;AACjE,UAAM,YAAY,MAAM,iBAAiB,gBAAgB,IAAI;AAC7D,WAAO,WAAW,SAAS,CAAC,GAAG,UAAU,MAAM,IAAI;AAAA,EACvD;AACJ;;;ACzyBA;AAAA,EAGI,WAAAS;AAAA,EACA,eAAAC;AAAA,OACG;AACP,SAAS,mBAAqC;AAGvC,IAAM,aAAN,MAAM,oBAAmBD,SAA+B;AAAA,EAC3D,OAAO,cAA2BC,aAAY;AAAA,EAE9C,cAAc;AACV,UAAM;AAAA,EACV;AAAA,EAEA,cAA2B;AACvB,WAAO,YAAW,YAAY;AAAA,EAClC;AAAA,EAEA,MAAM,WAAW,UAAwC;AAAA,EAAC;AAAA,EAE1D,MAAM,iBAAiB,WAAoC;AAEvD,UAAM,aAAa,IAAI,WAAW,SAAS;AAE3C,UAAM,MAAwB,MAAM,YAAY,EAAE,MAAM,WAAW,CAAC,EAC/D;AACL,UAAM,WAAW,IAAI;AACrB,UAAM,YAAsB,CAAC;AAE7B,aAAS,UAAU,GAAG,WAAW,UAAU,WAAW;AAClD,YAAM,OAAO,MAAM,IAAI,QAAQ,OAAO;AACtC,YAAM,cAAc,MAAM,KAAK,eAAe;AAC9C,YAAM,WAAW,YAAY,MACxB,OAAO,UAAU,EACjB,IAAI,CAAC,SAAS,KAAK,GAAG,EACtB,KAAK,GAAG;AACb,gBAAU,KAAK,QAAQ;AAAA,IAC3B;AAEA,WAAO,UAAU,KAAK,IAAI;AAAA,EAC9B;AACJ;AAGA,SAAS,WAAW,MAAsD;AACtE,SAAO,SAAS;AACpB;;;AChDA,SAAS,mBAAmB;AAC5B,SAAS,gBAAgB;AACzB,SAAS,sBAAsB;AAC/B,SAAwC,eAAAC,oBAAmB;;;ACHpD,SAAS,aACZ,aACA,YACA,eAAuB,GACvB,gBAAwB,IAClB;AACN,QAAM,YAAY,OAAO,MAAM,EAAE;AACjC,YAAU,MAAM,QAAQ,CAAC;AACzB,YAAU,cAAc,KAAK,aAAa,CAAC;AAC3C,YAAU,MAAM,QAAQ,CAAC;AACzB,YAAU,MAAM,QAAQ,EAAE;AAC1B,YAAU,cAAc,IAAI,EAAE;AAC9B,YAAU,cAAc,GAAG,EAAE;AAC7B,YAAU,cAAc,cAAc,EAAE;AACxC,YAAU,cAAc,YAAY,EAAE;AACtC,YAAU;AAAA,IACL,aAAa,gBAAgB,eAAgB;AAAA,IAC9C;AAAA,EACJ;AACA,YAAU,cAAe,gBAAgB,eAAgB,GAAG,EAAE;AAC9D,YAAU,cAAc,eAAe,EAAE;AACzC,YAAU,MAAM,QAAQ,EAAE;AAC1B,YAAU,cAAc,aAAa,EAAE;AACvC,SAAO;AACX;;;ADnBA,SAAS,WAAAC,gBAAe;;;AEJxB,SAAS,SAAS;AAEX,IAAM,gBAAgB,EAAE,OAAO;AAAA,EAClC,gBAAgB,EAAE,OAAO,EAAE,IAAI,GAAG,4BAA4B;AAAA;AAAA,EAG9D,uBAAuB,EAAE,OAAO,EAAE,SAAS;AAAA;AAAA,EAG3C,qBAAqB,EAAE,OAAO,EAAE,SAAS;AAAA,EACzC,qBAAqB,EAAE,OAAO,EAAE,SAAS;AAAA,EACzC,4BAA4B,EAAE,OAAO,EAAE,SAAS;AAAA,EAChD,mCAAmC,EAAE,OAAO,EAAE,SAAS;AAAA,EACvD,wBAAwB,EAAE,OAAO,EAAE,SAAS;AAAA,EAC5C,oCAAoC,EAAE,OAAO,EAAE,SAAS;AAAA,EACxD,uCAAuC,EAAE,OAAO,EAAE,SAAS;AAAA,EAC3D,0BAA0B,EAAE,OAAO,EAAE,SAAS;AAAA,EAC9C,YAAY,EAAE,OAAO,EAAE,SAAS;AAAA,EAChC,YAAY,EAAE,OAAO,EAAE,SAAS;AACpC,CAAC;AAID,eAAsB,mBAClB,SACmB;AACnB,MAAI;AACA,UAAM,gBAAgB,QAAQ,UAAU,UAAU;AAClD,UAAM,aAAa,eAAe;AAGlC,UAAM,SAAS;AAAA,MACX,gBACI,QAAQ,WAAW,gBAAgB,KACnC,QAAQ,IAAI;AAAA,MAChB,uBACI,QAAQ,WAAW,uBAAuB,KAC1C,QAAQ,IAAI;AAAA;AAAA,MAGhB,GAAI,QAAQ,WAAW,uBAAuB,KAAK;AAAA,QAC/C,qBACI,YAAY,SACZ,QAAQ,IAAI,uBACZ;AAAA,QACJ,qBACI,YAAY,WAAW,QAAQ,IAAI;AAAA,QACvC,4BACI,YAAY,aACZ,QAAQ,IAAI,8BACZ;AAAA,QACJ,mCACI,YAAY,mBACZ,QAAQ,IAAI,qCACZ;AAAA,QACJ,wBACI,YAAY,SACZ,QAAQ,IAAI,0BACZ;AAAA,QACJ,oCACI,YAAY,mBACZ,QAAQ,IAAI,sCACZ;AAAA,QACJ,uCACI,QAAQ,IAAI,yCAAyC;AAAA,QACzD,0BACI,QAAQ,IAAI,4BAA4B;AAAA,MAChD;AAAA;AAAA,MAGA,YAAY,eAAe,SAAS,QAAQ,IAAI;AAAA,MAChD,YAAY,QAAQ,IAAI;AAAA;AAAA,MAGxB,GAAI,QAAQ,WAAW,mBAAmB,KAAK;AAAA,QAC3C,mBAAmB,QAAQ,WAAW,mBAAmB;AAAA,QACzD,uBAAuB,QAAQ;AAAA,UAC3B;AAAA,QACJ;AAAA,QACA,YAAY,QAAQ,WAAW,YAAY;AAAA,QAC3C,eAAe,QAAQ,WAAW,eAAe;AAAA,QACjD,oBAAoB,QAAQ,WAAW,oBAAoB;AAAA,MAC/D;AAAA,IACJ;AAEA,WAAO,cAAc,MAAM,MAAM;AAAA,EACrC,SAAS,OAAO;AACZ,QAAI,iBAAiB,EAAE,UAAU;AAC7B,YAAM,gBAAgB,MAAM,OACvB,IAAI,CAAC,QAAQ,GAAG,IAAI,KAAK,KAAK,GAAG,CAAC,KAAK,IAAI,OAAO,EAAE,EACpD,KAAK,IAAI;AACd,YAAM,IAAI;AAAA,QACN;AAAA,EAA0C,aAAa;AAAA,MAC3D;AAAA,IACJ;AACA,UAAM;AAAA,EACV;AACJ;;;AF3FA,YAAY,gBAAgB;AAC5B,SAAS,eAAAC,oBAAmB;AAE5B,SAAS,iBACL,UACA,aACA,YACA,eAAuB,GACvB,gBAAwB,IAChB;AACR,QAAM,YAAY;AAAA,IACd;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ;AACA,MAAI,eAAe;AACnB,QAAM,cAAc,IAAI,YAAY;AACpC,WAAS,GAAG,QAAQ,SAAU,MAAM;AAChC,QAAI,CAAC,cAAc;AACf,kBAAY,KAAK,SAAS;AAC1B,qBAAe;AAAA,IACnB;AACA,gBAAY,KAAK,IAAI;AAAA,EACzB,CAAC;AACD,WAAS,GAAG,OAAO,WAAY;AAC3B,gBAAY,IAAI;AAAA,EACpB,CAAC;AACD,SAAO;AACX;AAEA,eAAe,iBAAiB,SAAwB;AACpD,QAAM,gBAAgB,CAAC,CAAC,QAAQ,WAAW,uBAAuB;AAClE,QAAM,UAAU,CAAC;AAGjB,QAAM,gBAAgB,QAAQ,UAAU,UAAU;AAClD,QAAM,qBAAqB,eAAe;AAE1C,EAAAA,aAAY,MAAM,mBAAmB;AAAA,IACjC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ,CAAC;AAED,SAAO;AAAA,IACH,mBACI,oBAAoB,WACpB,QAAQ,WAAW,qBAAqB;AAAA,IAC5C,iBACI,oBAAoB,SACpB,QAAQ,WAAW,qBAAqB,KACxC;AAAA,IACJ,qBACI,oBAAoB,aACpB,QAAQ,WAAW,4BAA4B,KAC/C;AAAA;AAAA,IAEJ,WACI,eAAe,SACf,eAAe,OACf,QAAQ,WAAW,YAAY,KAC/B;AAAA,IACJ;AAAA,EACJ;AACJ;AAEA,eAAe,aAAa,SAAwB,MAAc;AAC9D,QAAM,mBAAmB,OAAO;AAChC,QAAM,EAAE,kBAAkB,IAAI,MAAM,iBAAiB,OAAO;AAE5D,MAAI;AACA,UAAM,WAAW,MAAM;AAAA,MACnB,+CAA+C,iBAAiB,sCAAsC,QAAQ,WAAW,uCAAuC,CAAC,kBAAkB,QAAQ,WAAW,0BAA0B,CAAC;AAAA,MACjO;AAAA,QACI,QAAQ;AAAA,QACR,SAAS;AAAA,UACL,gBAAgB;AAAA,UAChB,cAAc,QAAQ,WAAW,uBAAuB;AAAA,QAC5D;AAAA,QACA,MAAM,KAAK,UAAU;AAAA,UACjB,UAAU,QAAQ,WAAW,qBAAqB;AAAA,UAClD;AAAA,UACA,gBAAgB;AAAA,YACZ,kBAAkB,QAAQ;AAAA,cACtB;AAAA,YACJ;AAAA,YACA,WAAW,QAAQ;AAAA,cACf;AAAA,YACJ;AAAA,YACA,OAAO,QAAQ,WAAW,wBAAwB;AAAA,YAClD,mBAAmB,QAAQ;AAAA,cACvB;AAAA,YACJ;AAAA,UACJ;AAAA,QACJ,CAAC;AAAA,MACL;AAAA,IACJ;AAEA,UAAM,SAAS,SAAS;AACxB,QAAI,UAAU,KAAK;AACf,YAAM,kBAAkB,MAAM,SAAS,KAAK;AAC5C,YAAM,YAAY,KAAK,MAAM,eAAe;AAG5C,UACI,WAAW,OACX,UAAU,QAAQ,WAAW,kBAC/B;AACE,gBAAQ,IAAI,iDAAiD;AAC7D,cAAM,IAAI,MAAM,gBAAgB;AAAA,MACpC;AAEA,YAAM,IAAI;AAAA,QACN,mBAAmB,MAAM,0BAA0B,eAAe;AAAA,MACtE;AAAA,IACJ;AAEA,QAAI,UAAU;AACV,YAAM,YAAY,eAAe;AAAA,QAC7B,SAAS;AAAA,MACb;AACA,YAAM,SAAS,UAAU,UAAU;AAEnC,YAAM,WAAW,IAAI,SAAS;AAAA,QAC1B,OAAO;AACH,iBAAO,KAAK,EAAE,KAAK,CAAC,EAAE,MAAM,MAAM,MAAM;AACpC,gBAAI,MAAM;AACN,mBAAK,KAAK,IAAI;AAAA,YAClB,OAAO;AACH,mBAAK,KAAK,KAAK;AAAA,YACnB;AAAA,UACJ,CAAC;AAAA,QACL;AAAA,MACJ,CAAC;AAED,UACI,QACK,WAAW,0BAA0B,EACrC,WAAW,MAAM,GACxB;AACE,cAAM,aAAa;AAAA,UACf,QAAQ,WAAW,0BAA0B,EAAE,UAAU,CAAC;AAAA,QAC9D;AACA,cAAM,aAAa;AAAA,UACf;AAAA,UACA,OAAO,OAAO;AAAA,UACd;AAAA,UACA;AAAA,UACA;AAAA,QACJ;AACA,eAAO;AAAA,MACX,OAAO;AACH,eAAO;AAAA,MACX;AAAA,IACJ,OAAO;AACH,aAAO,IAAI,SAAS;AAAA,QAChB,OAAO;AAAA,QAAC;AAAA,MACZ,CAAC;AAAA,IACL;AAAA,EACJ,SAAS,OAAO;AACZ,QAAI,MAAM,YAAY,kBAAkB;AAEpC,YAAM,EAAE,UAAU,IAAI,MAAM,iBAAiB,OAAO;AACpD,YAAM,EAAE,MAAM,IAAI,MAAiB,sBAAW,MAAM;AAAA,QAChD,QAAQ;AAAA,QACR,OAAO;AAAA,MACX,CAAC;AAED,UAAI;AACJ,UAAI,iBAAiB,QAAQ;AACzB,gBAAQ,IAAI,mBAAmB;AAC/B,oBAAY,SAAS,KAAK,KAAK;AAAA,MACnC,WAAW,mBAAmB,SAAS,gBAAgB,OAAO;AAC1D,gBAAQ,IAAI,qBAAqB;AACjC,cAAM,cAAc,OAAO,KAAK,MAAM,cAAc,CAAC,EAAE,MAAM;AAC7D,gBAAQ,IAAI,mBAAmB,YAAY,MAAM;AAGjD,cAAM,aAAa,MAAM;AAGzB,cAAM,aAAa,IAAI,aAAa,YAAY,MAAM;AAGtD,cAAM,YAAY,IAAI,WAAW,WAAW,MAAM;AAClD,iBAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AACxC,oBAAU,CAAC,IAAI,KAAK,MAAM,WAAW,CAAC,IAAI,KAAK;AAAA,QACnD;AAGA,cAAM,kBAAkB;AAAA,UACpB,UAAU,SAAS;AAAA,UACnB;AAAA,UACA;AAAA,UACA;AAAA,QACJ;AACA,cAAM,YAAY,OAAO,OAAO;AAAA,UAC5B;AAAA,UACA,OAAO,KAAK,UAAU,MAAM;AAAA,QAChC,CAAC;AAED,oBAAY,SAAS,KAAK,SAAS;AAAA,MACvC,OAAO;AACH,cAAM,IAAI,MAAM,0BAA0B;AAAA,MAC9C;AACA,aAAO;AAAA,IACX;AACA,UAAM;AAAA,EACV;AACJ;AAEA,eAAe,iBAAiB,OAA+B;AAC3D,MAAI;AACJ,MAAI,iBAAiB,QAAQ;AACzB,YAAQ,IAAI,mBAAmB;AAC/B,gBAAY,SAAS,KAAK,KAAK;AAAA,EACnC,WAAW,mBAAmB,SAAS,gBAAgB,OAAO;AAC1D,YAAQ,IAAI,qBAAqB;AACjC,UAAM,cAAc,OAAO,KAAK,MAAM,cAAc,CAAC,EAAE,MAAM;AAC7D,YAAQ,IAAI,mBAAmB,YAAY,MAAM;AAEjD,UAAM,aAAa,MAAM;AACzB,UAAM,aAAa,IAAI,aAAa,YAAY,MAAM;AACtD,UAAM,YAAY,IAAI,WAAW,WAAW,MAAM;AAElD,aAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AACxC,gBAAU,CAAC,IAAI,KAAK,MAAM,WAAW,CAAC,IAAI,KAAK;AAAA,IACnD;AAEA,UAAM,kBAAkB;AAAA,MACpB,UAAU,SAAS;AAAA,MACnB;AAAA,MACA;AAAA,MACA;AAAA,IACJ;AACA,UAAM,YAAY,OAAO,OAAO;AAAA,MAC5B;AAAA,MACA,OAAO,KAAK,UAAU,MAAM;AAAA,IAChC,CAAC;AACD,gBAAY,SAAS,KAAK,SAAS;AAAA,EACvC,OAAO;AACH,UAAM,IAAI,MAAM,0BAA0B;AAAA,EAC9C;AACA,SAAO;AACX;AAEA,eAAe,kBACX,SACA,MACiB;AACjB,QAAM,EAAE,UAAU,IAAI,MAAM,iBAAiB,OAAO;AACpD,QAAM,EAAE,MAAM,IAAI,MAAiB,sBAAW,MAAM;AAAA,IAChD,QAAQ;AAAA,IACR,OAAO;AAAA,EACX,CAAC;AACD,SAAO,iBAAiB,KAAK;AACjC;AAEO,IAAM,gBAAN,MAAM,uBAAsBC,SAAkC;AAAA,EACjE,OAAO,cAA2BC,aAAY;AAAA,EAE9C,MAAM,WAAW,UAAwC;AAAA,EAAC;AAAA,EAE1D,cAA8B;AAC1B,WAAO,eAAc,YAAY;AAAA,EACrC;AAAA,EAEA,MAAM,SAAS,SAAwB,MAAiC;AACpE,QAAI;AACA,YAAM,EAAE,QAAQ,IAAI,MAAM,iBAAiB,OAAO;AAElD,UAAI,WAAW,CAAC,QAAQ,WAAW,uBAAuB,GAAG;AACzD,eAAO,MAAM,kBAAkB,SAAS,IAAI;AAAA,MAChD;AAEA,aAAO,MAAM,aAAa,SAAS,IAAI;AAAA,IAC3C,SAAS,OAAO;AACZ,cAAQ,MAAM,4BAA4B,KAAK;AAC/C,aAAO,MAAM,kBAAkB,SAAS,IAAI;AAAA,IAChD;AAAA,EACJ;AACJ;;;AGlSA;AAAA,EACI,eAAAC;AAAA,EAGA,YAAAC;AAAA,EACA;AAAA,OACG;AACP,SAAS,WAAAC,UAAS,eAAAC,oBAAmB;AACrC,SAAS,YAAY;AACrB,SAAS,QAAAC,aAAY;AACrB,OAAOC,SAAQ;AACf,SAAS,mBAAmB;;;ACTrB,IAAM,iBAAyB;AAC/B,IAAM,aAA2D;EACtE,SAAS,CAAC,MAAmB,OAAO,CAAC,EAAE,QAAQ,QAAQ,GAAG;EAC1D,SAAS,CAAC,MAAmB,OAAO,CAAC;;AAEhC,IAAM,UAAU;;;ACHvB,IAAM,WAAW,MAAM;AAEvB,IAAM,aAAa,MAAK;AACtB,QAAM,QAAQ,CAAA;AACd,WAAS,IAAI,GAAG,IAAI,KAAK,EAAE,GAAG;AAC5B,UAAM,KAAK,QAAQ,IAAI,KAAK,MAAM,MAAM,EAAE,SAAS,EAAE,GAAG,YAAW,CAAE;;AAGvE,SAAO;AACT,GAAE;AAwHF,IAAM,QAAQ;AAEP,IAAM,SAMC,CAACC,MAAK,iBAAiB,SAAS,OAAO,WAAkB;AAGrE,MAAIA,KAAI,WAAW,GAAG;AACpB,WAAOA;;AAGT,MAAI,SAASA;AACb,MAAI,OAAOA,SAAQ,UAAU;AAC3B,aAAS,OAAO,UAAU,SAAS,KAAKA,IAAG;aAClC,OAAOA,SAAQ,UAAU;AAClC,aAAS,OAAOA,IAAG;;AAGrB,MAAI,YAAY,cAAc;AAC5B,WAAO,OAAO,MAAM,EAAE,QAAQ,mBAAmB,SAAU,IAAE;AAC3D,aAAO,WAAW,SAAS,GAAG,MAAM,CAAC,GAAG,EAAE,IAAI;IAChD,CAAC;;AAGH,MAAI,MAAM;AACV,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK,OAAO;AAC7C,UAAM,UAAU,OAAO,UAAU,QAAQ,OAAO,MAAM,GAAG,IAAI,KAAK,IAAI;AACtE,UAAM,MAAM,CAAA;AAEZ,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,EAAE,GAAG;AACvC,UAAI,IAAI,QAAQ,WAAW,CAAC;AAC5B,UACE,MAAM;MACN,MAAM;MACN,MAAM;MACN,MAAM;MACL,KAAK,MAAQ,KAAK;MAClB,KAAK,MAAQ,KAAK;MAClB,KAAK,MAAQ,KAAK;MAClB,WAAW,YAAY,MAAM,MAAQ,MAAM,KAC5C;AACA,YAAI,IAAI,MAAM,IAAI,QAAQ,OAAO,CAAC;AAClC;;AAGF,UAAI,IAAI,KAAM;AACZ,YAAI,IAAI,MAAM,IAAI,UAAU,CAAC;AAC7B;;AAGF,UAAI,IAAI,MAAO;AACb,YAAI,IAAI,MAAM,IAAI,UAAU,MAAQ,KAAK,CAAE,IAAK,UAAU,MAAQ,IAAI,EAAK;AAC3E;;AAGF,UAAI,IAAI,SAAU,KAAK,OAAQ;AAC7B,YAAI,IAAI,MAAM,IACZ,UAAU,MAAQ,KAAK,EAAG,IAAK,UAAU,MAAS,KAAK,IAAK,EAAK,IAAI,UAAU,MAAQ,IAAI,EAAK;AAClG;;AAGF,WAAK;AACL,UAAI,UAAa,IAAI,SAAU,KAAO,QAAQ,WAAW,CAAC,IAAI;AAE9D,UAAI,IAAI,MAAM,IACZ,UAAU,MAAQ,KAAK,EAAG,IAC1B,UAAU,MAAS,KAAK,KAAM,EAAK,IACnC,UAAU,MAAS,KAAK,IAAK,EAAK,IAClC,UAAU,MAAQ,IAAI,EAAK;;AAG/B,WAAO,IAAI,KAAK,EAAE;;AAGpB,SAAO;AACT;AA+BM,SAAU,UAAU,KAAQ;AAChC,MAAI,CAAC,OAAO,OAAO,QAAQ,UAAU;AACnC,WAAO;;AAGT,SAAO,CAAC,EAAE,IAAI,eAAe,IAAI,YAAY,YAAY,IAAI,YAAY,SAAS,GAAG;AACvF;AAMM,SAAU,UAAa,KAAU,IAAe;AACpD,MAAI,SAAS,GAAG,GAAG;AACjB,UAAM,SAAS,CAAA;AACf,aAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK,GAAG;AACtC,aAAO,KAAK,GAAG,IAAI,CAAC,CAAE,CAAC;;AAEzB,WAAO;;AAET,SAAO,GAAG,GAAG;AACf;;;ACpQA,IAAM,MAAM,OAAO,UAAU;AAE7B,IAAM,0BAA0B;EAC9B,SAAS,QAAmB;AAC1B,WAAO,OAAO,MAAM,IAAI;EAC1B;EACA,OAAO;EACP,QAAQ,QAAqB,KAAW;AACtC,WAAO,OAAO,MAAM,IAAI,MAAM,MAAM;EACtC;EACA,OAAO,QAAmB;AACxB,WAAO,OAAO,MAAM;EACtB;;AAGF,IAAMC,YAAW,MAAM;AACvB,IAAM,OAAO,MAAM,UAAU;AAC7B,IAAM,gBAAgB,SAAU,KAAY,gBAAmB;AAC7D,OAAK,MAAM,KAAKA,UAAS,cAAc,IAAI,iBAAiB,CAAC,cAAc,CAAC;AAC9E;AAEA,IAAM,SAAS,KAAK,UAAU;AAE9B,IAAM,WAAW;EACf,gBAAgB;EAChB,WAAW;EACX,kBAAkB;EAClB,aAAa;EACb,SAAS;EACT,iBAAiB;EACjB,WAAW;EACX,QAAQ;EACR,iBAAiB;EACjB,SAAS;EACT,kBAAkB;EAClB,QAAQ;EACR,WAAW,WAAW,cAAc;;EAEpC,SAAS;EACT,cAAc,MAAI;AAChB,WAAO,OAAO,KAAK,IAAI;EACzB;EACA,WAAW;EACX,oBAAoB;;AAGtB,SAAS,yBAAyB,GAAU;AAC1C,SACE,OAAO,MAAM,YACb,OAAO,MAAM,YACb,OAAO,MAAM,aACb,OAAO,MAAM,YACb,OAAO,MAAM;AAEjB;AAEA,IAAM,WAAW,CAAA;AAEjB,SAAS,gBACP,QACA,QACA,qBACA,gBACA,kBACA,oBACA,WACA,iBACA,SACA,QACA,MACA,WACA,eACA,QACA,WACA,kBACA,SACA,aAA8B;AAE9B,MAAI,MAAM;AAEV,MAAI,SAAS;AACb,MAAI,OAAO;AACX,MAAI,YAAY;AAChB,UAAQ,SAAS,OAAO,IAAI,QAAQ,OAAO,UAAkB,CAAC,WAAW;AAEvE,UAAM,MAAM,OAAO,IAAI,MAAM;AAC7B,YAAQ;AACR,QAAI,OAAO,QAAQ,aAAa;AAC9B,UAAI,QAAQ,MAAM;AAChB,cAAM,IAAI,WAAW,qBAAqB;aACrC;AACL,oBAAY;;;AAGhB,QAAI,OAAO,OAAO,IAAI,QAAQ,MAAM,aAAa;AAC/C,aAAO;;;AAIX,MAAI,OAAO,WAAW,YAAY;AAChC,UAAM,OAAO,QAAQ,GAAG;aACf,eAAe,MAAM;AAC9B,UAAM,gBAAgB,GAAG;aAChB,wBAAwB,WAAWA,UAAS,GAAG,GAAG;AAC3D,UAAM,UAAU,KAAK,SAAU,OAAK;AAClC,UAAI,iBAAiB,MAAM;AACzB,eAAO,gBAAgB,KAAK;;AAE9B,aAAO;IACT,CAAC;;AAGH,MAAI,QAAQ,MAAM;AAChB,QAAI,oBAAoB;AACtB,aAAO,WAAW,CAAC;;QAEf,QAAQ,QAAQ,SAAS,SAAS,SAAS,OAAO,MAAM;UACxD;;AAGN,UAAM;;AAGR,MAAI,yBAAyB,GAAG,KAAK,UAAU,GAAG,GAAG;AACnD,QAAI,SAAS;AACX,YAAM,YACJ,mBAAmB,SAEjB,QAAQ,QAAQ,SAAS,SAAS,SAAS,OAAO,MAAM;AAC5D,aAAO;QACL,YAAY,SAAS,IACnB;QAEA,YAAY,QAAQ,KAAK,SAAS,SAAS,SAAS,SAAS,MAAM,CAAC;;;AAG1E,WAAO,CAAC,YAAY,MAAM,IAAI,MAAM,YAAY,OAAO,GAAG,CAAC,CAAC;;AAG9D,QAAM,SAAmB,CAAA;AAEzB,MAAI,OAAO,QAAQ,aAAa;AAC9B,WAAO;;AAGT,MAAI;AACJ,MAAI,wBAAwB,WAAWA,UAAS,GAAG,GAAG;AAEpD,QAAI,oBAAoB,SAAS;AAE/B,YAAM,UAAU,KAAK,OAAO;;AAE9B,eAAW,CAAC,EAAE,OAAO,IAAI,SAAS,IAAI,IAAI,KAAK,GAAG,KAAK,OAAO,OAAc,CAAE;aACrEA,UAAS,MAAM,GAAG;AAC3B,eAAW;SACN;AACL,UAAM,OAAO,OAAO,KAAK,GAAG;AAC5B,eAAW,OAAO,KAAK,KAAK,IAAI,IAAI;;AAGtC,QAAM,iBAAiB,kBAAkB,OAAO,MAAM,EAAE,QAAQ,OAAO,KAAK,IAAI,OAAO,MAAM;AAE7F,QAAM,kBACJ,kBAAkBA,UAAS,GAAG,KAAK,IAAI,WAAW,IAAI,iBAAiB,OAAO;AAEhF,MAAI,oBAAoBA,UAAS,GAAG,KAAK,IAAI,WAAW,GAAG;AACzD,WAAO,kBAAkB;;AAG3B,WAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,EAAE,GAAG;AACxC,UAAM,MAAM,SAAS,CAAC;AACtB,UAAM;;MAEJ,OAAO,QAAQ,YAAY,OAAO,IAAI,UAAU,cAAc,IAAI,QAAQ,IAAI,GAAU;;AAE1F,QAAI,aAAa,UAAU,MAAM;AAC/B;;AAIF,UAAM,cAAc,aAAa,kBAAmB,IAAY,QAAQ,OAAO,KAAK,IAAI;AACxF,UAAM,aACJA,UAAS,GAAG,IACV,OAAO,wBAAwB,aAC7B,oBAAoB,iBAAiB,WAAW,IAChD,kBACF,mBAAmB,YAAY,MAAM,cAAc,MAAM,cAAc;AAE3E,gBAAY,IAAI,QAAQ,IAAI;AAC5B,UAAM,mBAAmB,oBAAI,QAAO;AACpC,qBAAiB,IAAI,UAAU,WAAW;AAC1C,kBACE,QACA;MACE;MACA;MACA;MACA;MACA;MACA;MACA;MACA;;MAEA,wBAAwB,WAAW,oBAAoBA,UAAS,GAAG,IAAI,OAAO;MAC9E;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;IAAgB,CACjB;;AAIL,SAAO;AACT;AAEA,SAAS,4BACP,OAAyB,UAAQ;AAEjC,MAAI,OAAO,KAAK,qBAAqB,eAAe,OAAO,KAAK,qBAAqB,WAAW;AAC9F,UAAM,IAAI,UAAU,wEAAwE;;AAG9F,MAAI,OAAO,KAAK,oBAAoB,eAAe,OAAO,KAAK,oBAAoB,WAAW;AAC5F,UAAM,IAAI,UAAU,uEAAuE;;AAG7F,MAAI,KAAK,YAAY,QAAQ,OAAO,KAAK,YAAY,eAAe,OAAO,KAAK,YAAY,YAAY;AACtG,UAAM,IAAI,UAAU,+BAA+B;;AAGrD,QAAM,UAAU,KAAK,WAAW,SAAS;AACzC,MAAI,OAAO,KAAK,YAAY,eAAe,KAAK,YAAY,WAAW,KAAK,YAAY,cAAc;AACpG,UAAM,IAAI,UAAU,mEAAmE;;AAGzF,MAAI,SAAS;AACb,MAAI,OAAO,KAAK,WAAW,aAAa;AACtC,QAAI,CAAC,IAAI,KAAK,YAAY,KAAK,MAAM,GAAG;AACtC,YAAM,IAAI,UAAU,iCAAiC;;AAEvD,aAAS,KAAK;;AAEhB,QAAM,YAAY,WAAW,MAAM;AAEnC,MAAI,SAAS,SAAS;AACtB,MAAI,OAAO,KAAK,WAAW,cAAcA,UAAS,KAAK,MAAM,GAAG;AAC9D,aAAS,KAAK;;AAGhB,MAAI;AACJ,MAAI,KAAK,eAAe,KAAK,eAAe,yBAAyB;AACnE,kBAAc,KAAK;aACV,aAAa,MAAM;AAC5B,kBAAc,KAAK,UAAU,YAAY;SACpC;AACL,kBAAc,SAAS;;AAGzB,MAAI,oBAAoB,QAAQ,OAAO,KAAK,mBAAmB,WAAW;AACxE,UAAM,IAAI,UAAU,+CAA+C;;AAGrE,QAAM,YACJ,OAAO,KAAK,cAAc,cACxB,CAAC,CAAC,KAAK,oBAAoB,OACzB,OACA,SAAS,YACX,CAAC,CAAC,KAAK;AAEX,SAAO;IACL,gBAAgB,OAAO,KAAK,mBAAmB,YAAY,KAAK,iBAAiB,SAAS;;IAE1F;IACA,kBACE,OAAO,KAAK,qBAAqB,YAAY,CAAC,CAAC,KAAK,mBAAmB,SAAS;IAClF;IACA;IACA,iBACE,OAAO,KAAK,oBAAoB,YAAY,KAAK,kBAAkB,SAAS;IAC9E,gBAAgB,CAAC,CAAC,KAAK;IACvB,WAAW,OAAO,KAAK,cAAc,cAAc,SAAS,YAAY,KAAK;IAC7E,QAAQ,OAAO,KAAK,WAAW,YAAY,KAAK,SAAS,SAAS;IAClE,iBACE,OAAO,KAAK,oBAAoB,YAAY,KAAK,kBAAkB,SAAS;IAC9E,SAAS,OAAO,KAAK,YAAY,aAAa,KAAK,UAAU,SAAS;IACtE,kBACE,OAAO,KAAK,qBAAqB,YAAY,KAAK,mBAAmB,SAAS;IAChF;IACA;IACA;IACA,eAAe,OAAO,KAAK,kBAAkB,aAAa,KAAK,gBAAgB,SAAS;IACxF,WAAW,OAAO,KAAK,cAAc,YAAY,KAAK,YAAY,SAAS;;IAE3E,MAAM,OAAO,KAAK,SAAS,aAAa,KAAK,OAAO;IACpD,oBACE,OAAO,KAAK,uBAAuB,YAAY,KAAK,qBAAqB,SAAS;;AAExF;AAEM,SAAU,UAAU,QAAa,OAAyB,CAAA,GAAE;AAChE,MAAI,MAAM;AACV,QAAM,UAAU,4BAA4B,IAAI;AAEhD,MAAI;AACJ,MAAI;AAEJ,MAAI,OAAO,QAAQ,WAAW,YAAY;AACxC,aAAS,QAAQ;AACjB,UAAM,OAAO,IAAI,GAAG;aACXA,UAAS,QAAQ,MAAM,GAAG;AACnC,aAAS,QAAQ;AACjB,eAAW;;AAGb,QAAM,OAAiB,CAAA;AAEvB,MAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;AAC3C,WAAO;;AAGT,QAAM,sBAAsB,wBAAwB,QAAQ,WAAW;AACvE,QAAM,iBAAiB,wBAAwB,WAAW,QAAQ;AAElE,MAAI,CAAC,UAAU;AACb,eAAW,OAAO,KAAK,GAAG;;AAG5B,MAAI,QAAQ,MAAM;AAChB,aAAS,KAAK,QAAQ,IAAI;;AAG5B,QAAM,cAAc,oBAAI,QAAO;AAC/B,WAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,EAAE,GAAG;AACxC,UAAM,MAAM,SAAS,CAAC;AAEtB,QAAI,QAAQ,aAAa,IAAI,GAAG,MAAM,MAAM;AAC1C;;AAEF,kBACE,MACA;MACE,IAAI,GAAG;MACP;;MAEA;MACA;MACA,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,QAAQ,SAAS,QAAQ,UAAU;MACnC,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR;IAAW,CACZ;;AAIL,QAAM,SAAS,KAAK,KAAK,QAAQ,SAAS;AAC1C,MAAI,SAAS,QAAQ,mBAAmB,OAAO,MAAM;AAErD,MAAI,QAAQ,iBAAiB;AAC3B,QAAI,QAAQ,YAAY,cAAc;AAEpC,gBAAU;WACL;AAEL,gBAAU;;;AAId,SAAO,OAAO,SAAS,IAAI,SAAS,SAAS;AAC/C;;;ACnYO,IAAM,UAAU;;;AC0BhB,IAAI,OAAO;AACX,IAAI,OAAkC;AACtC,IAAIC,SAAoC;AACxC,IAAIC,WAAwC;AAC5C,IAAIC,YAA0C;AAC9C,IAAIC,WAAwC;AAC5C,IAAI,WAA0C;AAC9C,IAAIC,QAAkC;AACtC,IAAI,OAAkC;AACtC,IAAIC,kBAAsD;AAC1D,IAAI,6BAA8E;AAClF,IAAI,kBAAwD;AAC5D,IAAI,eAAkD;AACtD,IAAI,iBAAsD;AAE3D,SAAU,SAAS,OAAc,UAA6B,EAAE,MAAM,MAAK,GAAE;AACjF,MAAI,MAAM;AACR,UAAM,IAAI,MACR,mCAAmC,MAAM,IAAI,gDAAgD;;AAGjG,MAAI,MAAM;AACR,UAAM,IAAI,MAAM,gCAAgC,MAAM,IAAI,oCAAoC,IAAI,KAAK;;AAEzG,SAAO,QAAQ;AACf,SAAO,MAAM;AACb,EAAAL,SAAQ,MAAM;AACd,EAAAC,WAAU,MAAM;AAChB,EAAAC,YAAW,MAAM;AACjB,EAAAC,WAAU,MAAM;AAChB,aAAW,MAAM;AACjB,EAAAC,QAAO,MAAM;AACb,SAAO,MAAM;AACb,EAAAC,kBAAiB,MAAM;AACvB,+BAA6B,MAAM;AACnC,oBAAkB,MAAM;AACxB,iBAAe,MAAM;AACrB,mBAAiB,MAAM;AACzB;;;;8BCzD2D;YAH/C,QAAQ;OAEb,oBAAoB;SAElB,cAAc,oBAAoB;;;ACR3C,IAAM,WAAW;AACjB,SAAS,iBAAiB;AACtB,MAAI,OAAO;AACX,MAAI,MAAM;AACV,SAAO,QAAQ;AACX,WAAO,SAAU,KAAK,OAAO,IAAI,SAAS,UAAW,CAAC;AAAA,EAC1D;AACA,SAAO;AACX;AACA,IAAO,yBAAQ;;;ACTf,IAAM,UAAU,CAAC,UAAW,OAAO,UAAU,SAAS,KAAK,KAAK,EAAE,MAAM,GAAG,EAAE,EAAE,YAAY;AAC3F,SAAS,cAAc,OAAO;AAC1B,MAAI,QAAQ,KAAK,MAAM,UAAU;AAC7B,WAAO;AAAA,EACX;AACA,QAAM,KAAK,OAAO,eAAe,KAAK;AACtC,MAAI,OAAO,QAAQ,OAAO,QAAW;AACjC,WAAO;AAAA,EACX;AACA,QAAM,OAAO,GAAG,eAAe,GAAG,YAAY,SAAS;AACvD,SAAO,SAAS,OAAO,SAAS;AACpC;AACA,IAAO,wBAAQ;;;ACZf,IAAM,iBAAiB,CAAC,UAAU,OAAO,KAAK,EACzC,QAAQ,UAAU,CAAC,OAAO,GAAGC,SAAQ;AACtC,MAAK,UAAU,QAAQA,KAAI,IAAI,CAAC,MAAM,QAC9B,UAAU,QAAQA,KAAI,IAAI,CAAC,MAAM,MAAO;AAC5C,WAAO;AAAA,EACX;AACA,SAAO;AACX,CAAC;AACD,IAAO,yBAAQ;;;ACRf,IAAM,aAAa,CAAC,SAAS,OAAO,IAAI,EACnC,QAAQ,OAAO,KAAK,EACpB,QAAQ,OAAO,KAAK,EACpB,QAAQ,MAAM,KAAK;AACxB,IAAO,qBAAQ;;;ACJf,IAAM,aAAa,CAAC,UAAW,OAAO,UAAU;AAChD,IAAO,qBAAQ;;;ACAR,IAAM,aAAa,CAAC,UAAU,QAAQ,SACtC,OAAO,UAAU,YACjB,mBAAW,MAAM,WAAW,KAC5B,MAAM,OAAO,WAAW,MAAM,UAC9B,mBAAW,MAAM,MAAM,KACvB,MAAM,QAAQ,QACd,MAAM,QAAQ,QACd,MAAM,gBAAgB,IAAI;;;ACP1B,IAAM,aAAa,CAAC,UAAU,QAAQ,SACtC,mBAAW,MAAM,WAAW,KAC5B,MAAM,OAAO,WAAW,MAAM,cAC9B,mBAAW,MAAM,MAAM,KACvB,mBAAW,MAAM,MAAM,KACvB,mBAAW,MAAM,OAAO,KACxB,mBAAW,MAAM,OAAO,QAAQ,CAAC,CAAC;;;ACPzC,IAAI,yBAAkE,SAAU,UAAU,OAAO,OAAOC,OAAM,GAAG;AAC7G,MAAIA,UAAS,IAAK,OAAM,IAAI,UAAU,gCAAgC;AACtE,MAAIA,UAAS,OAAO,CAAC,EAAG,OAAM,IAAI,UAAU,+CAA+C;AAC3F,MAAI,OAAO,UAAU,aAAa,aAAa,SAAS,CAAC,IAAI,CAAC,MAAM,IAAI,QAAQ,EAAG,OAAM,IAAI,UAAU,yEAAyE;AAChL,SAAQA,UAAS,MAAM,EAAE,KAAK,UAAU,KAAK,IAAI,IAAI,EAAE,QAAQ,QAAQ,MAAM,IAAI,UAAU,KAAK,GAAI;AACxG;AACA,IAAI,yBAAkE,SAAU,UAAU,OAAOA,OAAM,GAAG;AACtG,MAAIA,UAAS,OAAO,CAAC,EAAG,OAAM,IAAI,UAAU,+CAA+C;AAC3F,MAAI,OAAO,UAAU,aAAa,aAAa,SAAS,CAAC,IAAI,CAAC,MAAM,IAAI,QAAQ,EAAG,OAAM,IAAI,UAAU,0EAA0E;AACjL,SAAOA,UAAS,MAAM,IAAIA,UAAS,MAAM,EAAE,KAAK,QAAQ,IAAI,IAAI,EAAE,QAAQ,MAAM,IAAI,QAAQ;AAChG;AACA,IAAI;AAAJ,IAAgC;AAAhC,IAAuD;AAAvD,IAAoF;AAApF,IAAwH;AAAxH,IAAiJ;AAAjJ,IAA2K;AAA3K,IAAoM;AAApM,IAA2N;AAA3N,IAAqP;AAOrP,IAAM,iBAAiB;AAAA,EACnB,yBAAyB;AAC7B;AACO,IAAM,kBAAN,MAAsB;AAAA,EACzB,YAAY,MAAM,mBAAmB,SAAS;AAC1C,+BAA2B,IAAI,IAAI;AACnC,0BAAsB,IAAI,MAAM,MAAM;AACtC,gCAA4B,IAAI,MAAM,MAAM;AAC5C,uCAAmC,IAAI,MAAM,MAAM;AACnD,4BAAwB,IAAI,MAAM,IAAI,OAAO,CAAC,CAAC;AAC/C,6BAAyB,IAAI,MAAM,IAAI,YAAY,CAAC;AACpD,4BAAwB,IAAI,MAAM,MAAM;AACxC,0BAAsB,IAAI,MAAM,MAAM;AACtC,6BAAyB,IAAI,MAAM,MAAM;AACzC,QAAI,CAAC,WAAW,IAAI,GAAG;AACnB,YAAM,IAAI,UAAU,oDAAoD;AAAA,IAC5E;AACA,QAAI;AACJ,QAAI,sBAAc,iBAAiB,GAAG;AAClC,gBAAU;AAAA,IACd,OACK;AACD,iBAAW;AAAA,IACf;AACA,QAAI,CAAC,UAAU;AACX,iBAAW,uBAAe;AAAA,IAC9B;AACA,QAAI,OAAO,aAAa,UAAU;AAC9B,YAAM,IAAI,UAAU,4CAA4C;AAAA,IACpE;AACA,QAAI,WAAW,CAAC,sBAAc,OAAO,GAAG;AACpC,YAAM,IAAI,UAAU,4CAA4C;AAAA,IACpE;AACA,2BAAuB,MAAM,uBAAuB,MAAM,GAAG;AAC7D,2BAAuB,MAAM,0BAA0B,EAAE,GAAG,gBAAgB,GAAG,QAAQ,GAAG,GAAG;AAC7F,2BAAuB,MAAM,6BAA6B,uBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,uBAAuB,MAAM,uBAAuB,GAAG,CAAC,GAAG,GAAG;AAC3L,2BAAuB,MAAM,oCAAoC,uBAAuB,MAAM,6BAA6B,GAAG,EAAE,YAAY,GAAG;AAC/I,SAAK,WAAW,sBAAsB,QAAQ;AAC9C,SAAK,cAAc,iCAAiC,KAAK,QAAQ;AACjE,2BAAuB,MAAM,yBAAyB,uBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,GAAG,uBAAuB,MAAM,yBAAyB,GAAG,CAAC,GAAG,KAAK,QAAQ,GAAG,uBAAuB,MAAM,yBAAyB,GAAG,CAAC,GAAG,uBAAuB,MAAM,uBAAuB,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE,GAAG,GAAG;AAChV,SAAK,gBAAgB,OAAO,KAAK,iBAAiB,CAAC;AACnD,SAAK,UAAU,OAAO,OAAO;AAAA,MACzB,gBAAgB,KAAK;AAAA,MACrB,kBAAkB,KAAK;AAAA,IAC3B,CAAC;AACD,WAAO,iBAAiB,MAAM;AAAA,MAC1B,UAAU,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,MACjD,aAAa,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,MACpD,eAAe,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,MACtD,SAAS,EAAE,UAAU,OAAO,cAAc,MAAM;AAAA,IACpD,CAAC;AAAA,EACL;AAAA,EACA,mBAAmB;AACf,QAAI,SAAS;AACb,eAAW,CAAC,MAAM,GAAG,KAAK,uBAAuB,MAAM,uBAAuB,GAAG,GAAG;AAChF,YAAM,QAAQ,WAAW,GAAG,IAAI,MAAM,uBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,uBAAU,GAAG,CAAC;AACvH,gBAAU,uBAAuB,MAAM,4BAA4B,KAAK,+BAA+B,EAAE,KAAK,MAAM,MAAM,KAAK,EAAE;AACjI,gBAAU,WAAW,KAAK,IAAI,MAAM,OAAO,MAAM;AACjD,gBAAU,uBAAuB,MAAM,oCAAoC,GAAG;AAAA,IAClF;AACA,WAAO,SAAS,uBAAuB,MAAM,yBAAyB,GAAG,EAAE;AAAA,EAC/E;AAAA,EACA,CAAC,SAAS;AACN,eAAW,CAAC,MAAM,GAAG,KAAK,uBAAuB,MAAM,uBAAuB,GAAG,EAAE,QAAQ,GAAG;AAC1F,YAAM,QAAQ,WAAW,GAAG,IAAI,MAAM,uBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,uBAAU,GAAG,CAAC;AACvH,YAAM,uBAAuB,MAAM,4BAA4B,KAAK,+BAA+B,EAAE,KAAK,MAAM,MAAM,KAAK;AAC3H,YAAM;AACN,YAAM,uBAAuB,MAAM,6BAA6B,GAAG;AAAA,IACvE;AACA,UAAM,uBAAuB,MAAM,yBAAyB,GAAG;AAAA,EACnE;AAAA,EACA,OAAO,SAAS;AACZ,eAAW,QAAQ,KAAK,OAAO,GAAG;AAC9B,UAAI,WAAW,IAAI,GAAG;AAClB,eAAO,KAAK,OAAO;AAAA,MACvB,OACK;AACD,cAAM;AAAA,MACV;AAAA,IACJ;AAAA,EACJ;AAAA,EACA,EAAE,wBAAwB,oBAAI,QAAQ,GAAG,8BAA8B,oBAAI,QAAQ,GAAG,qCAAqC,oBAAI,QAAQ,GAAG,0BAA0B,oBAAI,QAAQ,GAAG,2BAA2B,oBAAI,QAAQ,GAAG,0BAA0B,oBAAI,QAAQ,GAAG,wBAAwB,oBAAI,QAAQ,GAAG,2BAA2B,oBAAI,QAAQ,GAAG,6BAA6B,oBAAI,QAAQ,GAAG,kCAAkC,SAASC,iCAAgC,MAAM,OAAO;AACvd,QAAI,SAAS;AACb,cAAU,GAAG,uBAAuB,MAAM,yBAAyB,GAAG,CAAC,GAAG,KAAK,QAAQ,GAAG,uBAAuB,MAAM,uBAAuB,GAAG,CAAC;AAClJ,cAAU,yCAAyC,mBAAO,IAAI,CAAC;AAC/D,QAAI,WAAW,KAAK,GAAG;AACnB,gBAAU,eAAe,mBAAO,MAAM,IAAI,CAAC,IAAI,uBAAuB,MAAM,uBAAuB,GAAG,CAAC;AACvG,gBAAU,iBAAiB,MAAM,QAAQ,0BAA0B;AAAA,IACvE;AACA,QAAI,uBAAuB,MAAM,0BAA0B,GAAG,EAAE,4BAA4B,MAAM;AAC9F,gBAAU,GAAG,uBAAuB,MAAM,uBAAuB,GAAG,CAAC,mBAAmB,WAAW,KAAK,IAAI,MAAM,OAAO,MAAM,UAAU;AAAA,IAC7I;AACA,WAAO,uBAAuB,MAAM,0BAA0B,GAAG,EAAE,OAAO,GAAG,MAAM,GAAG,uBAAuB,MAAM,uBAAuB,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE;AAAA,EAC9J,GAAG,OAAO,SAAS,IAAI;AACnB,WAAO,KAAK,OAAO;AAAA,EACvB;AAAA,EACA,CAAC,OAAO,aAAa,IAAI;AACrB,WAAO,KAAK,OAAO;AAAA,EACvB;AACJ;;;SR1GS,YAAAC,iBAAgB;;;ASRnB,IAAO,gBAAP,MAAoB;EACxB,YAAmB,MAAS;AAAT,SAAA,OAAA;EAAY;EAC/B,KAAK,OAAO,WAAW,IAAC;AACtB,WAAO;EACT;;;;STQO,kBAAAC,uBAAsB;AAI/B,IAAI,qBAAqB;AASzB,eAAeC,cAAaC,UAAiB,MAAW;AAEtD,QAAM,EAAE,cAAc,cAAa,IAAK,MAAM,OAAO,8BAA8B;AAEnF,MAAI,CAAC,oBAAoB;AACvB,YAAQ,KAAK,uDAAuD,KAAK,UAAUA,KAAI,CAAC,WAAW;AACnG,yBAAqB;;AAGvB,SAAO,MAAM,cAAcA,OAAM,GAAG,IAAI;AAC1C;AAEA,IAAM,mBAA0B,IAAI,eAAe,EAAE,WAAW,MAAM,SAAS,IAAI,KAAK,IAAI,CAAE;AAC9F,IAAM,oBAA2B,IAAI,eAAe,WAAW,EAAE,WAAW,MAAM,SAAS,IAAI,KAAK,IAAI,CAAE;AAE1G,eAAeC,4BACb,MACA,MAAuB;AAEvB,QAAM,UAAU,IAAI,gBAAgB,IAAI;AACxC,QAAM,WAAWC,UAAS,KAAK,OAAO;AACtC,QAAM,OAAO,IAAI,cAAc,QAAQ;AACvC,QAAM,UAAU;IACd,GAAG,KAAK;IACR,GAAG,QAAQ;IACX,kBAAkB,QAAQ;;AAG5B,SAAO,EAAE,GAAG,MAAM,MAAmB,QAAO;AAC9C;AAEM,SAAU,aAAU;AAExB,MAAI,OAAO,oBAAoB,aAAa;AAE1C,eAAW,kBAAkB,wBAAAC;;AAE/B,SAAO;IACL,MAAM;IACN,OAAU;IACV;IACA,UAAaC;IACb,SAAYC;IACZ,UAAa;IACb,MAAS;IACT,MAAS;IACT,gBAAAP;IACA,4BAAAG;IACA,iBAAiB,CAAC,QAAwB,IAAI,WAAW,OAAO,IAAI,oBAAoB;IACxF,cAAAF;IACA,gBAAgB,CAAC,UAAsC,iBAAiB;;AAE5E;;;AU3EA,IAAI,CAAO,KAAM,CAAM,SAAc,WAAW,GAAG,EAAE,MAAM,KAAK,CAAC;;;ACD3D,IAAO,cAAP,cAA2B,MAAK;;AAEhC,IAAO,WAAP,MAAO,kBAAiB,YAAW;EAWvC,YACE,QACA,OACA,SACA,SAA4B;AAE5B,UAAM,GAAG,UAAS,YAAY,QAAQ,OAAO,OAAO,CAAC,EAAE;AACvD,SAAK,SAAS;AACd,SAAK,UAAU;AACf,SAAK,aAAa,UAAU,cAAc;AAE1C,UAAM,OAAO;AACb,SAAK,QAAQ;AACb,SAAK,OAAO,OAAO,MAAM;AACzB,SAAK,QAAQ,OAAO,OAAO;AAC3B,SAAK,OAAO,OAAO,MAAM;EAC3B;EAEQ,OAAO,YAAY,QAA4B,OAAY,SAA2B;AAC5F,UAAM,MACJ,OAAO,UACL,OAAO,MAAM,YAAY,WACvB,MAAM,UACN,KAAK,UAAU,MAAM,OAAO,IAC9B,QAAQ,KAAK,UAAU,KAAK,IAC5B;AAEJ,QAAI,UAAU,KAAK;AACjB,aAAO,GAAG,MAAM,IAAI,GAAG;;AAEzB,QAAI,QAAQ;AACV,aAAO,GAAG,MAAM;;AAElB,QAAI,KAAK;AACP,aAAO;;AAET,WAAO;EACT;EAEA,OAAO,SACL,QACA,eACA,SACA,SAA4B;AAE5B,QAAI,CAAC,QAAQ;AACX,aAAO,IAAI,mBAAmB,EAAE,SAAS,OAAO,YAAY,aAAa,EAAC,CAAE;;AAG9E,UAAM,QAAS,gBAAwC,OAAO;AAE9D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,gBAAgB,QAAQ,OAAO,SAAS,OAAO;;AAG5D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,sBAAsB,QAAQ,OAAO,SAAS,OAAO;;AAGlE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,cAAc,QAAQ,OAAO,SAAS,OAAO;;AAG1D,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,yBAAyB,QAAQ,OAAO,SAAS,OAAO;;AAGrE,QAAI,WAAW,KAAK;AAClB,aAAO,IAAI,eAAe,QAAQ,OAAO,SAAS,OAAO;;AAG3D,QAAI,UAAU,KAAK;AACjB,aAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS,OAAO;;AAGhE,WAAO,IAAI,UAAS,QAAQ,OAAO,SAAS,OAAO;EACrD;;AAGI,IAAO,oBAAP,cAAiC,SAAQ;EAG7C,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,QAAW,QAAW,WAAW,wBAAwB,MAAS;AAHxD,SAAA,SAAoB;EAItC;;AAGI,IAAO,qBAAP,cAAkC,SAAQ;EAG9C,YAAY,EAAE,SAAS,MAAK,GAA+D;AACzF,UAAM,QAAW,QAAW,WAAW,qBAAqB,MAAS;AAHrD,SAAA,SAAoB;AAMpC,QAAI;AAAO,WAAK,QAAQ;EAC1B;;AAGI,IAAO,4BAAP,cAAyC,mBAAkB;EAC/D,YAAY,EAAE,QAAO,IAA2B,CAAA,GAAE;AAChD,UAAM,EAAE,SAAS,WAAW,qBAAoB,CAAE;EACpD;;AAGI,IAAO,kBAAP,cAA+B,SAAQ;EAA7C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,sBAAP,cAAmC,SAAQ;EAAjD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,wBAAP,cAAqC,SAAQ;EAAnD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,gBAAP,cAA6B,SAAQ;EAA3C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,gBAAP,cAA6B,SAAQ;EAA3C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,2BAAP,cAAwC,SAAQ;EAAtD,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,iBAAP,cAA8B,SAAQ;EAA5C,cAAA;;AACoB,SAAA,SAAc;EAClC;;AAEM,IAAO,sBAAP,cAAmC,SAAQ;;AAE3C,IAAO,0BAAP,cAAuC,YAAW;EACtD,cAAA;AACE,UAAM,kEAAkE;EAC1E;;AAGI,IAAO,iCAAP,cAA8C,YAAW;EAC7D,cAAA;AACE,UAAM,oFAAoF;EAC5F;;;;AC9JI,IAAO,cAAP,MAAO,aAAW;EAStB,cAAA;AACE,SAAK,SAAS,CAAA;AACd,SAAK,aAAa;EACpB;EAEA,OAAO,OAAY;AACjB,QAAI,OAAO,KAAK,WAAW,KAAK;AAEhC,QAAI,KAAK,YAAY;AACnB,aAAO,OAAO;AACd,WAAK,aAAa;;AAEpB,QAAI,KAAK,SAAS,IAAI,GAAG;AACvB,WAAK,aAAa;AAClB,aAAO,KAAK,MAAM,GAAG,EAAE;;AAGzB,QAAI,CAAC,MAAM;AACT,aAAO,CAAA;;AAGT,UAAM,kBAAkB,aAAY,cAAc,IAAI,KAAK,KAAK,SAAS,CAAC,KAAK,EAAE;AACjF,QAAI,QAAQ,KAAK,MAAM,aAAY,cAAc;AAIjD,QAAI,iBAAiB;AACnB,YAAM,IAAG;;AAGX,QAAI,MAAM,WAAW,KAAK,CAAC,iBAAiB;AAC1C,WAAK,OAAO,KAAK,MAAM,CAAC,CAAE;AAC1B,aAAO,CAAA;;AAGT,QAAI,KAAK,OAAO,SAAS,GAAG;AAC1B,cAAQ,CAAC,KAAK,OAAO,KAAK,EAAE,IAAI,MAAM,CAAC,GAAG,GAAG,MAAM,MAAM,CAAC,CAAC;AAC3D,WAAK,SAAS,CAAA;;AAGhB,QAAI,CAAC,iBAAiB;AACpB,WAAK,SAAS,CAAC,MAAM,IAAG,KAAM,EAAE;;AAGlC,WAAO;EACT;EAEA,WAAW,OAAY;AACrB,QAAI,SAAS;AAAM,aAAO;AAC1B,QAAI,OAAO,UAAU;AAAU,aAAO;AAGtC,QAAI,OAAO,WAAW,aAAa;AACjC,UAAI,iBAAiB,QAAQ;AAC3B,eAAO,MAAM,SAAQ;;AAEvB,UAAI,iBAAiB,YAAY;AAC/B,eAAO,OAAO,KAAK,KAAK,EAAE,SAAQ;;AAGpC,YAAM,IAAI,YACR,wCAAwC,MAAM,YAAY,IAAI,mIAAmI;;AAKrM,QAAI,OAAO,gBAAgB,aAAa;AACtC,UAAI,iBAAiB,cAAc,iBAAiB,aAAa;AAC/D,aAAK,gBAAL,KAAK,cAAgB,IAAI,YAAY,MAAM;AAC3C,eAAO,KAAK,YAAY,OAAO,KAAK;;AAGtC,YAAM,IAAI,YACR,oDACG,MAAc,YAAY,IAC7B,gDAAgD;;AAIpD,UAAM,IAAI,YACR,gGAAgG;EAEpG;EAEA,QAAK;AACH,QAAI,CAAC,KAAK,OAAO,UAAU,CAAC,KAAK,YAAY;AAC3C,aAAO,CAAA;;AAGT,UAAM,QAAQ,CAAC,KAAK,OAAO,KAAK,EAAE,CAAC;AACnC,SAAK,SAAS,CAAA;AACd,SAAK,aAAa;AAClB,WAAO;EACT;;AApGO,YAAA,gBAAgB,oBAAI,IAAI,CAAC,MAAM,IAAI,CAAC;AACpC,YAAA,iBAAiB;;;ACCpB,IAAO,SAAP,MAAO,QAAM;EAGjB,YACU,UACR,YAA2B;AADnB,SAAA,WAAA;AAGR,SAAK,aAAa;EACpB;EAEA,OAAO,gBAAsB,UAAoB,YAA2B;AAC1E,QAAI,WAAW;AAEf,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,OAAO,iBAAiB,UAAU,UAAU,GAAG;AAC9D,cAAI;AAAM;AAEV,cAAI,IAAI,KAAK,WAAW,QAAQ,GAAG;AACjC,mBAAO;AACP;;AAGF,cAAI,IAAI,UAAU,MAAM;AACtB,gBAAI;AAEJ,gBAAI;AACF,qBAAO,KAAK,MAAM,IAAI,IAAI;qBACnB,GAAG;AACV,sBAAQ,MAAM,sCAAsC,IAAI,IAAI;AAC5D,sBAAQ,MAAM,eAAe,IAAI,GAAG;AACpC,oBAAM;;AAGR,gBAAI,QAAQ,KAAK,OAAO;AACtB,oBAAM,IAAI,SAAS,QAAW,KAAK,OAAO,QAAW,MAAS;;AAGhE,kBAAM;iBACD;AACL,gBAAI;AACJ,gBAAI;AACF,qBAAO,KAAK,MAAM,IAAI,IAAI;qBACnB,GAAG;AACV,sBAAQ,MAAM,sCAAsC,IAAI,IAAI;AAC5D,sBAAQ,MAAM,eAAe,IAAI,GAAG;AACpC,oBAAM;;AAGR,gBAAI,IAAI,SAAS,SAAS;AACxB,oBAAM,IAAI,SAAS,QAAW,KAAK,OAAO,KAAK,SAAS,MAAS;;AAEnE,kBAAM,EAAE,OAAO,IAAI,OAAO,KAAU;;;AAGxC,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AAEA,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;;;;;EAMA,OAAO,mBAAyB,gBAAgC,YAA2B;AACzF,QAAI,WAAW;AAEf,oBAAgB,YAAS;AACvB,YAAM,cAAc,IAAI,YAAW;AAEnC,YAAM,OAAO,4BAAmC,cAAc;AAC9D,uBAAiB,SAAS,MAAM;AAC9B,mBAAW,QAAQ,YAAY,OAAO,KAAK,GAAG;AAC5C,gBAAM;;;AAIV,iBAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,cAAM;;IAEV;AAEA,oBAAgB,WAAQ;AACtB,UAAI,UAAU;AACZ,cAAM,IAAI,MAAM,0EAA0E;;AAE5F,iBAAW;AACX,UAAI,OAAO;AACX,UAAI;AACF,yBAAiB,QAAQ,UAAS,GAAI;AACpC,cAAI;AAAM;AACV,cAAI;AAAM,kBAAM,KAAK,MAAM,IAAI;;AAEjC,eAAO;eACA,GAAG;AAEV,YAAI,aAAa,SAAS,EAAE,SAAS;AAAc;AACnD,cAAM;;AAGN,YAAI,CAAC;AAAM,qBAAW,MAAK;;IAE/B;AAEA,WAAO,IAAI,QAAO,UAAU,UAAU;EACxC;EAEA,CAAC,OAAO,aAAa,IAAC;AACpB,WAAO,KAAK,SAAQ;EACtB;;;;;EAMA,MAAG;AACD,UAAM,OAA6C,CAAA;AACnD,UAAM,QAA8C,CAAA;AACpD,UAAM,WAAW,KAAK,SAAQ;AAE9B,UAAM,cAAc,CAAC,UAAoE;AACvF,aAAO;QACL,MAAM,MAAK;AACT,cAAI,MAAM,WAAW,GAAG;AACtB,kBAAM,SAAS,SAAS,KAAI;AAC5B,iBAAK,KAAK,MAAM;AAChB,kBAAM,KAAK,MAAM;;AAEnB,iBAAO,MAAM,MAAK;QACpB;;IAEJ;AAEA,WAAO;MACL,IAAI,QAAO,MAAM,YAAY,IAAI,GAAG,KAAK,UAAU;MACnD,IAAI,QAAO,MAAM,YAAY,KAAK,GAAG,KAAK,UAAU;;EAExD;;;;;;EAOA,mBAAgB;AACd,UAAM,OAAO;AACb,QAAI;AACJ,UAAM,UAAU,IAAI,YAAW;AAE/B,WAAO,IAAIO,gBAAe;MACxB,MAAM,QAAK;AACT,eAAO,KAAK,OAAO,aAAa,EAAC;MACnC;MACA,MAAM,KAAK,MAAS;AAClB,YAAI;AACF,gBAAM,EAAE,OAAO,KAAI,IAAK,MAAM,KAAK,KAAI;AACvC,cAAI;AAAM,mBAAO,KAAK,MAAK;AAE3B,gBAAM,QAAQ,QAAQ,OAAO,KAAK,UAAU,KAAK,IAAI,IAAI;AAEzD,eAAK,QAAQ,KAAK;iBACX,KAAK;AACZ,eAAK,MAAM,GAAG;;MAElB;MACA,MAAM,SAAM;AACV,cAAM,KAAK,SAAQ;MACrB;KACD;EACH;;AAGF,gBAAuB,iBACrB,UACA,YAA2B;AAE3B,MAAI,CAAC,SAAS,MAAM;AAClB,eAAW,MAAK;AAChB,UAAM,IAAI,YAAY,mDAAmD;;AAG3E,QAAM,aAAa,IAAI,WAAU;AACjC,QAAM,cAAc,IAAI,YAAW;AAEnC,QAAM,OAAO,4BAAmC,SAAS,IAAI;AAC7D,mBAAiB,YAAY,cAAc,IAAI,GAAG;AAChD,eAAW,QAAQ,YAAY,OAAO,QAAQ,GAAG;AAC/C,YAAM,MAAM,WAAW,OAAO,IAAI;AAClC,UAAI;AAAK,cAAM;;;AAInB,aAAW,QAAQ,YAAY,MAAK,GAAI;AACtC,UAAM,MAAM,WAAW,OAAO,IAAI;AAClC,QAAI;AAAK,YAAM;;AAEnB;AAMA,gBAAgB,cAAc,UAAsC;AAClE,MAAI,OAAO,IAAI,WAAU;AAEzB,mBAAiB,SAAS,UAAU;AAClC,QAAI,SAAS,MAAM;AACjB;;AAGF,UAAM,cACJ,iBAAiB,cAAc,IAAI,WAAW,KAAK,IACjD,OAAO,UAAU,WAAW,IAAI,YAAW,EAAG,OAAO,KAAK,IAC1D;AAEJ,QAAI,UAAU,IAAI,WAAW,KAAK,SAAS,YAAY,MAAM;AAC7D,YAAQ,IAAI,IAAI;AAChB,YAAQ,IAAI,aAAa,KAAK,MAAM;AACpC,WAAO;AAEP,QAAI;AACJ,YAAQ,eAAe,uBAAuB,IAAI,OAAO,IAAI;AAC3D,YAAM,KAAK,MAAM,GAAG,YAAY;AAChC,aAAO,KAAK,MAAM,YAAY;;;AAIlC,MAAI,KAAK,SAAS,GAAG;AACnB,UAAM;;AAEV;AAEA,SAAS,uBAAuB,QAAkB;AAIhD,QAAM,UAAU;AAChB,QAAM,WAAW;AAEjB,WAAS,IAAI,GAAG,IAAI,OAAO,SAAS,GAAG,KAAK;AAC1C,QAAI,OAAO,CAAC,MAAM,WAAW,OAAO,IAAI,CAAC,MAAM,SAAS;AAEtD,aAAO,IAAI;;AAEb,QAAI,OAAO,CAAC,MAAM,YAAY,OAAO,IAAI,CAAC,MAAM,UAAU;AAExD,aAAO,IAAI;;AAEb,QACE,OAAO,CAAC,MAAM,YACd,OAAO,IAAI,CAAC,MAAM,WAClB,IAAI,IAAI,OAAO,UACf,OAAO,IAAI,CAAC,MAAM,YAClB,OAAO,IAAI,CAAC,MAAM,SAClB;AAEA,aAAO,IAAI;;;AAIf,SAAO;AACT;AAEA,IAAM,aAAN,MAAgB;EAKd,cAAA;AACE,SAAK,QAAQ;AACb,SAAK,OAAO,CAAA;AACZ,SAAK,SAAS,CAAA;EAChB;EAEA,OAAO,MAAY;AACjB,QAAI,KAAK,SAAS,IAAI,GAAG;AACvB,aAAO,KAAK,UAAU,GAAG,KAAK,SAAS,CAAC;;AAG1C,QAAI,CAAC,MAAM;AAET,UAAI,CAAC,KAAK,SAAS,CAAC,KAAK,KAAK;AAAQ,eAAO;AAE7C,YAAM,MAAuB;QAC3B,OAAO,KAAK;QACZ,MAAM,KAAK,KAAK,KAAK,IAAI;QACzB,KAAK,KAAK;;AAGZ,WAAK,QAAQ;AACb,WAAK,OAAO,CAAA;AACZ,WAAK,SAAS,CAAA;AAEd,aAAO;;AAGT,SAAK,OAAO,KAAK,IAAI;AAErB,QAAI,KAAK,WAAW,GAAG,GAAG;AACxB,aAAO;;AAGT,QAAI,CAAC,WAAW,GAAG,KAAK,IAAI,UAAU,MAAM,GAAG;AAE/C,QAAI,MAAM,WAAW,GAAG,GAAG;AACzB,cAAQ,MAAM,UAAU,CAAC;;AAG3B,QAAI,cAAc,SAAS;AACzB,WAAK,QAAQ;eACJ,cAAc,QAAQ;AAC/B,WAAK,KAAK,KAAK,KAAK;;AAGtB,WAAO;EACT;;AAcF,SAAS,UAAUC,MAAa,WAAiB;AAC/C,QAAM,QAAQA,KAAI,QAAQ,SAAS;AACnC,MAAI,UAAU,IAAI;AAChB,WAAO,CAACA,KAAI,UAAU,GAAG,KAAK,GAAG,WAAWA,KAAI,UAAU,QAAQ,UAAU,MAAM,CAAC;;AAGrF,SAAO,CAACA,MAAK,IAAI,EAAE;AACrB;AAQM,SAAU,4BAA+B,QAAW;AACxD,MAAI,OAAO,OAAO,aAAa;AAAG,WAAO;AAEzC,QAAM,SAAS,OAAO,UAAS;AAC/B,SAAO;IACL,MAAM,OAAI;AACR,UAAI;AACF,cAAM,SAAS,MAAM,OAAO,KAAI;AAChC,YAAI,QAAQ;AAAM,iBAAO,YAAW;AACpC,eAAO;eACA,GAAG;AACV,eAAO,YAAW;AAClB,cAAM;;IAEV;IACA,MAAM,SAAM;AACV,YAAM,gBAAgB,OAAO,OAAM;AACnC,aAAO,YAAW;AAClB,YAAM;AACN,aAAO,EAAE,MAAM,MAAM,OAAO,OAAS;IACvC;IACA,CAAC,OAAO,aAAa,IAAC;AACpB,aAAO;IACT;;AAEJ;;;ACjVO,IAAM,iBAAiB,CAAC,UAC7B,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,QAAQ,YACrB,OAAO,MAAM,SAAS;AAEjB,IAAMC,cAAa,CAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,iBAAiB,YAC9B,WAAW,KAAK;AAMX,IAAM,aAAa,CAAC,UACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,YACtB,OAAO,MAAM,SAAS,cACtB,OAAO,MAAM,UAAU,cACvB,OAAO,MAAM,gBAAgB;AAExB,IAAM,eAAe,CAAC,UAAmC;AAC9D,SAAOA,YAAW,KAAK,KAAK,eAAe,KAAK,KAAK,eAAe,KAAK;AAC3E;AAaA,eAAsB,OACpB,OACA,MACA,SAAqC;AAGrC,UAAQ,MAAM;AAGd,MAAIA,YAAW,KAAK,GAAG;AACrB,WAAO;;AAGT,MAAI,eAAe,KAAK,GAAG;AACzB,UAAM,OAAO,MAAM,MAAM,KAAI;AAC7B,aAAA,OAAS,IAAI,IAAI,MAAM,GAAG,EAAE,SAAS,MAAM,OAAO,EAAE,IAAG,KAAM;AAK7D,UAAM,OAAO,WAAW,IAAI,IAAI,CAAE,MAAM,KAAK,YAAW,CAAU,IAAI,CAAC,IAAI;AAE3E,WAAO,IAAI,KAAK,MAAM,MAAM,OAAO;;AAGrC,QAAM,OAAO,MAAM,SAAS,KAAK;AAEjC,WAAA,OAAS,QAAQ,KAAK,KAAK;AAE3B,MAAI,CAAC,SAAS,MAAM;AAClB,UAAM,OAAQ,KAAK,CAAC,GAAW;AAC/B,QAAI,OAAO,SAAS,UAAU;AAC5B,gBAAU,EAAE,GAAG,SAAS,KAAI;;;AAIhC,SAAO,IAAI,KAAK,MAAM,MAAM,OAAO;AACrC;AAEA,eAAe,SAAS,OAAkB;AACxC,MAAI,QAAyB,CAAA;AAC7B,MACE,OAAO,UAAU,YACjB,YAAY,OAAO,KAAK;EACxB,iBAAiB,aACjB;AACA,UAAM,KAAK,KAAK;aACP,WAAW,KAAK,GAAG;AAC5B,UAAM,KAAK,MAAM,MAAM,YAAW,CAAE;aAEpC,wBAAwB,KAAK,GAC7B;AACA,qBAAiB,SAAS,OAAO;AAC/B,YAAM,KAAK,KAAiB;;SAEzB;AACL,UAAM,IAAI,MACR,yBAAyB,OAAO,KAAK,kBAAkB,OAAO,aAC1D,IAAI,YAAY,cAAc,KAAK,CAAC,EAAE;;AAI9C,SAAO;AACT;AAEA,SAAS,cAAc,OAAU;AAC/B,QAAM,QAAQ,OAAO,oBAAoB,KAAK;AAC9C,SAAO,IAAI,MAAM,IAAI,CAAC,MAAM,IAAI,CAAC,GAAG,EAAE,KAAK,IAAI,CAAC;AAClD;AAEA,SAAS,QAAQ,OAAU;AACzB,SACE,yBAAyB,MAAM,IAAI,KACnC,yBAAyB,MAAM,QAAQ;EAEvC,yBAAyB,MAAM,IAAI,GAAG,MAAM,OAAO,EAAE,IAAG;AAE5D;AAEA,IAAM,2BAA2B,CAAC,MAAoD;AACpF,MAAI,OAAO,MAAM;AAAU,WAAO;AAClC,MAAI,OAAO,WAAW,eAAe,aAAa;AAAQ,WAAO,OAAO,CAAC;AACzE,SAAO;AACT;AAEA,IAAM,0BAA0B,CAAC,UAC/B,SAAS,QAAQ,OAAO,UAAU,YAAY,OAAO,MAAM,OAAO,aAAa,MAAM;AAEhF,IAAM,kBAAkB,CAAC,SAC9B,QAAQ,OAAO,SAAS,YAAY,KAAK,QAAQ,KAAK,OAAO,WAAW,MAAM;AAezE,IAAM,8BAA8B,OACzC,SAC8C;AAC9C,QAAM,OAAO,MAAM,WAAW,KAAK,IAAI;AACvC,SAAO,2BAA2B,MAAM,IAAI;AAC9C;AAEO,IAAM,aAAa,OAAoC,SAA0C;AACtG,QAAM,OAAO,IAAI,SAAQ;AACzB,QAAM,QAAQ,IAAI,OAAO,QAAQ,QAAQ,CAAA,CAAE,EAAE,IAAI,CAAC,CAAC,KAAK,KAAK,MAAM,aAAa,MAAM,KAAK,KAAK,CAAC,CAAC;AAClG,SAAO;AACT;AAaA,IAAM,eAAe,OAAO,MAAgB,KAAa,UAAiC;AACxF,MAAI,UAAU;AAAW;AACzB,MAAI,SAAS,MAAM;AACjB,UAAM,IAAI,UACR,sBAAsB,GAAG,6DAA6D;;AAK1F,MAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,SAAK,OAAO,KAAK,OAAO,KAAK,CAAC;aACrB,aAAa,KAAK,GAAG;AAC9B,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,SAAK,OAAO,KAAK,IAAY;aACpB,MAAM,QAAQ,KAAK,GAAG;AAC/B,UAAM,QAAQ,IAAI,MAAM,IAAI,CAAC,UAAU,aAAa,MAAM,MAAM,MAAM,KAAK,CAAC,CAAC;aACpE,OAAO,UAAU,UAAU;AACpC,UAAM,QAAQ,IACZ,OAAO,QAAQ,KAAK,EAAE,IAAI,CAAC,CAAC,MAAM,IAAI,MAAM,aAAa,MAAM,GAAG,GAAG,IAAI,IAAI,KAAK,IAAI,CAAC,CAAC;SAErF;AACL,UAAM,IAAI,UACR,wGAAwG,KAAK,UAAU;;AAG7H;;;;;;;;;;;;;;;ACvNA,eAAe,qBAAwB,OAAuB;AAC5D,QAAM,EAAE,SAAQ,IAAK;AACrB,MAAI,MAAM,QAAQ,QAAQ;AACxB,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,SAAS,IAAI;AAKhF,QAAI,MAAM,QAAQ,eAAe;AAC/B,aAAO,MAAM,QAAQ,cAAc,gBAAgB,UAAU,MAAM,UAAU;;AAG/E,WAAO,OAAO,gBAAgB,UAAU,MAAM,UAAU;;AAI1D,MAAI,SAAS,WAAW,KAAK;AAC3B,WAAO;;AAGT,MAAI,MAAM,QAAQ,kBAAkB;AAClC,WAAO;;AAGT,QAAM,cAAc,SAAS,QAAQ,IAAI,cAAc;AACvD,QAAM,SACJ,aAAa,SAAS,kBAAkB,KAAK,aAAa,SAAS,0BAA0B;AAC/F,MAAI,QAAQ;AACV,UAAM,OAAO,MAAM,SAAS,KAAI;AAEhC,UAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAEvE,WAAO,cAAc,MAAM,QAAQ;;AAGrC,QAAM,OAAO,MAAM,SAAS,KAAI;AAChC,QAAM,YAAY,SAAS,QAAQ,SAAS,KAAK,SAAS,SAAS,IAAI;AAGvE,SAAO;AACT;AAOA,SAAS,cAAiB,OAAU,UAAkB;AACpD,MAAI,CAAC,SAAS,OAAO,UAAU,YAAY,MAAM,QAAQ,KAAK,GAAG;AAC/D,WAAO;;AAGT,SAAO,OAAO,eAAe,OAAO,eAAe;IACjD,OAAO,SAAS,QAAQ,IAAI,cAAc;IAC1C,YAAY;GACb;AACH;AAMM,IAAO,aAAP,MAAO,oBAAsB,QAAyB;EAG1D,YACU,iBACA,gBAEgC,sBAAoB;AAE5D,UAAM,CAAC,YAAW;AAIhB,cAAQ,IAAW;IACrB,CAAC;AAVO,SAAA,kBAAA;AACA,SAAA,gBAAA;EAUV;EAEA,YAAe,WAAkD;AAC/D,WAAO,IAAI,YAAW,KAAK,iBAAiB,OAAO,UACjD,cAAc,UAAU,MAAM,KAAK,cAAc,KAAK,GAAG,KAAK,GAAG,MAAM,QAAQ,CAAC;EAEpF;;;;;;;;;;;;;;EAeA,aAAU;AACR,WAAO,KAAK,gBAAgB,KAAK,CAAC,MAAM,EAAE,QAAQ;EACpD;;;;;;;;;;;;;;;;EAiBA,MAAM,eAAY;AAChB,UAAM,CAAC,MAAM,QAAQ,IAAI,MAAM,QAAQ,IAAI,CAAC,KAAK,MAAK,GAAI,KAAK,WAAU,CAAE,CAAC;AAC5E,WAAO,EAAE,MAAM,UAAU,YAAY,SAAS,QAAQ,IAAI,cAAc,EAAC;EAC3E;EAEQ,QAAK;AACX,QAAI,CAAC,KAAK,eAAe;AACvB,WAAK,gBAAgB,KAAK,gBAAgB,KAAK,KAAK,aAAa;;AAEnE,WAAO,KAAK;EACd;EAES,KACP,aACA,YAAmF;AAEnF,WAAO,KAAK,MAAK,EAAG,KAAK,aAAa,UAAU;EAClD;EAES,MACP,YAAiF;AAEjF,WAAO,KAAK,MAAK,EAAG,MAAM,UAAU;EACtC;EAES,QAAQ,WAA2C;AAC1D,WAAO,KAAK,MAAK,EAAG,QAAQ,SAAS;EACvC;;AAGI,IAAgB,YAAhB,MAAyB;EAS7B,YAAY;IACV;IACA,aAAa;IACb,UAAU;;IACV;IACA,OAAO;EAAc,GAOtB;AACC,SAAK,UAAU;AACf,SAAK,aAAa,wBAAwB,cAAc,UAAU;AAClE,SAAK,UAAU,wBAAwB,WAAW,OAAO;AACzD,SAAK,YAAY;AAEjB,SAAK,QAAQ,kBAAkBC;EACjC;EAEU,YAAY,MAAyB;AAC7C,WAAO,CAAA;EACT;;;;;;;;;EAUU,eAAe,MAAyB;AAChD,WAAO;MACL,QAAQ;MACR,gBAAgB;MAChB,cAAc,KAAK,aAAY;MAC/B,GAAG,mBAAkB;MACrB,GAAG,KAAK,YAAY,IAAI;;EAE5B;;;;EAOU,gBAAgB,SAAkB,eAAsB;EAAG;EAE3D,wBAAqB;AAC7B,WAAO,wBAAwB,MAAK,CAAE;EACxC;EAEA,IAAcC,OAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAOA,OAAM,IAAI;EAC7C;EAEA,KAAeA,OAAc,MAA0C;AACrE,WAAO,KAAK,cAAc,QAAQA,OAAM,IAAI;EAC9C;EAEA,MAAgBA,OAAc,MAA0C;AACtE,WAAO,KAAK,cAAc,SAASA,OAAM,IAAI;EAC/C;EAEA,IAAcA,OAAc,MAA0C;AACpE,WAAO,KAAK,cAAc,OAAOA,OAAM,IAAI;EAC7C;EAEA,OAAiBA,OAAc,MAA0C;AACvE,WAAO,KAAK,cAAc,UAAUA,OAAM,IAAI;EAChD;EAEQ,cACN,QACAA,OACA,MAA0C;AAE1C,WAAO,KAAK,QACV,QAAQ,QAAQ,IAAI,EAAE,KAAK,OAAOC,UAAQ;AACxC,YAAM,OACJA,SAAQ,WAAWA,OAAM,IAAI,IAAI,IAAI,SAAS,MAAMA,MAAK,KAAK,YAAW,CAAE,IACzEA,OAAM,gBAAgB,WAAWA,MAAK,OACtCA,OAAM,gBAAgB,cAAc,IAAI,SAASA,MAAK,IAAI,IAC1DA,SAAQ,YAAY,OAAOA,OAAM,IAAI,IAAI,IAAI,SAASA,MAAK,KAAK,MAAM,IACtEA,OAAM;AACV,aAAO,EAAE,QAAQ,MAAAD,OAAM,GAAGC,OAAM,KAAI;IACtC,CAAC,CAAC;EAEN;EAEA,WACED,OACAE,OACA,MAA0B;AAE1B,WAAO,KAAK,eAAeA,OAAM,EAAE,QAAQ,OAAO,MAAAF,OAAM,GAAG,KAAI,CAAE;EACnE;EAEQ,uBAAuB,MAAa;AAC1C,QAAI,OAAO,SAAS,UAAU;AAC5B,UAAI,OAAO,WAAW,aAAa;AACjC,eAAO,OAAO,WAAW,MAAM,MAAM,EAAE,SAAQ;;AAGjD,UAAI,OAAO,gBAAgB,aAAa;AACtC,cAAM,UAAU,IAAI,YAAW;AAC/B,cAAM,UAAU,QAAQ,OAAO,IAAI;AACnC,eAAO,QAAQ,OAAO,SAAQ;;eAEvB,YAAY,OAAO,IAAI,GAAG;AACnC,aAAO,KAAK,WAAW,SAAQ;;AAGjC,WAAO;EACT;EAEA,aACE,SACA,EAAE,aAAa,EAAC,IAA8B,CAAA,GAAE;AAEhD,UAAM,EAAE,QAAQ,MAAAA,OAAM,OAAO,UAAmB,CAAA,EAAE,IAAK;AAEvD,UAAM,OACJ,YAAY,OAAO,QAAQ,IAAI,KAAM,QAAQ,mBAAmB,OAAO,QAAQ,SAAS,WACtF,QAAQ,OACR,gBAAgB,QAAQ,IAAI,IAAI,QAAQ,KAAK,OAC7C,QAAQ,OAAO,KAAK,UAAU,QAAQ,MAAM,MAAM,CAAC,IACnD;AACJ,UAAM,gBAAgB,KAAK,uBAAuB,IAAI;AAEtD,UAAM,MAAM,KAAK,SAASA,OAAO,KAAK;AACtC,QAAI,aAAa;AAAS,8BAAwB,WAAW,QAAQ,OAAO;AAC5E,UAAM,UAAU,QAAQ,WAAW,KAAK;AACxC,UAAM,YAAY,QAAQ,aAAa,KAAK,aAAa,gBAAgB,GAAG;AAC5E,UAAM,kBAAkB,UAAU;AAClC,QACE,OAAQ,WAAmB,SAAS,YAAY,YAChD,mBAAoB,UAAkB,QAAQ,WAAW,IACzD;AAKC,gBAAkB,QAAQ,UAAU;;AAGvC,QAAI,KAAK,qBAAqB,WAAW,OAAO;AAC9C,UAAI,CAAC,QAAQ;AAAgB,gBAAQ,iBAAiB,KAAK,sBAAqB;AAChF,cAAQ,KAAK,iBAAiB,IAAI,QAAQ;;AAG5C,UAAM,aAAa,KAAK,aAAa,EAAE,SAAS,SAAS,eAAe,WAAU,CAAE;AAEpF,UAAM,MAAmB;MACvB;MACA,GAAI,QAAQ,EAAE,KAAiB;MAC/B,SAAS;MACT,GAAI,aAAa,EAAE,OAAO,UAAS;;;MAGnC,QAAQ,QAAQ,UAAU;;AAG5B,WAAO,EAAE,KAAK,KAAK,QAAO;EAC5B;EAEQ,aAAa,EACnB,SACA,SACA,eACA,WAAU,GAMX;AACC,UAAM,aAAqC,CAAA;AAC3C,QAAI,eAAe;AACjB,iBAAW,gBAAgB,IAAI;;AAGjC,UAAM,iBAAiB,KAAK,eAAe,OAAO;AAClD,oBAAgB,YAAY,cAAc;AAC1C,oBAAgB,YAAY,OAAO;AAGnC,QAAI,gBAAgB,QAAQ,IAAI,KAAK,SAAc,QAAQ;AACzD,aAAO,WAAW,cAAc;;AAMlC,QACE,UAAU,gBAAgB,yBAAyB,MAAM,UACzD,UAAU,SAAS,yBAAyB,MAAM,QAClD;AACA,iBAAW,yBAAyB,IAAI,OAAO,UAAU;;AAG3D,SAAK,gBAAgB,YAAY,OAAO;AAExC,WAAO;EACT;;;;EAKU,MAAM,eAAe,SAA4B;EAAkB;;;;;;;EAQnE,MAAM,eACd,SACA,EAAE,KAAK,QAAO,GAAiD;EAC/C;EAER,aAAa,SAAuC;AAC5D,WACE,CAAC,UAAU,CAAA,IACT,OAAO,YAAY,UACnB,OAAO,YAAY,MAAM,KAAK,OAA6B,EAAE,IAAI,CAAC,WAAW,CAAC,GAAG,MAAM,CAAC,CAAC,IACzF,EAAE,GAAG,QAAO;EAElB;EAEU,gBACR,QACA,OACA,SACA,SAA4B;AAE5B,WAAO,SAAS,SAAS,QAAQ,OAAO,SAAS,OAAO;EAC1D;EAEA,QACE,SACA,mBAAkC,MAAI;AAEtC,WAAO,IAAI,WAAW,KAAK,YAAY,SAAS,gBAAgB,CAAC;EACnE;EAEQ,MAAM,YACZ,cACA,kBAA+B;AAE/B,UAAM,UAAU,MAAM;AACtB,UAAM,aAAa,QAAQ,cAAc,KAAK;AAC9C,QAAI,oBAAoB,MAAM;AAC5B,yBAAmB;;AAGrB,UAAM,KAAK,eAAe,OAAO;AAEjC,UAAM,EAAE,KAAK,KAAK,QAAO,IAAK,KAAK,aAAa,SAAS,EAAE,YAAY,aAAa,iBAAgB,CAAE;AAEtG,UAAM,KAAK,eAAe,KAAK,EAAE,KAAK,QAAO,CAAE;AAE/C,UAAM,WAAW,KAAK,SAAS,IAAI,OAAO;AAE1C,QAAI,QAAQ,QAAQ,SAAS;AAC3B,YAAM,IAAI,kBAAiB;;AAG7B,UAAM,aAAa,IAAI,gBAAe;AACtC,UAAM,WAAW,MAAM,KAAK,iBAAiB,KAAK,KAAK,SAAS,UAAU,EAAE,MAAM,WAAW;AAE7F,QAAI,oBAAoB,OAAO;AAC7B,UAAI,QAAQ,QAAQ,SAAS;AAC3B,cAAM,IAAI,kBAAiB;;AAE7B,UAAI,kBAAkB;AACpB,eAAO,KAAK,aAAa,SAAS,gBAAgB;;AAEpD,UAAI,SAAS,SAAS,cAAc;AAClC,cAAM,IAAI,0BAAyB;;AAErC,YAAM,IAAI,mBAAmB,EAAE,OAAO,SAAQ,CAAE;;AAGlD,UAAM,kBAAkB,sBAAsB,SAAS,OAAO;AAE9D,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI,oBAAoB,KAAK,YAAY,QAAQ,GAAG;AAClD,cAAMG,gBAAe,aAAa,gBAAgB;AAClD,cAAM,oBAAoBA,aAAY,KAAK,SAAS,QAAQ,KAAK,eAAe;AAChF,eAAO,KAAK,aAAa,SAAS,kBAAkB,eAAe;;AAGrE,YAAM,UAAU,MAAM,SAAS,KAAI,EAAG,MAAM,CAAC,MAAM,YAAY,CAAC,EAAE,OAAO;AACzE,YAAM,UAAU,SAAS,OAAO;AAChC,YAAM,aAAa,UAAU,SAAY;AACzC,YAAM,eAAe,mBAAmB,kCAAkC;AAE1E,YAAM,oBAAoB,YAAY,KAAK,SAAS,QAAQ,KAAK,iBAAiB,UAAU;AAE5F,YAAM,MAAM,KAAK,gBAAgB,SAAS,QAAQ,SAAS,YAAY,eAAe;AACtF,YAAM;;AAGR,WAAO,EAAE,UAAU,SAAS,WAAU;EACxC;EAEA,eACED,OACA,SAA4B;AAE5B,UAAM,UAAU,KAAK,YAAY,SAAS,IAAI;AAC9C,WAAO,IAAI,YAA6B,MAAM,SAASA,KAAI;EAC7D;EAEA,SAAcF,OAAc,OAA6B;AACvD,UAAM,MACJ,cAAcA,KAAI,IAChB,IAAI,IAAIA,KAAI,IACZ,IAAI,IAAI,KAAK,WAAW,KAAK,QAAQ,SAAS,GAAG,KAAKA,MAAK,WAAW,GAAG,IAAIA,MAAK,MAAM,CAAC,IAAIA,MAAK;AAEtG,UAAM,eAAe,KAAK,aAAY;AACtC,QAAI,CAAC,WAAW,YAAY,GAAG;AAC7B,cAAQ,EAAE,GAAG,cAAc,GAAG,MAAK;;AAGrC,QAAI,OAAO,UAAU,YAAY,SAAS,CAAC,MAAM,QAAQ,KAAK,GAAG;AAC/D,UAAI,SAAS,KAAK,eAAe,KAAgC;;AAGnE,WAAO,IAAI,SAAQ;EACrB;EAEU,eAAe,OAA8B;AACrD,WAAO,OAAO,QAAQ,KAAK,EACxB,OAAO,CAAC,CAAC,GAAG,KAAK,MAAM,OAAO,UAAU,WAAW,EACnD,IAAI,CAAC,CAAC,KAAK,KAAK,MAAK;AACpB,UAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;AACxF,eAAO,GAAG,mBAAmB,GAAG,CAAC,IAAI,mBAAmB,KAAK,CAAC;;AAEhE,UAAI,UAAU,MAAM;AAClB,eAAO,GAAG,mBAAmB,GAAG,CAAC;;AAEnC,YAAM,IAAI,YACR,yBAAyB,OAAO,KAAK,mQAAmQ;IAE5S,CAAC,EACA,KAAK,GAAG;EACb;EAEA,MAAM,iBACJ,KACA,MACA,IACA,YAA2B;AAE3B,UAAM,EAAE,QAAQ,GAAG,QAAO,IAAK,QAAQ,CAAA;AACvC,QAAI;AAAQ,aAAO,iBAAiB,SAAS,MAAM,WAAW,MAAK,CAAE;AAErE,UAAM,UAAU,WAAW,MAAM,WAAW,MAAK,GAAI,EAAE;AAEvD,WACE,KAAK,iBAAgB,EAElB,MAAM,KAAK,QAAW,KAAK,EAAE,QAAQ,WAAW,QAAe,GAAG,QAAO,CAAE,EAC3E,QAAQ,MAAK;AACZ,mBAAa,OAAO;IACtB,CAAC;EAEP;EAEU,mBAAgB;AACxB,WAAO,EAAE,OAAO,KAAK,MAAK;EAC5B;EAEQ,YAAY,UAAkB;AAEpC,UAAM,oBAAoB,SAAS,QAAQ,IAAI,gBAAgB;AAG/D,QAAI,sBAAsB;AAAQ,aAAO;AACzC,QAAI,sBAAsB;AAAS,aAAO;AAG1C,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,WAAW;AAAK,aAAO;AAGpC,QAAI,SAAS,UAAU;AAAK,aAAO;AAEnC,WAAO;EACT;EAEQ,MAAM,aACZ,SACA,kBACA,iBAAqC;AAErC,QAAI;AAGJ,UAAM,yBAAyB,kBAAkB,gBAAgB;AACjE,QAAI,wBAAwB;AAC1B,YAAM,YAAY,WAAW,sBAAsB;AACnD,UAAI,CAAC,OAAO,MAAM,SAAS,GAAG;AAC5B,wBAAgB;;;AAKpB,UAAM,mBAAmB,kBAAkB,aAAa;AACxD,QAAI,oBAAoB,CAAC,eAAe;AACtC,YAAM,iBAAiB,WAAW,gBAAgB;AAClD,UAAI,CAAC,OAAO,MAAM,cAAc,GAAG;AACjC,wBAAgB,iBAAiB;aAC5B;AACL,wBAAgB,KAAK,MAAM,gBAAgB,IAAI,KAAK,IAAG;;;AAM3D,QAAI,EAAE,iBAAiB,KAAK,iBAAiB,gBAAgB,KAAK,MAAO;AACvE,YAAM,aAAa,QAAQ,cAAc,KAAK;AAC9C,sBAAgB,KAAK,mCAAmC,kBAAkB,UAAU;;AAEtF,UAAM,MAAM,aAAa;AAEzB,WAAO,KAAK,YAAY,SAAS,mBAAmB,CAAC;EACvD;EAEQ,mCAAmC,kBAA0B,YAAkB;AACrF,UAAM,oBAAoB;AAC1B,UAAM,gBAAgB;AAEtB,UAAM,aAAa,aAAa;AAGhC,UAAM,eAAe,KAAK,IAAI,oBAAoB,KAAK,IAAI,GAAG,UAAU,GAAG,aAAa;AAGxF,UAAM,SAAS,IAAI,KAAK,OAAM,IAAK;AAEnC,WAAO,eAAe,SAAS;EACjC;EAEQ,eAAY;AAClB,WAAO,GAAG,KAAK,YAAY,IAAI,OAAO,OAAO;EAC/C;;AAKI,IAAgB,eAAhB,MAA4B;EAOhC,YAAY,QAAmB,UAAoB,MAAe,SAA4B;AAN9F,yBAAA,IAAA,MAAA,MAAA;AAOE,IAAAI,wBAAA,MAAI,sBAAW,QAAM,GAAA;AACrB,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,OAAO;EACd;EAUA,cAAW;AACT,UAAM,QAAQ,KAAK,kBAAiB;AACpC,QAAI,CAAC,MAAM;AAAQ,aAAO;AAC1B,WAAO,KAAK,aAAY,KAAM;EAChC;EAEA,MAAM,cAAW;AACf,UAAM,WAAW,KAAK,aAAY;AAClC,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YACR,uFAAuF;;AAG3F,UAAM,cAAc,EAAE,GAAG,KAAK,QAAO;AACrC,QAAI,YAAY,YAAY,OAAO,YAAY,UAAU,UAAU;AACjE,kBAAY,QAAQ,EAAE,GAAG,YAAY,OAAO,GAAG,SAAS,OAAM;eACrD,SAAS,UAAU;AAC5B,YAAM,SAAS,CAAC,GAAG,OAAO,QAAQ,YAAY,SAAS,CAAA,CAAE,GAAG,GAAG,SAAS,IAAI,aAAa,QAAO,CAAE;AAClG,iBAAW,CAAC,KAAK,KAAK,KAAK,QAAQ;AACjC,iBAAS,IAAI,aAAa,IAAI,KAAK,KAAY;;AAEjD,kBAAY,QAAQ;AACpB,kBAAY,OAAO,SAAS,IAAI,SAAQ;;AAE1C,WAAO,MAAMC,wBAAA,MAAI,sBAAA,GAAA,EAAS,eAAe,KAAK,aAAoB,WAAW;EAC/E;EAEA,OAAO,YAAS;AAEd,QAAI,OAAa;AACjB,UAAM;AACN,WAAO,KAAK,YAAW,GAAI;AACzB,aAAO,MAAM,KAAK,YAAW;AAC7B,YAAM;;EAEV;EAEA,SAAO,uBAAA,oBAAA,QAAA,GAAC,OAAO,cAAa,IAAC;AAC3B,qBAAiB,QAAQ,KAAK,UAAS,GAAI;AACzC,iBAAW,QAAQ,KAAK,kBAAiB,GAAI;AAC3C,cAAM;;;EAGZ;;AAYI,IAAO,cAAP,cAII,WAAqB;EAG7B,YACE,QACA,SACAH,OAA4E;AAE5E,UACE,SACA,OAAO,UACL,IAAIA,MACF,QACA,MAAM,UACN,MAAM,qBAAqB,KAAK,GAChC,MAAM,OAAO,CACc;EAEnC;;;;;;;;EASA,QAAQ,OAAO,aAAa,IAAC;AAC3B,UAAM,OAAO,MAAM;AACnB,qBAAiB,QAAQ,MAAM;AAC7B,YAAM;;EAEV;;AAGK,IAAM,wBAAwB,CACnC,YAC0B;AAC1B,SAAO,IAAI,MACT,OAAO;;IAEL,QAAQ,QAAO;EAAE,GAEnB;IACE,IAAI,QAAQ,MAAI;AACd,YAAM,MAAM,KAAK,SAAQ;AACzB,aAAO,OAAO,IAAI,YAAW,CAAE,KAAK,OAAO,GAAG;IAChD;GACD;AAEL;AAiCA,IAAM,qBAA+C;EACnD,QAAQ;EACR,MAAM;EACN,OAAO;EACP,MAAM;EACN,SAAS;EAET,YAAY;EACZ,QAAQ;EACR,SAAS;EACT,WAAW;EACX,QAAQ;EACR,gBAAgB;EAEhB,iBAAiB;EACjB,kBAAkB;EAClB,eAAe;;AAGV,IAAM,mBAAmB,CAAC,QAAuC;AACtE,SACE,OAAO,QAAQ,YACf,QAAQ,QACR,CAAC,WAAW,GAAG,KACf,OAAO,KAAK,GAAG,EAAE,MAAM,CAAC,MAAM,OAAO,oBAAoB,CAAC,CAAC;AAE/D;AA8BA,IAAM,wBAAwB,MAAyB;AACrD,MAAI,OAAO,SAAS,eAAe,KAAK,SAAS,MAAM;AACrD,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,KAAK,MAAM,EAAE;MACjD,oBAAoB,cAAc,KAAK,MAAM,IAAI;MACjD,uBAAuB;MACvB,+BACE,OAAO,KAAK,YAAY,WAAW,KAAK,UAAU,KAAK,SAAS,QAAQ;;;AAG9E,MAAI,OAAO,gBAAgB,aAAa;AACtC,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB,SAAS,WAAW;MACxC,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,MAAI,OAAO,UAAU,SAAS,KAAK,OAAO,YAAY,cAAc,UAAU,CAAC,MAAM,oBAAoB;AACvG,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB,kBAAkB,QAAQ,QAAQ;MACpD,oBAAoB,cAAc,QAAQ,IAAI;MAC9C,uBAAuB;MACvB,+BAA+B,QAAQ;;;AAI3C,QAAM,cAAc,eAAc;AAClC,MAAI,aAAa;AACf,WAAO;MACL,oBAAoB;MACpB,+BAA+B;MAC/B,kBAAkB;MAClB,oBAAoB;MACpB,uBAAuB,WAAW,YAAY,OAAO;MACrD,+BAA+B,YAAY;;;AAK/C,SAAO;IACL,oBAAoB;IACpB,+BAA+B;IAC/B,kBAAkB;IAClB,oBAAoB;IACpB,uBAAuB;IACvB,+BAA+B;;AAEnC;AAUA,SAAS,iBAAc;AACrB,MAAI,OAAO,cAAc,eAAe,CAAC,WAAW;AAClD,WAAO;;AAIT,QAAM,kBAAkB;IACtB,EAAE,KAAK,QAAiB,SAAS,uCAAsC;IACvE,EAAE,KAAK,MAAe,SAAS,uCAAsC;IACrE,EAAE,KAAK,MAAe,SAAS,6CAA4C;IAC3E,EAAE,KAAK,UAAmB,SAAS,yCAAwC;IAC3E,EAAE,KAAK,WAAoB,SAAS,0CAAyC;IAC7E,EAAE,KAAK,UAAmB,SAAS,oEAAmE;;AAIxG,aAAW,EAAE,KAAK,QAAO,KAAM,iBAAiB;AAC9C,UAAM,QAAQ,QAAQ,KAAK,UAAU,SAAS;AAC9C,QAAI,OAAO;AACT,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAC1B,YAAM,QAAQ,MAAM,CAAC,KAAK;AAE1B,aAAO,EAAE,SAAS,KAAK,SAAS,GAAG,KAAK,IAAI,KAAK,IAAI,KAAK,GAAE;;;AAIhE,SAAO;AACT;AAEA,IAAM,gBAAgB,CAAC,SAAsB;AAK3C,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,YAAY,SAAS;AAAO,WAAO;AAChD,MAAI,SAAS;AAAO,WAAO;AAC3B,MAAI,SAAS,aAAa,SAAS;AAAS,WAAO;AACnD,MAAI;AAAM,WAAO,SAAS,IAAI;AAC9B,SAAO;AACT;AAEA,IAAM,oBAAoB,CAAC,aAAkC;AAO3D,aAAW,SAAS,YAAW;AAM/B,MAAI,SAAS,SAAS,KAAK;AAAG,WAAO;AACrC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAU,WAAO;AAClC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAW,WAAO;AACnC,MAAI,aAAa;AAAS,WAAO;AACjC,MAAI;AAAU,WAAO,SAAS,QAAQ;AACtC,SAAO;AACT;AAEA,IAAI;AACJ,IAAM,qBAAqB,MAAK;AAC9B,SAAQ,qBAAA,mBAAqB,sBAAqB;AACpD;AAEO,IAAM,WAAW,CAAC,SAAgB;AACvC,MAAI;AACF,WAAO,KAAK,MAAM,IAAI;WACf,KAAK;AACZ,WAAO;;AAEX;AAGA,IAAM,yBAAyB,IAAI,OAAO,mBAAmB,GAAG;AAChE,IAAM,gBAAgB,CAAC,QAAwB;AAC7C,SAAO,uBAAuB,KAAK,GAAG;AACxC;AAEO,IAAM,QAAQ,CAAC,OAAe,IAAI,QAAQ,CAAC,YAAY,WAAW,SAAS,EAAE,CAAC;AAErF,IAAM,0BAA0B,CAAC,MAAc,MAAsB;AACnE,MAAI,OAAO,MAAM,YAAY,CAAC,OAAO,UAAU,CAAC,GAAG;AACjD,UAAM,IAAI,YAAY,GAAG,IAAI,qBAAqB;;AAEpD,MAAI,IAAI,GAAG;AACT,UAAM,IAAI,YAAY,GAAG,IAAI,6BAA6B;;AAE5D,SAAO;AACT;AAEO,IAAM,cAAc,CAAC,QAAmB;AAC7C,MAAI,eAAe;AAAO,WAAO;AACjC,MAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;AAC3C,QAAI;AACF,aAAO,IAAI,MAAM,KAAK,UAAU,GAAG,CAAC;YAC9B;IAAA;;AAEV,SAAO,IAAI,MAAM,GAAG;AACtB;AAcO,IAAM,UAAU,CAACI,SAAmC;AACzD,MAAI,OAAO,YAAY,aAAa;AAClC,WAAO,QAAQ,MAAMA,IAAG,GAAG,KAAI,KAAM;;AAEvC,MAAI,OAAO,SAAS,aAAa;AAC/B,WAAO,KAAK,KAAK,MAAMA,IAAG,GAAG,KAAI;;AAEnC,SAAO;AACT;AA4CM,SAAU,WAAW,KAA8B;AACvD,MAAI,CAAC;AAAK,WAAO;AACjB,aAAW,MAAM;AAAK,WAAO;AAC7B,SAAO;AACT;AAGM,SAAU,OAAO,KAAa,KAAW;AAC7C,SAAO,OAAO,UAAU,eAAe,KAAK,KAAK,GAAG;AACtD;AAQA,SAAS,gBAAgB,eAAwB,YAAmB;AAClE,aAAW,KAAK,YAAY;AAC1B,QAAI,CAAC,OAAO,YAAY,CAAC;AAAG;AAC5B,UAAM,WAAW,EAAE,YAAW;AAC9B,QAAI,CAAC;AAAU;AAEf,UAAM,MAAM,WAAW,CAAC;AAExB,QAAI,QAAQ,MAAM;AAChB,aAAO,cAAc,QAAQ;eACpB,QAAQ,QAAW;AAC5B,oBAAc,QAAQ,IAAI;;;AAGhC;AAEM,SAAU,MAAM,WAAmB,MAAW;AAClD,MAAI,OAAO,YAAY,eAAe,SAAS,MAAM,OAAO,MAAM,QAAQ;AACxE,YAAQ,IAAI,gBAAgB,MAAM,IAAI,GAAG,IAAI;;AAEjD;AAKA,IAAM,QAAQ,MAAK;AACjB,SAAO,uCAAuC,QAAQ,SAAS,CAAC,MAAK;AACnE,UAAM,IAAK,KAAK,OAAM,IAAK,KAAM;AACjC,UAAM,IAAI,MAAM,MAAM,IAAK,IAAI,IAAO;AACtC,WAAO,EAAE,SAAS,EAAE;EACtB,CAAC;AACH;AAEO,IAAM,qBAAqB,MAAK;AACrC;;IAEE,OAAO,WAAW;IAElB,OAAO,OAAO,aAAa;IAE3B,OAAO,cAAc;;AAEzB;AAOO,IAAM,oBAAoB,CAAC,YAA4C;AAC5E,SAAO,OAAO,SAAS,QAAQ;AACjC;AAUO,IAAM,YAAY,CAAC,SAAgC,WAAsC;AAC9F,QAAM,mBAAmB,OAAO,YAAW;AAC3C,MAAI,kBAAkB,OAAO,GAAG;AAE9B,UAAM,kBACJ,OAAO,CAAC,GAAG,YAAW,IACtB,OAAO,UAAU,CAAC,EAAE,QAAQ,gBAAgB,CAAC,IAAI,IAAI,OAAO,KAAK,GAAG,YAAW,CAAE;AACnF,eAAW,OAAO,CAAC,QAAQ,kBAAkB,OAAO,YAAW,GAAI,eAAe,GAAG;AACnF,YAAM,QAAQ,QAAQ,IAAI,GAAG;AAC7B,UAAI,OAAO;AACT,eAAO;;;;AAKb,aAAW,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,OAAO,GAAG;AAClD,QAAI,IAAI,YAAW,MAAO,kBAAkB;AAC1C,UAAI,MAAM,QAAQ,KAAK,GAAG;AACxB,YAAI,MAAM,UAAU;AAAG,iBAAO,MAAM,CAAC;AACrC,gBAAQ,KAAK,YAAY,MAAM,MAAM,oBAAoB,MAAM,iCAAiC;AAChG,eAAO,MAAM,CAAC;;AAEhB,aAAO;;;AAIX,SAAO;AACT;AAkBM,SAAU,MAAM,KAAY;AAChC,SAAO,OAAO,QAAQ,OAAO,QAAQ,YAAY,CAAC,MAAM,QAAQ,GAAG;AACrE;;;ACzsCM,IAAOC,QAAP,cAA0B,aAAkB;EAKhD,YAAY,QAAmB,UAAoB,MAA0B,SAA4B;AACvG,UAAM,QAAQ,UAAU,MAAM,OAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;AACzB,SAAK,SAAS,KAAK;EACrB;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;;;;;;EAOA,iBAAc;AACZ,WAAO;EACT;EAEA,eAAY;AACV,WAAO;EACT;;AAaI,IAAO,aAAP,cACI,aAAkB;EAK1B,YACE,QACA,UACA,MACA,SAA4B;AAE5B,UAAM,QAAQ,UAAU,MAAM,OAAO;AAErC,SAAK,OAAO,KAAK,QAAQ,CAAA;EAC3B;EAEA,oBAAiB;AACf,WAAO,KAAK,QAAQ,CAAA;EACtB;;EAGA,iBAAc;AACZ,UAAM,OAAO,KAAK,aAAY;AAC9B,QAAI,CAAC;AAAM,aAAO;AAClB,QAAI,YAAY;AAAM,aAAO,KAAK;AAClC,UAAM,SAAS,OAAO,YAAY,KAAK,IAAI,YAAY;AACvD,QAAI,CAAC,OAAO,KAAK,MAAM,EAAE;AAAQ,aAAO;AACxC,WAAO;EACT;EAEA,eAAY;AACV,UAAM,OAAO,KAAK,kBAAiB;AACnC,QAAI,CAAC,KAAK,QAAQ;AAChB,aAAO;;AAGT,UAAM,KAAK,KAAK,KAAK,SAAS,CAAC,GAAG;AAClC,QAAI,CAAC,IAAI;AACP,aAAO;;AAGT,WAAO,EAAE,QAAQ,EAAE,OAAO,GAAE,EAAE;EAChC;;;;AC5FI,IAAO,cAAP,MAAkB;EAGtB,YAAY,QAAc;AACxB,SAAK,UAAU;EACjB;;;;ACEI,IAAO,cAAP,cAA2B,YAAW;EAmB1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAG,SAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAGlG;;;;ACII,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EACvF;;AAsCA,KAAK,cAAc;;;AC3Eb,IAAO,SAAP,cAAsB,YAAW;;;;EAIrC,OAAO,MAA0B,SAA6B;AAC5D,WAAO,KAAK,QAAQ,KAAK,iBAAiB,EAAE,MAAM,GAAG,SAAS,kBAAkB,KAAI,CAAE;EACxF;;;;ACNI,IAAO,iBAAP,cAA8B,YAAW;EAiB7C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,yBAA8B,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAC1G;;;;ACrBI,IAAO,eAAP,cAA4B,YAAW;EAiB3C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,uBAA4B,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACxG;;;;ACLI,IAAO,QAAP,cAAqB,YAAW;EAAtC,cAAA;;AACE,SAAA,iBAAmD,IAAsB,eAAe,KAAK,OAAO;AACpG,SAAA,eAA6C,IAAoB,aAAa,KAAK,OAAO;AAC1F,SAAA,SAA2B,IAAc,OAAO,KAAK,OAAO;EAC9D;;AAUA,MAAM,iBAAiB;AACvB,MAAM,eAAe;AACrB,MAAM,SAAS;;;AChCT,IAAO,UAAP,cAAuB,YAAW;;;;EAItC,OAAO,MAAyB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,KAAK,YAAY,EAAE,MAAM,GAAG,QAAO,CAAE;EAC3D;;;;EAKA,SAAS,SAAiB,SAA6B;AACrD,WAAO,KAAK,QAAQ,IAAI,YAAY,OAAO,IAAI,OAAO;EACxD;EAOA,KACE,QAA+C,CAAA,GAC/C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,YAAY,aAAa,EAAE,OAAO,GAAG,QAAO,CAAE;EAC/E;;;;;;EAOA,OAAO,SAAiB,SAA6B;AACnD,WAAO,KAAK,QAAQ,KAAK,YAAY,OAAO,WAAW,OAAO;EAChE;;AAGI,IAAO,cAAP,cAA2B,WAAiB;;AAsMlD,QAAQ,cAAc;;;ACxOhB,IAAO,aAAP,cAA0B,YAAW;;;;EAIzC,OAAO,MAA6B,SAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,eAAe;MACtC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,aAAqB,SAA6B;AACzD,WAAO,KAAK,QAAQ,IAAI,eAAe,WAAW,IAAI;MACpD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,aACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,WAAW,IAAI;MACrD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAUA,KACE,QAAmD,CAAA,GACnD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,eAAe,gBAAgB;MAC5D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,aAAqB,SAA6B;AACpD,WAAO,KAAK,QAAQ,OAAO,eAAe,WAAW,IAAI;MACvD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,iBAAP,cAA8B,WAAqB;;AAiyCzD,WAAW,iBAAiB;;;ACtyCtB,SAAU,4BACd,IAAO;AAEP,SAAO,OAAQ,GAAW,UAAU;AACtC;;;AC5EO,IAAM,qBAAqB,CAChC,YACkD;AAClD,SAAO,SAAS,SAAS;AAC3B;AAEO,IAAM,oBAAoB,CAC/B,YACiD;AACjD,SAAO,SAAS,SAAS;AAC3B;AAEO,IAAM,gBAAgB,CAC3B,YAC6C;AAC7C,SAAO,SAAS,SAAS;AAC3B;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrBM,IAAO,cAAP,MAAkB;EAoBtB,cAAA;;AAnBA,SAAA,aAA8B,IAAI,gBAAe;AAEjD,kCAAA,IAAA,MAAA,MAAA;AACA,yCAAA,IAAA,MAAuC,MAAK;IAAE,CAAC;AAC/C,wCAAA,IAAA,MAAwD,MAAK;IAAE,CAAC;AAEhE,4BAAA,IAAA,MAAA,MAAA;AACA,mCAAA,IAAA,MAAiC,MAAK;IAAE,CAAC;AACzC,kCAAA,IAAA,MAAkD,MAAK;IAAE,CAAC;AAE1D,2BAAA,IAAA,MAEI,CAAA,CAAE;AAEN,uBAAA,IAAA,MAAS,KAAK;AACd,yBAAA,IAAA,MAAW,KAAK;AAChB,yBAAA,IAAA,MAAW,KAAK;AAChB,wCAAA,IAAA,MAA0B,KAAK;AAG7B,IAAAC,wBAAA,MAAI,+BAAqB,IAAI,QAAc,CAAC,SAAS,WAAU;AAC7D,MAAAA,wBAAA,MAAI,sCAA4B,SAAO,GAAA;AACvC,MAAAA,wBAAA,MAAI,qCAA2B,QAAM,GAAA;IACvC,CAAC,GAAC,GAAA;AAEF,IAAAA,wBAAA,MAAI,yBAAe,IAAI,QAAc,CAAC,SAAS,WAAU;AACvD,MAAAA,wBAAA,MAAI,gCAAsB,SAAO,GAAA;AACjC,MAAAA,wBAAA,MAAI,+BAAqB,QAAM,GAAA;IACjC,CAAC,GAAC,GAAA;AAMF,IAAAC,wBAAA,MAAI,+BAAA,GAAA,EAAmB,MAAM,MAAK;IAAE,CAAC;AACrC,IAAAA,wBAAA,MAAI,yBAAA,GAAA,EAAa,MAAM,MAAK;IAAE,CAAC;EACjC;EAEU,KAAoC,UAA4B;AAGxE,eAAW,MAAK;AACd,eAAQ,EAAG,KAAK,MAAK;AACnB,aAAK,WAAU;AACf,aAAK,MAAM,KAAK;MAClB,GAAGA,wBAAA,MAAI,wBAAA,KAAA,wBAAA,EAAc,KAAK,IAAI,CAAC;IACjC,GAAG,CAAC;EACN;EAEU,aAAU;AAClB,QAAI,KAAK;AAAO;AAChB,IAAAA,wBAAA,MAAI,sCAAA,GAAA,EAAyB,KAA7B,IAAI;AACJ,SAAK,MAAM,SAAS;EACtB;EAEA,IAAI,QAAK;AACP,WAAOA,wBAAA,MAAI,oBAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,sBAAA,GAAA;EACb;EAEA,IAAI,UAAO;AACT,WAAOA,wBAAA,MAAI,sBAAA,GAAA;EACb;EAEA,QAAK;AACH,SAAK,WAAW,MAAK;EACvB;;;;;;;;EASA,GAAmC,OAAc,UAA0C;AACzF,UAAM,YACJA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,SAAQ,CAAE;AAC3B,WAAO;EACT;;;;;;;;EASA,IAAoC,OAAc,UAA0C;AAC1F,UAAM,YAAYA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK;AACvC,QAAI,CAAC;AAAW,aAAO;AACvB,UAAM,QAAQ,UAAU,UAAU,CAAC,MAAM,EAAE,aAAa,QAAQ;AAChE,QAAI,SAAS;AAAG,gBAAU,OAAO,OAAO,CAAC;AACzC,WAAO;EACT;;;;;;EAOA,KAAqC,OAAc,UAA0C;AAC3F,UAAM,YACJA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,MAAMA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,IAAI,CAAA;AACtD,cAAU,KAAK,EAAE,UAAU,MAAM,KAAI,CAAE;AACvC,WAAO;EACT;;;;;;;;;;;;EAaA,QACE,OAAY;AAMZ,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAU;AACrC,MAAAD,wBAAA,MAAI,qCAA2B,MAAI,GAAA;AACnC,UAAI,UAAU;AAAS,aAAK,KAAK,SAAS,MAAM;AAChD,WAAK,KAAK,OAAO,OAAc;IACjC,CAAC;EACH;EAEA,MAAM,OAAI;AACR,IAAAA,wBAAA,MAAI,qCAA2B,MAAI,GAAA;AACnC,UAAMC,wBAAA,MAAI,yBAAA,GAAA;EACZ;EAyBA,MAEE,UACG,MAAwC;AAG3C,QAAIA,wBAAA,MAAI,oBAAA,GAAA,GAAS;AACf;;AAGF,QAAI,UAAU,OAAO;AACnB,MAAAD,wBAAA,MAAI,oBAAU,MAAI,GAAA;AAClB,MAAAC,wBAAA,MAAI,gCAAA,GAAA,EAAmB,KAAvB,IAAI;;AAGN,UAAM,YAA2DA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK;AACtF,QAAI,WAAW;AACb,MAAAA,wBAAA,MAAI,wBAAA,GAAA,EAAY,KAAK,IAAI,UAAU,OAAO,CAAC,MAAM,CAAC,EAAE,IAAI;AACxD,gBAAU,QAAQ,CAAC,EAAE,SAAQ,MAAY,SAAS,GAAI,IAAY,CAAC;;AAGrE,QAAI,UAAU,SAAS;AACrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,qCAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AACvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,qCAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,+BAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;AAChB;;AAGF,QAAI,UAAU,SAAS;AAGrB,YAAM,QAAQ,KAAK,CAAC;AACpB,UAAI,CAACA,wBAAA,MAAI,qCAAA,GAAA,KAA4B,CAAC,WAAW,QAAQ;AAOvD,gBAAQ,OAAO,KAAK;;AAEtB,MAAAA,wBAAA,MAAI,qCAAA,GAAA,EAAwB,KAA5B,MAA6B,KAAK;AAClC,MAAAA,wBAAA,MAAI,+BAAA,GAAA,EAAkB,KAAtB,MAAuB,KAAK;AAC5B,WAAK,MAAM,KAAK;;EAEpB;EAEU,aAAU;EAAU;;qxBA1Ec,OAAc;AACxD,EAAAD,wBAAA,MAAI,sBAAY,MAAI,GAAA;AACpB,MAAI,iBAAiB,SAAS,MAAM,SAAS,cAAc;AACzD,YAAQ,IAAI,kBAAiB;;AAE/B,MAAI,iBAAiB,mBAAmB;AACtC,IAAAA,wBAAA,MAAI,sBAAY,MAAI,GAAA;AACpB,WAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,MAAI,iBAAiB,aAAa;AAChC,WAAO,KAAK,MAAM,SAAS,KAAK;;AAElC,MAAI,iBAAiB,OAAO;AAC1B,UAAM,cAA2B,IAAI,YAAY,MAAM,OAAO;AAE9D,gBAAY,QAAQ;AACpB,WAAO,KAAK,MAAM,SAAS,WAAW;;AAExC,SAAO,KAAK,MAAM,SAAS,IAAI,YAAY,OAAO,KAAK,CAAC,CAAC;AAC3D;;;AC/GI,SAAU,6BACd,iBAAoB;AAEpB,SAAO,kBAAkB,QAAQ,MAAM;AACzC;AAmDM,SAAU,mBAAmB,MAAS;AAC1C,SAAO,OAAO,QAAQ,MAAM;AAC9B;AAEM,SAAU,yBAGd,YAA4B,QAAc;AAC1C,MAAI,CAAC,UAAU,CAAC,sBAAsB,MAAM,GAAG;AAC7C,WAAO;MACL,GAAG;MACH,SAAS,WAAW,QAAQ,IAAI,CAAC,YAAY;QAC3C,GAAG;QACH,SAAS,EAAE,GAAG,OAAO,SAAS,QAAQ,MAAM,YAAY,OAAO,QAAQ,cAAc,CAAA,EAAE;QACvF;;;AAIN,SAAO,oBAAoB,YAAY,MAAM;AAC/C;AAEM,SAAU,oBAGd,YAA4B,QAAc;AAC1C,QAAM,UAAwC,WAAW,QAAQ,IAAI,CAAC,WAAiC;AACrG,QAAI,OAAO,kBAAkB,UAAU;AACrC,YAAM,IAAI,wBAAuB;;AAGnC,QAAI,OAAO,kBAAkB,kBAAkB;AAC7C,YAAM,IAAI,+BAA8B;;AAG1C,WAAO;MACL,GAAG;MACH,SAAS;QACP,GAAG,OAAO;QACV,YAAY,OAAO,QAAQ,YAAY,IAAI,CAAC,aAAa,cAAc,QAAQ,QAAQ,CAAC,KAAK,CAAA;QAC7F,QACE,OAAO,QAAQ,WAAW,CAAC,OAAO,QAAQ,UACxC,oBAAoB,QAAQ,OAAO,QAAQ,OAAO,IAClD;;;EAGV,CAAC;AAED,SAAO,EAAE,GAAG,YAAY,QAAO;AACjC;AAEA,SAAS,oBAGP,QAAgB,SAAe;AAC/B,MAAI,OAAO,iBAAiB,SAAS,eAAe;AAClD,WAAO;;AAGT,MAAI,OAAO,iBAAiB,SAAS,eAAe;AAClD,QAAI,eAAe,OAAO,iBAAiB;AACzC,YAAM,kBAAkB,OAAO;AAE/B,aAAO,gBAAgB,UAAU,OAAO;;AAG1C,WAAO,KAAK,MAAM,OAAO;;AAG3B,SAAO;AACT;AAEA,SAAS,cACP,QACA,UAAuC;AAEvC,QAAM,YAAY,OAAO,OAAO,KAAK,CAACE,eAAcA,WAAU,UAAU,SAAS,SAAS,SAAS,IAAI;AACvG,SAAO;IACL,GAAG;IACH,UAAU;MACR,GAAG,SAAS;MACZ,kBACE,mBAAmB,SAAS,IAAI,UAAU,UAAU,SAAS,SAAS,SAAS,IAC7E,WAAW,SAAS,SAAS,KAAK,MAAM,SAAS,SAAS,SAAS,IACnE;;;AAGV;AAEM,SAAU,oBACd,QACA,UAAuC;AAEvC,MAAI,CAAC,QAAQ;AACX,WAAO;;AAGT,QAAM,YAAY,OAAO,OAAO,KAAK,CAACA,eAAcA,WAAU,UAAU,SAAS,SAAS,SAAS,IAAI;AACvG,SAAO,mBAAmB,SAAS,KAAK,WAAW,SAAS,UAAU;AACxE;AAEM,SAAU,sBAAsB,QAAqC;AACzE,MAAI,6BAA6B,OAAO,eAAe,GAAG;AACxD,WAAO;;AAGT,SACE,OAAO,OAAO,KACZ,CAAC,MAAM,mBAAmB,CAAC,KAAM,EAAE,SAAS,cAAc,EAAE,SAAS,WAAW,IAAK,KAClF;AAET;AAEM,SAAU,mBAAmB,OAAuC;AACxE,aAAW,QAAQ,SAAS,CAAA,GAAI;AAC9B,QAAI,KAAK,SAAS,YAAY;AAC5B,YAAM,IAAI,YACR,2EAA2E,KAAK,IAAI,IAAI;;AAI5F,QAAI,KAAK,SAAS,WAAW,MAAM;AACjC,YAAM,IAAI,YACR,SAAS,KAAK,SAAS,IAAI,4FAA4F;;;AAI/H;;;;;;;;;;;;;;;;AC/MA,IAAM,+BAA+B;AAM/B,IAAO,+BAAP,cAGI,YAAuB;EAHjC,cAAA;;;AAIY,SAAA,mBAAoD,CAAA;AAC9D,SAAA,WAAyC,CAAA;EAmc3C;EAjcY,mBAER,gBAA6C;AAE7C,SAAK,iBAAiB,KAAK,cAAc;AACzC,SAAK,MAAM,kBAAkB,cAAc;AAC3C,UAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,QAAI;AAAS,WAAK,YAAY,OAAqC;AACnE,WAAO;EACT;EAEU,YAER,SACA,OAAO,MAAI;AAEX,QAAI,EAAE,aAAa;AAAU,cAAQ,UAAU;AAE/C,SAAK,SAAS,KAAK,OAAO;AAE1B,QAAI,MAAM;AACR,WAAK,MAAM,WAAW,OAAO;AAC7B,WAAK,kBAAkB,OAAO,KAAK,cAAc,OAAO,MAAM,QAAQ,SAAS;AAE7E,aAAK,MAAM,sBAAsB,QAAQ,OAAiB;iBACjD,mBAAmB,OAAO,KAAK,QAAQ,eAAe;AAC/D,aAAK,MAAM,gBAAgB,QAAQ,aAAa;iBACvC,mBAAmB,OAAO,KAAK,QAAQ,YAAY;AAC5D,mBAAW,aAAa,QAAQ,YAAY;AAC1C,cAAI,UAAU,SAAS,YAAY;AACjC,iBAAK,MAAM,gBAAgB,UAAU,QAAQ;;;;;EAKvD;;;;;EAMA,MAAM,sBAAmB;AACvB,UAAM,KAAK,KAAI;AACf,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI,CAAC;AAAY,YAAM,IAAI,YAAY,iDAAiD;AACxF,WAAO;EACT;;;;;EAUA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOC,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EA4BA,MAAM,eAAY;AAChB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;EACb;;;;;EAoBA,MAAM,oBAAiB;AACrB,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;EACb;EAyBA,MAAM,0BAAuB;AAC3B,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;EACb;EAkBA,MAAM,aAAU;AACd,UAAM,KAAK,KAAI;AACf,WAAOA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI;EACb;EAEA,qBAAkB;AAChB,WAAO,CAAC,GAAG,KAAK,gBAAgB;EAClC;EAEmB,aAAU;AAG3B,UAAM,aAAa,KAAK,iBAAiB,KAAK,iBAAiB,SAAS,CAAC;AACzE,QAAI;AAAY,WAAK,MAAM,uBAAuB,UAAU;AAC5D,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AACzD,UAAM,eAAeA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI;AACzB,QAAI;AAAc,WAAK,MAAM,gBAAgB,YAAY;AAEzD,UAAM,oBAAoBA,wBAAA,MAAI,yCAAA,KAAA,kDAAA,EAAsB,KAA1B,IAAI;AAC9B,QAAI;AAAmB,WAAK,MAAM,qBAAqB,iBAAiB;AAExE,UAAM,0BAA0BA,wBAAA,MAAI,yCAAA,KAAA,wDAAA,EAA4B,KAAhC,IAAI;AACpC,QAAI,2BAA2B;AAAM,WAAK,MAAM,2BAA2B,uBAAuB;AAElG,QAAI,KAAK,iBAAiB,KAAK,CAAC,MAAM,EAAE,KAAK,GAAG;AAC9C,WAAK,MAAM,cAAcA,wBAAA,MAAI,yCAAA,KAAA,iDAAA,EAAqB,KAAzB,IAAI,CAAuB;;EAExD;EAUU,MAAM,sBACd,QACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,yCAAA,KAAA,4CAAA,EAAgB,KAApB,MAAqB,MAAM;AAE3B,UAAM,iBAAiB,MAAM,OAAO,KAAK,YAAY,OACnD,EAAE,GAAG,QAAQ,QAAQ,MAAK,GAC1B,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,WAAO,KAAK,mBAAmB,oBAAoB,gBAAgB,MAAM,CAAC;EAC5E;EAEU,MAAM,mBACd,QACA,QACA,SAA6B;AAE7B,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAEjC,WAAO,MAAM,KAAK,sBAAsB,QAAQ,QAAQ,OAAO;EACjE;EAEU,MAAM,cACd,QACA,QAGA,SAAuB;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,gBAAgB,QAAQ,QAAQ,GAAG,WAAU,IAAK;AAC1D,UAAM,uBAAuB,OAAO,kBAAkB,YAAY,eAAe;AACjF,UAAM,EAAE,qBAAqB,6BAA4B,IAAK,WAAW,CAAA;AAEzE,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,OAAO,WAAW;AAChC,sBAAgB,EAAE,QAAQ,EAAE,SAAS,IAAI,IAAI;;AAG/C,UAAM,YAAmD,OAAO,UAAU,IACxE,CAAC,OAA4C;MAC3C,MAAM,EAAE,QAAQ,EAAE,SAAS;MAC3B,YAAY,EAAE;MACd,aAAa,EAAE;MACf;AAGJ,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,QACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7B,OAAO;AAET,YAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ;AAAe;AAC5B,YAAM,EAAE,MAAM,WAAW,KAAI,IAAK,QAAQ;AAC1C,YAAM,KAAK,gBAAgB,IAAI;AAC/B,UAAI,CAAC,IAAI;AACP,cAAMC,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,4BAA4B,UACvF,IAAI,CAAC,MAAM,KAAK,UAAU,EAAE,IAAI,CAAC,EACjC,KAAK,IAAI,CAAC;AAEb,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;iBACS,wBAAwB,yBAAyB,MAAM;AAChE,cAAMA,WAAU,0BAA0B,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UACtE,oBAAoB,CACrB;AAED,aAAK,YAAY,EAAE,MAAM,MAAM,SAAAA,SAAO,CAAE;AACxC;;AAGF,UAAI;AACJ,UAAI;AACF,iBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;eAC3D,OAAO;AACd,aAAK,YAAY;UACf;UACA;UACA,SAAS,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;SAC/D;AACD;;AAIF,YAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,YAAM,UAAUD,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAE5D,WAAK,YAAY,EAAE,MAAM,MAAM,QAAO,CAAE;AAExC,UAAI;AAAsB;;EAE9B;EAEU,MAAM,UACd,QACA,QAGA,SAAuB;AAEvB,UAAM,OAAO;AACb,UAAM,EAAE,cAAc,QAAQ,QAAQ,GAAG,WAAU,IAAK;AACxD,UAAM,uBAAuB,OAAO,gBAAgB,YAAY,aAAa,UAAU;AACvF,UAAM,EAAE,qBAAqB,6BAA4B,IAAK,WAAW,CAAA;AAGzE,UAAM,aAAa,OAAO,MAAM,IAAI,CAAC,SAAmC;AACtE,UAAI,mBAAmB,IAAI,GAAG;AAC5B,YAAI,CAAC,KAAK,WAAW;AACnB,gBAAM,IAAI,YAAY,uEAAuE;;AAG/F,eAAO;UACL,MAAM;UACN,UAAU;YACR,UAAU,KAAK;YACf,MAAM,KAAK,SAAS;YACpB,aAAa,KAAK,SAAS,eAAe;YAC1C,YAAY,KAAK,SAAS;YAC1B,OAAO,KAAK;YACZ,QAAQ;;;;AAKd,aAAO;IACT,CAAC;AAED,UAAM,kBAAyD,CAAA;AAC/D,eAAW,KAAK,YAAY;AAC1B,UAAI,EAAE,SAAS,YAAY;AACzB,wBAAgB,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS,IAAI,IAAI,EAAE;;;AAIrE,UAAM,QACJ,WAAW,SACT,WAAW,IAAI,CAAC,MACd,EAAE,SAAS,aACT;MACE,MAAM;MACN,UAAU;QACR,MAAM,EAAE,SAAS,QAAQ,EAAE,SAAS,SAAS;QAC7C,YAAY,EAAE,SAAS;QACvB,aAAa,EAAE,SAAS;QACxB,QAAQ,EAAE,SAAS;;QAGtB,CAAmC,IAEvC;AAEL,eAAW,WAAW,OAAO,UAAU;AACrC,WAAK,YAAY,SAAS,KAAK;;AAGjC,aAAS,IAAI,GAAG,IAAI,oBAAoB,EAAE,GAAG;AAC3C,YAAM,iBAAiC,MAAM,KAAK,sBAChD,QACA;QACE,GAAG;QACH;QACA;QACA,UAAU,CAAC,GAAG,KAAK,QAAQ;SAE7B,OAAO;AAET,YAAM,UAAU,eAAe,QAAQ,CAAC,GAAG;AAC3C,UAAI,CAAC,SAAS;AACZ,cAAM,IAAI,YAAY,4CAA4C;;AAEpE,UAAI,CAAC,QAAQ,YAAY,QAAQ;AAC/B;;AAGF,iBAAW,aAAa,QAAQ,YAAY;AAC1C,YAAI,UAAU,SAAS;AAAY;AACnC,cAAM,eAAe,UAAU;AAC/B,cAAM,EAAE,MAAM,WAAW,KAAI,IAAK,UAAU;AAC5C,cAAM,KAAK,gBAAgB,IAAI;AAE/B,YAAI,CAAC,IAAI;AACP,gBAAMC,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,4BAA4B,OAAO,KAC3F,eAAe,EAEd,IAAI,CAACC,UAAS,KAAK,UAAUA,KAAI,CAAC,EAClC,KAAK,IAAI,CAAC;AAEb,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAD,SAAO,CAAE;AAChD;mBACS,wBAAwB,yBAAyB,MAAM;AAChE,gBAAMA,WAAU,sBAAsB,KAAK,UAAU,IAAI,CAAC,KAAK,KAAK,UAClE,oBAAoB,CACrB;AAED,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAGF,YAAI;AACJ,YAAI;AACF,mBAAS,4BAA4B,EAAE,IAAI,MAAM,GAAG,MAAM,IAAI,IAAI;iBAC3D,OAAO;AACd,gBAAMA,WAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACrE,eAAK,YAAY,EAAE,MAAM,cAAc,SAAAA,SAAO,CAAE;AAChD;;AAIF,cAAM,aAAa,MAAM,GAAG,SAAS,QAAQ,IAAI;AACjD,cAAM,UAAUD,wBAAA,MAAI,yCAAA,KAAA,yDAAA,EAA6B,KAAjC,MAAkC,UAAU;AAC5D,aAAK,YAAY,EAAE,MAAM,cAAc,QAAO,CAAE;AAEhD,YAAI,sBAAsB;AACxB;;;;AAKN;EACF;;;AAvYE,SAAOA,wBAAA,MAAI,yCAAA,KAAA,6CAAA,EAAiB,KAArB,IAAI,EAAoB,WAAW;AAC5C,GAAC,gDAAA,SAAAG,iDAAA;AAYC,MAAI,IAAI,KAAK,SAAS;AACtB,SAAO,MAAM,GAAG;AACd,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,GAAG;AAC/B,YAAM,EAAE,eAAe,GAAG,KAAI,IAAK;AAGnC,YAAM,MAA4C;QAChD,GAAG;QACH,SAAU,QAAkC,WAAW;QACvD,SAAU,QAAkC,WAAW;;AAEzD,UAAI,eAAe;AACjB,YAAI,gBAAgB;;AAEtB,aAAO;;;AAGX,QAAM,IAAI,YAAY,4EAA4E;AACpG,GAAC,qDAAA,SAAAC,sDAAA;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,mBAAmB,OAAO,KAAK,SAAS,eAAe;AACzD,aAAO,QAAQ;;AAEjB,QAAI,mBAAmB,OAAO,KAAK,SAAS,YAAY,QAAQ;AAC9D,aAAO,QAAQ,WAAW,GAAG,EAAE,GAAG;;;AAItC;AACF,GAAC,2DAAA,SAAAC,4DAAA;AAYC,WAAS,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK,GAAG,KAAK;AAClD,UAAM,UAAU,KAAK,SAAS,CAAC;AAC/B,QAAI,kBAAkB,OAAO,KAAK,QAAQ,WAAW,MAAM;AACzD,aAAO,QAAQ;;AAEjB,QACE,cAAc,OAAO,KACrB,QAAQ,WAAW,QACnB,OAAO,QAAQ,YAAY,YAC3B,KAAK,SAAS,KACZ,CAAC,MACC,EAAE,SAAS,eACX,EAAE,YAAY,KAAK,CAAC,MAAM,EAAE,SAAS,cAAc,EAAE,OAAO,QAAQ,YAAY,CAAC,GAErF;AACA,aAAO,QAAQ;;;AAInB;AACF,GAAC,oDAAA,SAAAC,qDAAA;AAQC,QAAM,QAAyB;IAC7B,mBAAmB;IACnB,eAAe;IACf,cAAc;;AAEhB,aAAW,EAAE,MAAK,KAAM,KAAK,kBAAkB;AAC7C,QAAI,OAAO;AACT,YAAM,qBAAqB,MAAM;AACjC,YAAM,iBAAiB,MAAM;AAC7B,YAAM,gBAAgB,MAAM;;;AAGhC,SAAO;AACT,GAAC,+CAAA,SAAAC,8CAgCe,QAAkC;AAChD,MAAI,OAAO,KAAK,QAAQ,OAAO,IAAI,GAAG;AACpC,UAAM,IAAI,YACR,8HAA8H;;AAGpI,GAAC,4DAAA,SAAAC,2DAuP4B,YAAmB;AAC9C,SACE,OAAO,eAAe,WAAW,aAC/B,eAAe,SAAY,cAC3B,KAAK,UAAU,UAAU;AAE/B;;;ACxcI,IAAO,uBAAP,MAAO,8BAA6C,6BAGzD;;EAEC,OAAO,aACL,QACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,QAAQ,QAAQ,IAAI,CAAC;AAC5D,WAAO;EACT;EAEA,OAAO,SACL,QACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,sBAAoB;AACvC,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,QAAQ,QAAQ,IAAI,CAAC;AACxD,WAAO;EACT;EAES,YAEP,SACA,OAAgB,MAAI;AAEpB,UAAM,YAAY,SAAS,IAAI;AAC/B,QAAI,mBAAmB,OAAO,KAAK,QAAQ,SAAS;AAClD,WAAK,MAAM,WAAW,QAAQ,OAAiB;;EAEnD;;;;AC1EF,IAAM,MAAM;AACZ,IAAM,MAAM;AACZ,IAAM,MAAM;AACZ,IAAM,MAAM;AACZ,IAAM,OAAO;AACb,IAAM,OAAO;AACb,IAAM,MAAM;AACZ,IAAM,WAAW;AACjB,IAAM,iBAAiB;AAEvB,IAAM,MAAM,WAAW;AACvB,IAAM,UAAU,OAAO,OAAO,MAAM;AACpC,IAAM,OAAO,MAAM,MAAM;AACzB,IAAM,aAAa,MAAM;AACzB,IAAM,MAAM,OAAO;AAEnB,IAAM,QAAQ;EACZ;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;AAIF,IAAM,cAAN,cAA0B,MAAK;;AAE/B,IAAM,gBAAN,cAA4B,MAAK;;AAUjC,SAAS,UAAU,YAAoB,eAAuB,MAAM,KAAG;AACrE,MAAI,OAAO,eAAe,UAAU;AAClC,UAAM,IAAI,UAAU,sBAAsB,OAAO,UAAU,EAAE;;AAE/D,MAAI,CAAC,WAAW,KAAI,GAAI;AACtB,UAAM,IAAI,MAAM,GAAG,UAAU,WAAW;;AAE1C,SAAO,WAAW,WAAW,KAAI,GAAI,YAAY;AACnD;AAEA,IAAM,aAAa,CAAC,YAAoB,UAAiB;AACvD,QAAM,SAAS,WAAW;AAC1B,MAAI,QAAQ;AAEZ,QAAM,kBAAkB,CAAC,QAAe;AACtC,UAAM,IAAI,YAAY,GAAG,GAAG,gBAAgB,KAAK,EAAE;EACrD;AAEA,QAAM,sBAAsB,CAAC,QAAe;AAC1C,UAAM,IAAI,cAAc,GAAG,GAAG,gBAAgB,KAAK,EAAE;EACvD;AAEA,QAAM,WAAsB,MAAK;AAC/B,cAAS;AACT,QAAI,SAAS;AAAQ,sBAAgB,yBAAyB;AAC9D,QAAI,WAAW,KAAK,MAAM;AAAK,aAAO,SAAQ;AAC9C,QAAI,WAAW,KAAK,MAAM;AAAK,aAAO,SAAQ;AAC9C,QAAI,WAAW,KAAK,MAAM;AAAK,aAAO,SAAQ;AAC9C,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,UAC1C,MAAM,OAAO,SAAS,SAAS,QAAQ,KAAK,OAAO,WAAW,WAAW,UAAU,KAAK,CAAC,GAC1F;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,UAC1C,MAAM,OAAO,SAAS,SAAS,QAAQ,KAAK,OAAO,WAAW,WAAW,UAAU,KAAK,CAAC,GAC1F;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,WAC1C,MAAM,OAAO,SAAS,SAAS,QAAQ,KAAK,QAAQ,WAAW,WAAW,UAAU,KAAK,CAAC,GAC3F;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,cAC1C,MAAM,WAAW,SAAS,SAAS,QAAQ,KAAK,WAAW,WAAW,WAAW,UAAU,KAAK,CAAC,GAClG;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,eAC1C,MAAM,iBAAiB,SACtB,IAAI,SAAS,SACb,SAAS,QAAQ,KACjB,YAAY,WAAW,WAAW,UAAU,KAAK,CAAC,GACpD;AACA,eAAS;AACT,aAAO;;AAET,QACE,WAAW,UAAU,OAAO,QAAQ,CAAC,MAAM,SAC1C,MAAM,MAAM,SAAS,SAAS,QAAQ,KAAK,MAAM,WAAW,WAAW,UAAU,KAAK,CAAC,GACxF;AACA,eAAS;AACT,aAAO;;AAET,WAAO,SAAQ;EACjB;AAEA,QAAM,WAAyB,MAAK;AAClC,UAAM,QAAQ;AACd,QAAIC,UAAS;AACb;AACA,WAAO,QAAQ,WAAW,WAAW,KAAK,MAAM,OAAQA,WAAU,WAAW,QAAQ,CAAC,MAAM,OAAQ;AAClG,MAAAA,UAAS,WAAW,KAAK,MAAM,OAAO,CAACA,UAAS;AAChD;;AAEF,QAAI,WAAW,OAAO,KAAK,KAAK,KAAK;AACnC,UAAI;AACF,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,EAAE,QAAQ,OAAOA,OAAM,CAAC,CAAC;eAChE,GAAG;AACV,4BAAoB,OAAO,CAAC,CAAC;;eAEtB,MAAM,MAAM,OAAO;AAC5B,UAAI;AACF,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,QAAQ,OAAOA,OAAM,CAAC,IAAI,GAAG;eACpE,GAAG;AAEV,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,WAAW,YAAY,IAAI,CAAC,IAAI,GAAG;;;AAGrF,oBAAgB,6BAA6B;EAC/C;AAEA,QAAM,WAAW,MAAK;AACpB;AACA,cAAS;AACT,UAAM,MAA2B,CAAA;AACjC,QAAI;AACF,aAAO,WAAW,KAAK,MAAM,KAAK;AAChC,kBAAS;AACT,YAAI,SAAS,UAAU,MAAM,MAAM;AAAO,iBAAO;AACjD,cAAM,MAAM,SAAQ;AACpB,kBAAS;AACT;AACA,YAAI;AACF,gBAAM,QAAQ,SAAQ;AACtB,iBAAO,eAAe,KAAK,KAAK,EAAE,OAAO,UAAU,MAAM,YAAY,MAAM,cAAc,KAAI,CAAE;iBACxF,GAAG;AACV,cAAI,MAAM,MAAM;AAAO,mBAAO;;AACzB,kBAAM;;AAEb,kBAAS;AACT,YAAI,WAAW,KAAK,MAAM;AAAK;;aAE1B,GAAG;AACV,UAAI,MAAM,MAAM;AAAO,eAAO;;AACzB,wBAAgB,+BAA+B;;AAEtD;AACA,WAAO;EACT;AAEA,QAAM,WAAW,MAAK;AACpB;AACA,UAAM,MAAM,CAAA;AACZ,QAAI;AACF,aAAO,WAAW,KAAK,MAAM,KAAK;AAChC,YAAI,KAAK,SAAQ,CAAE;AACnB,kBAAS;AACT,YAAI,WAAW,KAAK,MAAM,KAAK;AAC7B;;;aAGG,GAAG;AACV,UAAI,MAAM,MAAM,OAAO;AACrB,eAAO;;AAET,sBAAgB,8BAA8B;;AAEhD;AACA,WAAO;EACT;AAEA,QAAM,WAAW,MAAK;AACpB,QAAI,UAAU,GAAG;AACf,UAAI,eAAe,OAAO,MAAM,MAAM;AAAO,wBAAgB,sBAAsB;AACnF,UAAI;AACF,eAAO,KAAK,MAAM,UAAU;eACrB,GAAG;AACV,YAAI,MAAM,MAAM,OAAO;AACrB,cAAI;AACF,gBAAI,QAAQ,WAAW,WAAW,SAAS,CAAC;AAC1C,qBAAO,KAAK,MAAM,WAAW,UAAU,GAAG,WAAW,YAAY,GAAG,CAAC,CAAC;AACxE,mBAAO,KAAK,MAAM,WAAW,UAAU,GAAG,WAAW,YAAY,GAAG,CAAC,CAAC;mBAC/DC,IAAG;UAAA;;AAEd,4BAAoB,OAAO,CAAC,CAAC;;;AAIjC,UAAM,QAAQ;AAEd,QAAI,WAAW,KAAK,MAAM;AAAK;AAC/B,WAAO,WAAW,KAAK,KAAK,CAAC,MAAM,SAAS,WAAW,KAAK,CAAE;AAAG;AAEjE,QAAI,SAAS,UAAU,EAAE,MAAM,MAAM;AAAQ,sBAAgB,6BAA6B;AAE1F,QAAI;AACF,aAAO,KAAK,MAAM,WAAW,UAAU,OAAO,KAAK,CAAC;aAC7C,GAAG;AACV,UAAI,WAAW,UAAU,OAAO,KAAK,MAAM,OAAO,MAAM,MAAM;AAC5D,wBAAgB,sBAAsB;AACxC,UAAI;AACF,eAAO,KAAK,MAAM,WAAW,UAAU,OAAO,WAAW,YAAY,GAAG,CAAC,CAAC;eACnEA,IAAG;AACV,4BAAoB,OAAOA,EAAC,CAAC;;;EAGnC;AAEA,QAAM,YAAY,MAAK;AACrB,WAAO,QAAQ,UAAU,SAAU,SAAS,WAAW,KAAK,CAAE,GAAG;AAC/D;;EAEJ;AAEA,SAAO,SAAQ;AACjB;AAGA,IAAM,eAAe,CAAC,UAAkB,UAAU,OAAO,MAAM,MAAM,MAAM,GAAG;;;;;;;;;;;;;;;;;;;;;;;;;;ACtHxE,IAAO,uBAAP,MAAO,8BACH,6BAA0E;EAOlF,YAAY,QAAyC;AACnD,UAAK;;AALP,iCAAA,IAAA,MAAA,MAAA;AACA,4CAAA,IAAA,MAAA,MAAA;AACA,wDAAA,IAAA,MAAA,MAAA;AAIE,IAAAC,wBAAA,MAAI,8BAAW,QAAM,GAAA;AACrB,IAAAA,wBAAA,MAAI,yCAAsB,CAAA,GAAE,GAAA;EAC9B;EAEA,IAAI,gCAA6B;AAC/B,WAAOC,wBAAA,MAAI,qDAAA,GAAA;EACb;;;;;;;;EASA,OAAO,mBAAmB,QAAsB;AAC9C,UAAM,SAAS,IAAI,sBAAqB,IAAI;AAC5C,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;EAEA,OAAO,qBACL,QACA,QACA,SAA6B;AAE7B,UAAM,SAAS,IAAI,sBAA8B,MAA6C;AAC9F,WAAO,KAAK,MACV,OAAO,mBACL,QACA,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAG,SAAS,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ,EAAE,CAAE,CACxF;AAEH,WAAO;EACT;EAoMmB,MAAM,sBACvB,QACA,QACA,SAA6B;AAE7B,UAAM;AACN,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AAEJ,UAAM,SAAS,MAAM,OAAO,KAAK,YAAY,OAC3C,EAAE,GAAG,QAAQ,QAAQ,KAAI,GACzB,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAEhD,SAAK,WAAU;AACf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAEU,MAAM,oBACd,gBACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,IAAAA,wBAAA,MAAI,iCAAA,KAAA,kCAAA,EAAc,KAAlB,IAAI;AACJ,SAAK,WAAU;AACf,UAAM,SAAS,OAAO,mBAAwC,gBAAgB,KAAK,UAAU;AAC7F,QAAI;AACJ,qBAAiB,SAAS,QAAQ;AAChC,UAAI,UAAU,WAAW,MAAM,IAAI;AAEjC,aAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;;AAG5C,MAAAA,wBAAA,MAAI,iCAAA,KAAA,8BAAA,EAAU,KAAd,MAAe,KAAK;AACpB,eAAS,MAAM;;AAEjB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,mBAAmBA,wBAAA,MAAI,iCAAA,KAAA,gCAAA,EAAY,KAAhB,IAAI,CAAc;EACnD;EAuHA,EAAA,+BAAA,oBAAA,QAAA,GAAA,0CAAA,oBAAA,QAAA,GAAA,sDAAA,oBAAA,QAAA,GAAA,kCAAA,oBAAA,QAAA,GAAA,qCAAA,SAAAC,sCAAA;AA7WE,QAAI,KAAK;AAAO;AAChB,IAAAF,wBAAA,MAAI,qDAAkC,QAAS,GAAA;EACjD,GAAC,4CAAA,SAAAG,2CAEoB,QAAqC;AACxD,QAAI,QAAQF,wBAAA,MAAI,yCAAA,GAAA,EAAoB,OAAO,KAAK;AAChD,QAAI,OAAO;AACT,aAAO;;AAGT,YAAQ;MACN,cAAc;MACd,cAAc;MACd,uBAAuB;MACvB,uBAAuB;MACvB,iBAAiB,oBAAI,IAAG;MACxB,yBAAyB;;AAE3B,IAAAA,wBAAA,MAAI,yCAAA,GAAA,EAAoB,OAAO,KAAK,IAAI;AACxC,WAAO;EACT,GAAC,iCAAA,SAAAG,gCAE8C,OAA0B;AACvE,QAAI,KAAK;AAAO;AAEhB,UAAM,aAAaH,wBAAA,MAAI,iCAAA,KAAA,8CAAA,EAA0B,KAA9B,MAA+B,KAAK;AACvD,SAAK,MAAM,SAAS,OAAO,UAAU;AAErC,eAAW,UAAU,MAAM,SAAS;AAClC,YAAM,iBAAiB,WAAW,QAAQ,OAAO,KAAK;AAEtD,UACE,OAAO,MAAM,WAAW,QACxB,eAAe,SAAS,SAAS,eACjC,eAAe,SAAS,SACxB;AACA,aAAK,MAAM,WAAW,OAAO,MAAM,SAAS,eAAe,QAAQ,OAAO;AAC1E,aAAK,MAAM,iBAAiB;UAC1B,OAAO,OAAO,MAAM;UACpB,UAAU,eAAe,QAAQ;UACjC,QAAQ,eAAe,QAAQ;SAChC;;AAGH,UACE,OAAO,MAAM,WAAW,QACxB,eAAe,SAAS,SAAS,eACjC,eAAe,SAAS,SACxB;AACA,aAAK,MAAM,iBAAiB;UAC1B,OAAO,OAAO,MAAM;UACpB,UAAU,eAAe,QAAQ;SAClC;;AAGH,UAAI,OAAO,UAAU,WAAW,QAAQ,eAAe,SAAS,SAAS,aAAa;AACpF,aAAK,MAAM,0BAA0B;UACnC,SAAS,OAAO,UAAU;UAC1B,UAAU,eAAe,UAAU,WAAW,CAAA;SAC/C;;AAGH,UAAI,OAAO,UAAU,WAAW,QAAQ,eAAe,SAAS,SAAS,aAAa;AACpF,aAAK,MAAM,0BAA0B;UACnC,SAAS,OAAO,UAAU;UAC1B,UAAU,eAAe,UAAU,WAAW,CAAA;SAC/C;;AAGH,YAAM,QAAQA,wBAAA,MAAI,iCAAA,KAAA,yCAAA,EAAqB,KAAzB,MAA0B,cAAc;AAEtD,UAAI,eAAe,eAAe;AAChC,QAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,cAAc;AAE1C,YAAI,MAAM,2BAA2B,MAAM;AACzC,UAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,gBAAgB,MAAM,uBAAuB;;;AAI7E,iBAAW,YAAY,OAAO,MAAM,cAAc,CAAA,GAAI;AACpD,YAAI,MAAM,4BAA4B,SAAS,OAAO;AACpD,UAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,cAAc;AAG1C,cAAI,MAAM,2BAA2B,MAAM;AACzC,YAAAA,wBAAA,MAAI,iCAAA,KAAA,2CAAA,EAAuB,KAA3B,MAA4B,gBAAgB,MAAM,uBAAuB;;;AAI7E,cAAM,0BAA0B,SAAS;;AAG3C,iBAAW,iBAAiB,OAAO,MAAM,cAAc,CAAA,GAAI;AACzD,cAAM,mBAAmB,eAAe,QAAQ,aAAa,cAAc,KAAK;AAChF,YAAI,CAAC,kBAAkB,MAAM;AAC3B;;AAGF,YAAI,kBAAkB,SAAS,YAAY;AACzC,eAAK,MAAM,uCAAuC;YAChD,MAAM,iBAAiB,UAAU;YACjC,OAAO,cAAc;YACrB,WAAW,iBAAiB,SAAS;YACrC,kBAAkB,iBAAiB,SAAS;YAC5C,iBAAiB,cAAc,UAAU,aAAa;WACvD;eACI;AACL,sBAAY,kBAAkB,IAAI;;;;EAI1C,GAAC,8CAAA,SAAAI,6CAEsB,gBAA+C,eAAqB;AACzF,UAAM,QAAQJ,wBAAA,MAAI,iCAAA,KAAA,yCAAA,EAAqB,KAAzB,MAA0B,cAAc;AACtD,QAAI,MAAM,gBAAgB,IAAI,aAAa,GAAG;AAE5C;;AAGF,UAAM,mBAAmB,eAAe,QAAQ,aAAa,aAAa;AAC1E,QAAI,CAAC,kBAAkB;AACrB,YAAM,IAAI,MAAM,uBAAuB;;AAEzC,QAAI,CAAC,iBAAiB,MAAM;AAC1B,YAAM,IAAI,MAAM,mCAAmC;;AAGrD,QAAI,iBAAiB,SAAS,YAAY;AACxC,YAAM,YAAYA,wBAAA,MAAI,8BAAA,GAAA,GAAU,OAAO,KACrC,CAAC,SAAS,KAAK,SAAS,cAAc,KAAK,SAAS,SAAS,iBAAiB,SAAS,IAAI;AAG7F,WAAK,MAAM,sCAAsC;QAC/C,MAAM,iBAAiB,SAAS;QAChC,OAAO;QACP,WAAW,iBAAiB,SAAS;QACrC,kBACE,mBAAmB,SAAS,IAAI,UAAU,UAAU,iBAAiB,SAAS,SAAS,IACrF,WAAW,SAAS,SAAS,KAAK,MAAM,iBAAiB,SAAS,SAAS,IAC3E;OACL;WACI;AACL,kBAAY,iBAAiB,IAAI;;EAErC,GAAC,8CAAA,SAAAK,6CAEsB,gBAA6C;AAClE,UAAM,QAAQL,wBAAA,MAAI,iCAAA,KAAA,yCAAA,EAAqB,KAAzB,MAA0B,cAAc;AAEtD,QAAI,eAAe,QAAQ,WAAW,CAAC,MAAM,cAAc;AACzD,YAAM,eAAe;AAErB,YAAM,iBAAiBA,wBAAA,MAAI,iCAAA,KAAA,oDAAA,EAAgC,KAApC,IAAI;AAE3B,WAAK,MAAM,gBAAgB;QACzB,SAAS,eAAe,QAAQ;QAChC,QAAQ,iBAAiB,eAAe,UAAU,eAAe,QAAQ,OAAO,IAAK;OACtF;;AAGH,QAAI,eAAe,QAAQ,WAAW,CAAC,MAAM,cAAc;AACzD,YAAM,eAAe;AAErB,WAAK,MAAM,gBAAgB,EAAE,SAAS,eAAe,QAAQ,QAAO,CAAE;;AAGxE,QAAI,eAAe,UAAU,WAAW,CAAC,MAAM,uBAAuB;AACpE,YAAM,wBAAwB;AAE9B,WAAK,MAAM,yBAAyB,EAAE,SAAS,eAAe,SAAS,QAAO,CAAE;;AAGlF,QAAI,eAAe,UAAU,WAAW,CAAC,MAAM,uBAAuB;AACpE,YAAM,wBAAwB;AAE9B,WAAK,MAAM,yBAAyB,EAAE,SAAS,eAAe,SAAS,QAAO,CAAE;;EAEpF,GAAC,mCAAA,SAAAM,oCAAA;AAGC,QAAI,KAAK,OAAO;AACd,YAAM,IAAI,YAAY,yCAAyC;;AAEjE,UAAM,WAAWN,wBAAA,MAAI,qDAAA,GAAA;AACrB,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,YAAY,0CAA0C;;AAElE,IAAAD,wBAAA,MAAI,qDAAkC,QAAS,GAAA;AAC/C,IAAAA,wBAAA,MAAI,yCAAsB,CAAA,GAAE,GAAA;AAC5B,WAAO,uBAAuB,UAAUC,wBAAA,MAAI,8BAAA,GAAA,CAAQ;EACtD,GAAC,uDAAA,SAAAO,wDAAA;AA0DC,UAAM,iBAAiBP,wBAAA,MAAI,8BAAA,GAAA,GAAU;AACrC,QAAI,6BAAsC,cAAc,GAAG;AACzD,aAAO;;AAGT,WAAO;EACT,GAAC,iDAAA,SAAAQ,gDAEyB,OAA0B;;AAClD,QAAI,WAAWR,wBAAA,MAAI,qDAAA,GAAA;AACnB,UAAM,EAAE,SAAS,GAAG,KAAI,IAAK;AAC7B,QAAI,CAAC,UAAU;AACb,iBAAWD,wBAAA,MAAI,qDAAkC;QAC/C,GAAG;QACH,SAAS,CAAA;SACV,GAAA;WACI;AACL,aAAO,OAAO,UAAU,IAAI;;AAG9B,eAAW,EAAE,OAAO,eAAe,OAAO,WAAW,MAAM,GAAG,MAAK,KAAM,MAAM,SAAS;AACtF,UAAI,SAAS,SAAS,QAAQ,KAAK;AACnC,UAAI,CAAC,QAAQ;AACX,iBAAS,SAAS,QAAQ,KAAK,IAAI,EAAE,eAAe,OAAO,SAAS,CAAA,GAAI,UAAU,GAAG,MAAK;;AAG5F,UAAI,UAAU;AACZ,YAAI,CAAC,OAAO,UAAU;AACpB,iBAAO,WAAW,OAAO,OAAO,CAAA,GAAI,QAAQ;eACvC;AACL,gBAAM,EAAE,SAAAU,UAAS,SAAAC,UAAS,GAAGC,MAAI,IAAK;AACtC,wBAAcA,KAAI;AAClB,iBAAO,OAAO,OAAO,UAAUA,KAAI;AAEnC,cAAIF,UAAS;AACX,aAAAG,MAAA,OAAO,UAAS,YAAOA,IAAP,UAAY,CAAA;AAC5B,mBAAO,SAAS,QAAQ,KAAK,GAAGH,QAAO;;AAGzC,cAAIC,UAAS;AACX,aAAA,KAAA,OAAO,UAAS,YAAO,GAAP,UAAY,CAAA;AAC5B,mBAAO,SAAS,QAAQ,KAAK,GAAGA,QAAO;;;;AAK7C,UAAI,eAAe;AACjB,eAAO,gBAAgB;AAEvB,YAAIV,wBAAA,MAAI,8BAAA,GAAA,KAAY,sBAAsBA,wBAAA,MAAI,8BAAA,GAAA,CAAQ,GAAG;AACvD,cAAI,kBAAkB,UAAU;AAC9B,kBAAM,IAAI,wBAAuB;;AAGnC,cAAI,kBAAkB,kBAAkB;AACtC,kBAAM,IAAI,+BAA8B;;;;AAK9C,aAAO,OAAO,QAAQ,KAAK;AAE3B,UAAI,CAAC;AAAO;AAEZ,YAAM,EAAE,SAAS,SAAS,eAAe,MAAM,YAAY,GAAGW,MAAI,IAAK;AACvE,oBAAcA,KAAI;AAClB,aAAO,OAAO,OAAO,SAASA,KAAI;AAElC,UAAI,SAAS;AACX,eAAO,QAAQ,WAAW,OAAO,QAAQ,WAAW,MAAM;;AAG5D,UAAI;AAAM,eAAO,QAAQ,OAAO;AAChC,UAAI,eAAe;AACjB,YAAI,CAAC,OAAO,QAAQ,eAAe;AACjC,iBAAO,QAAQ,gBAAgB;eAC1B;AACL,cAAI,cAAc;AAAM,mBAAO,QAAQ,cAAc,OAAO,cAAc;AAC1E,cAAI,cAAc,WAAW;AAC3B,aAAA,KAAA,OAAO,QAAQ,eAAc,cAAS,GAAT,YAAc;AAC3C,mBAAO,QAAQ,cAAc,aAAa,cAAc;;;;AAI9D,UAAI,SAAS;AACX,eAAO,QAAQ,WAAW,OAAO,QAAQ,WAAW,MAAM;AAE1D,YAAI,CAAC,OAAO,QAAQ,WAAWX,wBAAA,MAAI,iCAAA,KAAA,oDAAA,EAAgC,KAApC,IAAI,GAAoC;AACrE,iBAAO,QAAQ,SAAS,aAAa,OAAO,QAAQ,OAAO;;;AAI/D,UAAI,YAAY;AACd,YAAI,CAAC,OAAO,QAAQ;AAAY,iBAAO,QAAQ,aAAa,CAAA;AAE5D,mBAAW,EAAE,OAAAa,QAAO,IAAI,MAAM,UAAU,IAAI,GAAGF,MAAI,KAAM,YAAY;AACnE,gBAAM,aAAY,KAAC,OAAO,QAAQ,YAAWE,MAAK,MAAA,GAALA,MAAK,IAChD,CAAA;AACF,iBAAO,OAAO,WAAWF,KAAI;AAC7B,cAAI;AAAI,sBAAU,KAAK;AACvB,cAAI;AAAM,sBAAU,OAAO;AAC3B,cAAI;AAAI,sBAAU,aAAV,UAAU,WAAa,EAAE,MAAM,GAAG,QAAQ,IAAI,WAAW,GAAE;AACnE,cAAI,IAAI;AAAM,sBAAU,SAAU,OAAO,GAAG;AAC5C,cAAI,IAAI,WAAW;AACjB,sBAAU,SAAU,aAAa,GAAG;AAEpC,gBAAI,oBAAoBX,wBAAA,MAAI,8BAAA,GAAA,GAAU,SAAS,GAAG;AAChD,wBAAU,SAAU,mBAAmB,aAAa,UAAU,SAAU,SAAS;;;;;;AAM3F,WAAO;EACT,GAEC,OAAO,cAAa,IAAC;AACpB,UAAM,YAAmC,CAAA;AACzC,UAAM,YAGA,CAAA;AACN,QAAI,OAAO;AAEX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,QAAQ,KAAK;aACf;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,QAAQ,MAAS;;AAE1B,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,YAAyD;AAC7D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAAyC,CAAC,SAAS,WAC5D,UAAU,KAAK,EAAE,SAAS,OAAM,CAAE,CAAC,EACnC,KAAK,CAACc,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAE9F,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC;MACA,QAAQ,YAAW;AACjB,aAAK,MAAK;AACV,eAAO,EAAE,OAAO,QAAW,MAAM,KAAI;MACvC;;EAEJ;EAEA,mBAAgB;AACd,UAAM,SAAS,IAAI,OAAO,KAAK,OAAO,aAAa,EAAE,KAAK,IAAI,GAAG,KAAK,UAAU;AAChF,WAAO,OAAO,iBAAgB;EAChC;;AAGF,SAAS,uBACP,UACA,QAAyC;AAEzC,QAAM,EAAE,IAAI,SAAS,SAAS,OAAO,oBAAoB,GAAG,KAAI,IAAK;AACrE,QAAM,aAA6B;IACjC,GAAG;IACH;IACA,SAAS,QAAQ,IACf,CAAC,EAAE,SAAS,eAAe,OAAO,UAAU,GAAG,WAAU,MAA6B;AACpF,UAAI,CAAC,eAAe;AAClB,cAAM,IAAI,YAAY,oCAAoC,KAAK,EAAE;;AAGnE,YAAM,EAAE,UAAU,MAAM,eAAe,YAAY,GAAG,YAAW,IAAK;AACtE,YAAM,OAAO,QAAQ;AACrB,UAAI,CAAC,MAAM;AACT,cAAM,IAAI,YAAY,2BAA2B,KAAK,EAAE;;AAG1D,UAAI,eAAe;AACjB,cAAM,EAAE,WAAW,MAAM,KAAI,IAAK;AAClC,YAAI,QAAQ,MAAM;AAChB,gBAAM,IAAI,YAAY,8CAA8C,KAAK,EAAE;;AAG7E,YAAI,CAAC,MAAM;AACT,gBAAM,IAAI,YAAY,yCAAyC,KAAK,EAAE;;AAGxE,eAAO;UACL,GAAG;UACH,SAAS;YACP;YACA,eAAe,EAAE,WAAW,MAAM,KAAI;YACtC;YACA,SAAS,QAAQ,WAAW;;UAE9B;UACA;UACA;;;AAIJ,UAAI,YAAY;AACd,eAAO;UACL,GAAG;UACH;UACA;UACA;UACA,SAAS;YACP,GAAG;YACH;YACA;YACA,SAAS,QAAQ,WAAW;YAC5B,YAAY,WAAW,IAAI,CAAC,WAAW,MAAK;AAC1C,oBAAM,EAAE,UAAU,IAAI,MAAM,IAAAC,KAAI,GAAG,SAAQ,IAAK;AAChD,oBAAM,EAAE,WAAW,MAAM,MAAM,GAAG,OAAM,IAAK,MAAM,CAAA;AACnD,kBAAIA,OAAM,MAAM;AACd,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAS,IAAI,QAAQ,CAAC,EAAE;;AAEzF,kBAAI,QAAQ,MAAM;AAChB,sBAAM,IAAI,YAAY,mBAAmB,KAAK,gBAAgB,CAAC;EAAW,IAAI,QAAQ,CAAC,EAAE;;AAE3F,kBAAI,QAAQ,MAAM;AAChB,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAoB,IAAI,QAAQ,CAAC,EAAE;;AAGhF,kBAAI,QAAQ,MAAM;AAChB,sBAAM,IAAI,YACR,mBAAmB,KAAK,gBAAgB,CAAC;EAAyB,IAAI,QAAQ,CAAC,EAAE;;AAIrF,qBAAO,EAAE,GAAG,UAAU,IAAAA,KAAI,MAAM,UAAU,EAAE,GAAG,QAAQ,MAAM,WAAW,KAAI,EAAE;YAChF,CAAC;;;;AAIP,aAAO;QACL,GAAG;QACH,SAAS,EAAE,GAAG,aAAa,SAAS,MAAM,SAAS,QAAQ,WAAW,KAAI;QAC1E;QACA;QACA;;IAEJ,CAAC;IAEH;IACA;IACA,QAAQ;IACR,GAAI,qBAAqB,EAAE,mBAAkB,IAAK,CAAA;;AAGpD,SAAO,yBAAyB,YAAY,MAAM;AACpD;AAEA,SAAS,IAAI,GAAU;AACrB,SAAO,KAAK,UAAU,CAAC;AACzB;AA+JA,SAAS,cAA4B,KAAqB;AACxD;AACF;AAEA,SAAS,YAAY,IAAS;AAAG;;;ACv0B3B,IAAO,gCAAP,MAAO,uCACH,qBAA6B;EAGrC,OAAgB,mBAAmB,QAAsB;AACvD,UAAM,SAAS,IAAI,+BAA8B,IAAI;AACrD,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;;EAGA,OAAO,aACL,QACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI,+BAA8B,IAAI;AACrD,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,eAAc;;AAE7E,WAAO,KAAK,MAAM,OAAO,cAAc,QAAQ,QAAQ,IAAI,CAAC;AAC5D,WAAO;EACT;EAEA,OAAO,SACL,QACA,QACA,SAAuB;AAEvB,UAAM,SAAS,IAAI;;MAEjB;IAAM;AAER,UAAM,OAAO;MACX,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,WAAU;;AAEzE,WAAO,KAAK,MAAM,OAAO,UAAU,QAAQ,QAAQ,IAAI,CAAC;AACxD,WAAO;EACT;;;;ACLI,IAAOC,eAAP,cAA2B,YAAW;EAC1C,MACE,MACA,SAA6B;AAE7B,uBAAmB,KAAK,KAAK;AAE7B,WAAO,KAAK,QAAQ,KAAK,YACtB,OAAO,MAAM;MACZ,GAAG;MACH,SAAS;QACP,GAAG,SAAS;QACZ,6BAA6B;;KAEhC,EACA,YAAY,CAAC,eAAe,oBAAoB,YAAY,IAAI,CAAC;EACtE;EAaA,aACE,MAGA,SAA6B;AAE7B,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,aACnC,KAAK,SACL,MACA,OAAO;;AAGX,WAAO,qBAAqB,aAC1B,KAAK,SACL,MACA,OAAO;EAEX;EAqBA,SAIE,MACA,SAAuB;AAEvB,QAAI,KAAK,QAAQ;AACf,aAAO,8BAA8B,SACnC,KAAK,SACL,MACA,OAAO;;AAIX,WAAO,qBAAqB,SAAS,KAAK,SAAS,MAA6C,OAAO;EACzG;;;;EAKA,OACE,MACA,SAA6B;AAE7B,WAAO,qBAAqB,qBAAqB,KAAK,SAAS,MAAM,OAAO;EAC9E;;;;AC1JI,IAAOC,QAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmBC,aAAY,KAAK,OAAO;EACvF;;CAEA,SAAiBD,OAAI;AACL,EAAAA,MAAA,cAA6BC;AAC7C,GAFiBD,UAAAA,QAAI,CAAA,EAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC+Df,IAAO,kBAAP,MAAO,yBACH,YAAkC;EAD5C,cAAA;;;AAKE,4BAAA,IAAA,MAAkC,CAAA,CAAE;AAIpC,sCAAA,IAAA,MAAoD,CAAA,CAAE;AACtD,sCAAA,IAAA,MAA+C,CAAA,CAAE;AACjD,qCAAA,IAAA,MAAA,MAAA;AACA,8BAAA,IAAA,MAAA,MAAA;AACA,yCAAA,IAAA,MAAA,MAAA;AACA,oCAAA,IAAA,MAAA,MAAA;AACA,0CAAA,IAAA,MAAA,MAAA;AACA,qCAAA,IAAA,MAAA,MAAA;AAGA,kCAAA,IAAA,MAAA,MAAA;AACA,wCAAA,IAAA,MAAA,MAAA;AACA,4CAAA,IAAA,MAAA,MAAA;EAwqBF;EAtqBE,EAAA,0BAAA,oBAAA,QAAA,GAAA,oCAAA,oBAAA,QAAA,GAAA,oCAAA,oBAAA,QAAA,GAAA,mCAAA,oBAAA,QAAA,GAAA,4BAAA,oBAAA,QAAA,GAAA,uCAAA,oBAAA,QAAA,GAAA,kCAAA,oBAAA,QAAA,GAAA,wCAAA,oBAAA,QAAA,GAAA,mCAAA,oBAAA,QAAA,GAAA,gCAAA,oBAAA,QAAA,GAAA,sCAAA,oBAAA,QAAA,GAAA,0CAAA,oBAAA,QAAA,GAAA,6BAAA,oBAAA,QAAA,GAAC,OAAO,cAAa,IAAC;AACpB,UAAM,YAAoC,CAAA;AAC1C,UAAM,YAGA,CAAA;AACN,QAAI,OAAO;AAGX,SAAK,GAAG,SAAS,CAAC,UAAS;AACzB,YAAM,SAAS,UAAU,MAAK;AAC9B,UAAI,QAAQ;AACV,eAAO,QAAQ,KAAK;aACf;AACL,kBAAU,KAAK,KAAK;;IAExB,CAAC;AAED,SAAK,GAAG,OAAO,MAAK;AAClB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,QAAQ,MAAS;;AAE1B,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,QAAO;AACvB,aAAO;AACP,iBAAW,UAAU,WAAW;AAC9B,eAAO,OAAO,GAAG;;AAEnB,gBAAU,SAAS;IACrB,CAAC;AAED,WAAO;MACL,MAAM,YAA0D;AAC9D,YAAI,CAAC,UAAU,QAAQ;AACrB,cAAI,MAAM;AACR,mBAAO,EAAE,OAAO,QAAW,MAAM,KAAI;;AAEvC,iBAAO,IAAI,QAA0C,CAAC,SAAS,WAC7D,UAAU,KAAK,EAAE,SAAS,OAAM,CAAE,CAAC,EACnC,KAAK,CAACE,WAAWA,SAAQ,EAAE,OAAOA,QAAO,MAAM,MAAK,IAAK,EAAE,OAAO,QAAW,MAAM,KAAI,CAAG;;AAE9F,cAAM,QAAQ,UAAU,MAAK;AAC7B,eAAO,EAAE,OAAO,OAAO,MAAM,MAAK;MACpC;MACA,QAAQ,YAAW;AACjB,aAAK,MAAK;AACV,eAAO,EAAE,OAAO,QAAW,MAAM,KAAI;MACvC;;EAEJ;EAEA,OAAO,mBAAmB,QAAsB;AAC9C,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MAAM,OAAO,oBAAoB,MAAM,CAAC;AACpD,WAAO;EACT;EAEU,MAAM,oBACd,gBACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAEhE,SAAK,WAAU;AACf,UAAM,SAAS,OAAO,mBAAyC,gBAAgB,KAAK,UAAU;AAC9F,qBAAiB,SAAS,QAAQ;AAChC,MAAAC,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAE7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEA,mBAAgB;AACd,UAAM,SAAS,IAAI,OAAO,KAAK,OAAO,aAAa,EAAE,KAAK,IAAI,GAAG,KAAK,UAAU;AAChF,WAAO,OAAO,iBAAgB;EAChC;EAEA,OAAO,0BACL,UACA,OACA,MACA,QACA,SAAmC;AAEnC,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,wBAAwB,UAAU,OAAO,MAAM,QAAQ;MAC5D,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEU,MAAM,2BACd,KACA,UACA,OACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAA4C,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAC3E,UAAM,SAAS,MAAM,IAAI,kBAAkB,UAAU,OAAO,MAAM;MAChE,GAAG;MACH,QAAQ,KAAK,WAAW;KACzB;AAED,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEA,OAAO,4BACL,QACA,QACA,SAAwB;AAExB,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,uBAAuB,QAAQ,QAAQ;MAC5C,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEA,OAAO,sBACL,UACA,MACA,QACA,SAAwB;AAExB,UAAM,SAAS,IAAI,iBAAe;AAClC,WAAO,KAAK,MACV,OAAO,oBAAoB,UAAU,MAAM,QAAQ;MACjD,GAAG;MACH,SAAS,EAAE,GAAG,SAAS,SAAS,6BAA6B,SAAQ;KACtE,CAAC;AAEJ,WAAO;EACT;EAEA,eAAY;AACV,WAAOA,wBAAA,MAAI,+BAAA,GAAA;EACb;EAEA,aAAU;AACR,WAAOA,wBAAA,MAAI,qCAAA,GAAA;EACb;EAEA,yBAAsB;AACpB,WAAOA,wBAAA,MAAI,kCAAA,GAAA;EACb;EAEA,yBAAsB;AACpB,WAAOA,wBAAA,MAAI,yCAAA,GAAA;EACb;EAEA,MAAM,gBAAa;AACjB,UAAM,KAAK,KAAI;AAEf,WAAO,OAAO,OAAOA,wBAAA,MAAI,mCAAA,GAAA,CAAkB;EAC7C;EAEA,MAAM,gBAAa;AACjB,UAAM,KAAK,KAAI;AAEf,WAAO,OAAO,OAAOA,wBAAA,MAAI,mCAAA,GAAA,CAAkB;EAC7C;EAEA,MAAM,WAAQ;AACZ,UAAM,KAAK,KAAI;AACf,QAAI,CAACA,wBAAA,MAAI,2BAAA,GAAA;AAAY,YAAM,MAAM,6BAA6B;AAE9D,WAAOA,wBAAA,MAAI,2BAAA,GAAA;EACb;EAEU,MAAM,6BACd,QACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAAiC,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAChE,UAAM,SAAS,MAAM,OAAO,aAAa,MAAM,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAE7F,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EAEU,MAAM,uBACd,KACA,UACA,QACA,SAA6B;AAE7B,UAAM,SAAS,SAAS;AACxB,QAAI,QAAQ;AACV,UAAI,OAAO;AAAS,aAAK,WAAW,MAAK;AACzC,aAAO,iBAAiB,SAAS,MAAM,KAAK,WAAW,MAAK,CAAE;;AAGhE,UAAM,OAAiC,EAAE,GAAG,QAAQ,QAAQ,KAAI;AAChE,UAAM,SAAS,MAAM,IAAI,OAAO,UAAU,MAAM,EAAE,GAAG,SAAS,QAAQ,KAAK,WAAW,OAAM,CAAE;AAE9F,SAAK,WAAU;AAEf,qBAAiB,SAAS,QAAQ;AAChC,MAAAA,wBAAA,MAAI,4BAAA,KAAA,yBAAA,EAAU,KAAd,MAAe,KAAK;;AAEtB,QAAI,OAAO,WAAW,QAAQ,SAAS;AACrC,YAAM,IAAI,kBAAiB;;AAG7B,WAAO,KAAK,QAAQA,wBAAA,MAAI,4BAAA,KAAA,2BAAA,EAAY,KAAhB,IAAI,CAAc;EACxC;EA6SA,OAAO,gBAAgB,KAA0B,OAA0B;AACzE,eAAW,CAAC,KAAK,UAAU,KAAK,OAAO,QAAQ,KAAK,GAAG;AACrD,UAAI,CAAC,IAAI,eAAe,GAAG,GAAG;AAC5B,YAAI,GAAG,IAAI;AACX;;AAGF,UAAI,WAAW,IAAI,GAAG;AACtB,UAAI,aAAa,QAAQ,aAAa,QAAW;AAC/C,YAAI,GAAG,IAAI;AACX;;AAIF,UAAI,QAAQ,WAAW,QAAQ,QAAQ;AACrC,YAAI,GAAG,IAAI;AACX;;AAIF,UAAI,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;AAClE,oBAAY;iBACH,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;AACzE,oBAAY;iBACE,MAAM,QAAQ,KAAU,MAAM,UAAU,GAAG;AACzD,mBAAW,KAAK,gBAAgB,UAAiC,UAAiC;iBACzF,MAAM,QAAQ,QAAQ,KAAK,MAAM,QAAQ,UAAU,GAAG;AAC/D,YAAI,SAAS,MAAM,CAAC,MAAM,OAAO,MAAM,YAAY,OAAO,MAAM,QAAQ,GAAG;AACzE,mBAAS,KAAK,GAAG,UAAU;AAC3B;;AAGF,mBAAW,cAAc,YAAY;AACnC,cAAI,CAAM,MAAM,UAAU,GAAG;AAC3B,kBAAM,IAAI,MAAM,uDAAuD,UAAU,EAAE;;AAGrF,gBAAM,QAAQ,WAAW,OAAO;AAChC,cAAI,SAAS,MAAM;AACjB,oBAAQ,MAAM,UAAU;AACxB,kBAAM,IAAI,MAAM,wDAAwD;;AAG1E,cAAI,OAAO,UAAU,UAAU;AAC7B,kBAAM,IAAI,MAAM,wEAAwE,KAAK,EAAE;;AAGjG,gBAAM,WAAW,SAAS,KAAK;AAC/B,cAAI,YAAY,MAAM;AACpB,qBAAS,KAAK,UAAU;iBACnB;AACL,qBAAS,KAAK,IAAI,KAAK,gBAAgB,UAAU,UAAU;;;AAG/D;aACK;AACL,cAAM,MAAM,0BAA0B,GAAG,iBAAiB,UAAU,eAAe,QAAQ,EAAE;;AAE/F,UAAI,GAAG,IAAI;;AAGb,WAAO;EACT;EA2BU,QAAQ,KAAQ;AACxB,WAAO;EACT;EAEU,MAAM,uBACd,QACA,QACA,SAA6B;AAE7B,WAAO,MAAM,KAAK,6BAA6B,QAAQ,QAAQ,OAAO;EACxE;EAEU,MAAM,oBACd,UACA,MACA,QACA,SAA6B;AAE7B,WAAO,MAAM,KAAK,uBAAuB,MAAM,UAAU,QAAQ,OAAO;EAC1E;EAEU,MAAM,wBACd,UACA,OACA,MACA,QACA,SAA6B;AAE7B,WAAO,MAAM,KAAK,2BAA2B,MAAM,UAAU,OAAO,QAAQ,OAAO;EACrF;;gEAjaU,OAA2B;AACnC,MAAI,KAAK;AAAO;AAEhB,EAAAC,wBAAA,MAAI,+BAAiB,OAAK,GAAA;AAE1B,EAAAD,wBAAA,MAAI,4BAAA,KAAA,4BAAA,EAAa,KAAjB,MAAkB,KAAK;AAEvB,UAAQ,MAAM,OAAO;IACnB,KAAK;AAEH;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,0BAAA,EAAW,KAAf,MAAgB,KAAK;AACrB;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,8BAAA,EAAe,KAAnB,MAAoB,KAAK;AACzB;IAEF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,4BAAA,KAAA,8BAAA,EAAe,KAAnB,MAAoB,KAAK;AACzB;IAEF,KAAK;AAEH,YAAM,IAAI,MACR,qFAAqF;;AAG7F,GAAC,8BAAA,SAAAE,+BAAA;AAGC,MAAI,KAAK,OAAO;AACd,UAAM,IAAI,YAAY,yCAAyC;;AAGjE,MAAI,CAACF,wBAAA,MAAI,2BAAA,GAAA;AAAY,UAAM,MAAM,iCAAiC;AAElE,SAAOA,wBAAA,MAAI,2BAAA,GAAA;AACb,GAAC,iCAAA,SAAAG,gCAEqC,OAAyB;AAC7D,QAAM,CAAC,oBAAoB,UAAU,IAAIH,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MAAwB,OAAOA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAC7F,EAAAC,wBAAA,MAAI,kCAAoB,oBAAkB,GAAA;AAC1C,EAAAD,wBAAA,MAAI,mCAAA,GAAA,EAAmB,mBAAmB,EAAE,IAAI;AAEhD,aAAW,WAAW,YAAY;AAChC,UAAM,kBAAkB,mBAAmB,QAAQ,QAAQ,KAAK;AAChE,QAAI,iBAAiB,QAAQ,QAAQ;AACnC,WAAK,MAAM,eAAe,gBAAgB,IAAI;;;AAIlD,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,WAAK,MAAM,kBAAkB,MAAM,IAAI;AACvC;IAEF,KAAK;AACH;IAEF,KAAK;AACH,WAAK,MAAM,gBAAgB,MAAM,KAAK,OAAO,kBAAkB;AAE/D,UAAI,MAAM,KAAK,MAAM,SAAS;AAC5B,mBAAW,WAAW,MAAM,KAAK,MAAM,SAAS;AAE9C,cAAI,QAAQ,QAAQ,UAAU,QAAQ,MAAM;AAC1C,gBAAI,YAAY,QAAQ;AACxB,gBAAI,WAAW,mBAAmB,QAAQ,QAAQ,KAAK;AACvD,gBAAI,YAAY,SAAS,QAAQ,QAAQ;AACvC,mBAAK,MAAM,aAAa,WAAW,SAAS,IAAI;mBAC3C;AACL,oBAAM,MAAM,qEAAqE;;;AAIrF,cAAI,QAAQ,SAASA,wBAAA,MAAI,sCAAA,GAAA,GAAuB;AAE9C,gBAAIA,wBAAA,MAAI,iCAAA,GAAA,GAAkB;AACxB,sBAAQA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,MAAM;gBACjC,KAAK;AACH,uBAAK,MAAM,YAAYA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,MAAMA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AACvE;gBACF,KAAK;AACH,uBAAK,MAAM,iBAAiBA,wBAAA,MAAI,iCAAA,GAAA,EAAiB,YAAYA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAClF;;;AAIN,YAAAC,wBAAA,MAAI,sCAAwB,QAAQ,OAAK,GAAA;;AAG3C,UAAAA,wBAAA,MAAI,iCAAmB,mBAAmB,QAAQ,QAAQ,KAAK,GAAC,GAAA;;;AAIpE;IAEF,KAAK;IACL,KAAK;AAEH,UAAID,wBAAA,MAAI,sCAAA,GAAA,MAA0B,QAAW;AAC3C,cAAM,iBAAiB,MAAM,KAAK,QAAQA,wBAAA,MAAI,sCAAA,GAAA,CAAqB;AACnE,YAAI,gBAAgB;AAClB,kBAAQ,eAAe,MAAM;YAC3B,KAAK;AACH,mBAAK,MAAM,iBAAiB,eAAe,YAAYA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAC5E;YACF,KAAK;AACH,mBAAK,MAAM,YAAY,eAAe,MAAMA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AACjE;;;;AAKR,UAAIA,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,aAAK,MAAM,eAAe,MAAM,IAAI;;AAGtC,MAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;AAEvC,GAAC,iCAAA,SAAAG,gCAEqC,OAAyB;AAC7D,QAAM,qBAAqBJ,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MAAwB,KAAK;AACxD,EAAAC,wBAAA,MAAI,yCAA2B,oBAAkB,GAAA;AAEjD,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,WAAK,MAAM,kBAAkB,MAAM,IAAI;AACvC;IACF,KAAK;AACH,YAAM,QAAQ,MAAM,KAAK;AACzB,UACE,MAAM,gBACN,MAAM,aAAa,QAAQ,gBAC3B,MAAM,aAAa,cACnB,mBAAmB,aAAa,QAAQ,cACxC;AACA,mBAAW,YAAY,MAAM,aAAa,YAAY;AACpD,cAAI,SAAS,SAASD,wBAAA,MAAI,uCAAA,GAAA,GAAwB;AAChD,iBAAK,MACH,iBACA,UACA,mBAAmB,aAAa,WAAW,SAAS,KAAK,CAAa;iBAEnE;AACL,gBAAIA,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,mBAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;;AAGlD,YAAAC,wBAAA,MAAI,uCAAyB,SAAS,OAAK,GAAA;AAC3C,YAAAA,wBAAA,MAAI,kCAAoB,mBAAmB,aAAa,WAAW,SAAS,KAAK,GAAC,GAAA;AAClF,gBAAID,wBAAA,MAAI,kCAAA,GAAA;AAAmB,mBAAK,MAAM,mBAAmBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;;;;AAKpF,WAAK,MAAM,gBAAgB,MAAM,KAAK,OAAO,kBAAkB;AAC/D;IACF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAC,wBAAA,MAAI,yCAA2B,QAAS,GAAA;AACxC,YAAM,UAAU,MAAM,KAAK;AAC3B,UAAI,QAAQ,QAAQ,cAAc;AAChC,YAAID,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,eAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAA6B;AAC5D,UAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;;AAGrC,WAAK,MAAM,eAAe,MAAM,MAAM,kBAAkB;AACxD;IACF,KAAK;AACH;;AAEN,GAAC,+BAAA,SAAAI,8BAEmC,OAA2B;AAC7D,EAAAL,wBAAA,MAAI,yBAAA,GAAA,EAAS,KAAK,KAAK;AACvB,OAAK,MAAM,SAAS,KAAK;AAC3B,GAAC,qCAAA,SAAAM,oCAEkB,OAAyB;AAC1C,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH,MAAAN,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI,MAAM;AAC9C,aAAO,MAAM;IAEf,KAAK;AACH,UAAI,WAAWA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AACnD,UAAI,CAAC,UAAU;AACb,cAAM,MAAM,uDAAuD;;AAGrE,UAAI,OAAO,MAAM;AAEjB,UAAI,KAAK,OAAO;AACd,cAAM,cAAc,gBAAgB,gBAAgB,UAAU,KAAK,KAAK;AACxE,QAAAA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI;;AAG1C,aAAOA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;IAE7C,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE,IAAI,MAAM;AAC9C;;AAGJ,MAAIA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AAAG,WAAOA,wBAAA,MAAI,mCAAA,GAAA,EAAmB,MAAM,KAAK,EAAE;AACtF,QAAM,IAAI,MAAM,uBAAuB;AACzC,GAAC,qCAAA,SAAAO,oCAGC,OACA,UAA6B;AAE7B,MAAI,aAAoC,CAAA;AAExC,UAAQ,MAAM,OAAO;IACnB,KAAK;AAEH,aAAO,CAAC,MAAM,MAAM,UAAU;IAEhC,KAAK;AACH,UAAI,CAAC,UAAU;AACb,cAAM,MACJ,wFAAwF;;AAI5F,UAAI,OAAO,MAAM;AAGjB,UAAI,KAAK,MAAM,SAAS;AACtB,mBAAW,kBAAkB,KAAK,MAAM,SAAS;AAC/C,cAAI,eAAe,SAAS,SAAS,SAAS;AAC5C,gBAAI,iBAAiB,SAAS,QAAQ,eAAe,KAAK;AAC1D,qBAAS,QAAQ,eAAe,KAAK,IAAIP,wBAAA,MAAI,4BAAA,KAAA,kCAAA,EAAmB,KAAvB,MACvC,gBACA,cAAc;iBAEX;AACL,qBAAS,QAAQ,eAAe,KAAK,IAAI;AAEzC,uBAAW,KAAK,cAAc;;;;AAKpC,aAAO,CAAC,UAAU,UAAU;IAE9B,KAAK;IACL,KAAK;IACL,KAAK;AAEH,UAAI,UAAU;AACZ,eAAO,CAAC,UAAU,UAAU;aACvB;AACL,cAAM,MAAM,yDAAyD;;;AAG3E,QAAM,MAAM,yCAAyC;AACvD,GAAC,qCAAA,SAAAQ,oCAGC,gBACA,gBAA0C;AAE1C,SAAO,gBAAgB,gBAAgB,gBAA+C,cAAc;AAGtG,GAAC,6BAAA,SAAAC,4BAkEiC,OAAqB;AACrD,EAAAR,wBAAA,MAAI,qCAAuB,MAAM,MAAI,GAAA;AACrC,UAAQ,MAAM,OAAO;IACnB,KAAK;AACH;IACF,KAAK;AACH;IACF,KAAK;AACH;IACF,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,MAAAA,wBAAA,MAAI,2BAAa,MAAM,MAAI,GAAA;AAC3B,UAAID,wBAAA,MAAI,kCAAA,GAAA,GAAmB;AACzB,aAAK,MAAM,gBAAgBA,wBAAA,MAAI,kCAAA,GAAA,CAAiB;AAChD,QAAAC,wBAAA,MAAI,kCAAoB,QAAS,GAAA;;AAEnC;IACF,KAAK;AACH;;AAEN;;;AC7tBI,IAAO,WAAP,cAAwB,YAAW;;;;EAIvC,OACE,UACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa;MACxD;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkB,WAAmB,SAA6B;AACzE,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,aAAa,SAAS,IAAI;MACpE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,WACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa,SAAS,IAAI;MACrE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAAiD,CAAA,GACjD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,aAAa,cAAc;MAC5E;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,UAAkB,WAAmB,SAA6B;AACpE,WAAO,KAAK,QAAQ,OAAO,YAAY,QAAQ,aAAa,SAAS,IAAI;MACvE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,eAAP,cAA4B,WAAmB;;AA8nBrD,SAAS,eAAe;;;AC3sBlB,IAAO,QAAP,cAAqB,YAAW;EAiBpC,SACE,UACA,OACA,QACA,QAAkD,CAAA,GAClD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,SAAS,UAAU,OAAO,QAAQ,CAAA,GAAI,KAAK;;AAEzD,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,UAAU,MAAM,IAAI;MAC5E;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAgBA,KACE,UACA,OACA,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,OAAO,CAAA,GAAI,KAAK;;AAE7C,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,KAAK,UAAU,cAAc;MACvF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,eAAP,cAA4B,WAAmB;;AA2pBrD,MAAM,eAAe;;;AC1rBf,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;EA+PzD;EA3OE,OACE,UACA,QACA,SAA6B;AAE7B,UAAM,EAAE,SAAS,GAAG,KAAI,IAAK;AAC7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS;MACpD,OAAO,EAAE,QAAO;MAChB;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;MAC9D,QAAQ,OAAO,UAAU;KAC1B;EACH;;;;EAKA,SAAS,UAAkB,OAAe,SAA6B;AACrE,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC5D,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,IAAI;MAC7D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAWA,KACE,UACA,QAA6C,CAAA,GAC7C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,UAAU,CAAA,GAAI,KAAK;;AAEtC,WAAO,KAAK,QAAQ,WAAW,YAAY,QAAQ,SAAS,UAAU;MACpE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,OAAe,SAA6B;AACnE,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,WAAW;MACpE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;;;EAOA,MAAM,cACJ,UACA,MACA,SAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,OAAO,UAAU,MAAM,OAAO;AACrD,WAAO,MAAM,KAAK,KAAK,UAAU,IAAI,IAAI,OAAO;EAClD;;;;;;EAOA,gBACE,UACA,MACA,SAA6B;AAE7B,WAAO,gBAAgB,sBAAsB,UAAU,KAAK,QAAQ,KAAK,QAAQ,MAAM,MAAM,OAAO;EACtG;;;;;;EAOA,MAAM,KACJ,UACA,OACA,SAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAG,SAAS,SAAS,2BAA2B,OAAM;AAEnG,QAAI,SAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAI,QAAQ,eAAe,SAAQ;;AAG/E,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,KAAK,SAAQ,IAAK,MAAM,KAAK,SAAS,UAAU,OAAO;QACnE,GAAG;QACH,SAAS,EAAE,GAAG,SAAS,SAAS,GAAG,QAAO;OAC3C,EAAE,aAAY;AAEf,cAAQ,IAAI,QAAQ;;QAElB,KAAK;QACL,KAAK;QACL,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAI,SAAS,gBAAgB;AAC3B,4BAAgB,QAAQ;iBACnB;AACL,kBAAM,iBAAiB,SAAS,QAAQ,IAAI,sBAAsB;AAClE,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;;QAEF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;EAKA,OAAO,UAAkB,MAAiC,SAA6B;AACrF,WAAO,gBAAgB,sBAAsB,UAAU,KAAK,QAAQ,KAAK,QAAQ,MAAM,MAAM,OAAO;EACtG;EA0BA,kBACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,SAAS,KAAK,wBAAwB;MACjF;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;MAC9D,QAAQ,KAAK,UAAU;KACxB;EACH;;;;;;EAOA,MAAM,yBACJ,UACA,OACA,MACA,SAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,kBAAkB,UAAU,OAAO,MAAM,OAAO;AACvE,WAAO,MAAM,KAAK,KAAK,UAAU,IAAI,IAAI,OAAO;EAClD;;;;;;EAOA,wBACE,UACA,OACA,MACA,SAA6B;AAE7B,WAAO,gBAAgB,0BACrB,UACA,OACA,KAAK,QAAQ,KAAK,QAAQ,MAC1B,MACA,OAAO;EAEX;;AAGI,IAAO,WAAP,cAAwB,WAAe;;AAi0C7C,KAAK,WAAW;AAChB,KAAK,QAAQ;AACb,KAAK,eAAe;;;ACxiDd,IAAO,UAAP,cAAuB,YAAW;EAAxC,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;AAClD,SAAA,WAAiC,IAAgB,SAAS,KAAK,OAAO;EAqGxE;EA9FE,OACE,OAAiD,CAAA,GACjD,SAA6B;AAE7B,QAAI,iBAAiB,IAAI,GAAG;AAC1B,aAAO,KAAK,OAAO,CAAA,GAAI,IAAI;;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY;MACnC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,UAAkB,SAA6B;AACtD,WAAO,KAAK,QAAQ,IAAI,YAAY,QAAQ,IAAI;MAC9C,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OAAO,UAAkB,MAA0B,SAA6B;AAC9E,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,IAAI;MAC/C;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,UAAkB,SAA6B;AACjD,WAAO,KAAK,QAAQ,OAAO,YAAY,QAAQ,IAAI;MACjD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAiBA,aACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,iBAAiB;MACxC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;MAC9D,QAAQ,KAAK,UAAU;KACxB;EACH;;;;;;EAOA,MAAM,iBACJ,MACA,SAA2D;AAE3D,UAAM,MAAM,MAAM,KAAK,aAAa,MAAM,OAAO;AACjD,WAAO,MAAM,KAAK,KAAK,KAAK,IAAI,WAAW,IAAI,IAAI,OAAO;EAC5D;;;;EAKA,mBACE,MACA,SAA6B;AAE7B,WAAO,gBAAgB,4BAA4B,MAAM,KAAK,QAAQ,KAAK,SAAS,OAAO;EAC7F;;AA61CF,QAAQ,OAAO;AACf,QAAQ,WAAW;AACnB,QAAQ,WAAW;AACnB,QAAQ,eAAe;;;AC1gDhB,IAAM,sBAAsB,OAAU,aAAwC;AACnF,QAAM,UAAU,MAAM,QAAQ,WAAW,QAAQ;AACjD,QAAM,WAAW,QAAQ,OAAO,CAAC,WAA4C,OAAO,WAAW,UAAU;AACzG,MAAI,SAAS,QAAQ;AACnB,eAAW,UAAU,UAAU;AAC7B,cAAQ,MAAM,OAAO,MAAM;;AAG7B,UAAM,IAAI,MAAM,GAAG,SAAS,MAAM,2CAA2C;;AAI/E,QAAM,SAAc,CAAA;AACpB,aAAW,UAAU,SAAS;AAC5B,QAAI,OAAO,WAAW,aAAa;AACjC,aAAO,KAAK,OAAO,KAAK;;;AAG5B,SAAO;AACT;;;ACdM,IAAO,QAAP,cAAqB,YAAW;;;;;;EAMpC,OACE,eACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,UAAU;MAChE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,eACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,UAAU,MAAM,IAAI;MACzE,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAcA,KACE,eACA,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,eAAe,CAAA,GAAI,KAAK;;AAE3C,WAAO,KAAK,QAAQ,WAAW,kBAAkB,aAAa,UAAU,sBAAsB;MAC5F;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;;;;EAQA,IACE,eACA,QACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,OAAO,kBAAkB,aAAa,UAAU,MAAM,IAAI;MAC5E,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,MAAM,cACJ,eACA,MACA,SAA2D;AAE3D,UAAM,OAAO,MAAM,KAAK,OAAO,eAAe,MAAM,OAAO;AAC3D,WAAO,MAAM,KAAK,KAAK,eAAe,KAAK,IAAI,OAAO;EACxD;;;;;;;EAQA,MAAM,KACJ,eACA,QACA,SAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAG,SAAS,SAAS,2BAA2B,OAAM;AACnG,QAAI,SAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAI,QAAQ,eAAe,SAAQ;;AAE/E,WAAO,MAAM;AACX,YAAM,eAAe,MAAM,KAAK,SAAS,eAAe,QAAQ;QAC9D,GAAG;QACH;OACD,EAAE,aAAY;AAEf,YAAM,OAAO,aAAa;AAE1B,cAAQ,KAAK,QAAQ;QACnB,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAI,SAAS,gBAAgB;AAC3B,4BAAgB,QAAQ;iBACnB;AACL,kBAAM,iBAAiB,aAAa,SAAS,QAAQ,IAAI,sBAAsB;AAC/E,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;QACF,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;;;;EAQA,MAAM,OACJ,eACA,MACA,SAA6B;AAE7B,UAAM,WAAW,MAAM,KAAK,QAAQ,MAAM,OAAO,EAAE,MAAY,SAAS,aAAY,GAAI,OAAO;AAC/F,WAAO,KAAK,OAAO,eAAe,EAAE,SAAS,SAAS,GAAE,GAAI,OAAO;EACrE;;;;EAKA,MAAM,cACJ,eACA,MACA,SAA2D;AAE3D,UAAM,WAAW,MAAM,KAAK,OAAO,eAAe,MAAM,OAAO;AAC/D,WAAO,MAAM,KAAK,KAAK,eAAe,SAAS,IAAI,OAAO;EAC5D;;AAGI,IAAO,uBAAP,cAAoC,WAA2B;;AAoHrE,MAAM,uBAAuB;;;AClRvB,IAAO,cAAP,cAA2B,YAAW;;;;EAI1C,OACE,eACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,iBAAiB;MACvE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SACE,eACA,SACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,iBAAiB,OAAO,IAAI;MACjF,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;;EAMA,OACE,eACA,SACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,iBAAiB,OAAO,WAAW;MACzF,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,MAAM,cACJ,eACA,MACA,SAA2D;AAE3D,UAAM,QAAQ,MAAM,KAAK,OAAO,eAAe,IAAI;AACnD,WAAO,MAAM,KAAK,KAAK,eAAe,MAAM,IAAI,OAAO;EACzD;EAgBA,UACE,eACA,SACA,QAAwD,CAAA,GACxD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,UAAU,eAAe,SAAS,CAAA,GAAI,KAAK;;AAEzD,WAAO,KAAK,QAAQ,WAClB,kBAAkB,aAAa,iBAAiB,OAAO,UACvD,sBACA,EAAE,OAAO,GAAG,SAAS,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO,EAAE,CAAE;EAE3F;;;;;;;EAQA,MAAM,KACJ,eACA,SACA,SAA2D;AAE3D,UAAM,UAAqC,EAAE,GAAG,SAAS,SAAS,2BAA2B,OAAM;AACnG,QAAI,SAAS,gBAAgB;AAC3B,cAAQ,kCAAkC,IAAI,QAAQ,eAAe,SAAQ;;AAG/E,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,OAAO,SAAQ,IAAK,MAAM,KAAK,SAAS,eAAe,SAAS;QAC5E,GAAG;QACH;OACD,EAAE,aAAY;AAEf,cAAQ,MAAM,QAAQ;QACpB,KAAK;AACH,cAAI,gBAAgB;AAEpB,cAAI,SAAS,gBAAgB;AAC3B,4BAAgB,QAAQ;iBACnB;AACL,kBAAM,iBAAiB,SAAS,QAAQ,IAAI,sBAAsB;AAClE,gBAAI,gBAAgB;AAClB,oBAAM,mBAAmB,SAAS,cAAc;AAChD,kBAAI,CAAC,MAAM,gBAAgB,GAAG;AAC5B,gCAAgB;;;;AAItB,gBAAM,MAAM,aAAa;AACzB;QACF,KAAK;QACL,KAAK;QACL,KAAK;AACH,iBAAO;;;EAGf;;;;;;EAOA,MAAM,cACJ,eACA,EAAE,OAAO,UAAU,CAAA,EAAE,GACrB,SAAoF;AAEpF,QAAI,SAAS,QAAQ,MAAM,UAAU,GAAG;AACtC,YAAM,IAAI,MACR,gHAAgH;;AAIpH,UAAM,wBAAwB,SAAS,kBAAkB;AAGzD,UAAM,mBAAmB,KAAK,IAAI,uBAAuB,MAAM,MAAM;AAErE,UAAM,SAAS,KAAK;AACpB,UAAM,eAAe,MAAM,OAAM;AACjC,UAAM,aAAuB,CAAC,GAAG,OAAO;AAIxC,mBAAe,aAAa,UAAsC;AAChE,eAAS,QAAQ,UAAU;AACzB,cAAM,UAAU,MAAM,OAAO,MAAM,OAAO,EAAE,MAAM,MAAM,SAAS,aAAY,GAAI,OAAO;AACxF,mBAAW,KAAK,QAAQ,EAAE;;IAE9B;AAGA,UAAM,UAAU,MAAM,gBAAgB,EAAE,KAAK,YAAY,EAAE,IAAI,YAAY;AAG3E,UAAM,oBAAoB,OAAO;AAEjC,WAAO,MAAM,KAAK,cAAc,eAAe;MAC7C,UAAU;KACX;EACH;;;;ACvKI,IAAO,eAAP,cAA4B,YAAW;EAA7C,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;AACvD,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EAqEvF;;;;EAhEE,OAAO,MAA+B,SAA6B;AACjE,WAAO,KAAK,QAAQ,KAAK,kBAAkB;MACzC;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,SAAS,eAAuB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,IAAI,kBAAkB,aAAa,IAAI;MACzD,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,OACE,eACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,kBAAkB,aAAa,IAAI;MAC1D;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;EAUA,KACE,QAAqD,CAAA,GACrD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,kBAAkB,kBAAkB;MACjE;MACA,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;;;EAKA,IAAI,eAAuB,SAA6B;AACtD,WAAO,KAAK,QAAQ,OAAO,kBAAkB,aAAa,IAAI;MAC5D,GAAG;MACH,SAAS,EAAE,eAAe,iBAAiB,GAAG,SAAS,QAAO;KAC/D;EACH;;AAGI,IAAO,mBAAP,cAAgC,WAAuB;;AAkS7D,aAAa,mBAAmB;AAChC,aAAa,QAAQ;AACrB,aAAa,uBAAuB;AACpC,aAAa,cAAc;;;AC1UrB,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,eAA6C,IAAoB,aAAa,KAAK,OAAO;AAC1F,SAAA,OAAqB,IAAYS,MAAK,KAAK,OAAO;AAClD,SAAA,aAAuC,IAAkB,WAAW,KAAK,OAAO;AAChF,SAAA,UAA8B,IAAe,QAAQ,KAAK,OAAO;EACnE;;AAEA,KAAK,eAAe;AACpB,KAAK,mBAAmB;AACxB,KAAK,aAAa;AAClB,KAAK,iBAAiB;AACtB,KAAK,UAAU;;;AC7DT,IAAOC,eAAP,cAA2B,YAAW;EAa1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAG,SAAS,QAAQ,KAAK,UAAU,MAAK,CAAE;EAG7F;;;;ACxBI,IAAO,aAAP,cAA0B,YAAW;;;;EAIzC,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,eAAe,EAAE,MAAM,GAAG,QAAO,CAAE;EAC9D;;;;ACJI,IAAOC,SAAP,cAAqB,YAAW;;;;;;;;;;;;;;;;;;;;;;;;EAwBpC,OAAO,MAAwB,SAA6B;AAC1D,WAAO,KAAK,QAAQ,KAAK,UAAe,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAC3F;;;;EAKA,SAAS,QAAgB,SAA6B;AACpD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,IAAI,OAAO;EACrD;EAOA,KACE,QAA8C,CAAA,GAC9C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,UAAU,iBAAiB,EAAE,OAAO,GAAG,QAAO,CAAE;EACjF;;;;EAKA,IAAI,QAAgB,SAA6B;AAC/C,WAAO,KAAK,QAAQ,OAAO,UAAU,MAAM,IAAI,OAAO;EACxD;;;;EAKA,QAAQ,QAAgB,SAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAY,EAAE,GAAG,SAAS,kBAAkB,KAAI,CAAE;EAC5F;;;;;;EAOA,gBAAgB,QAAgB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,IAAI,UAAU,MAAM,YAAY;MAClD,GAAG;MACH,SAAS,EAAE,QAAQ,oBAAoB,GAAG,SAAS,QAAO;KAC3D;EACH;;;;EAKA,MAAM,kBACJ,IACA,EAAE,eAAe,KAAM,UAAU,KAAK,KAAK,IAAI,IAAkD,CAAA,GAAE;AAEnG,UAAM,kBAAkB,oBAAI,IAAI,CAAC,aAAa,SAAS,SAAS,CAAC;AAEjE,UAAM,QAAQ,KAAK,IAAG;AACtB,QAAI,OAAO,MAAM,KAAK,SAAS,EAAE;AAEjC,WAAO,CAAC,KAAK,UAAU,CAAC,gBAAgB,IAAI,KAAK,MAAM,GAAG;AACxD,YAAM,MAAM,YAAY;AAExB,aAAO,MAAM,KAAK,SAAS,EAAE;AAC7B,UAAI,KAAK,IAAG,IAAK,QAAQ,SAAS;AAChC,cAAM,IAAI,0BAA0B;UAClC,SAAS,iCAAiC,EAAE,+BAA+B,OAAO;SACnF;;;AAIL,WAAO;EACT;;AAGI,IAAO,kBAAP,cAA+B,WAAsB;;AAgH3DA,OAAM,kBAAkB;;;AC1NlB,IAAO,cAAP,cAA2B,YAAW;EAa1C,KACE,iBACA,QAAoD,CAAA,GACpD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,iBAAiB,CAAA,GAAI,KAAK;;AAE7C,WAAO,KAAK,QAAQ,WAClB,qBAAqB,eAAe,gBACpC,8BACA,EAAE,OAAO,GAAG,QAAO,CAAE;EAEzB;;AAGI,IAAO,+BAAP,cAA4C,WAAmC;;AAkErF,YAAY,+BAA+B;;;ACxFrC,IAAO,OAAP,cAAoB,YAAW;EAArC,cAAA;;AACE,SAAA,cAA0C,IAAmB,YAAY,KAAK,OAAO;EA0EvF;;;;;;;;;;EA/DE,OAAO,MAAuB,SAA6B;AACzD,WAAO,KAAK,QAAQ,KAAK,qBAAqB,EAAE,MAAM,GAAG,QAAO,CAAE;EACpE;;;;;;EAOA,SAAS,iBAAyB,SAA6B;AAC7D,WAAO,KAAK,QAAQ,IAAI,qBAAqB,eAAe,IAAI,OAAO;EACzE;EAUA,KACE,QAA6C,CAAA,GAC7C,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,KAAK,CAAA,GAAI,KAAK;;AAE5B,WAAO,KAAK,QAAQ,WAAW,qBAAqB,oBAAoB,EAAE,OAAO,GAAG,QAAO,CAAE;EAC/F;;;;EAKA,OAAO,iBAAyB,SAA6B;AAC3D,WAAO,KAAK,QAAQ,KAAK,qBAAqB,eAAe,WAAW,OAAO;EACjF;EAcA,WACE,iBACA,QAAmD,CAAA,GACnD,SAA6B;AAE7B,QAAI,iBAAiB,KAAK,GAAG;AAC3B,aAAO,KAAK,WAAW,iBAAiB,CAAA,GAAI,KAAK;;AAEnD,WAAO,KAAK,QAAQ,WAAW,qBAAqB,eAAe,WAAW,yBAAyB;MACrG;MACA,GAAG;KACJ;EACH;;AAGI,IAAO,qBAAP,cAAkC,WAAyB;;AAE3D,IAAO,0BAAP,cAAuC,WAA8B;;AAuW3E,KAAK,qBAAqB;AAC1B,KAAK,0BAA0B;AAC/B,KAAK,cAAc;AACnB,KAAK,+BAA+B;;;ACrb9B,IAAO,aAAP,cAA0B,YAAW;EAA3C,cAAA;;AACE,SAAA,OAAqB,IAAY,KAAK,KAAK,OAAO;EACpD;;AAEA,WAAW,OAAO;AAClB,WAAW,qBAAqB;AAChC,WAAW,0BAA0B;;;ACnB/B,IAAO,SAAP,cAAsB,YAAW;;;;EAIrC,gBACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,sBAA2B,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EACvG;;;;EAKA,KAAK,MAAuB,SAA6B;AACvD,WAAO,KAAK,QAAQ,KAAK,iBAAsB,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAClG;;;;EAKA,SAAS,MAA2B,SAA6B;AAC/D,WAAO,KAAK,QAAQ,KAAK,uBAAuB,EAAE,MAAM,GAAG,QAAO,CAAE;EACtE;;;;ACtBI,IAAO,SAAP,cAAsB,YAAW;;;;;EAKrC,SAAS,OAAe,SAA6B;AACnD,WAAO,KAAK,QAAQ,IAAI,WAAW,KAAK,IAAI,OAAO;EACrD;;;;;EAMA,KAAK,SAA6B;AAChC,WAAO,KAAK,QAAQ,WAAW,WAAW,YAAY,OAAO;EAC/D;;;;;EAMA,IAAI,OAAe,SAA6B;AAC9C,WAAO,KAAK,QAAQ,OAAO,WAAW,KAAK,IAAI,OAAO;EACxD;;AAMI,IAAO,aAAP,cAA0BC,MAAW;;AAmC3C,OAAO,aAAa;;;ACjEd,IAAO,cAAP,cAA2B,YAAW;;;;;EAK1C,OACE,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,gBAAgB,EAAE,MAAM,GAAG,QAAO,CAAE;EAC/D;;;;ACVI,IAAO,QAAP,cAAqB,YAAW;;;;;;;;;;;;;;EAcpC,OACE,UACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAClB,YAAY,QAAQ,UACf,4BAA4B,EAAE,MAAM,GAAG,QAAO,CAAE,CAAC;EAE1D;;;;ACpBI,IAAO,UAAP,cAAuB,YAAW;EAAxC,cAAA;;AACE,SAAA,QAAwB,IAAa,MAAM,KAAK,OAAO;EAyDzD;;;;;;;;;;;;;;;;;;;;;;;EAjCE,OAAO,MAA0B,SAA6B;AAC5D,WAAO,KAAK,QAAQ,KAAK,YAAY,EAAE,MAAM,GAAG,QAAO,CAAE;EAC3D;;;;EAKA,OAAO,UAAkB,SAA6B;AACpD,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,WAAW,OAAO;EACjE;;;;;;;;;;;;;;;;EAiBA,SACE,UACA,MACA,SAA6B;AAE7B,WAAO,KAAK,QAAQ,KAAK,YAAY,QAAQ,aAAa,EAAE,MAAM,GAAG,QAAO,CAAE;EAChF;;AAgGF,QAAQ,QAAQ;;;;AC4BV,IAAO,SAAP,cAA2B,UAAS;;;;;;;;;;;;;;;;EAsBxC,YAAY,EACV,UAAe,QAAQ,iBAAiB,GACxC,SAAc,QAAQ,gBAAgB,GACtC,eAAoB,QAAQ,eAAe,KAAK,MAChD,UAAe,QAAQ,mBAAmB,KAAK,MAC/C,GAAG,KAAI,IACU,CAAA,GAAE;AACnB,QAAI,WAAW,QAAW;AACxB,YAAM,IAAW,YACf,oLAAoL;;AAIxL,UAAM,UAAyB;MAC7B;MACA;MACA;MACA,GAAG;MACH,SAAS,WAAW;;AAGtB,QAAI,CAAC,QAAQ,2BAAgC,mBAAkB,GAAI;AACjE,YAAM,IAAW,YACf,obAAob;;AAIxb,UAAM;MACJ,SAAS,QAAQ;MACjB,SAAS,QAAQ,WAAW;MAC5B,WAAW,QAAQ;MACnB,YAAY,QAAQ;MACpB,OAAO,QAAQ;KAChB;AASH,SAAA,cAA+B,IAAQC,aAAY,IAAI;AACvD,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAClC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,QAAmB,IAAQC,OAAM,IAAI;AACrC,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,QAAmB,IAAQ,MAAM,IAAI;AACrC,SAAA,cAA+B,IAAQ,YAAY,IAAI;AACvD,SAAA,SAAqB,IAAQ,OAAO,IAAI;AACxC,SAAA,aAA6B,IAAQ,WAAW,IAAI;AACpD,SAAA,OAAiB,IAAQ,KAAK,IAAI;AAClC,SAAA,UAAuB,IAAQ,QAAQ,IAAI;AAC3C,SAAA,UAAuB,IAAQ,QAAQ,IAAI;AAlBzC,SAAK,WAAW;AAEhB,SAAK,SAAS;AACd,SAAK,eAAe;AACpB,SAAK,UAAU;EACjB;EAemB,eAAY;AAC7B,WAAO,KAAK,SAAS;EACvB;EAEmB,eAAe,MAA8B;AAC9D,WAAO;MACL,GAAG,MAAM,eAAe,IAAI;MAC5B,uBAAuB,KAAK;MAC5B,kBAAkB,KAAK;MACvB,GAAG,KAAK,SAAS;;EAErB;EAEmB,YAAY,MAA8B;AAC3D,WAAO,EAAE,eAAe,UAAU,KAAK,MAAM,GAAE;EACjD;EAEmB,eAAe,OAA8B;AAC9D,WAAU,UAAU,OAAO,EAAE,aAAa,WAAU,CAAE;EACxD;;;AAEO,OAAA,SAAS;AACT,OAAA,kBAAkB;AAElB,OAAA,cAAqB;AACrB,OAAA,WAAkB;AAClB,OAAA,qBAA4B;AAC5B,OAAA,4BAAmC;AACnC,OAAA,oBAA2B;AAC3B,OAAA,gBAAuB;AACvB,OAAA,gBAAuB;AACvB,OAAA,iBAAwB;AACxB,OAAA,kBAAyB;AACzB,OAAA,sBAA6B;AAC7B,OAAA,sBAA6B;AAC7B,OAAA,wBAA+B;AAC/B,OAAA,2BAAkC;AAElC,OAAA,SAAiB;AACjB,OAAA,eAAuB;AAGhC,OAAO,cAAcD;AACrB,OAAO,OAAO;AACd,OAAO,aAAa;AACpB,OAAO,QAAQC;AACf,OAAO,kBAAkB;AACzB,OAAO,SAAS;AAChB,OAAO,QAAQ;AACf,OAAO,cAAc;AACrB,OAAO,SAAS;AAChB,OAAO,aAAa;AACpB,OAAO,aAAa;AACpB,OAAO,OAAO;AACd,OAAO,UAAU;AACjB,OAAO,cAAc;AACrB,OAAO,UAAU;AAqVjB,IAAA,iBAAe;;;AhE1oBf,OAAOC,SAAQ;AACf,OAAOC,WAAU;AACjB,SAAS,iBAAAC,sBAAqB;AAC9B,SAAS,iBAAiB;;;AiEhBpB,IAAO,gBAAP,cAA6B,MAAK;EAGtC,YAAY,SAAe;AACzB,UAAM,OAAO;AAHL,SAAA,YAAY;AAIpB,SAAK,OAAO;EACd;;AAGI,SAAU,gBAAgB,OAAc;AAC5C,SAAO,OAAO,UAAU,YAAY,UAAU,QAAQ,eAAe;AACvE;AAEM,IAAO,mBAAP,cAAgC,cAAa;EAGjD,YAAY,SAAiB,QAAc;AACzC,UAAM,OAAO;AACb,SAAK,OAAO;AACZ,SAAK,SAAS;EAChB;EAEA,SAAM;AACJ,WAAO;MACL,MAAM,KAAK;MACX,SAAS,KAAK;MACd,QAAQ,KAAK;;EAEjB;;AAGI,IAAO,uBAAP,cAAoC,cAAa;EAGrD,YAAY,SAAiB,eAAsB;AACjD,UAAM,OAAO;AACb,SAAK,OAAO;AACZ,SAAK,gBAAgB;EACvB;;AAGI,IAAO,uBAAP,cAAoC,cAAa;EACrD,cAAA;AACE,UACE,wGAAwG;AAG1G,SAAK,OAAO;EACd;;;;AChDF,SAAS,oBAAoB;;;ACU7B,yBAA6C;AAE7C,uBAAkB;AAOX,IAAM,YAAY,MAAM,kBAAkB;AAE1C,IAAM,SAAS,MAAM,iBAAiB;AAEtC,IAAM,QAAQ,MAAM,gBAAgB;AAErC,SAAU,cAAoB,UAAsB,CAAA,GAAI,cAA0B,CAAA,GAAE;AACxF,aAAO,iBAAAC,SAAM,aAAa,OAAO;AACnC;AAEM,SAAU,mBACd,cACA,SAAgC;AAEhC,SAAO,KAAK,OAAO,EAAE,QAAQ,CAAC,MAAK;AACjC,QAAI,MAAM,QAAQ,QAAQ,CAAC,CAAC,GAAG;AAC7B,YAAM,cAAc,QAAQ,CAAC;AAC7B,kBAAY,QAAQ,CAAC,UAAS;AAC5B,qBAAa,OAAO,GAAG,OAAO,KAAK,CAAC;MACtC,CAAC;WACI;AACL,mBAAa,OAAO,GAAG,OAAO,QAAQ,CAAC,CAAC,CAAC;;EAE7C,CAAC;AACH;AAEO,IAAM,4BAA4B,MAAK;AAC5C,MAAI,OAAO,YAAY,aAAa;AAClC,WAAO,mBAAAC;;AAGT,SAAO;AACT;AAEO,IAAM,cAAc,CACzB,mBAC+B;AAC/B,MAAK,eAA6B;AAAK,WAAO;AAE9C,SAAO;AACT;AAEO,IAAM,eAAe,CAC1B,mBACgC;AAChC,MAAK,eAA8B;AAAM,WAAO;AAEhD,SAAO;AACT;AAEO,IAAM,eAAe,CAAC,mBAAmE;AAC9F,MAAI,mBAAmB,cAAc,KAAK,eAAe,cAAc;AAAG,WAAO;AAEjF,SAAO;AACT;AAEA,IAAM,iBAAiB,CAAC,mBAA+D;AACrF,MAAI;AAA0B,WAAO;AAErC,SAAO;AACT;AAEA,IAAM,qBAAqB,CAAC,mBAAiE;AAC3F,MAAI;AAA4B,WAAO;AAEvC,SAAO;AACT;AAMO,IAAM,sBAAsB,CAAC,QAAe;AACjD,QAAM,UAAU,CAAC,WAAmB,OAAO,YAAW,EAAG,QAAQ,SAAS,IAAI;AAE9E,SAAO,QAAQ,GAAG;AACpB;AAqBO,IAAM,uBAAuB,CAAC,eAA4D;;AAC/F,QAAM,aAAoC,CAAA;AAE1C,MAAI,WAAW,0BAA0B;AACvC,eAAW,SAAS;MAClB,OAAO;QACL,QAAQ,WAAW;;;;AAKzB,mBAAa,iBAAAC,SAAM,YAAY,UAAU;AAEzC,OAAIC,MAAA,WAAW,eAAS,QAAAA,QAAA,SAAA,SAAAA,IAAE,KAAK;AAC7B,eAAW,SAAS;MAClB,OAAO;QACL,SAAS;UACP,OAAO;YACL,MAAK,KAAA,WAAW,eAAS,QAAA,OAAA,SAAA,SAAA,GAAE;;;;;;AAOrC,mBAAa,iBAAAD,SAAM,YAAY,UAAU;AAEzC,OAAI,KAAA,WAAW,YAAM,QAAA,OAAA,SAAA,SAAA,GAAE,KAAK;AAC1B,eAAW,SAAS;MAClB,OAAO;QACL,SAAS;UACP,KAAK,WAAW,OAAO;;;MAG3B,WAAW;QACT,SAAS;UACP,KAAK,WAAW,OAAO;;;;;AAM/B,mBAAa,iBAAAA,SAAM,YAAY,UAAU;AAEzC,OAAI,KAAA,WAAW,YAAM,QAAA,OAAA,SAAA,SAAA,GAAE,SAAS;AAC9B,eAAW,SAAS;MAClB,OAAO;QACL,SAAS;UACP,UAAS,KAAA,WAAW,YAAM,QAAA,OAAA,SAAA,SAAA,GAAE;;;MAGhC,WAAW;QACT,SAAS;UACP,mBAAkB,KAAA,WAAW,YAAM,QAAA,OAAA,SAAA,SAAA,GAAE;;;;;AAM7C,mBAAa,iBAAAA,SAAM,YAAY,UAAU;AAEzC,SAAO;AACT;;;AClLO,IAAM,UAAU;;;ACIhB,IAAM,eACX,OAAO,YAAY,eAAe,QAAQ,YAAY,QAAQ,SAAS,OACnE,QAAQ,SAAS,OACjB;AAEC,IAAM,cACX,OAAO,YAAY,eAAe,QAAQ,YAAY,QAAQ,SAAS,MACnE,QAAQ,SAAS,MACjB;AAEC,IAAM,gBACX,OAAO,WAAW,eAAe,OAAO,aAAa,OAAO,UAAU,YAClE,OAAO,UAAU,YACjB;AAEN,IAAM,WAAW,MAAK;AACpB,MAAI,OAAM,GAAI;AACZ,WAAO,QAAQ,YAAY;aAClB,MAAK,GAAI;AAClB,WAAO,OAAO,WAAW;aAChB,UAAS,GAAI;AACtB,WAAO,cAAc,aAAa;SAC7B;AACL,WAAO;;AAEX;AAEO,IAAM,kBAAkB;EAC7B,gBAAgB;EAChB,iBAAiB,kBAAkB,UAAS,IAAK,YAAY,QAAQ,MAAM,OAAO;EAClF,cAAc,iBAAiB,OAAO,IAAI,SAAQ,CAAE;;AAG/C,IAAM,cAAc;AAEpB,IAAM,yBAA2D;EACtE,OAAO,EAAE,SAAS,EAAE,KAAK,aAAa,SAAS,gBAAe,EAAE;EAChE,WAAW;IACT,SAAS,EAAE,KAAK,oBAAoB,WAAW,GAAG,kBAAkB,gBAAe;;;AAIhF,IAAM,kBAAwC;EACnD,QAAQ;;AAGV,IAAY;CAAZ,SAAYE,gBAAa;AACvB,EAAAA,eAAAA,eAAA,YAAA,IAAA,CAAA,IAAA;AACA,EAAAA,eAAAA,eAAA,MAAA,IAAA,CAAA,IAAA;AACA,EAAAA,eAAAA,eAAA,SAAA,IAAA,CAAA,IAAA;AACA,EAAAA,eAAAA,eAAA,QAAA,IAAA,CAAA,IAAA;AACF,GALY,kBAAA,gBAAa,CAAA,EAAA;AAOzB,IAAY;CAAZ,SAAYC,mBAAgB;AAC1B,EAAAA,kBAAA,YAAA,IAAA;AACA,EAAAA,kBAAA,MAAA,IAAA;AACA,EAAAA,kBAAA,SAAA,IAAA;AACA,EAAAA,kBAAA,QAAA,IAAA;AACF,GALY,qBAAA,mBAAgB,CAAA,EAAA;;;AH9CrB,IAAM,OAAO,MAAK;AAAE;AAYrB,IAAgB,iBAAhB,cAAuC,aAAY;;;;;;;;;;;EAmBvD,YAAY,SAA8B;AACxC,UAAK;AAnBG,SAAA,UAAgC;AAGnC,SAAA,YAAoB;AACpB,SAAA,UAAkB;AAClB,SAAA,UAAkB;AAClB,SAAA,SAAmB;AAexB,QAAI;AAEJ,QAAI,OAAO,QAAQ,QAAQ,YAAY;AACrC,WAAK,UAAU,QAAQ;AACvB,YAAM,KAAK,QAAO;WACb;AACL,YAAM,QAAQ;;AAGhB,QAAI,CAAC,KAAK;AACR,YAAM,QAAQ,IAAI;;AAGpB,QAAI,CAAC,KAAK;AACR,YAAM,IAAI,cAAc,iCAAiC;;AAG3D,SAAK,MAAM;AAEX,cAAU,qBAAqB,OAAO;AAKtC,SAAK,UAAU,cACb,SACA,eAAe;EAEnB;;;;;;;EAQO,EAAEC,WAAkB,MAAI;AAC7B,SAAK,UAAUA;AAEf,WAAO;EACT;;;;;;;;EASA,IAAI,mBAAgB;AAClB,UAAMC,YAAW,cACd,KAAK,QAAgB,KAAK,SAAS,GACpC,KAAK,QAAQ,MAAM;AAGrB,WAAA,OAAA,OAAA,OAAA,OAAA,CAAA,GACKA,SAAQ,GAAA,EACX,KAAK,KAAK,IAAG,CAAA;EAEjB;;;;;;;;;EAUO,cACL,UACA,SAAoC,EAAE,SAAS,KAAK,QAAO,GAC3D,sBAEC;AAKD,WAAO,UAAU,KAAK;AAKtB,eAAW,SAAS,QAAQ,WAAW,SAAU,GAAG,KAAG;AACrD,aAAO,OAAQ,GAAG;IACpB,CAAC;AAKD,UAAM,MAAM,IAAI,IAAI,UAAoB,KAAK,OAAO;AAKpD,QAAI,sBAAsB;AACxB,yBAAmB,IAAI,cAAc,oBAAoB;;AAG3D,WAAO;EACT;;;;;;EAOO,IAAIC,OAAc,KAAa,MAAU;AAC9C,SAAK,OAAOA,OAAM,KAAK,IAAI;EAC7B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AIzGF,IAAM,6BAA6B,OAAO,cAAc;AASlD,IAAgB,qBAAhB,cAA2C,eAAc;EAM7D,YAAY,SAA8B;AACxC,UAAM,OAAO;AAJR,SAAA,OAA6B;AAC7B,SAAA,aAAyB,CAAA;AA8GzB,SAAA,YAA2C;AAzGhD,UAAM,EACJ,KACA,WAAW,EAAE,SAAS,kBAAkB,OAAM,EAAE,IAC9C,KAAK;AAET,QAAI,KAAK,OAAO;AACd,WAAK,UAAU,iBAAiB,MAAO;WAClC;AACL,WAAK,UAAU,iBAAiB;;AAGlC,QAAI,QAAQ;AACV,WAAK,YAAY;WACZ;AACL,WAAK,YAAY;;AAGnB,QAAI,iBAAiB,kBAAkB;AACrC,WAAK,UAAU,iBAAiB;WAC3B;AACL,WAAK,UAAU,CAAA;;AAGjB,QAAI,EAAE,mBAAmB,KAAK,UAAU;AACtC,WAAK,QAAQ,eAAe,IAAI,SAAS,GAAG;;EAEhD;;;;;;EAOU,QAAQ,sBAAkC,UAAgB;AAClE,QAAI,KAAK,MAAM;AACb;;AAGF,SAAK,YAAY,CAAC,UAAU,yBAAwB;AAClD,WAAK,QAAQ,SAAS,QAAQ;IAChC;AAEA,UAAM,aAAa,KAAK,cAAc,UAAU,CAAA,GAAI,oBAAoB;AAKxE,QAAI,KAAK,WAAW;AAClB,WAAK,OAAO,IAAI,KAAK,UAAU,YAAY,QAAW;QACpD,SAAS,KAAK;OACf;AACD;;AASF,QAAI,MAAK,GAAI;AACX,aAAO,uBAAI,EAAE,KAAK,CAAC,EAAE,SAAS,GAAE,MAAM;AACpC,aAAK,OAAO,IAAI,GAAG,YAAY;UAC7B,SAAS,KAAK;SACf;AACD,gBAAQ,IAAI,kBAAkB;AAC9B,aAAK,gBAAe;MACtB,CAAC;AACD;;AAMF,QAAI,4BAA4B;AAC9B,WAAK,OAAO,IAAI,UAAU,YAAY,CAAC,SAAS,KAAK,iBAAiB,GAAG,CAAC;AAC1E,WAAK,gBAAe;AACpB;;AAMF,SAAK,OAAO,IAAI,iBAAiB,YAAY,QAAW;MACtD,OAAO,MAAK;AACV,aAAK,OAAO;MACd;KACD;AAKD,WAAO,uBAAI,EAAE,KAAK,CAAC,EAAE,SAAS,GAAE,MAAM;AACpC,WAAK,OAAO,IAAI,GAAG,YAAY,QAAW;QACxC,SAAS,KAAK;OACf;AACD,WAAK,gBAAe;IACtB,CAAC;EACH;;;;;;;EAeO,WAAW,MAAe,QAAe;AAC9C,QAAI,KAAK,MAAM;AACb,WAAK,KAAK,UAAU,WAAA;MAAa;AACjC,UAAI,MAAM;AACR,aAAK,KAAK,MAAM,MAAM,WAAM,QAAN,WAAM,SAAN,SAAU,EAAE;aAC7B;AACL,aAAK,KAAK,MAAK;;AAEjB,WAAK,OAAO;;EAEhB;;;;;;EAOO,kBAAe;AACpB,YAAQ,KAAK,QAAQ,KAAK,KAAK,YAAY;MACzC,KAAK,cAAc;AACjB,eAAO,iBAAiB;MAC1B,KAAK,cAAc;AACjB,eAAO,iBAAiB;MAC1B,KAAK,cAAc;AACjB,eAAO,iBAAiB;MAC1B;AACE,eAAO,iBAAiB;;EAE9B;;;;;;EAOO,gBAAa;;AAClB,YAAO,MAAAC,MAAA,KAAK,UAAI,QAAAA,QAAA,SAAA,SAAAA,IAAE,gBAAU,QAAA,OAAA,SAAA,KAAI,cAAc;EAChD;;;;EAKO,cAAW;AAChB,WAAO,KAAK,gBAAe,MAAO,iBAAiB;EACrD;;;;;;;;EASA,KAAK,MAAoB;AACvB,UAAM,WAAW,MAAW,UAAA,MAAA,QAAA,QAAA,aAAA;;AAC1B,UAAI,gBAAgB,MAAM;AACxB,YAAI,KAAK,SAAS,GAAG;AACnB,eAAK,IAAI,QAAQ,sCAAsC,IAAI;AAE3D;;AAGF,eAAO,MAAM,KAAK,YAAW;;AAG/B,UAAI,OAAO,SAAS,UAAU;AAC5B,YAAI,KAAK,eAAe,GAAG;AACzB,eAAK,IAAI,QAAQ,sCAAsC,IAAI;AAE3D;;;AAIJ,OAAAA,MAAA,KAAK,UAAI,QAAAA,QAAA,SAAA,SAAAA,IAAE,KAAK,IAAI;IACtB,CAAC;AAED,QAAI,KAAK,YAAW,GAAI;AACtB,eAAQ;WACH;AACL,WAAK,WAAW,KAAK,QAAQ;;EAEjC;;;;;EAMA,IAAI,QAAK;;AACP,WAAO,KAAK,QAAQ,WAAW,CAAC,GAACA,MAAA,KAAK,iBAAiB,UAAU,QAAQ,WAAK,QAAAA,QAAA,SAAA,SAAAA,IAAE;EAClF;;AAUF,IAAM,mBAAN,MAAsB;EAWpB,YAAY,SAAc,YAAuB,SAA4B;AAV7E,SAAA,aAAqB;AAErB,SAAA,UAAoB,MAAK;IAAE;AAC3B,SAAA,UAAoB,MAAK;IAAE;AAC3B,SAAA,YAAsB,MAAK;IAAE;AAC7B,SAAA,SAAmB,MAAK;IAAE;AAC1B,SAAA,aAAqB,cAAc;AACnC,SAAA,OAAiB,MAAK;IAAE;AACxB,SAAA,MAA2B;AAGzB,SAAK,MAAM,QAAQ,SAAQ;AAC3B,SAAK,QAAQ,QAAQ;EACvB;;;;ACrSF,IAAAC,sBAAuB;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAShB,IAAM,eAAe,CAAC,gBAA8B;AACzD,MAAI;AAEJ,MAAI,aAAa;AACf,aAAS;aACA,OAAO,UAAU,aAAa;AACvC,aAAS,oBAAAC;SACJ;AACL,aAAS;;AAGX,SAAO,IAAI,SAAS,OAAO,GAAG,IAAI;AACpC;AASO,IAAM,gBAAgB,CAAC,QAAgB,gBAA8B;AAC1E,QAAMC,SAAQ,aAAa,WAAW;AACtC,QAAM,qBAAqB,0BAAyB;AAEpD,SAAO,CAAO,OAAO,SAAQC,WAAA,QAAA,QAAA,QAAA,aAAA;AAC3B,UAAM,UAAU,IAAI,mBAAmB,SAAI,QAAJ,SAAI,SAAA,SAAJ,KAAM,OAAO;AAEpD,QAAI,CAAC,QAAQ,IAAI,eAAe,GAAG;AACjC,cAAQ,IAAI,iBAAiB,SAAS,MAAM,EAAE;;AAGhD,WAAOD,OAAM,OAAK,OAAA,OAAA,OAAA,OAAA,CAAA,GAAO,IAAI,GAAA,EAAE,QAAO,CAAA,CAAA;EACxC,CAAC;AACH;AAOO,IAAM,kBAAkB,MAAWC,WAAA,QAAA,QAAA,QAAA,aAAA;AACxC,MAAI,OAAO,aAAa,aAAa;AACnC,YAAQ,MAAM,OAAO,6BAAa,GAAG;;AAGvC,SAAO;AACT,CAAC;;;AClDD,IAAAC,oBAAkB;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAMZ,IAAgB,qBAAhB,cAA2C,eAAc;;;;;;;EAS7D,YAAY,SAA8B;AACxC,UAAM,OAAO;AAEb,QAAI,UAAS,KAAM,CAAC,KAAK,OAAO;AAC9B,YAAM,IAAI,cACR,sKAAsK;;AAI1K,SAAK,QAAQ,cAAc,KAAK,KAAK,KAAK,iBAAiB,MAAM,MAAM;AAEvE,QAAI,KAAK,OAAO;AACd,WAAK,UAAU,KAAK,iBAAiB,MAAM,QAAQ,MAAO;WACrD;AACL,WAAK,UAAU,KAAK,iBAAiB,MAAM,QAAQ;;EAEvD;;;;;;;EAQU,iBAAiB,KAAQ;AACjC,WAAO,IAAI,OAAO,IAAI,WAAW,IAAI,qBAAqB,IAAI,SAAS,KAAK,UAAU,GAAG;EAC3F;;;;;;;;EASgB,aAAa,OAAgB,QAA8B;;AACzE,YAAM,MAAM,MAAM,gBAAe;AAEjC,UAAI,iBAAiB,KAAK;AACxB,cACG,KAAI,EACJ,KAAK,CAAC,QAAO;AACZ,iBAAO,IAAI,iBAAiB,KAAK,iBAAiB,GAAG,GAAG,MAAM,UAAU,GAAG,CAAC;QAC9E,CAAC,EACA,MAAM,CAAC,QAAO;AACb,iBAAO,IAAI,qBAAqB,KAAK,iBAAiB,GAAG,GAAG,GAAG,CAAC;QAClE,CAAC;aACE;AACL,eAAO,IAAI,qBAAqB,KAAK,iBAAiB,KAAK,GAAG,KAAK,CAAC;;IAExE,CAAC;;;;;;;;;;EAUS,mBACR,QACA,eACA,SAAsB;AAEtB,QAAI,aAA2B,EAAE,OAAM;AAEvC,QAAI,WAAW,SAAS,WAAW,UAAU;AAC3C,mBAAU,OAAA,OAAA,OAAA,OAAA,CAAA,GAAQ,UAAU,GAAM,aAA8B;WAC3D;AACL,mBAAU,OAAA,OAAA,OAAA,OAAA,EACR,QAAQ,QACR,MAAM,cAAyB,GAC5B,UAAU,GACV,OAAO;;AAId,eAAO,kBAAAC,SAAM,KAAK,iBAAiB,MAAM,SAAS,YAAY,EAAE,OAAO,MAAK,CAAE;EAChF;EAsBgB,eACd,QACA,KACA,eACA,SAAsB;;AAEtB,aAAO,IAAI,QAAQ,CAAC,SAAS,WAAU;AACrC,cAAM,UAAU,KAAK;AAErB,gBAAQ,KAAK,KAAK,mBAAmB,QAAQ,eAAe,OAAO,CAAC,EACjE,KAAK,CAAC,WAAU;AACf,cAAI,CAAC,OAAO;AAAI,kBAAM;AACtB,kBAAQ,MAAM;QAChB,CAAC,EACA,MAAM,CAAC,UAAU,KAAK,aAAa,OAAO,MAAM,CAAC;MACtD,CAAC;IACH,CAAC;;;;;;;;;EASe,IAAI,KAAU,SAAsB;;AAClD,aAAO,KAAK,eAAe,OAAO,KAAK,OAAO;IAChD,CAAC;;;;;;;;;;EAUe,KACd,KACA,MACA,SAAsB;;AAEtB,aAAO,KAAK,eAAe,QAAQ,KAAK,MAAM,OAAO;IACvD,CAAC;;;;;;;;;;EAUe,IACd,KACA,MACA,SAAsB;;AAEtB,aAAO,KAAK,eAAe,OAAO,KAAK,MAAM,OAAO;IACtD,CAAC;;;;;;;;;;EAUe,MACd,KACA,MACA,SAAsB;;AAEtB,aAAO,KAAK,eAAe,SAAS,KAAK,MAAM,OAAO;IACxD,CAAC;;;;;;;;;EASe,OAAO,KAAU,SAAsB;;AACrD,aAAO,KAAK,eAAe,UAAU,KAAK,OAAO;IACnD,CAAC;;;;;;EAMD,IAAI,QAAK;;AACP,WAAO,KAAK,QAAQ,WAAW,CAAC,GAACC,MAAA,KAAK,iBAAiB,MAAM,QAAQ,WAAK,QAAAA,QAAA,SAAA,SAAAA,IAAE;EAC9E;;;;AC7MF,IAAY;CAAZ,SAAYC,0BAAuB;AAIjC,EAAAA,yBAAA,MAAA,IAAA;AACA,EAAAA,yBAAA,OAAA,IAAA;AACA,EAAAA,yBAAA,OAAA,IAAA;AAKA,EAAAA,yBAAA,YAAA,IAAA;AACA,EAAAA,yBAAA,UAAA,IAAA;AACA,EAAAA,yBAAA,cAAA,IAAA;AACA,EAAAA,yBAAA,eAAA,IAAA;AAKA,EAAAA,yBAAA,WAAA,IAAA;AACF,GApBY,4BAAA,0BAAuB,CAAA,EAAA;;;ACDnC,IAAY;CAAZ,SAAYC,gBAAa;AAIvB,EAAAA,eAAA,MAAA,IAAA;AACA,EAAAA,eAAA,OAAA,IAAA;AACA,EAAAA,eAAA,OAAA,IAAA;AAKA,EAAAA,eAAA,UAAA,IAAA;AACA,EAAAA,eAAA,SAAA,IAAA;AACA,EAAAA,eAAA,SAAA,IAAA;AAKA,EAAAA,eAAA,OAAA,IAAA;AAKA,EAAAA,eAAA,WAAA,IAAA;AACF,GAxBY,kBAAA,gBAAa,CAAA,EAAA;;;ACQnB,IAAO,mBAAP,cAAgC,mBAAkB;;;;;;;;EAUtD,YACE,SACA,uBAAmC,CAAA,GACnC,WAAmB,mBAAiB;AAEpC,UAAM,OAAO;AAdR,SAAA,YAAoB;AAgBzB,SAAK,QAAQ,sBAAsB,QAAQ;EAC7C;;;;;;;;;EAUO,kBAAe;AACpB,QAAI,KAAK,MAAM;AACb,WAAK,KAAK,SAAS,MAAK;AACtB,aAAK,KAAK,wBAAwB,MAAM,IAAI;MAC9C;AAEA,WAAK,KAAK,UAAU,CAAC,UAAc;AACjC,aAAK,KAAK,wBAAwB,OAAO,KAAK;MAChD;AAEA,WAAK,KAAK,UAAU,CAAC,UAAqB;AACxC,aAAK,KAAK,wBAAwB,OAAO,KAAK;MAChD;AAEA,WAAK,KAAK,YAAY,CAAC,UAAuB;AAC5C,YAAI;AACF,gBAAM,OAAY,KAAK,MAAM,MAAM,KAAK,SAAQ,CAAE;AAElD,cAAI,KAAK,SAAS,wBAAwB,UAAU;AAClD,iBAAK,KAAK,wBAAwB,UAAU,IAAI;qBACvC,KAAK,SAAS,wBAAwB,YAAY;AAC3D,iBAAK,KAAK,wBAAwB,YAAY,IAAI;qBACzC,KAAK,SAAS,wBAAwB,cAAc;AAC7D,iBAAK,KAAK,wBAAwB,cAAc,IAAI;qBAC3C,KAAK,SAAS,wBAAwB,eAAe;AAC9D,iBAAK,KAAK,wBAAwB,eAAe,IAAI;iBAChD;AACL,iBAAK,KAAK,wBAAwB,WAAW,IAAI;;iBAE5C,OAAO;AACd,eAAK,KAAK,wBAAwB,OAAO;YACvC;YACA,SAAS;YACT;WACD;;MAEL;;EAEJ;;;;;;;EAQO,UAAU,QAAyB;AACxC,SAAK,KACH,KAAK,UAAU;MACb,MAAM;MACN,YAAY;KACb,CAAC;EAEN;;;;EAKO,YAAS;AACd,SAAK,KACH,KAAK,UAAU;MACb,MAAM;KACP,CAAC;EAEN;;;;EAKO,WAAQ;AACb,SAAK,KACH,KAAK,UAAU;MACb,MAAM;KACP,CAAC;EAEN;;;;EAKO,SAAM;AACX,SAAK,aAAY;EACnB;;;;EAKO,eAAY;AACjB,SAAK,KACH,KAAK,UAAU;MACb,MAAM;KACP,CAAC;EAEN;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrHI,IAAO,mBAAP,cAAgC,mBAAkB;EAAxD,cAAA;;AACS,SAAA,YAAoB;EA6K7B;;;;;;;;;EAnKQ,cACJ,QACA,SACA,WAAW,mBAAiB;;AAE5B,UAAI;AACF,YAAI;AAEJ,YAAI,YAAY,MAAM,GAAG;AACvB,iBAAO,KAAK,UAAU,MAAM;eACvB;AACL,gBAAM,IAAI,cAAc,mCAAmC;;AAG7D,YAAI,YAAY,UAAa,cAAc,SAAS;AAClD,gBAAM,IAAI,cACR,2IAA2I;;AAI/I,cAAM,aAAa,KAAK,cAAc,UAAU,CAAA,GAAE,OAAA,OAAO,CAAA,GAAO,OAAO,CAAA;AACvE,cAAM,SAAkC,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACC,YAC9EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,eACJ,QACA,SACA,WAAW,mBAAiB;;AAE5B,UAAI;AACF,YAAI;AAEJ,YAAI,aAAa,MAAM,GAAG;AACxB,iBAAO;eACF;AACL,gBAAM,IAAI,cAAc,mCAAmC;;AAG7D,YAAI,YAAY,UAAa,cAAc,SAAS;AAClD,gBAAM,IAAI,cACR,2IAA2I;;AAI/I,cAAM,aAAa,KAAK,cAAc,UAAU,CAAA,GAAE,OAAA,OAAO,CAAA,GAAO,OAAO,CAAA;AACvE,cAAM,SAAkC,MAAM,KAAK,KAAK,YAAY,MAAM;UACxE,SAAS,EAAE,gBAAgB,uBAAsB;SAClD,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAEjC,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,sBACJ,QACA,UACA,SACA,WAAW,mBAAiB;;AAE5B,UAAI;AACF,YAAI;AAEJ,YAAI,YAAY,MAAM,GAAG;AACvB,iBAAO,KAAK,UAAU,MAAM;eACvB;AACL,gBAAM,IAAI,cAAc,mCAAmC;;AAG7D,cAAM,aAAa,KAAK,cACtB,UACA,CAAA,GAAE,OAAA,OAAA,OAAA,OAAA,CAAA,GACG,OAAO,GAAA,EAAE,UAAU,SAAS,SAAQ,EAAE,CAAA,CAAA;AAE7C,cAAM,SAAmC,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACA,YAC/EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,uBACJ,QACA,UACA,SACA,WAAW,mBAAiB;;AAE5B,UAAI;AACF,YAAI;AAEJ,YAAI,aAAa,MAAM,GAAG;AACxB,iBAAO;eACF;AACL,gBAAM,IAAI,cAAc,mCAAmC;;AAG7D,cAAM,aAAa,KAAK,cACtB,UACA,CAAA,GAAE,OAAA,OAAA,OAAA,OAAA,CAAA,GACG,OAAO,GAAA,EAAE,UAAU,SAAS,SAAQ,EAAE,CAAA,CAAA;AAE7C,cAAM,SAAmC,MAAM,KAAK,KAAK,YAAY,MAAM;UACzE,SAAS,EAAE,gBAAgB,uBAAsB;SAClD,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAEjC,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;ACxLG,IAAO,eAAP,cAA4B,eAAc;EAAhD,cAAA;;AACS,SAAA,YAAoB;EAqB7B;;;;EAhBE,IAAI,cAAW;AACb,WAAO,IAAI,iBAAiB,KAAK,OAAO;EAC1C;;;;;;;EAQO,KACL,uBAAmC,CAAA,GACnC,WAAmB,mBAAiB;AAEpC,WAAO,IAAI,iBAAiB,KAAK,SAAS,sBAAsB,QAAQ;EAC1E;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC4DI,IAAO,mBAAP,cAAgC,mBAAkB;EAAxD,cAAA;;AACS,SAAA,YAAoB;EAyuB7B;;;;;;;EAjuBQ,gBACJ,WAAW,uBAAqB;;AAEhC,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,QAAQ;AAC9C,cAAM,SAAkC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACC,YACvEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;EASK,YACJ,WAAW,qBAAmB;;AAE9B,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,QAAQ;AAC9C,cAAM,SAA8B,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YACnEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,WACJ,WACA,WAAW,gCAA8B;;AAEzC,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,SAA6B,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAE5F,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,cACJ,WACA,SACA,WAAW,gCAA8B;;AAEzC,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,GAAI,OAAO;AACtE,cAAM,OAAO,KAAK,UAAU,OAAO;AAEnC,cAAM,SAA0B,MAAM,KAAK,MAAM,YAAY,IAAI,EAAE,KAAK,CAACA,YACvEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,cACJ,WACA,WAAW,gCAA8B;;AAEzC,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,KAAK,OAAO,UAAU;AAE5B,eAAO,EAAE,OAAO,KAAI;eACb,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,MAAK;;AAGhB,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,eACJ,WACA,WAAW,qCAAmC;;AAE9C,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,SAAiC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YACtEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,cACJ,WACA,OACA,WAAW,4CAA0C;;AAErD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,MAAK,CAAE;AACpE,cAAM,SAAgC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YACrEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,iBACJ,WACA,SACA,WAAW,qCAAmC;;AAE9C,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,GAAI,OAAO;AACtE,cAAM,OAAO,KAAK,UAAU,OAAO;AAEnC,cAAM,SAAmC,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACA,YAC/EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,iBACJ,WACA,OACA,WAAW,4CAA0C;;AAErD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,MAAK,CAAE;AACpE,cAAM,KAAK,OAAO,UAAU;AAE5B,eAAO,EAAE,OAAO,KAAI;eACb,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,MAAK;;AAGhB,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,kBACJ,WACA,WAAW,wCAAsC;;AAEjD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,SAAoC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YACzEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,oBACJ,WACA,UACA,WAAW,kDAAgD;;AAE3D,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,SAAQ,CAAE;AACvE,cAAM,KAAK,OAAO,UAAU;AAE5B,eAAO,EAAE,OAAO,KAAI;eACb,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,MAAK;;AAGhB,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,uBACJ,WACA,UACA,WAAW,yDAAuD;;AAElE,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,SAAQ,CAAE;AACvE,cAAM,SAAyC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAC9EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;;EAYK,yBACJ,WACA,UACA,SACA,WAAW,yDAAuD;;AAElE,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,SAAQ,GAAI,OAAO;AAChF,cAAM,OAAO,KAAK,UAAU,OAAO;AAEnC,cAAM,SAA0B,MAAM,KAAK,IAAI,YAAY,IAAI,EAAE,KAAK,CAACA,YACrEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,kBACJ,WACA,WAAW,wCAAsC;;AAEjD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,SAAoC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YACzEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,kBACJ,WACA,SACA,WAAW,wCAAsC;;AAEjD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,GAAI,OAAO;AACtE,cAAM,OAAO,KAAK,UAAU,OAAO;AAEnC,cAAM,SAA0B,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACA,YACtEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,oBACJ,WACA,OACA,WAAW,+CAA6C;;AAExD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,MAAK,CAAE;AACpE,cAAM,KAAK,OAAO,UAAU,EAAE,KAAK,CAAC,WAAW,OAAO,KAAI,CAAE;AAE5D,eAAO,EAAE,OAAO,KAAI;eACb,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,MAAK;;AAGhB,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,aACJ,WACA,WAAW,sCAAoC;;AAE/C,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,SAA0B,MAAM,KAAK,OAAO,UAAU,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAE5F,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,wBACJ,WACA,SACA,WAAW,yCAAuC;;AAElD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,GAAI,OAAO;AACtE,cAAM,SAA0C,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAC/EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,uBACJ,WACA,WACA,WAAW,oDAAkD;;AAE7D,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,UAAS,CAAE;AACxE,cAAM,SAAyC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAC9EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,uBACJ,WACA,SACA,WAAW,sCAAoC;;AAE/C,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,GAAI,OAAO;AACtE,cAAM,SAAyC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAC9EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,sBACJ,WACA,SACA,WAAW,6CAA2C;;AAEtD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,GAAI,OAAO;AACtE,cAAM,SAAwC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAC7EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,mBACJ,WACA,WAAW,yCAAuC;;AAElD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,SAAqC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAC1EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,kBACJ,WACA,WACA,WAAW,oDAAkD;;AAE7D,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,UAAS,CAAE;AACxE,cAAM,SAAoC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YACzEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;;;;;;;;;;;;EAsBK,aACJ,WACA,UAA2B,CAAA,GAC3B,WAAW,uCAAqC;;AAEhD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,GAAI,OAAO;AACtE,cAAM,SAA4B,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAE3F,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;;;;;;;;;;;;;EAuBK,SACJ,WACA,SACA,WAAW,gDAA8C;;AAEzD,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,QAAO,CAAE;AACtE,cAAM,SAA2B,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAE1F,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvzBG,IAAO,mBAAP,cAAgC,mBAAkB;EAAxD,cAAA;;AACS,SAAA,YAAoB;EA4E7B;;;;;;;;;;;;;;;;;;;;EAvDQ,OACJ,WAAW,mBACX,UAA2B,CAAA,GAAE;;AAE7B,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,CAAA,GAAI,OAAO;AAC3D,cAAM,SAA4B,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACC,YAAWA,QAAO,KAAI,CAAE;AAE3F,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;;;;;;;;;;;;EAsBK,SACJ,SACA,WAAW,4BAA0B;;AAErC,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,QAAO,CAAE;AAC3D,cAAM,SAA2B,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAE1F,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpEG,IAAO,iBAAP,cAA8B,mBAAkB;EAAtD,cAAA;;AACS,SAAA,YAAoB;EA6K7B;;;;;;;;;EAnKQ,WACJ,QACA,SACA,WAAW,iBAAe;;AAE1B,UAAI;AACF,YAAI;AAEJ,YAAI,YAAY,MAAM,GAAG;AACvB,iBAAO,KAAK,UAAU,MAAM;eACvB;AACL,gBAAM,IAAI,cAAc,qBAAqB;;AAG/C,YAAI,YAAY,UAAa,cAAc,SAAS;AAClD,gBAAM,IAAI,cACR,qIAAqI;;AAIzI,cAAM,aAAa,KAAK,cAAc,UAAU,CAAA,GAAE,OAAA,OAAO,CAAA,GAAO,OAAO,CAAA;AACvE,cAAM,SAA8B,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACC,YAC1EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,YACJ,QACA,SACA,WAAW,iBAAe;;AAE1B,UAAI;AACF,YAAI;AAEJ,YAAI,aAAa,MAAM,GAAG;AACxB,iBAAO,KAAK,UAAU,MAAM;eACvB;AACL,gBAAM,IAAI,cAAc,qBAAqB;;AAG/C,YAAI,YAAY,UAAa,cAAc,SAAS;AAClD,gBAAM,IAAI,cACR,gIAAgI;;AAIpI,cAAM,aAAa,KAAK,cAAc,UAAU,CAAA,GAAE,OAAA,OAAO,CAAA,GAAO,OAAO,CAAA;AACvE,cAAM,SAA8B,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACA,YAC1EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,mBACJ,QACA,UACA,SACA,WAAW,iBAAe;;AAE1B,UAAI;AACF,YAAI;AAEJ,YAAI,YAAY,MAAM,GAAG;AACvB,iBAAO,KAAK,UAAU,MAAM;eACvB;AACL,gBAAM,IAAI,cAAc,qBAAqB;;AAG/C,cAAM,aAAa,KAAK,cACtB,UACA,CAAA,GAAE,OAAA,OAAA,OAAA,OAAA,CAAA,GACG,OAAO,GAAA,EAAE,UAAU,SAAS,SAAQ,EAAE,CAAA,CAAA;AAE7C,cAAM,SAA+B,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACA,YAC3EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;EAWK,oBACJ,QACA,UACA,SACA,WAAW,iBAAe;;AAE1B,UAAI;AACF,YAAI;AAEJ,YAAI,aAAa,MAAM,GAAG;AACxB,iBAAO,KAAK,UAAU,MAAM;eACvB;AACL,gBAAM,IAAI,cAAc,qBAAqB;;AAG/C,cAAM,aAAa,KAAK,cACtB,UACA,CAAA,GAAE,OAAA,OAAA,OAAA,OAAA,CAAA,GACG,OAAO,GAAA,EAAE,UAAU,SAAS,SAAQ,EAAE,CAAA,CAAA;AAE7C,cAAM,SAA+B,MAAM,KAAK,KAAK,YAAY,MAAM;UACrE,SAAS,EAAE,gBAAgB,uBAAsB;SAClD,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAEjC,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrLG,IAAO,uBAAP,cAAoC,mBAAkB;EAA5D,cAAA;;AACS,SAAA,YAAoB;EAmH7B;;;;;;;;EA1GQ,gBACJ,WACA,WAAW,gEAA8D;;AAEzE,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,SAAwC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACC,YAC7EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,eACJ,WACA,eACA,WAAW,+EAA6E;;AAExF,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,cAAa,CAAE;AAC5E,cAAM,SAAmC,MAAM,KAAK,IAAI,UAAU,EAAE,KAAK,CAACA,YACxEA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,kBACJ,WACA,SACA,WAAW,gEAA8D;;AAEzE,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,UAAS,CAAE;AAC7D,cAAM,OAAO,KAAK,UAAU,OAAO;AAEnC,cAAM,SAAmC,MAAM,KAAK,KAAK,YAAY,IAAI,EAAE,KAAK,CAACA,YAC/EA,QAAO,KAAI,CAAE;AAGf,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;;;;;;EAUK,kBACJ,WACA,eACA,WAAW,+EAA6E;;AAExF,UAAI;AACF,cAAM,aAAa,KAAK,cAAc,UAAU,EAAE,WAAW,cAAa,CAAE;AAC5E,cAAM,SAA0B,MAAM,KAAK,OAAO,UAAU,EAAE,KAAK,CAACA,YAAWA,QAAO,KAAI,CAAE;AAE5F,eAAO,EAAE,QAAQ,OAAO,KAAI;eACrB,OAAO;AACd,YAAI,gBAAgB,KAAK,GAAG;AAC1B,iBAAO,EAAE,QAAQ,MAAM,MAAK;;AAG9B,cAAM;;IAEV,CAAC;;;;;ACnHG,IAAO,kBAAP,cAA+B,mBAAkB;;;;;;;;EAUrD,YACE,SACA,eAA+C,CAAA,GAC/C,WAAmB,kBAAgB;AAEnC,UAAM,OAAO;AAdR,SAAA,YAAoB;AAgBzB,SAAK,QAAQ,cAAc,QAAQ;EACrC;;;;;;;;;EAUO,kBAAe;AACpB,QAAI,KAAK,MAAM;AACb,WAAK,KAAK,SAAS,MAAK;AACtB,aAAK,KAAK,cAAc,MAAM,IAAI;MACpC;AAEA,WAAK,KAAK,UAAU,CAAC,UAAc;AACjC,aAAK,KAAK,cAAc,OAAO,KAAK;MACtC;AAEA,WAAK,KAAK,UAAU,CAAC,UAAqB;AACxC,aAAK,KAAK,cAAc,OAAO,KAAK;MACtC;AAEA,WAAK,KAAK,YAAY,CAAC,UAAuB;AAC5C,aAAK,cAAc,KAAK;MAC1B;;EAEJ;;;;;EAMU,kBAAkB,MAAS;AACnC,QAAI,KAAK,SAAS,cAAc,UAAU;AACxC,WAAK,KAAK,cAAc,UAAU,IAAI;eAC7B,KAAK,SAAS,cAAc,SAAS;AAC9C,WAAK,KAAK,cAAc,SAAS,IAAI;eAC5B,KAAK,SAAS,cAAc,SAAS;AAC9C,WAAK,KAAK,cAAc,SAAS,IAAI;WAChC;AACL,WAAK,KAAK,cAAc,WAAW,IAAI;;EAE3C;;;;;EAMU,oBAAoB,MAAY;AACxC,SAAK,KAAK,cAAc,OAAO,IAAI;EACrC;;;;;;EAOO,SAAS,MAAY;AAC1B,SAAK,KACH,KAAK,UAAU;MACb,MAAM;MACN;KACD,CAAC;EAEN;;;;EAKO,QAAK;AACV,SAAK,KACH,KAAK,UAAU;MACb,MAAM;KACP,CAAC;EAEN;;;;EAKO,QAAK;AACV,SAAK,KACH,KAAK,UAAU;MACb,MAAM;KACP,CAAC;EAEN;;;;EAKO,eAAY;AACjB,SAAK,KACH,KAAK,UAAU;MACb,MAAM;KACP,CAAC;EAEN;;;;;EAMU,cAAc,OAAmB;AACzC,QAAI,OAAO,MAAM,SAAS,UAAU;AAClC,UAAI;AACF,cAAM,OAAO,KAAK,MAAM,MAAM,IAAI;AAClC,aAAK,kBAAkB,IAAI;eACpB,OAAO;AACd,aAAK,KAAK,cAAc,OAAO;UAC7B;UACA,SAAS;UACT;SACD;;eAEM,MAAM,gBAAgB,MAAM;AACrC,YAAM,KAAK,YAAW,EAAG,KAAK,CAAC,WAAU;AACvC,aAAK,oBAAoB,OAAO,KAAK,MAAM,CAAC;MAC9C,CAAC;eACQ,MAAM,gBAAgB,aAAa;AAC5C,WAAK,oBAAoB,OAAO,KAAK,MAAM,IAAI,CAAC;eACvC,OAAO,SAAS,MAAM,IAAI,GAAG;AACtC,WAAK,oBAAoB,MAAM,IAAI;WAC9B;AACL,cAAQ,IAAI,8BAA8B,MAAM,IAAI;AACpD,WAAK,KAAK,cAAc,OAAO;QAC7B;QACA,SAAS;OACV;;EAEL;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7JI,IAAO,kBAAP,cAA+B,mBAAkB;EAAvD,cAAA;;AACS,SAAA,YAAoB;EA+D7B;;;;;;;;;;;;EAjDQ,QACJ,QACA,SACA,WAAW,kBAAgB;;AAE3B,UAAI;AAEJ,UAAI,aAAa,MAAM,GAAG;AACxB,eAAO,KAAK,UAAU,MAAM;aACvB;AACL,cAAM,IAAI,cAAc,mCAAmC;;AAG7D,YAAM,aAAa,KAAK,cACtB,UACA,CAAA,GAAE,OAAA,OACG,EAAE,OAAO,kBAAiB,GAAO,OAAO,CAAA;AAE/C,WAAK,SAAS,MAAM,KAAK,KAAK,YAAY,MAAM;QAC9C,SAAS,EAAE,QAAQ,WAAW,gBAAgB,mBAAkB;OACjE;AAED,aAAO;IACT,CAAC;;;;;;;;EAQK,YAAS;;AACb,UAAI,CAAC,KAAK;AACR,cAAM,IAAI,qBAAqB,6CAA6C,EAAE;AAEhF,aAAO,KAAK,OAAO;IACrB,CAAC;;;;;;;EAOK,aAAU;;AACd,UAAI,CAAC,KAAK;AACR,cAAM,IAAI,qBAAqB,8CAA8C,EAAE;AAEjF,aAAO,KAAK,OAAO;IACrB,CAAC;;;;;AC1DG,IAAO,cAAP,cAA2B,eAAc;EAA/C,cAAA;;AACS,SAAA,YAAoB;EAoB7B;;;;EAfS,QAAQ,QAAoB,SAAuB,WAAW,kBAAgB;AACnF,UAAM,SAAS,IAAI,gBAAgB,KAAK,OAAO;AAE/C,WAAO,OAAO,QAAQ,QAAQ,SAAS,QAAQ;EACjD;;;;;;;EAQO,KAAK,aAA0B,CAAA,GAAI,WAAmB,kBAAgB;AAC3E,WAAO,IAAI,gBAAgB,KAAK,SAAS,YAAY,QAAQ;EAC/D;;;;AChBF,IAAqB,iBAArB,cAA4C,eAAc;;;;;;EAMxD,IAAI,SAAM;AACR,WAAO,IAAI,aAAa,KAAK,OAAO;EACtC;;;;;;EAOA,IAAI,SAAM;AACR,WAAO,IAAI,iBAAa,KAAK,OAAO;EACtC;;;;;;EAOA,IAAI,SAAM;AACR,WAAO,IAAI,iBAAiB,KAAK,OAAO;EAC1C;;;;;;;EAQA,IAAI,SAAM;AACR,WAAO,KAAK;EACd;;;;;;EAOA,IAAI,aAAU;AACZ,WAAO,IAAI,qBAAqB,KAAK,OAAO;EAC9C;;;;;;EAOA,IAAI,OAAI;AACN,WAAO,IAAI,eAAW,KAAK,OAAO;EACpC;;;;;;EAOA,IAAI,QAAK;AACP,WAAO,IAAI,YAAY,KAAK,OAAO;EACrC;;;;;EAMA,IAAI,gBAAa;AACf,UAAM,IAAI,qBAAoB;EAChC;;;;;EAMA,IAAI,WAAQ;AACV,UAAM,IAAI,qBAAoB;EAChC;;;;;EAMA,IAAI,OAAI;AACN,UAAM,IAAI,qBAAoB;EAChC;;;;;EAMA,IAAI,UAAO;AACT,UAAM,IAAI,qBAAoB;EAChC;;;;;EAMA,IAAI,SAAM;AACR,UAAM,IAAI,qBAAoB;EAChC;;;;;EAMA,IAAI,aAAU;AACZ,UAAM,IAAI,qBAAoB;EAChC;;;;;EAMA,IAAI,QAAK;AACP,UAAM,IAAI,qBAAoB;EAChC;;;;;EAMA,IAAI,UAAO;AACT,UAAM,IAAI,qBAAoB;EAChC;;;;ACtHF,SAAS,aACP,cACA,SAA+B;AAE/B,MAAI,kBAAyC,CAAA;AAE7C,MAAI,OAAO,iBAAiB,YAAY,OAAO,iBAAiB,YAAY;AAC1E,QAAI,OAAO,YAAY,UAAU;AAC/B,wBAAkB;;AAGpB,oBAAgB,MAAM;aACb,OAAO,iBAAiB,UAAU;AAC3C,sBAAkB;;AAGpB,SAAO,IAAI,eAAe,eAAe;AAC3C;;;AtFvBA,IAAM,aAAaC,eAAc,YAAY,GAAG;AAChD,IAAMC,aAAYC,MAAK,QAAQ,UAAU;AAEzC,IAAM,YAAY,UAAU,IAAI;AAEzB,IAAM,uBAAN,cACKC,SAEZ;AAAA,EACY,UAAgC;AAAA,EACxC,OAAO,cAA2BC,aAAY;AAAA,EACtC;AAAA,EACA;AAAA,EACA,qBAAqB;AAAA;AAAA,EACrB,kBAA2B;AAAA;AAAA;AAAA;AAAA;AAAA,EAM3B,wBAAsD;AAAA,EAEtD,WAAkC;AAAA,EAClC,SAAwB;AAAA;AAAA;AAAA;AAAA,EAKxB,QAA2D,CAAC;AAAA,EAC5D,aAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQ9B,MAAM,WAAW,UAAwC;AACrD,SAAK,UAAU;AAGf,QAAI,iBAA+C;AACnD,UAAM,cAAc,KAAK,QAAQ,WAAW,UAAU;AAEtD,QAAI,gBAAgB,sBAAsB,UAAU;AAChD,YAAM,cAAc,KAAK,QAAQ,WAAW,kBAAkB;AAC9D,UAAI,aAAa;AACb,aAAK,WAAW,aAAa,WAAW;AACxC,yBAAiB,sBAAsB;AAAA,MAC3C;AAAA,IACJ,WAAW,gBAAgB,sBAAsB,QAAQ;AACrD,YAAM,YAAY,KAAK,QAAQ,WAAW,gBAAgB;AAC1D,UAAI,WAAW;AACX,aAAK,SAAS,IAAI,eAAO,EAAE,QAAQ,UAAU,CAAC;AAC9C,yBAAiB,sBAAsB;AAAA,MAC3C;AAAA,IACJ,WAAW,gBAAgB,sBAAsB,OAAO;AACpD,uBAAiB,sBAAsB;AAAA,IAC3C;AAGA,QAAI,CAAC,gBAAgB;AACjB,YAAM,cAAc,KAAK,QAAQ,WAAW,wBAAwB;AACpE,UAAI,aAAa;AACb,gBAAQ,YAAY,YAAY,GAAG;AAAA,UAC/B,KAAK;AACL;AACI,oBAAM,QAAQ,KAAK,QAAQ,WAAW,kBAAkB;AACxD,kBAAI,OAAO;AACP,qBAAK,WAAW,aAAa,KAAK;AAClC,iCAAiB,sBAAsB;AAAA,cAC3C;AAAA,YACJ;AACI;AAAA,UACJ,KAAK;AACL;AACI,oBAAM,YAAY,KAAK,QAAQ,WAAW,gBAAgB;AAC1D,kBAAI,WAAW;AACX,qBAAK,SAAS,IAAI,eAAO,EAAE,QAAQ,UAAU,CAAC;AAC9C,iCAAiB,sBAAsB;AAAA,cAC3C;AAAA,YACJ;AACI;AAAA,UACJ,KAAK;AACD,6BAAiB,sBAAsB;AACvC;AAAA,QACR;AAAA,MACJ;AAAA,IACJ;AAGA,QAAI,CAAC,gBAAgB;AACjB,YAAM,cAAc,KAAK,QAAQ,WAAW,kBAAkB;AAC9D,UAAI,aAAa;AACb,aAAK,WAAW,aAAa,WAAW;AACxC,yBAAiB,sBAAsB;AAAA,MAC3C,OAAO;AACH,cAAM,YAAY,KAAK,QAAQ,WAAW,gBAAgB;AAC1D,YAAI,WAAW;AACX,eAAK,SAAS,IAAI,eAAO,EAAE,QAAQ,UAAU,CAAC;AAC9C,2BAAiB,sBAAsB;AAAA,QAC3C,OAAO;AACH,2BAAiB,sBAAsB;AAAA,QAC3C;AAAA,MACJ;AAAA,IACJ;AAEA,SAAK,wBAAwB;AAG7B,SAAK,WAAW;AAAA,EACpB;AAAA,EAEA,cAAc;AACV,UAAM;AACN,UAAM,UAAUF,MAAK,QAAQD,YAAW,QAAQ;AAChD,SAAK,oBAAoBC,MAAK,KAAK,SAAS,eAAe;AAC3D,SAAK,kBAAkBA,MAAK,KAAK,SAAS,aAAa;AACvD,SAAK,2BAA2B;AAChC,SAAK,2BAA2B;AAAA,EAUpC;AAAA,EAEQ,6BAA6B;AACjC,QAAI,CAACG,IAAG,WAAW,KAAK,iBAAiB,GAAG;AACxC,MAAAA,IAAG,UAAU,KAAK,mBAAmB,EAAE,WAAW,KAAK,CAAC;AAAA,IAC5D;AAAA,EACJ;AAAA,EAEQ,6BAA6B;AACjC,QAAI,CAACA,IAAG,WAAW,KAAK,eAAe,GAAG;AACtC,MAAAA,IAAG,UAAU,KAAK,iBAAiB,EAAE,WAAW,KAAK,CAAC;AAAA,IAC1D;AAAA,EACJ;AAAA,EAEQ,aAAa;AACjB,UAAM,WAAWC,IAAG,SAAS;AAC7B,QAAI,aAAa,SAAS;AACtB,UAAI;AACA,QAAAD,IAAG,WAAW,4BAA4BA,IAAG,UAAU,IAAI;AAC3D,aAAK,kBAAkB;AACvB,gBAAQ;AAAA,UACJ;AAAA,QACJ;AAAA,MAEJ,SAAS,QAAQ;AACb,gBAAQ;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ,WAAW,aAAa,SAAS;AAC7B,YAAM,WAAWH,MAAK;AAAA,QAClBK,UAAS,aACT;AAAA,QACA;AAAA,QACA;AAAA,MACJ;AACA,UAAIF,IAAG,WAAW,QAAQ,GAAG;AACzB,aAAK,kBAAkB;AACvB,gBAAQ;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ,OAAO;AACH,gBAAQ;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ,OAAO;AACH,cAAQ;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AAAA,EAEA,MAAc,aAAa,aAA2C;AAClE,UAAM,YAAYH,MAAK;AAAA,MACnB,KAAK;AAAA,MACL,SAAS,KAAK,IAAI,CAAC;AAAA,IACvB;AACA,UAAM,aAAaA,MAAK;AAAA,MACpB,KAAK;AAAA,MACL,UAAU,KAAK,IAAI,CAAC;AAAA,IACxB;AAEA,IAAAG,IAAG,cAAc,WAAW,OAAO,KAAK,WAAW,CAAC;AAEpD,QAAI;AACA,YAAM,EAAE,OAAO,IAAI,MAAM;AAAA,QACrB,mFAAmF,SAAS;AAAA,MAChG;AACA,YAAM,cAAc,KAAK,MAAM,MAAM;AACrC,YAAM,SAAS,YAAY,QAAQ,CAAC;AAEpC,MAAAG,aAAY,IAAI,qBAAqB,MAAM;AAE3C,UAAI,gBAAgB,cAAc,SAAS,SAAS,KAAK,kBAAkB;AAE3E,UAAI,OAAO,eAAe,aAAa;AACnC,yBAAiB;AAAA,MACrB;AAEA,uBAAiB,KAAK,UAAU;AAEhC,MAAAA,aAAY,IAAI,mBAAmB,aAAa;AAEhD,YAAM,UAAU,aAAa;AAE7B,YAAM,kBAAkBH,IAAG,aAAa,UAAU;AAClD,MAAAA,IAAG,WAAW,SAAS;AACvB,MAAAA,IAAG,WAAW,UAAU;AACxB,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,MAAAG,aAAY,MAAM,2BAA2B,KAAK;AAClD,YAAM;AAAA,IACV;AAAA,EACJ;AAAA,EAEA,MAAc,eAAe,aAA0B,QAAgB;AACnE,SAAK,2BAA2B;AAEhC,UAAM,WAAW,GAAG,MAAM,IAAI,KAAK,IAAI,CAAC;AACxC,UAAM,WAAWN,MAAK,KAAK,KAAK,iBAAiB,QAAQ;AAEzD,IAAAG,IAAG,cAAc,UAAU,OAAO,KAAK,WAAW,CAAC;AACnD,IAAAG,aAAY,IAAI,sBAAsB,QAAQ,EAAE;AAAA,EACpD;AAAA,EAEA,MAAa,qBACT,aACsB;AACtB,WAAO,MAAM,KAAK,WAAW,WAAW;AAAA,EAC5C;AAAA;AAAA;AAAA;AAAA,EAKA,MAAa,WAAW,aAAkD;AAEtE,QAAI,YAAY,aAAa,MAAM,MAAO;AACtC,aAAO;AAAA,IACX;AACA,WAAO,IAAI,QAAQ,CAAC,YAAY;AAC5B,WAAK,MAAM,KAAK,EAAE,aAAa,QAAQ,CAAC;AACxC,UAAI,CAAC,KAAK,YAAY;AAClB,aAAK,aAAa;AAAA,MACtB;AAAA,IACJ,CAAC;AAAA,EACL;AAAA,EAEA,MAAa,4BACT,aACsB;AACtB,WAAO,KAAK,kBAAkB,WAAW;AAAA,EAC7C;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,eAA8B;AAExC,QAAI,KAAK,cAAc,KAAK,MAAM,WAAW,EAAG;AAChD,SAAK,aAAa;AAElB,WAAO,KAAK,MAAM,SAAS,GAAG;AAC1B,YAAM,EAAE,aAAa,QAAQ,IAAI,KAAK,MAAM,MAAM;AAClD,UAAI,SAAwB;AAE5B,cAAQ,KAAK,uBAAuB;AAAA,QAChC,KAAK,sBAAsB;AACvB,mBAAS,MAAM,KAAK,uBAAuB,WAAW;AACtD;AAAA,QACJ,KAAK,sBAAsB;AACvB,mBAAS,MAAM,KAAK,qBAAqB,WAAW;AACpD;AAAA,QACJ;AACI,mBAAS,MAAM,KAAK,kBAAkB,WAAW;AAAA,MACzD;AAEA,cAAQ,MAAM;AAAA,IAClB;AAEA,SAAK,aAAa;AAAA,EACtB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAc,4BAA4B,aAAkD;AACxF,QAAI,KAAK,UAAU;AACf,aAAO,MAAM,KAAK,uBAAuB,WAAW;AAAA,IACxD,WAAW,KAAK,QAAQ;AACpB,aAAO,MAAM,KAAK,qBAAqB,WAAW;AAAA,IACtD;AACA,WAAO,MAAM,KAAK,kBAAkB,WAAW;AAAA,EACnD;AAAA,EAEA,MAAc,uBACV,aACsB;AACtB,UAAM,SAAS,OAAO,KAAK,WAAW;AACtC,UAAM,WAAW,MAAM,KAAK,SAAS,OAAO,YAAY;AAAA,MACpD;AAAA,MACA;AAAA,QACI,OAAO;AAAA,QACP,UAAU;AAAA,QACV,cAAc;AAAA,MAClB;AAAA,IACJ;AACA,UAAM,SACF,SAAS,OAAO,QAAQ,SAAS,CAAC,EAAE,aAAa,CAAC,EAAE;AACxD,WAAO;AAAA,EACX;AAAA,EAEA,MAAc,qBACV,aACsB;AACtB,IAAAA,aAAY,IAAI,mCAAmC;AAEnD,QAAI;AACA,YAAM,KAAK,eAAe,aAAa,uBAAuB;AAE9D,YAAM,kBAAkB,MAAM,KAAK,aAAa,WAAW;AAE3D,YAAM,KAAK;AAAA,QACP;AAAA,QACA;AAAA,MACJ;AAEA,YAAM,OAAO,IAAIC,MAAK,CAAC,eAAe,GAAG,aAAa;AAAA,QAClD,MAAM;AAAA,MACV,CAAC;AAED,YAAM,SAAS,MAAM,KAAK,OAAQ,MAAM,eAAe,OAAO;AAAA,QAC1D,OAAO;AAAA,QACP,UAAU;AAAA,QACV,iBAAiB;AAAA,QACjB;AAAA,MACJ,CAAC;AAED,YAAM,gBAAiB,OAAe,KAAK;AAC3C,MAAAD,aAAY,IAAI,kCAAkC,aAAa,GAAG;AAElE,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,MAAAA,aAAY;AAAA,QACR;AAAA,QACA;AAAA,MACJ;AACA,UAAI,MAAM,UAAU;AAChB,QAAAA,aAAY,MAAM,kBAAkB,MAAM,SAAS,IAAI;AACvD,QAAAA,aAAY,MAAM,oBAAoB,MAAM,SAAS,MAAM;AAC3D,QAAAA,aAAY,MAAM,qBAAqB,MAAM,SAAS,OAAO;AAAA,MACjE,WAAW,MAAM,SAAS;AACtB,QAAAA,aAAY,MAAM,yBAAyB,MAAM,OAAO;AAAA,MAC5D,OAAO;AACH,QAAAA,aAAY,MAAM,6BAA6B,MAAM,OAAO;AAAA,MAChE;AACA,aAAO;AAAA,IACX;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAa,kBACT,aACsB;AACtB,QAAI;AACA,MAAAA,aAAY,IAAI,+BAA+B;AAE/C,YAAM,KAAK,eAAe,aAAa,sBAAsB;AAE7D,YAAM,kBAAkB,MAAM,KAAK,aAAa,WAAW;AAE3D,YAAM,KAAK,eAAe,iBAAiB,uBAAuB;AAElE,YAAM,cAAcN,MAAK;AAAA,QACrB,KAAK;AAAA,QACL,QAAQ,KAAK,IAAI,CAAC;AAAA,MACtB;AACA,MAAAG,IAAG,cAAc,aAAa,eAAe;AAE7C,MAAAG,aAAY,MAAM,+BAA+B,WAAW,EAAE;AAE9D,UAAI,SAAS,MAAM,YAAY,aAAa;AAAA,QACxC,WAAW;AAAA,QACX,uBAAuB;AAAA,QACvB,SAAS;AAAA,QACT,iCAAiC;AAAA,QACjC,UAAU,KAAK;AAAA,QACf,gBAAgB;AAAA,UACZ,cAAc;AAAA,UACd,aAAa;AAAA,UACb,aAAa;AAAA,UACb,aAAa;AAAA,UACb,oBAAoB;AAAA,UACpB,gBAAgB;AAAA,UAChB,mBAAmB;AAAA;AAAA,QAEvB;AAAA,MACJ,CAAC;AAED,eAAS,OACJ,MAAM,IAAI,EACV,IAAI,CAAC,SAAS;AACX,YAAI,KAAK,KAAK,EAAE,WAAW,GAAG,GAAG;AAC7B,gBAAM,WAAW,KAAK,QAAQ,GAAG;AACjC,iBAAO,KAAK,UAAU,WAAW,CAAC;AAAA,QACtC;AACA,eAAO;AAAA,MACX,CAAC,EACA,KAAK,IAAI;AAEd,MAAAH,IAAG,WAAW,WAAW;AAEzB,UAAI,CAAC,UAAU,OAAO,SAAS,GAAG;AAC9B,QAAAG,aAAY,IAAI,6CAA6C;AAC7D,eAAO;AAAA,MACX;AACA,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,MAAAA,aAAY;AAAA,QACR;AAAA,QACA;AAAA,MACJ;AACA,aAAO;AAAA,IACX;AAAA,EACJ;AACJ;;;AuF3cA;AAAA,EAKI,WAAAE;AAAA,EACA,eAAAC;AAAA,EACA,gBAAAC;AAAA,OACG;AACP,OAAO,YAAY;AACnB,OAAOC,SAAQ;AACf,SAAS,cAAc;AACvB,OAAOC,WAAU;AACjB,OAAO,eAAe;AAEf,IAAM,eAAN,MAAM,sBAAqBJ,SAAiC;AAAA,EAC/D,OAAO,cAA2BC,aAAY;AAAA,EACtC,WAAW;AAAA,EACX,UAAU;AAAA,EAEV,QAAkB,CAAC;AAAA,EACnB,aAAsB;AAAA,EAE9B,cAAc;AACV,UAAM;AACN,SAAK,0BAA0B;AAAA,EACnC;AAAA,EAEA,cAA6B;AACzB,WAAO,cAAa,YAAY;AAAA,EACpC;AAAA,EAEA,MAAM,WAAW,UAAwC;AAAA,EAAC;AAAA,EAElD,4BAA4B;AAChC,QAAI,CAACE,IAAG,WAAW,KAAK,OAAO,GAAG;AAC9B,MAAAA,IAAG,UAAU,KAAK,OAAO;AAAA,IAC7B;AAAA,EACJ;AAAA,EAEO,WAAW,KAAsB;AACpC,WACI,IAAI,SAAS,aAAa,KAC1B,IAAI,SAAS,UAAU,KACvB,IAAI,SAAS,WAAW;AAAA,EAEhC;AAAA,EAEA,MAAa,cAAc,KAA8B;AACrD,UAAM,UAAU,KAAK,WAAW,GAAG;AACnC,UAAM,aAAaC,MAAK,KAAK,KAAK,SAAS,GAAG,OAAO,MAAM;AAG3D,QAAID,IAAG,WAAW,UAAU,GAAG;AAC3B,aAAO;AAAA,IACX;AAEA,QAAI;AACA,YAAM,UAAU,KAAK;AAAA,QACjB,SAAS;AAAA,QACT,QAAQ;AAAA,QACR,eAAe;AAAA,MACnB,CAAC;AACD,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,cAAQ,MAAM,4BAA4B,KAAK;AAC/C,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC9C;AAAA,EACJ;AAAA,EAEA,MAAa,cAAc,WAAiC;AACxD,UAAM,UAAU,KAAK,WAAW,UAAU,WAAW;AACrD,UAAM,aAAaC,MAAK,KAAK,KAAK,SAAS,GAAG,OAAO,MAAM;AAG3D,QAAID,IAAG,WAAW,UAAU,GAAG;AAC3B,aAAO;AAAA,IACX;AAEA,QAAI;AACA,YAAM,UAAU,UAAU,aAAa;AAAA,QACnC,SAAS;AAAA,QACT,QAAQ;AAAA,QACR,QAAQ;AAAA,QACR,eAAe;AAAA,MACnB,CAAC;AACD,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,cAAQ,MAAM,4BAA4B,KAAK;AAC/C,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC9C;AAAA,EACJ;AAAA,EAEA,MAAa,aACT,KACA,SACc;AACd,SAAK,MAAM,KAAK,GAAG;AACnB,SAAK,aAAa,OAAO;AAEzB,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,YAAM,aAAa,YAAY;AAC3B,cAAM,QAAQ,KAAK,MAAM,QAAQ,GAAG;AACpC,YAAI,UAAU,IAAI;AACd,qBAAW,YAAY,GAAG;AAAA,QAC9B,OAAO;AACH,cAAI;AACA,kBAAM,SAAS,MAAM,KAAK;AAAA,cACtB;AAAA,cACA;AAAA,YACJ;AACA,oBAAQ,MAAM;AAAA,UAClB,SAAS,OAAO;AACZ,mBAAO,KAAK;AAAA,UAChB;AAAA,QACJ;AAAA,MACJ;AACA,iBAAW;AAAA,IACf,CAAC;AAAA,EACL;AAAA,EAEA,MAAc,aAAa,SAAwB;AAC/C,QAAI,KAAK,cAAc,KAAK,MAAM,WAAW,GAAG;AAC5C;AAAA,IACJ;AAEA,SAAK,aAAa;AAElB,WAAO,KAAK,MAAM,SAAS,GAAG;AAC1B,YAAM,MAAM,KAAK,MAAM,MAAM;AAC7B,YAAM,KAAK,oBAAoB,KAAK,OAAO;AAAA,IAC/C;AAEA,SAAK,aAAa;AAAA,EACtB;AAAA,EAEA,MAAc,oBACV,KACA,SACc;AACd,UAAM,UACF,IAAI;AAAA,MACA;AAAA;AAAA,IACJ,IAAI,CAAC,KAAK;AACd,UAAM,YAAY,KAAK,WAAW,OAAO;AACzC,UAAM,WAAW,GAAG,KAAK,QAAQ,IAAI,SAAS;AAE9C,UAAM,SAAS,MAAM,QAAQ,aAAa,IAAW,QAAQ;AAE7D,QAAI,QAAQ;AACR,cAAQ,IAAI,6BAA6B;AACzC,aAAO;AAAA,IACX;AAEA,YAAQ,IAAI,8BAA8B;AAC1C,YAAQ,IAAI,qBAAqB;AACjC,UAAM,YAAY,MAAM,KAAK,eAAe,GAAG;AAC/C,YAAQ,IAAI,oBAAoB;AAChC,UAAM,aAAa,MAAM,KAAK,cAAc,KAAK,WAAW,OAAO;AAEnE,UAAM,SAAgB;AAAA,MAClB,IAAI;AAAA,MACJ;AAAA,MACA,OAAO,UAAU;AAAA,MACjB,QAAQ,UAAU;AAAA,MAClB,aAAa,UAAU;AAAA,MACvB,MAAM;AAAA,IACV;AAEA,UAAM,QAAQ,aAAa,IAAI,UAAU,MAAM;AAE/C,WAAO;AAAA,EACX;AAAA,EAEQ,WAAW,KAAqB;AACpC,WAAOD,cAAa,GAAG;AAAA,EAC3B;AAAA,EAEA,MAAM,eAAe,KAA2B;AAC5C,QAAI,IAAI,SAAS,MAAM,KAAK,IAAI,SAAS,OAAO,GAAG;AAC/C,UAAI;AACA,cAAM,WAAW,MAAM,MAAM,GAAG;AAChC,YAAI,SAAS,IAAI;AAEb,iBAAO;AAAA,YACH,OAAOE,MAAK,SAAS,GAAG;AAAA,YACxB,aAAa;AAAA,YACb,SAAS;AAAA,UACb;AAAA,QACJ;AAAA,MACJ,SAAS,OAAO;AACZ,gBAAQ,MAAM,+BAA+B,KAAK;AAAA,MAEtD;AAAA,IACJ;AAEA,QAAI;AACA,YAAM,SAAS,MAAM,UAAU,KAAK;AAAA,QAChC,UAAU;AAAA,QACV,SAAS;AAAA,QACT,UAAU;AAAA,QACV,qBAAqB;AAAA,QACrB,mBAAmB;AAAA,QACnB,yBAAyB;AAAA,QACzB,UAAU;AAAA,QACV,cAAc;AAAA,QACd,SAAS;AAAA,QACT,cAAc;AAAA,MAClB,CAAC;AACD,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,cAAQ,MAAM,8BAA8B,KAAK;AACjD,YAAM,IAAI,MAAM,mCAAmC;AAAA,IACvD;AAAA,EACJ;AAAA,EAEA,MAAc,cACV,KACA,WACA,SACe;AACf,YAAQ,IAAI,oBAAoB;AAChC,QAAI;AAEA,UAAI,UAAU,aAAa,UAAU,UAAU,IAAI;AAC/C,gBAAQ,IAAI,wBAAwB;AACpC,cAAM,aAAa,MAAM,KAAK;AAAA,UAC1B,UAAU,UAAU,GAAG,CAAC,EAAE;AAAA,QAC9B;AACA,eAAO,KAAK,SAAS,UAAU;AAAA,MACnC;AAGA,UACI,UAAU,sBACV,UAAU,mBAAmB,IAC/B;AACE,gBAAQ,IAAI,0BAA0B;AACtC,cAAM,aAAa,UAAU,mBAAmB,GAAG,CAAC,EAAE;AACtD,cAAM,iBAAiB,MAAM,KAAK,gBAAgB,UAAU;AAC5D,eAAO,KAAK,aAAa,cAAc;AAAA,MAC3C;AAGA,UACI,UAAU,cACV,UAAU,WAAW,SAAS,OAAO,GACvC;AACE,gBAAQ,IAAI,2CAA2C;AACvD,eAAO;AAAA,MACX;AAGA,cAAQ;AAAA,QACJ;AAAA,MACJ;AACA,aAAO,KAAK,gBAAgB,KAAK,OAAO;AAAA,IAC5C,SAAS,OAAO;AACZ,cAAQ,MAAM,2BAA2B,KAAK;AAC9C,YAAM;AAAA,IACV;AAAA,EACJ;AAAA,EAEA,MAAc,gBAAgB,KAA8B;AACxD,YAAQ,IAAI,6BAA6B,GAAG;AAC5C,UAAM,WAAW,MAAM,MAAM,GAAG;AAChC,QAAI,CAAC,SAAS,IAAI;AACd,YAAM,IAAI;AAAA,QACN,+BAA+B,SAAS,UAAU;AAAA,MACtD;AAAA,IACJ;AACA,WAAO,MAAM,SAAS,KAAK;AAAA,EAC/B;AAAA,EAEQ,aAAa,gBAAgC;AACjD,YAAQ,IAAI,iBAAiB;AAC7B,QAAI;AACA,YAAM,cAAc,KAAK,MAAM,cAAc;AAC7C,UAAI,YAAY,QAAQ;AACpB,eAAO,YAAY,OACd,OAAO,CAAC,UAAU,MAAM,IAAI,EAC5B,IAAI,CAAC,UAAU,MAAM,KAAK,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE,KAAK,EAAE,CAAC,EACzD,KAAK,EAAE,EACP,QAAQ,MAAM,GAAG;AAAA,MAC1B,OAAO;AACH,gBAAQ,MAAM,8BAA8B,WAAW;AACvD,eAAO;AAAA,MACX;AAAA,IACJ,SAAS,OAAO;AACZ,cAAQ,MAAM,0BAA0B,KAAK;AAC7C,aAAO;AAAA,IACX;AAAA,EACJ;AAAA,EAEQ,SAAS,YAA4B;AAEzC,WAAO,WACF,MAAM,MAAM,EACZ,IAAI,CAAC,UAAU,MAAM,MAAM,IAAI,EAAE,MAAM,CAAC,EAAE,KAAK,GAAG,CAAC,EACnD,KAAK,GAAG;AAAA,EACjB;AAAA,EAEA,MAAc,YAAY,KAA8B;AACpD,YAAQ,IAAI,aAAa;AACzB,UAAM,WAAW,MAAM,MAAM,GAAG;AAChC,WAAO,MAAM,SAAS,KAAK;AAAA,EAC/B;AAAA,EAEA,MAAM,gBACF,KACA,SACe;AACf,YAAQ,IAAI,sCAAsC;AAClD,UAAM,cAAcA,MAAK;AAAA,MACrB,KAAK;AAAA,MACL,GAAG,KAAK,WAAW,GAAG,CAAC;AAAA,IAC3B;AAEA,UAAM,cAAcA,MAAK;AAAA,MACrB,KAAK;AAAA,MACL,GAAG,KAAK,WAAW,GAAG,CAAC;AAAA,IAC3B;AAEA,QAAI,CAACD,IAAG,WAAW,WAAW,GAAG;AAC7B,UAAIA,IAAG,WAAW,WAAW,GAAG;AAC5B,gBAAQ,IAAI,sCAAsC;AAClD,cAAM,KAAK,gBAAgB,aAAa,WAAW;AAAA,MACvD,OAAO;AACH,gBAAQ,IAAI,sBAAsB;AAClC,cAAM,KAAK,cAAc,KAAK,WAAW;AAAA,MAC7C;AAAA,IACJ;AAEA,YAAQ,IAAI,qBAAqB,WAAW,EAAE;AAE9C,UAAM,cAAcA,IAAG,aAAa,WAAW;AAC/C,YAAQ,IAAI,oBAAoB,YAAY,MAAM,QAAQ;AAE1D,YAAQ,IAAI,2BAA2B;AACvC,UAAM,YAAY,KAAK,IAAI;AAC3B,UAAM,uBAAuB,QAAQ;AAAA,MACjCF,aAAY;AAAA,IAChB;AAEA,QAAI,CAAC,sBAAsB;AACvB,YAAM,IAAI,MAAM,iCAAiC;AAAA,IACrD;AAEA,UAAM,aAAa,MAAM,qBAAqB,WAAW,WAAW;AAEpE,UAAM,UAAU,KAAK,IAAI;AACzB,YAAQ;AAAA,MACJ,+BAA+B,UAAU,aAAa,GAAI;AAAA,IAC9D;AAGA,WAAO,cAAc;AAAA,EACzB;AAAA,EAEA,MAAc,gBACV,WACA,YACa;AACb,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,aAAO,SAAS,EACX,OAAO,UAAU,EACjB,QAAQ,EACR,WAAW,YAAY,EACvB,GAAG,OAAO,MAAM;AACb,gBAAQ,IAAI,4BAA4B;AACxC,gBAAQ;AAAA,MACZ,CAAC,EACA,GAAG,SAAS,CAAC,QAAQ;AAClB,gBAAQ,MAAM,4BAA4B,GAAG;AAC7C,eAAO,GAAG;AAAA,MACd,CAAC,EACA,IAAI;AAAA,IACb,CAAC;AAAA,EACL;AAAA,EAEA,MAAc,cACV,KACA,YACe;AACf,YAAQ,IAAI,mBAAmB;AAC/B,iBACI,cACAG,MAAK,KAAK,KAAK,SAAS,GAAG,KAAK,WAAW,GAAG,CAAC,MAAM;AAEzD,QAAI;AACA,UAAI,IAAI,SAAS,MAAM,KAAK,IAAI,SAAS,OAAO,GAAG;AAC/C,gBAAQ;AAAA,UACJ;AAAA,QACJ;AACA,cAAM,cAAcA,MAAK;AAAA,UACrB,OAAO;AAAA,UACP,GAAG,KAAK,WAAW,GAAG,CAAC;AAAA,QAC3B;AACA,cAAM,WAAW,MAAM,MAAM,GAAG;AAChC,cAAM,cAAc,MAAM,SAAS,YAAY;AAC/C,cAAM,SAAS,OAAO,KAAK,WAAW;AACtC,QAAAD,IAAG,cAAc,aAAa,MAAM;AAEpC,cAAM,IAAI,QAAc,CAAC,SAAS,WAAW;AACzC,iBAAO,WAAW,EACb,OAAO,UAAU,EACjB,QAAQ,EACR,WAAW,YAAY,EACvB,GAAG,OAAO,MAAM;AACb,YAAAA,IAAG,WAAW,WAAW;AACzB,oBAAQ;AAAA,UACZ,CAAC,EACA,GAAG,SAAS,CAAC,QAAQ;AAClB,mBAAO,GAAG;AAAA,UACd,CAAC,EACA,IAAI;AAAA,QACb,CAAC;AAAA,MACL,OAAO;AACH,gBAAQ;AAAA,UACJ;AAAA,QACJ;AACA,cAAM,UAAU,KAAK;AAAA,UACjB,SAAS;AAAA,UACT,cAAc;AAAA,UACd,aAAa;AAAA,UACb,QAAQ;AAAA,UACR,eAAe;AAAA,QACnB,CAAC;AAAA,MACL;AACA,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,cAAQ,MAAM,4BAA4B,KAAK;AAC/C,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC9C;AAAA,EACJ;AACJ;;;ACnbA;AAAA,EAGI,WAAAE;AAAA,EACA,eAAAC;AAAA,OACG;AACP;AAAA,EACI;AAAA,EACA;AAAA,EACA;AAAA,OACG;AACP,SAAS,oBAAoB;AAC7B,YAAYC,SAAQ;AACpB,YAAYC,WAAU;AAYf,IAAM,eAAN,cAA2BH,SAAiC;AAAA,EAC/D,OAAO,cAA2BC,aAAY;AAAA,EAEtC,WAA4B;AAAA,EAC5B,SAAiB;AAAA,EACjB,iBAAyB;AAAA,EACzB,UAAgC;AAAA,EAExC,MAAM,WAAW,SAAuC;AACpD,YAAQ,IAAI,2BAA2B;AACvC,SAAK,UAAU;AACf,SAAK,iBAAiB,QAAQ,WAAW,oBAAoB,KAAK;AAAA,EACtE;AAAA,EAEA,MAAc,qBAAuC;AACjD,QAAI,KAAK,SAAU,QAAO;AAC1B,QAAI,CAAC,KAAK,QAAS,QAAO;AAE1B,UAAM,oBAAoB,KAAK,QAAQ,WAAW,mBAAmB;AACrE,UAAM,wBAAwB,KAAK,QAAQ;AAAA,MACvC;AAAA,IACJ;AACA,UAAM,aAAa,KAAK,QAAQ,WAAW,YAAY;AACvD,UAAM,gBAAgB,KAAK,QAAQ,WAAW,eAAe;AAE7D,QACI,CAAC,qBACD,CAAC,yBACD,CAAC,cACD,CAAC,eACH;AACE,aAAO;AAAA,IACX;AAEA,SAAK,WAAW,IAAI,SAAS;AAAA,MACzB,QAAQ;AAAA,MACR,aAAa;AAAA,QACT,aAAa;AAAA,QACb,iBAAiB;AAAA,MACrB;AAAA,IACJ,CAAC;AACD,SAAK,SAAS;AACd,WAAO;AAAA,EACX;AAAA,EAEA,MAAM,WACF,UACA,eAAuB,IACvB,eAAwB,OACxB,YAAoB,KACC;AACrB,QAAI;AACA,UAAI,CAAE,MAAM,KAAK,mBAAmB,GAAI;AACpC,eAAO;AAAA,UACH,SAAS;AAAA,UACT,OAAO;AAAA,QACX;AAAA,MACJ;AAEA,UAAI,CAAI,eAAW,QAAQ,GAAG;AAC1B,eAAO;AAAA,UACH,SAAS;AAAA,UACT,OAAO;AAAA,QACX;AAAA,MACJ;AAEA,YAAM,cAAiB,iBAAa,QAAQ;AAE5C,YAAM,eAAe,GAAG,KAAK,IAAI,CAAC,IAAS,eAAS,QAAQ,CAAC;AAE7D,YAAM,WACF,GAAG,KAAK,cAAc,GAAG,YAAY,IAAI,YAAY,GAAG;AAAA,QACpD;AAAA,QACA;AAAA,MACJ;AAEJ,YAAM,eAAe;AAAA,QACjB,QAAQ,KAAK;AAAA,QACb,KAAK;AAAA,QACL,MAAM;AAAA,QACN,aAAa,KAAK,eAAe,QAAQ;AAAA,MAC7C;AAGA,YAAM,KAAK,SAAS,KAAK,IAAI,iBAAiB,YAAY,CAAC;AAG3D,YAAM,SAAuB;AAAA,QACzB,SAAS;AAAA,MACb;AAGA,UAAI,CAAC,cAAc;AACf,eAAO,MAAM,WAAW,KAAK,MAAM,OAAO,QAAQ,IAAI,UAAU,kBAAkB,QAAQ;AAAA,MAC9F,OAAO;AACH,cAAM,mBAAmB,IAAI,iBAAiB;AAAA,UAC1C,QAAQ,KAAK;AAAA,UACb,KAAK;AAAA,QACT,CAAC;AACD,eAAO,MAAM,MAAM;AAAA,UACf,KAAK;AAAA,UACL;AAAA,UACA;AAAA,YACI;AAAA;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AAEA,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,aAAO;AAAA,QACH,SAAS;AAAA,QACT,OACI,iBAAiB,QACX,MAAM,UACN;AAAA,MACd;AAAA,IACJ;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,kBACF,UACA,YAAoB,KACL;AACf,QAAI,CAAE,MAAM,KAAK,mBAAmB,GAAI;AACpC,YAAM,IAAI,MAAM,mCAAmC;AAAA,IACvD;AAEA,UAAM,UAAU,IAAI,iBAAiB;AAAA,MACjC,QAAQ,KAAK;AAAA,MACb,KAAK;AAAA,IACT,CAAC;AAED,WAAO,MAAM,aAAa,KAAK,UAAU,SAAS,EAAE,UAAU,CAAC;AAAA,EACnE;AAAA,EAEQ,eAAe,UAA0B;AAC7C,UAAM,MAAW,cAAQ,QAAQ,EAAE,YAAY;AAC/C,UAAM,eAA0C;AAAA,MAC5C,QAAQ;AAAA,MACR,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,MACR,SAAS;AAAA,IACb;AACA,WAAO,aAAa,GAAG,KAAK;AAAA,EAChC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,WACF,UACA,UACA,cACA,eAAwB,OACxB,YAAoB,KACK;AACzB,QAAI;AACA,UAAI,CAAE,MAAM,KAAK,mBAAmB,GAAI;AACpC,eAAO;AAAA,UACH,SAAS;AAAA,UACT,OAAO;AAAA,QACX;AAAA,MACJ;AAGA,UAAI,CAAC,UAAU;AACX,eAAO;AAAA,UACH,SAAS;AAAA,UACT,OAAO;AAAA,QACX;AAAA,MACJ;AAGA,YAAM,YAAY,KAAK,IAAI;AAC3B,YAAM,iBAAiB,YAAY,GAAG,SAAS;AAG/C,UAAI,WAAW,KAAK,kBAAkB;AACtC,UAAI,cAAc;AACd,mBAAW,GAAG,QAAQ,IAAI,YAAY,GAAG,QAAQ,QAAQ,GAAG;AAAA,MAChE;AACA,YAAM,MAAM,GAAG,QAAQ,IAAI,cAAc,GAAG,QAAQ,QAAQ,GAAG;AAG/D,YAAM,aAAa,KAAK,UAAU,UAAU,MAAM,CAAC;AAGnD,YAAM,eAAe;AAAA,QACjB,QAAQ,KAAK;AAAA,QACb,KAAK;AAAA,QACL,MAAM;AAAA,QACN,aAAa;AAAA,MACjB;AAGA,YAAM,KAAK,SAAS,KAAK,IAAI,iBAAiB,YAAY,CAAC;AAG3D,YAAM,SAA2B;AAAA,QAC7B,SAAS;AAAA,QACT;AAAA,MACJ;AAGA,UAAI,CAAC,cAAc;AACf,eAAO,MAAM,WAAW,KAAK,MAAM,OAAO,QAAQ,IAAI,UAAU,kBAAkB,GAAG;AAAA,MACzF,OAAO;AACH,cAAM,mBAAmB,IAAI,iBAAiB;AAAA,UAC1C,QAAQ,KAAK;AAAA,UACb,KAAK;AAAA,QACT,CAAC;AACD,eAAO,MAAM,MAAM;AAAA,UACf,KAAK;AAAA,UACL;AAAA,UACA,EAAE,UAAU;AAAA,QAChB;AAAA,MACJ;AAEA,aAAO;AAAA,IACX,SAAS,OAAO;AACZ,aAAO;AAAA,QACH,SAAS;AAAA,QACT,OACI,iBAAiB,QACX,MAAM,UACN;AAAA,MACd;AAAA,IACJ;AAAA,EACJ;AACJ;;;ACxQA;AAAA,EAMI;AAAA,EACA;AAAA,EAEA,cAAAG;AAAA,EACA,eAAAC;AAAA,EACA,eAAAC;AAAA,OAEG;;;ACbA,IAAM,0BAA0B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAvC,SAAS,KAAAC,UAAS;AAEX,IAAM,2BAA2BA,GAAE,OAAO;AAAA,EAC7C,cAAcA,GAAE,OAAO,EAAE,IAAI,CAAC;AAClC,CAAC;AAIM,SAAS,qBAAqB,KAAyC;AAC1E,SAAO,yBAAyB,UAAU,GAAG,EAAE;AACnD;;;AFOO,IAAM,gBAAwB;AAAA,EACjC,MAAM;AAAA,EACN,SAAS,CAAC,oBAAoB,mBAAmB,eAAe;AAAA,EAChE,UAAU,OAAO,UAAyB,aAAqB;AAC3D,WAAO;AAAA,EACX;AAAA,EACA,aAAa;AAAA,EACb,SAAS,OACL,SACA,SACA,OACA,UACA,aACmB;AAEnB,UAAM,yBAAyB,eAAe;AAAA,MAC1C;AAAA,MACA,UAAU;AAAA,IACd,CAAC;AAED,UAAM,2BAA2B,MAAM,eAAe;AAAA,MAClD;AAAA,MACA,SAAS;AAAA,MACT,YAAYC,YAAW;AAAA,MACvB,QAAQ;AAAA,MACR,MAAM,CAAC,IAAI;AAAA,IACf,CAAC;AAED,QAAI,CAAC,qBAAqB,0BAA0B,MAAM,GAAG;AACzD,MAAAC,aAAY,MAAM,kCAAkC;AACpD,aAAO;AAAA,IACX;AAEA,UAAM,EAAE,aAAa,IAAI,yBAAyB;AAElD,UAAM,EAAE,YAAY,IAAI,MAAM,QACzB,WAAqCC,aAAY,iBAAiB,EAClE,cAAc,YAAY;AAE/B,YAAQ,eAAe,aAAa;AAAA,MAChC,QAAQ,QAAQ;AAAA,MAChB,SAAS,QAAQ;AAAA,MACjB,QAAQ,QAAQ;AAAA,MAChB,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ,CAAC;AAED,aAAS;AAAA,MACL,MAAM;AAAA,IACV,CAAC;AAED,WAAO;AAAA,EACX;AAAA,EACA,UAAU;AAAA,IACN;AAAA,MACI;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,QACV;AAAA,MACJ;AAAA,MACA;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,UACN,QAAQ;AAAA,QACZ;AAAA,MACJ;AAAA,MACA;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,QACV;AAAA,MACJ;AAAA,IACJ;AAAA,IACA;AAAA,MACI;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,QACV;AAAA,MACJ;AAAA,MACA;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,UACN,QAAQ;AAAA,QACZ;AAAA,MACJ;AAAA,MACA;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,QACV;AAAA,MACJ;AAAA,IACJ;AAAA,IACA;AAAA,MACI;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,QACV;AAAA,MACJ;AAAA,MACA;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,UACN,QAAQ;AAAA,QACZ;AAAA,MACJ;AAAA,MACA;AAAA,QACI,MAAM;AAAA,QACN,SAAS;AAAA,UACL,MAAM;AAAA,QACV;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AACJ;;;AGtHO,SAAS,mBAAmB;AAC/B,SAAO;AAAA,IACH,MAAM;AAAA,IACN,aAAa;AAAA,IACb,UAAU;AAAA,MACN,IAAI,eAAe;AAAA,MACnB,IAAI,wBAAwB;AAAA,MAC5B,IAAI,aAAa;AAAA,MACjB,IAAI,WAAW;AAAA,MACf,IAAI,cAAc;AAAA,MAClB,IAAI,qBAAqB;AAAA,MACzB,IAAI,aAAa;AAAA,MACjB,IAAI,aAAa;AAAA,IACrB;AAAA,IACA,SAAS,CAAC,aAAa;AAAA,EAC3B;AACJ;","names":["EventTarget","defineEventAttribute","AbortController","isMergeableObject","Service","ServiceType","elizaLogger","ServiceType","ModelProviderName","Service","fs","path","response","ollamaUrl","embeddingModel","Service","ServiceType","ServiceType","Service","elizaLogger","Service","ServiceType","elizaLogger","settings","Service","ServiceType","File","fs","str","is_array","fetch","Request","Response","Headers","Blob","ReadableStream","str","kind","_FormDataEncoder_getFieldHeader","Readable","ReadableStream","fileFromPath","path","getMultipartRequestOptions","Readable","AbortControllerPolyfill","Response","Headers","ReadableStream","str","isFileLike","fetch","path","opts","Page","retryMessage","__classPrivateFieldSet","__classPrivateFieldGet","env","Page","__classPrivateFieldSet","__classPrivateFieldGet","inputTool","__classPrivateFieldGet","content","name","_AbstractChatCompletionRunner_getFinalMessage","_AbstractChatCompletionRunner_getFinalFunctionCall","_AbstractChatCompletionRunner_getFinalFunctionCallResult","_AbstractChatCompletionRunner_calculateTotalUsage","_AbstractChatCompletionRunner_validateParams","_AbstractChatCompletionRunner_stringifyFunctionCallResult","escape","e","__classPrivateFieldSet","__classPrivateFieldGet","_ChatCompletionStream_beginRequest","_ChatCompletionStream_getChoiceEventState","_ChatCompletionStream_addChunk","_ChatCompletionStream_emitToolCallDoneEvent","_ChatCompletionStream_emitContentDoneEvents","_ChatCompletionStream_endRequest","_ChatCompletionStream_getAutoParseableResponseFormat","_ChatCompletionStream_accumulateChatCompletion","content","refusal","rest","_a","index","chunk","id","Completions","Chat","Completions","chunk","__classPrivateFieldGet","__classPrivateFieldSet","_AssistantStream_endRequest","_AssistantStream_handleMessage","_AssistantStream_handleRunStep","_AssistantStream_handleEvent","_AssistantStream_accumulateRunStep","_AssistantStream_accumulateMessage","_AssistantStream_accumulateContent","_AssistantStream_handleRun","Chat","Completions","Files","Page","Completions","Files","os","path","fileURLToPath","merge","CrossFetchHeaders","merge","_a","SOCKET_STATES","CONNECTION_STATE","version","defaults","kind","_a","import_cross_fetch","crossFetch","fetch","__awaiter","import_deepmerge","merge","_a","LiveTranscriptionEvents","LiveTTSEvents","result","result","result","result","result","fileURLToPath","__dirname","path","Service","ServiceType","fs","os","settings","elizaLogger","File","Service","ServiceType","stringToUuid","fs","path","Service","ServiceType","fs","path","ModelClass","elizaLogger","ServiceType","z","ModelClass","elizaLogger","ServiceType"]}